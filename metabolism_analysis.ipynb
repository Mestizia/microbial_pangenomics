{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "from random import sample\n",
    "from collections import Counter, defaultdict\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from bioinfokit import analys, visuz\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import maxRstat\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/DATA_RAID2/vtracann/shared/db/isolates/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          M00001  M00002  M00003  M00004  M00005  M00006  M00007  M00008   \n",
      "0                                                                          \n",
      "CALOFZ02       0       0       0       0       0       0       0       0  \\\n",
      "CALOGA02       0       0       0       0       0       0       0       0   \n",
      "CALOGB02       0       0       0       0       0       0       0       0   \n",
      "CALOGC02       0       0       0       0       0       0       0       0   \n",
      "CALOGD02       0       0       0       0       0       0       0       0   \n",
      "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "S65            0       0       0       0       0       0       0       0   \n",
      "S7             0       0       0       0       0       0       0       0   \n",
      "S71            0       0       0       0       0       0       0       0   \n",
      "S72            0       0       0       0       0       0       0       0   \n",
      "Si1            0       0       0       0       0       0       0       0   \n",
      "\n",
      "          M00009  M00010  ...  M00923  M00924  M00925  M00926  M00930  M00931   \n",
      "0                         ...                                                   \n",
      "CALOFZ02       0       0  ...       0       0       0       0       0       0  \\\n",
      "CALOGA02       0       0  ...       0       0       0       0       0       0   \n",
      "CALOGB02       0       0  ...       0       0       0       0       0       0   \n",
      "CALOGC02       0       0  ...       0       0       0       0       0       0   \n",
      "CALOGD02       0       0  ...       0       0       0       0       0       0   \n",
      "...          ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
      "S65            0       0  ...       0       0       0       0       0       0   \n",
      "S7             0       0  ...       0       0       0       0       0       0   \n",
      "S71            0       0  ...       0       0       0       0       0       0   \n",
      "S72            0       0  ...       0       0       0       0       0       0   \n",
      "Si1            0       0  ...       0       0       0       0       0       0   \n",
      "\n",
      "          M00932  M00935  M00936  taxa  \n",
      "0                                       \n",
      "CALOFZ02       0       0       0     0  \n",
      "CALOGA02       0       0       0     0  \n",
      "CALOGB02       0       0       0     0  \n",
      "CALOGC02       0       0       0     0  \n",
      "CALOGD02       0       0       0     0  \n",
      "...          ...     ...     ...   ...  \n",
      "S65            0       0       0     0  \n",
      "S7             0       0       0     0  \n",
      "S71            0       0       0     0  \n",
      "S72            0       0       0     0  \n",
      "Si1            0       0       0     0  \n",
      "\n",
      "[1602 rows x 371 columns]\n",
      "          M00001  M00002  M00003  M00004  M00005  M00006  M00007  M00008   \n",
      "0                                                                          \n",
      "CALOFZ02     0.9     1.0   1.000   1.000       1     1.0    1.00    1.00  \\\n",
      "CALOGA02     0.9     1.0   1.000   1.000       1     1.0    1.00    1.00   \n",
      "CALOGB02     0.8     1.0   1.000   1.000       1     1.0    1.00    1.00   \n",
      "CALOGC02     0.9     1.0   1.000   1.000       1     1.0    1.00    1.00   \n",
      "CALOGD02     0.9     1.0   1.000   1.000       1     1.0    1.00    1.00   \n",
      "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "S65          1.0     1.0   0.875   1.000       1     1.0    1.00    0.75   \n",
      "S7           0.9     1.0   1.000   0.875       1     1.0    0.75    0.50   \n",
      "S71          0.9     1.0   1.000   0.875       1     1.0    0.75    0.50   \n",
      "S72          0.9     1.0   1.000   1.000       1     1.0    1.00    1.00   \n",
      "Si1          1.0     1.0   1.000   1.000       1     1.0    1.00    0.75   \n",
      "\n",
      "            M00009    M00010  ...  M00923    M00924    M00925    M00926   \n",
      "0                             ...                                         \n",
      "CALOFZ02  1.000000  1.000000  ...    0.50  0.916667  0.939394  0.777778  \\\n",
      "CALOGA02  1.000000  1.000000  ...    0.00  0.083333  0.151515  0.555556   \n",
      "CALOGB02  1.000000  1.000000  ...    0.00  0.750000  1.000000  0.555556   \n",
      "CALOGC02  1.000000  1.000000  ...    0.00  0.916667  0.939394  0.777778   \n",
      "CALOGD02  1.000000  1.000000  ...    0.00  0.916667  0.939394  0.777778   \n",
      "...            ...       ...  ...     ...       ...       ...       ...   \n",
      "S65       0.833333  1.000000  ...    0.00  0.181818  0.090909  1.000000   \n",
      "S7        0.833333  0.666667  ...    0.00  0.636364  0.848485  1.000000   \n",
      "S71       0.833333  0.666667  ...    0.00  0.636364  0.848485  1.000000   \n",
      "S72       1.000000  1.000000  ...    0.00  0.166667  0.121212  0.777778   \n",
      "Si1       0.875000  0.666667  ...    0.75  0.166667  0.090909  0.777778   \n",
      "\n",
      "            M00930  M00931    M00932    M00935  M00936                 taxa  \n",
      "0                                                                            \n",
      "CALOFZ02  0.000000     0.0  0.142857  0.166667     0.0     Pseudomonadaceae  \n",
      "CALOGA02  0.000000     0.0  0.000000  0.000000     0.0    Sphingomonadaceae  \n",
      "CALOGB02  0.000000     0.0  0.000000  0.000000     0.0    Sphingomonadaceae  \n",
      "CALOGC02  0.000000     0.0  0.142857  0.166667     0.0     Pseudomonadaceae  \n",
      "CALOGD02  0.000000     0.0  0.142857  0.166667     0.0     Pseudomonadaceae  \n",
      "...            ...     ...       ...       ...     ...                  ...  \n",
      "S65       0.000000     0.0  0.600000  0.000000     0.0    Cellulomonadaceae  \n",
      "S7        0.166667     0.0  0.500000  0.000000     0.0   Enterobacteriaceae  \n",
      "S71       0.166667     0.0  0.500000  0.000000     0.0      Nocardioidaceae  \n",
      "S72       0.000000     0.0  0.000000  0.000000     0.0     Burkholderiaceae  \n",
      "Si1       1.000000     0.8  0.142857  0.000000     0.0  Sphingobacteriaceae  \n",
      "\n",
      "[1602 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "# iterate over the taxa\n",
    "# get all the modules in their metabolism\n",
    "\n",
    "taxa_df = pd.read_csv('/DATA_RAID2/vtracann/shared/db/isolates/family_gtdbtk_annot.tsv', sep='\\t', index_col=0, header=None)\n",
    "anvioBasedb = '/DATA_RAID2/vtracann/shared/db/isolates/anvio/'\n",
    "modules = set()\n",
    "for taxa in set(taxa_df.loc[:, 1].values):\n",
    "    if taxa != 'unclassified':\n",
    "        genomes = taxa_df[taxa_df.loc[:, 1] == taxa]\n",
    "        if len(genomes) > 10:\n",
    "            for genome in genomes.index:\n",
    "                metabolism = pd.read_csv('{}{}/metabolism/{}_metabolism_modules.txt'.format(anvioBasedb, taxa, genome), sep='\\t', index_col=0)\n",
    "                modules = set(metabolism.loc[:, 'kegg_module'].values).union(modules)\n",
    "\n",
    "# make a df with all the modules as columns and the taxa as rows\n",
    "# for each genome, fill in the dataframe with the metabolite pathways\n",
    "\n",
    "modules = sorted(modules)\n",
    "modules.append('taxa')\n",
    "\n",
    "metabolism_df = pd.DataFrame(0, index=taxa_df.index, columns=modules)\n",
    "print (metabolism_df)\n",
    "\n",
    "for genome in taxa_df.index:\n",
    "    taxa = taxa_df.loc[genome, 1]\n",
    "    if taxa != 'unclassified':\n",
    "        if len(taxa_df[taxa_df.loc[:, 1] == taxa]) > 10:\n",
    "            metabolism = pd.read_csv('{}{}/metabolism/{}_metabolism_modules.txt'.format(anvioBasedb, taxa, genome), sep='\\t', index_col=0)\n",
    "            for _mod in metabolism.index:\n",
    "                module = metabolism.loc[_mod, 'kegg_module']\n",
    "                metabolism_df.loc[genome, module] += metabolism.loc[_mod, 'module_completeness']\n",
    "            metabolism_df.loc[genome, 'taxa'] = taxa\n",
    "\n",
    "print (metabolism_df)\n",
    "\n",
    "complete_metabolism_df = pd.DataFrame(0, index=taxa_df.index, columns=modules)\n",
    "\n",
    "for genome in taxa_df.index:\n",
    "    taxa = taxa_df.loc[genome, 1]\n",
    "    if taxa != 'unclassified':\n",
    "        if len(taxa_df[taxa_df.loc[:, 1] == taxa]) > 10:\n",
    "            metabolism = pd.read_csv('{}{}/metabolism/{}_metabolism_modules.txt'.format(anvioBasedb, taxa, genome), sep='\\t', index_col=0)\n",
    "            for _mod in metabolism.index:\n",
    "                if metabolism.loc[_mod, 'module_completeness'] == 1:\n",
    "                    module = metabolism.loc[_mod, 'kegg_module']\n",
    "                    complete_metabolism_df.loc[genome, module] += metabolism.loc[_mod, 'module_completeness']\n",
    "            complete_metabolism_df.loc[genome, 'taxa'] = taxa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si1\n",
      "143.65287420912415\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "118.47343975468979\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "145.38342837717838\n",
      "Si1\n",
      "145.90047521922517\n",
      "Si1\n",
      "143.65287420912415\n",
      "Si1\n",
      "146.4326347263847\n",
      "Si1\n",
      "144.17285839160834\n",
      "Si1\n",
      "148.15952727827718\n",
      "Si1\n",
      "122.86510642135646\n",
      "Si1\n",
      "149.27033313908314\n",
      "Si1\n",
      "120.05630640494773\n",
      "Si1\n",
      "123.09886710511717\n",
      "Si1\n",
      "143.65287420912415\n",
      "Si1\n",
      "120.34727980352986\n",
      "Si1\n",
      "117.34298687423691\n",
      "Si1\n",
      "123.32592338217344\n",
      "Si1\n",
      "122.86510642135646\n",
      "Si1\n",
      "142.78396950271946\n",
      "Si1\n",
      "145.35168234543232\n",
      "Si1\n",
      "116.53484730848866\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "145.05009504384506\n",
      "Si1\n",
      "115.65965354090358\n",
      "Si1\n",
      "145.1731109168609\n",
      "Si1\n",
      "142.51954087579082\n",
      "Si1\n",
      "143.65287420912415\n",
      "Si1\n",
      "120.7732977469391\n",
      "Si1\n",
      "145.468349012099\n",
      "Si1\n",
      "125.95204170829176\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "116.637003968254\n",
      "Si1\n",
      "118.90593781218787\n",
      "Si1\n",
      "144.0695408757908\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "124.2673453659867\n",
      "Si1\n",
      "143.41914266289263\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "145.8016823454323\n",
      "Si1\n",
      "144.49057123432124\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "118.57535402399537\n",
      "Si1\n",
      "123.09886710511717\n",
      "Si1\n",
      "143.15287420912415\n",
      "Si1\n",
      "113.31401862026866\n",
      "Si1\n",
      "116.69216499080632\n",
      "Si1\n",
      "143.58238220113216\n",
      "Si1\n",
      "136.32460803085797\n",
      "Si1\n",
      "144.1731109168609\n",
      "Si1\n",
      "120.09641400266406\n",
      "Si1\n",
      "120.09641400266406\n",
      "Si1\n",
      "145.35168234543232\n",
      "Si1\n",
      "146.4326347263847\n",
      "Si1\n",
      "145.10168234543232\n",
      "Si1\n",
      "144.80009504384503\n",
      "Si1\n",
      "146.13342837717838\n",
      "Si1\n",
      "146.00644425019422\n",
      "Si1\n",
      "119.54122703986836\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "144.4231109168609\n",
      "Si1\n",
      "138.99080710955707\n",
      "Si1\n",
      "143.5695408757908\n",
      "Si1\n",
      "145.05009504384506\n",
      "Si1\n",
      "123.93339091464095\n",
      "Si1\n",
      "143.15287420912415\n",
      "Si1\n",
      "147.39706474081467\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "121.96023074148079\n",
      "Si1\n",
      "145.05009504384506\n",
      "Si1\n",
      "120.6841845654346\n",
      "Si1\n",
      "145.38342837717838\n",
      "Si1\n",
      "142.42285839160834\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "145.05009504384506\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "144.80009504384503\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "123.95752511377516\n",
      "Si1\n",
      "116.85727258852263\n",
      "Si1\n",
      "144.4306519869019\n",
      "Si1\n",
      "143.5695408757908\n",
      "Si1\n",
      "118.01441544566549\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "122.70189740814746\n",
      "Si1\n",
      "143.48382659007652\n",
      "Si1\n",
      "146.08501567876564\n",
      "Si1\n",
      "145.38342837717838\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "117.34298687423691\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "143.48382659007652\n",
      "Si1\n",
      "145.90047521922517\n",
      "Si1\n",
      "123.4778353590854\n",
      "Si1\n",
      "148.15952727827718\n",
      "Si1\n",
      "145.38342837717838\n",
      "Si1\n",
      "121.19760447885453\n",
      "Si1\n",
      "146.4326347263847\n",
      "Si1\n",
      "146.34930139305135\n",
      "Si1\n",
      "143.15287420912415\n",
      "Si1\n",
      "143.15287420912415\n",
      "Si1\n",
      "145.38342837717838\n",
      "Si1\n",
      "146.4326347263847\n",
      "Si1\n",
      "143.9306519869019\n",
      "Si1\n",
      "144.4231109168609\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "149.1983093295593\n",
      "Si1\n",
      "143.15287420912415\n",
      "Si1\n",
      "145.1731109168609\n",
      "Si1\n",
      "122.81205808080813\n",
      "Si1\n",
      "143.47404886779879\n",
      "Si1\n",
      "118.53045447909582\n",
      "Si1\n",
      "146.03272630147626\n",
      "Si1\n",
      "149.31199980574976\n",
      "Si1\n",
      "143.15287420912415\n",
      "Si1\n",
      "145.77439296814293\n",
      "Si1\n",
      "122.3637739374153\n",
      "Si1\n",
      "144.17285839160834\n",
      "Si1\n",
      "120.59727980352986\n",
      "Si1\n",
      "144.97911879786875\n",
      "Si1\n",
      "141.4561917249417\n",
      "Si1\n",
      "145.718349012099\n",
      "Si1\n",
      "145.10168234543232\n",
      "Si1\n",
      "139.3093136030636\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "144.61398393273393\n",
      "Si1\n",
      "143.239525058275\n",
      "Si1\n",
      "117.19486277611283\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "119.66870837495843\n",
      "Si1\n",
      "149.27033313908314\n",
      "Si1\n",
      "122.7589320401821\n",
      "Si1\n",
      "144.17285839160834\n",
      "Si1\n",
      "144.17285839160834\n",
      "Si1\n",
      "120.25338432702566\n",
      "Si1\n",
      "123.4778353590854\n",
      "Si1\n",
      "121.8176700413114\n",
      "Si1\n",
      "118.03093781218786\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "117.6086873573287\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "118.19926393051396\n",
      "Si1\n",
      "143.39096944721936\n",
      "Si1\n",
      "145.03604520479516\n",
      "Si1\n",
      "142.51954087579082\n",
      "Si1\n",
      "142.70619172494168\n",
      "Si1\n",
      "142.67285839160834\n",
      "Si1\n",
      "144.6572379009879\n",
      "Si1\n",
      "145.1731109168609\n",
      "Si1\n",
      "123.93339091464095\n",
      "Si1\n",
      "123.63523074148078\n",
      "Si1\n",
      "125.30186917551049\n",
      "Si1\n",
      "117.18365683229817\n",
      "Si1\n",
      "145.31959498834493\n",
      "Si1\n",
      "124.31178981043112\n",
      "Si1\n",
      "120.65680361305367\n",
      "Si1\n",
      "118.95789370653503\n",
      "Si1\n",
      "116.45965354090359\n",
      "Si1\n",
      "120.72805965170099\n",
      "Si1\n",
      "120.09641400266406\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "117.76607767232771\n",
      "Si1\n",
      "123.12996101121105\n",
      "Si1\n",
      "121.1686079922493\n",
      "Si1\n",
      "120.01282814407817\n",
      "Si1\n",
      "126.09353584217716\n",
      "Si1\n",
      "122.86510642135646\n",
      "Si1\n",
      "122.95911241536245\n",
      "Si1\n",
      "123.93530289155292\n",
      "Si1\n",
      "123.66553377178381\n",
      "Si1\n",
      "120.6464861527362\n",
      "Si1\n",
      "123.383584682226\n",
      "Si1\n",
      "123.06856407481413\n",
      "Si1\n",
      "119.54370837495843\n",
      "Si1\n",
      "121.4742278554779\n",
      "Si1\n",
      "118.49869457233589\n",
      "Si1\n",
      "120.99093059718065\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "130.0747934734347\n",
      "Si1\n",
      "120.28284978909983\n",
      "Si1\n",
      "118.03232670107676\n",
      "Si1\n",
      "118.27740800865804\n",
      "Si1\n",
      "122.8655337717838\n",
      "Si1\n",
      "119.70157273282278\n",
      "Si1\n",
      "121.63934329559333\n",
      "Si1\n",
      "145.468349012099\n",
      "Si1\n",
      "144.93501567876567\n",
      "Si1\n",
      "141.3647789710289\n",
      "Si1\n",
      "122.12899531024533\n",
      "Si1\n",
      "123.0778353590854\n",
      "Si1\n",
      "125.97845647709781\n",
      "Si1\n",
      "123.02012314376448\n",
      "Si1\n",
      "121.92974733599739\n",
      "Si1\n",
      "121.30345647709781\n",
      "Si1\n",
      "124.29244574869578\n",
      "Si1\n",
      "122.55345647709782\n",
      "Si1\n",
      "121.16982670107674\n",
      "Si1\n",
      "120.40316003441006\n",
      "Si1\n",
      "121.6984702797203\n",
      "Si1\n",
      "123.00911241536245\n",
      "Si1\n",
      "123.62419178044182\n",
      "Si1\n",
      "117.20813145188148\n",
      "Si1\n",
      "127.04135330249466\n",
      "Si1\n",
      "122.42974733599739\n",
      "Si1\n",
      "123.05911241536246\n",
      "Si1\n",
      "116.71942987567991\n",
      "Si1\n",
      "114.89241751605888\n",
      "Si1\n",
      "125.02795142659278\n",
      "Si1\n",
      "122.91820332445336\n",
      "Si1\n",
      "119.0025800588301\n",
      "Si1\n",
      "119.0025800588301\n",
      "Si1\n",
      "121.96275599400605\n",
      "Si1\n",
      "119.19926393051396\n",
      "Si1\n",
      "124.02419178044183\n",
      "Si1\n",
      "121.0696102508603\n",
      "Si1\n",
      "121.94085844710852\n",
      "Si1\n",
      "123.90200563325568\n",
      "Si1\n",
      "123.00911241536245\n",
      "Si1\n",
      "117.74958860583864\n",
      "Si1\n",
      "122.17022352647355\n",
      "Si1\n",
      "121.46762612387616\n",
      "Si1\n",
      "122.91820332445336\n",
      "Si1\n",
      "122.6183115495616\n",
      "Si1\n",
      "126.56575806439938\n",
      "Si1\n",
      "121.65752511377518\n",
      "Si1\n",
      "118.67816003441007\n",
      "Si1\n",
      "122.6183115495616\n",
      "Si1\n",
      "124.02419178044183\n",
      "Si1\n",
      "124.02419178044183\n",
      "Si1\n",
      "124.29244574869578\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "122.96841977466983\n",
      "Si1\n",
      "119.91870837495843\n",
      "Si1\n",
      "117.86636904761912\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "118.81972631836767\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "120.57054820179823\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "124.20002934867067\n",
      "Si1\n",
      "123.61308066933069\n",
      "Si1\n",
      "123.433584682226\n",
      "Si1\n",
      "120.2574247310661\n",
      "Si1\n",
      "118.37528187392323\n",
      "Si1\n",
      "125.27468663582798\n",
      "Si1\n",
      "129.02195512820518\n",
      "Si1\n",
      "120.44482670107674\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "119.56139298503435\n",
      "Si1\n",
      "121.19760447885453\n",
      "Si1\n",
      "122.5424457486958\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "123.9075251137752\n",
      "Si1\n",
      "121.30240800865803\n",
      "Si1\n",
      "125.42577908202912\n",
      "Si1\n",
      "126.56575806439938\n",
      "Si1\n",
      "122.62806845931846\n",
      "Si1\n",
      "114.08878968253973\n",
      "Si1\n",
      "122.65164488289491\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "122.55345647709782\n",
      "Si1\n",
      "120.05593781218785\n",
      "Si1\n",
      "118.51308066933072\n",
      "Si1\n",
      "120.47101717726719\n",
      "Si1\n",
      "127.07857025221156\n",
      "Si1\n",
      "123.8207003443417\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "120.8642711455212\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "120.39886710511715\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "127.04135330249466\n",
      "Si1\n",
      "119.8002818739232\n",
      "Si1\n",
      "121.6575251137752\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "118.27740800865804\n",
      "Si1\n",
      "121.6575251137752\n",
      "Si1\n",
      "117.33259726384729\n",
      "Si1\n",
      "123.17481289845423\n",
      "Si1\n",
      "118.69919962284096\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "124.40911241536246\n",
      "Si1\n",
      "124.20259067623202\n",
      "Si1\n",
      "118.93652944277949\n",
      "Si1\n",
      "119.14363622488628\n",
      "Si1\n",
      "121.9787968975469\n",
      "Si1\n",
      "123.30752511377516\n",
      "Si1\n",
      "123.77974733599737\n",
      "Si1\n",
      "125.01467581331713\n",
      "Si1\n",
      "120.86694854058989\n",
      "Si1\n",
      "120.27419178044185\n",
      "Si1\n",
      "120.54277042402046\n",
      "Si1\n",
      "127.56881660006665\n",
      "Si1\n",
      "120.39212107337109\n",
      "Si1\n",
      "120.03497821622824\n",
      "Si1\n",
      "124.93242473106605\n",
      "Si1\n",
      "122.91116869241871\n",
      "Si1\n",
      "122.03671766035899\n",
      "Si1\n",
      "122.47931443556449\n",
      "Si1\n",
      "121.14919178044184\n",
      "Si1\n",
      "122.36691801555935\n",
      "Si1\n",
      "116.99926393051396\n",
      "Si1\n",
      "122.30752511377518\n",
      "Si1\n",
      "122.53497821622824\n",
      "Si1\n",
      "122.20901203265336\n",
      "Si1\n",
      "117.74255952380959\n",
      "Si1\n",
      "121.97931443556449\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "113.98901862026865\n",
      "Si1\n",
      "120.11149336774339\n",
      "Si1\n",
      "120.11149336774339\n",
      "Si1\n",
      "123.64447379311514\n",
      "Si1\n",
      "123.5516448828949\n",
      "Si1\n",
      "119.91870837495843\n",
      "Si1\n",
      "120.8642711455212\n",
      "Si1\n",
      "122.37419178044186\n",
      "Si1\n",
      "120.65196955821962\n",
      "Si1\n",
      "123.22921960286091\n",
      "Si1\n",
      "124.77845647709779\n",
      "Si1\n",
      "121.47998737373742\n",
      "Si1\n",
      "120.86694854058989\n",
      "Si1\n",
      "117.20568528693535\n",
      "Si1\n",
      "125.42577908202912\n",
      "Si1\n",
      "125.06549769674768\n",
      "Si1\n",
      "121.69569250194252\n",
      "Si1\n",
      "123.58123425487561\n",
      "Si1\n",
      "122.36831154956158\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "124.23689019314024\n",
      "Si1\n",
      "117.33259726384729\n",
      "Si1\n",
      "124.57227980352985\n",
      "Si1\n",
      "118.63339091464097\n",
      "Si1\n",
      "119.14237359862364\n",
      "Si1\n",
      "120.11149336774339\n",
      "Si1\n",
      "120.61149336774339\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "120.8642711455212\n",
      "Si1\n",
      "120.86694854058989\n",
      "Si1\n",
      "120.11149336774339\n",
      "Si1\n",
      "121.11694854058989\n",
      "Si1\n",
      "122.03513035877168\n",
      "Si1\n",
      "122.01615488979623\n",
      "Si1\n",
      "123.22921960286091\n",
      "Si1\n",
      "120.14006479631482\n",
      "Si1\n",
      "120.8642711455212\n",
      "Si1\n",
      "127.04135330249466\n",
      "Si1\n",
      "120.86149336774339\n",
      "Si1\n",
      "122.12988005352133\n",
      "Si1\n",
      "124.33497821622824\n",
      "Si1\n",
      "124.84237359862367\n",
      "Si1\n",
      "122.34963252327387\n",
      "Si1\n",
      "120.65196955821962\n",
      "Si1\n",
      "123.55752511377516\n",
      "Si1\n",
      "121.19760447885453\n",
      "Si1\n",
      "122.70164488289494\n",
      "Si1\n",
      "122.16030289155292\n",
      "Si1\n",
      "123.00911241536245\n",
      "Si1\n",
      "118.51308066933072\n",
      "Si1\n",
      "122.5908584471085\n",
      "Si1\n",
      "122.86510642135646\n",
      "Si1\n",
      "121.43169538794544\n",
      "Si1\n",
      "124.12243194607329\n",
      "Si1\n",
      "123.80175310800315\n",
      "Si1\n",
      "122.46030289155294\n",
      "Si1\n",
      "118.6067314629815\n",
      "Si1\n",
      "122.01520909645913\n",
      "Si1\n",
      "119.46149336774342\n",
      "Si1\n",
      "121.11694854058989\n",
      "Si1\n",
      "122.84341977466983\n",
      "Si1\n",
      "120.72101717726721\n",
      "Si1\n",
      "121.03649336774343\n",
      "Si1\n",
      "125.96748737373738\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "121.31315281940286\n",
      "Si1\n",
      "125.3769695582196\n",
      "Si1\n",
      "128.51193181818184\n",
      "Si1\n",
      "125.05511454125586\n",
      "Si1\n",
      "123.02758005883008\n",
      "Si1\n",
      "123.60474733599739\n",
      "Si1\n",
      "122.31528908893046\n",
      "Si1\n",
      "121.19760447885453\n",
      "Si1\n",
      "120.26381001245132\n",
      "Si1\n",
      "122.89843975468979\n",
      "Si1\n",
      "123.18061313686317\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "122.40752511377516\n",
      "Si1\n",
      "122.21924672549675\n",
      "Si1\n",
      "118.73768384393387\n",
      "Si1\n",
      "118.11268384393388\n",
      "Si1\n",
      "123.07227980352984\n",
      "Si1\n",
      "121.0696102508603\n",
      "Si1\n",
      "123.10911241536247\n",
      "Si1\n",
      "122.53497821622824\n",
      "Si1\n",
      "125.23592400956538\n",
      "Si1\n",
      "123.74665404040405\n",
      "Si1\n",
      "122.58689019314025\n",
      "Si1\n",
      "118.64486277611282\n",
      "Si1\n",
      "120.98433670797807\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "122.86593059718062\n",
      "Si1\n",
      "125.32956696081695\n",
      "Si1\n",
      "122.62419178044183\n",
      "Si1\n",
      "118.1300437786851\n",
      "Si1\n",
      "123.693022949273\n",
      "Si1\n",
      "119.51308066933072\n",
      "Si1\n",
      "119.02647235011365\n",
      "Si1\n",
      "121.85319610944616\n",
      "Si1\n",
      "118.02647235011365\n",
      "Si1\n",
      "119.46149336774342\n",
      "Si1\n",
      "125.40153665778669\n",
      "Si1\n",
      "119.34919178044181\n",
      "Si1\n",
      "120.56713911088914\n",
      "Si1\n",
      "120.52974733599741\n",
      "Si1\n",
      "120.81218663582798\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "123.18061313686317\n",
      "Si1\n",
      "118.24926393051395\n",
      "Si1\n",
      "124.5692573428987\n",
      "Si1\n",
      "123.56189019314026\n",
      "Si1\n",
      "121.93209728073862\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "121.98220043845048\n",
      "Si1\n",
      "124.07022352647357\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "129.01232864357863\n",
      "Si1\n",
      "122.77816003441009\n",
      "Si1\n",
      "122.3408584471085\n",
      "Si1\n",
      "118.71052718416855\n",
      "Si1\n",
      "123.60164488289489\n",
      "Si1\n",
      "117.19151564015696\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "121.45028187392323\n",
      "Si1\n",
      "123.61308066933069\n",
      "Si1\n",
      "123.34244574869578\n",
      "Si1\n",
      "124.47759067623201\n",
      "Si1\n",
      "124.47759067623201\n",
      "Si1\n",
      "124.35077908202913\n",
      "Si1\n",
      "120.65804820179824\n",
      "Si1\n",
      "127.93427197802197\n",
      "Si1\n",
      "117.33259726384729\n",
      "Si1\n",
      "125.67409139773272\n",
      "Si1\n",
      "126.67686917551049\n",
      "Si1\n",
      "122.51615488979623\n",
      "Si1\n",
      "118.66593059718063\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "122.91820332445336\n",
      "Si1\n",
      "127.04135330249466\n",
      "Si1\n",
      "123.34244574869578\n",
      "Si1\n",
      "120.78296356421357\n",
      "Si1\n",
      "120.8642711455212\n",
      "Si1\n",
      "122.21939380064384\n",
      "Si1\n",
      "122.35997821622824\n",
      "Si1\n",
      "120.10752511377518\n",
      "Si1\n",
      "120.68996441360576\n",
      "Si1\n",
      "120.8642711455212\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "122.3683115495616\n",
      "Si1\n",
      "116.44323939948944\n",
      "Si1\n",
      "117.04323939948942\n",
      "Si1\n",
      "121.11694854058989\n",
      "Si1\n",
      "120.40219385083518\n",
      "Si1\n",
      "120.91149336774338\n",
      "Si1\n",
      "127.04135330249466\n",
      "Si1\n",
      "120.99129689754692\n",
      "Si1\n",
      "126.56575806439938\n",
      "Si1\n",
      "120.25575743700746\n",
      "Si1\n",
      "115.74179639804646\n",
      "Si1\n",
      "119.54370837495843\n",
      "Si1\n",
      "122.91116869241871\n",
      "Si1\n",
      "126.56575806439938\n",
      "Si1\n",
      "120.11149336774339\n",
      "Si1\n",
      "125.97845647709781\n",
      "Si1\n",
      "119.58649336774342\n",
      "Si1\n",
      "124.65752511377516\n",
      "Si1\n",
      "122.98530289155295\n",
      "Si1\n",
      "122.82419178044184\n",
      "Si1\n",
      "116.3683790545204\n",
      "Si1\n",
      "120.85677308802313\n",
      "Si1\n",
      "118.31704892329896\n",
      "Si1\n",
      "124.90608211233216\n",
      "Si1\n",
      "123.2692573428987\n",
      "Si1\n",
      "116.65424228549234\n",
      "Si1\n",
      "124.07022352647357\n",
      "Si1\n",
      "120.10752511377518\n",
      "Si1\n",
      "120.1984397546898\n",
      "Si1\n",
      "120.48177308802313\n",
      "Si1\n",
      "122.82419178044184\n",
      "Si1\n",
      "122.50164488289492\n",
      "Si1\n",
      "120.86694854058989\n",
      "Si1\n",
      "120.86694854058989\n",
      "Si1\n",
      "124.9380806693307\n",
      "Si1\n",
      "122.0676700413114\n",
      "Si1\n",
      "125.45100337464474\n",
      "Si1\n",
      "120.86694854058989\n",
      "Si1\n",
      "122.70164488289493\n",
      "Si1\n",
      "121.63508644133648\n",
      "Si1\n",
      "122.6794226606727\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "118.78093781218787\n",
      "Si1\n",
      "124.80911241536246\n",
      "Si1\n",
      "123.72419178044181\n",
      "Si1\n",
      "125.12322559686696\n",
      "Si1\n",
      "123.9075251137752\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "133.34565365190366\n",
      "Si1\n",
      "134.8848672161172\n",
      "Si1\n",
      "142.59432303807301\n",
      "Si1\n",
      "135.12184412809407\n",
      "Si1\n",
      "134.60398698523696\n",
      "Si1\n",
      "133.71906635031635\n",
      "Si1\n",
      "109.38532786657791\n",
      "Si1\n",
      "130.38862456987462\n",
      "Si1\n",
      "115.73652389277387\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "112.41130605505609\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "104.97129329004328\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "10.517565073815069\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "68.32871364746372\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "90.26131993006994\n",
      "Si1\n",
      "84.09441877566876\n",
      "Si1\n",
      "90.34253038628039\n",
      "Si1\n",
      "90.65113081363089\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "111.98469239094234\n",
      "Si1\n",
      "19.449984948626245\n",
      "Si1\n",
      "105.4392780830281\n",
      "Si1\n",
      "107.43725788100792\n",
      "Si1\n",
      "71.38877719502726\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "55.02421904786037\n",
      "Si1\n",
      "67.99621558996563\n",
      "Si1\n",
      "61.98085178710182\n",
      "Si1\n",
      "96.03711635586637\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "22.085433527824826\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "24.625736974378277\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "126.67584706959711\n",
      "Si1\n",
      "135.21423597537722\n",
      "Si1\n",
      "40.91053182928185\n",
      "Si1\n",
      "48.297123015873034\n",
      "Si1\n",
      "77.17469613719616\n",
      "Si1\n",
      "51.996842740592776\n",
      "Si1\n",
      "112.76110625485633\n",
      "Si1\n",
      "98.61547549672557\n",
      "Si1\n",
      "45.64286567900698\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "131.30490551115548\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "130.90349580974578\n",
      "Si1\n",
      "118.91150814764943\n",
      "Si1\n",
      "90.0518987956488\n",
      "Si1\n",
      "116.80016303141306\n",
      "Si1\n",
      "63.46713078588081\n",
      "Si1\n",
      "77.03455988455993\n",
      "Si1\n",
      "23.60219086469087\n",
      "Si1\n",
      "67.4003947441447\n",
      "Si1\n",
      "99.96724456099457\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "69.10704642579647\n",
      "Si1\n",
      "82.00793650793655\n",
      "Si1\n",
      "40.21221438585572\n",
      "Si1\n",
      "78.5554993617494\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "35.349087717837726\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "75.95741688866693\n",
      "Si1\n",
      "6.000112387612388\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "82.8809988622489\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "91.07545995670999\n",
      "Si1\n",
      "105.54994241869241\n",
      "Si1\n",
      "108.14232871597002\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "69.8431422743923\n",
      "Si1\n",
      "95.86233141858145\n",
      "Si1\n",
      "57.65148809523814\n",
      "Si1\n",
      "18.03865509490509\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "135.91704844068974\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "116.12141539016538\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "3.7686008436008427\n",
      "Si1\n",
      "73.29514256878389\n",
      "Si1\n",
      "125.96777687891813\n",
      "Si1\n",
      "108.13005397380405\n",
      "Si1\n",
      "112.95254814629816\n",
      "Si1\n",
      "103.7959505772006\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "101.17911186036191\n",
      "Si1\n",
      "113.24015498390499\n",
      "Si1\n",
      "111.42580079944213\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "108.86405885780893\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "100.55743353868355\n",
      "Si1\n",
      "94.72367493617499\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "111.9880140692641\n",
      "Si1\n",
      "99.03272075147085\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "120.67262112887119\n",
      "Si1\n",
      "123.97209387834393\n",
      "Si1\n",
      "117.40113150738152\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "100.30493326118328\n",
      "Si1\n",
      "95.54108738483751\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "111.73402084027087\n",
      "Si1\n",
      "108.30800935175938\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "137.5838205574619\n",
      "Si1\n",
      "103.31801184926186\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "109.48984418359423\n",
      "Si1\n",
      "79.34461580086582\n",
      "Si1\n",
      "81.27208971583973\n",
      "Si1\n",
      "126.9707036019536\n",
      "Si1\n",
      "116.08541389166388\n",
      "Si1\n",
      "118.53771298146303\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "19.449909329800626\n",
      "Si1\n",
      "134.46500513375517\n",
      "Si1\n",
      "93.39536088911092\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "9.838258480649781\n",
      "Si1\n",
      "138.99887494751619\n",
      "Si1\n",
      "94.35447954822962\n",
      "Si1\n",
      "134.98097666222665\n",
      "Si1\n",
      "120.12691544566546\n",
      "Si1\n",
      "126.37644647019651\n",
      "Si1\n",
      "98.13464660339662\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "100.17413489288496\n",
      "Si1\n",
      "109.14472631836769\n",
      "Si1\n",
      "97.74109015984024\n",
      "Si1\n",
      "73.21215589965591\n",
      "Si1\n",
      "84.96945623820626\n",
      "Si1\n",
      "128.59129065379062\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "88.7721715784216\n",
      "Si1\n",
      "57.26871114996116\n",
      "Si1\n",
      "81.5493041680542\n",
      "Si1\n",
      "127.04001762126768\n",
      "Si1\n",
      "24.71864892354022\n",
      "Si1\n",
      "98.8193896381397\n",
      "Si1\n",
      "11.979785009676311\n",
      "Si1\n",
      "111.36657717282719\n",
      "Si1\n",
      "64.21516747141749\n",
      "Si1\n",
      "82.92591089466092\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "91.44922091797095\n",
      "Si1\n",
      "102.16228701853704\n",
      "Si1\n",
      "84.79019612633749\n",
      "Si1\n",
      "121.30640678765678\n",
      "Si1\n",
      "78.65446012321013\n",
      "Si1\n",
      "112.41209831834834\n",
      "Si1\n",
      "116.45319610944608\n",
      "Si1\n",
      "130.31050962925963\n",
      "Si1\n",
      "56.64191156066158\n",
      "Si1\n",
      "50.173296842046874\n",
      "Si1\n",
      "107.17030955155955\n",
      "Si1\n",
      "117.89525960150961\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "100.84359876234882\n",
      "Si1\n",
      "115.90238025863025\n",
      "Si1\n",
      "118.57468663582789\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "85.96416292041296\n",
      "Si1\n",
      "106.11041666666672\n",
      "Si1\n",
      "107.04365287490286\n",
      "Si1\n",
      "51.00015470640472\n",
      "Si1\n",
      "32.11184093684093\n",
      "Si1\n",
      "47.63059509934511\n",
      "Si1\n",
      "102.75160880785883\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "121.70982142857143\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "113.06225371850367\n",
      "Si1\n",
      "140.48781843156846\n",
      "Si1\n",
      "47.23821317571317\n",
      "Si1\n",
      "70.67980699855703\n",
      "Si1\n",
      "95.02633963258965\n",
      "Si1\n",
      "97.05570471195475\n",
      "Si1\n",
      "105.57078268953272\n",
      "Si1\n",
      "47.22532766146895\n",
      "Si1\n",
      "137.83247377622376\n",
      "Si1\n",
      "110.37142926517926\n",
      "Si1\n",
      "103.22604686979687\n",
      "Si1\n",
      "120.75334318459322\n",
      "Si1\n",
      "112.17740245865252\n",
      "Si1\n",
      "81.87814060939058\n",
      "Si1\n",
      "84.10351662226664\n",
      "Si1\n",
      "7.455112942612942\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "44.05367292731426\n",
      "Si1\n",
      "93.12846528471523\n",
      "Si1\n",
      "113.55779380643511\n",
      "Si1\n",
      "30.10187243312242\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "73.30929972804975\n",
      "Si1\n",
      "108.22009379509385\n",
      "Si1\n",
      "105.82583458208462\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "104.38562756687762\n",
      "Si1\n",
      "90.13501012876016\n",
      "Si1\n",
      "136.85379412254412\n",
      "Si1\n",
      "119.53996718860851\n",
      "Si1\n",
      "120.85305548919685\n",
      "Si1\n",
      "127.38293949408082\n",
      "Si1\n",
      "127.54960616074749\n",
      "Si1\n",
      "117.48877671241804\n",
      "Si1\n",
      "118.53163385527516\n",
      "Si1\n",
      "118.4812009548423\n",
      "Si1\n",
      "118.88120095484229\n",
      "Si1\n",
      "119.41453428817563\n",
      "Si1\n",
      "127.54960616074749\n",
      "Si1\n",
      "120.33222215586352\n",
      "Si1\n",
      "122.2050992787406\n",
      "Si1\n",
      "123.07295642159775\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "131.52015505629637\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "109.87769938394936\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "112.16909965034966\n",
      "Si1\n",
      "129.9392614330114\n",
      "Si1\n",
      "131.03832070707065\n",
      "Si1\n",
      "129.9392614330114\n",
      "Si1\n",
      "131.34759476634468\n",
      "Si1\n",
      "130.59001900876896\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "86.91544635919638\n",
      "Si1\n",
      "75.50755425130426\n",
      "Si1\n",
      "102.55007145632146\n",
      "Si1\n",
      "79.55414516039515\n",
      "Si1\n",
      "78.08291777666776\n",
      "Si1\n",
      "88.2958534521035\n",
      "Si1\n",
      "77.23292887667888\n",
      "Si1\n",
      "119.68445096570099\n",
      "Si1\n",
      "84.31622266622266\n",
      "Si1\n",
      "135.94962745587748\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "137.26664467778596\n",
      "Si1\n",
      "94.7115530303031\n",
      "Si1\n",
      "60.875036768786785\n",
      "Si1\n",
      "88.3168005605506\n",
      "Si1\n",
      "59.43522311022311\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "80.0934017371518\n",
      "Si1\n",
      "94.55199314574314\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "116.53594946719946\n",
      "Si1\n",
      "99.96593475968477\n",
      "Si1\n",
      "135.32514083139077\n",
      "Si1\n",
      "101.48182165057166\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "86.13041007905137\n",
      "Si1\n",
      "121.82975566100568\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "80.53139152514153\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "88.56954920079917\n",
      "Si1\n",
      "123.32582854946985\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "85.07561813186814\n",
      "Si1\n",
      "101.17693487068486\n",
      "Si1\n",
      "101.95016580641577\n",
      "Si1\n",
      "92.52510059385061\n",
      "Si1\n",
      "88.00458499833499\n",
      "Si1\n",
      "72.91291555666555\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "109.53899503274504\n",
      "Si1\n",
      "111.20004786879788\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "106.73920177045177\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "45.289242007992016\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "116.6707697194111\n",
      "Si1\n",
      "131.3467534578947\n",
      "Si1\n",
      "126.07420010545012\n",
      "Si1\n",
      "131.63126616740752\n",
      "Si1\n",
      "136.99919455544457\n",
      "Si1\n",
      "136.69919455544456\n",
      "Si1\n",
      "131.36664467778593\n",
      "Si1\n",
      "142.98318972693966\n",
      "Si1\n",
      "145.44628496503492\n",
      "Si1\n",
      "142.15206897571025\n",
      "Si1\n",
      "120.32210310824445\n",
      "Si1\n",
      "137.5720661283161\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "155.62911831525955\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "139.80665189279316\n",
      "Si1\n",
      "145.1299124486624\n",
      "Si1\n",
      "139.72381528495654\n",
      "Si1\n",
      "127.02420010545012\n",
      "Si1\n",
      "155.17749264624257\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "124.05338480963476\n",
      "Si1\n",
      "124.05338480963476\n",
      "Si1\n",
      "123.30338480963476\n",
      "Si1\n",
      "123.56688242313248\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "134.4442531803945\n",
      "Si1\n",
      "143.74300768675764\n",
      "Si1\n",
      "120.82664488289494\n",
      "Si1\n",
      "139.77096583971576\n",
      "Si1\n",
      "137.8712003274503\n",
      "Si1\n",
      "146.87787420912414\n",
      "Si1\n",
      "148.45595723720712\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "133.43840902455034\n",
      "Si1\n",
      "133.25031378645508\n",
      "Si1\n",
      "130.06210616074748\n",
      "Si1\n",
      "130.83667742281875\n",
      "Si1\n",
      "130.3534883896297\n",
      "Si1\n",
      "130.461821722963\n",
      "Si1\n",
      "129.31023442137572\n",
      "Si1\n",
      "130.68682172296303\n",
      "Si1\n",
      "152.44246656121643\n",
      "Si1\n",
      "117.29146756021757\n",
      "Si1\n",
      "147.56571553446548\n",
      "Si1\n",
      "128.9342423578837\n",
      "Si1\n",
      "114.34616563991563\n",
      "Si1\n",
      "104.47988469863468\n",
      "Si1\n",
      "142.40287420912418\n",
      "Si1\n",
      "143.3231109168609\n",
      "Si1\n",
      "128.9411539849039\n",
      "Si1\n",
      "148.6097437284937\n",
      "Si1\n",
      "129.17265533379665\n",
      "Si1\n",
      "141.10418075282203\n",
      "Si1\n",
      "133.3798772785186\n",
      "Si1\n",
      "145.10168234543232\n",
      "Si1\n",
      "125.83661963036965\n",
      "Si1\n",
      "100.68313145188144\n",
      "Si1\n",
      "129.9534883896297\n",
      "Si1\n",
      "130.0443974805388\n",
      "Si1\n",
      "129.92015505629638\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "142.16573357198357\n",
      "Si1\n",
      "146.2604952716366\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.14237727851855\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "130.7225360086773\n",
      "Si1\n",
      "120.90146818760947\n",
      "Si1\n",
      "121.0912409148822\n",
      "Si1\n",
      "121.31813485427614\n",
      "Si1\n",
      "121.06813485427614\n",
      "Si1\n",
      "120.56813485427614\n",
      "Si1\n",
      "121.31813485427614\n",
      "Si1\n",
      "120.40146818760948\n",
      "Si1\n",
      "121.06813485427614\n",
      "Si1\n",
      "121.31813485427614\n",
      "Si1\n",
      "121.35146818760947\n",
      "Si1\n",
      "120.90146818760947\n",
      "Si1\n",
      "121.31813485427614\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "128.66657252771384\n",
      "Si1\n",
      "132.30850281964413\n",
      "Si1\n",
      "132.4085028196441\n",
      "Si1\n",
      "134.67877698991828\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.67877698991828\n",
      "Si1\n",
      "134.31817092931223\n",
      "Si1\n",
      "134.67877698991828\n",
      "Si1\n",
      "134.67877698991828\n",
      "Si1\n",
      "134.8787769899183\n",
      "Si1\n",
      "132.4085028196441\n",
      "Si1\n",
      "131.43270916885047\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "132.4085028196441\n",
      "Si1\n",
      "131.9085028196441\n",
      "Si1\n",
      "130.74313485427615\n",
      "Si1\n",
      "132.01456342570472\n",
      "Si1\n",
      "133.84147540261668\n",
      "Si1\n",
      "134.8787769899183\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.67877698991828\n",
      "Si1\n",
      "134.67877698991828\n",
      "Si1\n",
      "134.67877698991828\n",
      "Si1\n",
      "134.5070598182011\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.10150426264556\n",
      "Si1\n",
      "134.81817092931223\n",
      "Si1\n",
      "134.81817092931223\n",
      "Si1\n",
      "134.81817092931223\n",
      "Si1\n",
      "134.81817092931223\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.6181709293122\n",
      "Si1\n",
      "134.81817092931223\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "127.14952013566148\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "123.06170010545013\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "147.25944957819954\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "122.70753343878347\n",
      "Si1\n",
      "124.5045572483073\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "155.08495324120318\n",
      "Si1\n",
      "123.97003343878347\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "124.5045572483073\n",
      "Si1\n",
      "146.5176469363969\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "155.13390706515702\n",
      "Si1\n",
      "123.97003343878347\n",
      "Si1\n",
      "126.01467629592631\n",
      "Si1\n",
      "124.5045572483073\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "146.5176469363969\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "132.08372391497392\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "141.26072746697744\n",
      "Si1\n",
      "139.66666597291604\n",
      "Si1\n",
      "140.30739468864468\n",
      "Si1\n",
      "135.83736194361188\n",
      "Si1\n",
      "135.33730644355637\n",
      "Si1\n",
      "137.2396707459208\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "129.20702374316505\n",
      "Si1\n",
      "128.92369040983172\n",
      "Si1\n",
      "130.50861104475234\n",
      "Si1\n",
      "130.65146818760948\n",
      "Si1\n",
      "129.3736904098317\n",
      "Si1\n",
      "128.11972215586349\n",
      "Si1\n",
      "137.52456314820446\n",
      "Si1\n",
      "129.3736904098317\n",
      "Si1\n",
      "130.10424596538724\n",
      "Si1\n",
      "130.65146818760948\n",
      "Si1\n",
      "128.99869040983174\n",
      "Si1\n",
      "129.2486904098317\n",
      "Si1\n",
      "130.70702374316505\n",
      "Si1\n",
      "140.1885061496474\n",
      "Si1\n",
      "140.43136329250456\n",
      "Si1\n",
      "126.62985139860143\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "125.8242001054501\n",
      "Si1\n",
      "137.72023601398595\n",
      "Si1\n",
      "133.68126616740747\n",
      "Si1\n",
      "147.10684246309233\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "149.5195394882895\n",
      "Si1\n",
      "103.16472069597069\n",
      "Si1\n",
      "153.15775960150953\n",
      "Si1\n",
      "101.3637230824731\n",
      "Si1\n",
      "143.27459138084131\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "130.91649344013473\n",
      "Si1\n",
      "131.0953173939587\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "141.9650018761431\n",
      "Si1\n",
      "97.83313145188146\n",
      "Si1\n",
      "125.0268321955822\n",
      "Si1\n",
      "118.89519529383664\n",
      "Si1\n",
      "111.91256868131867\n",
      "Si1\n",
      "119.07708333333338\n",
      "Si1\n",
      "112.9894251581751\n",
      "Si1\n",
      "122.14234536598669\n",
      "Si1\n",
      "119.91124084249087\n",
      "Si1\n",
      "118.9433115495616\n",
      "Si1\n",
      "149.66641761016757\n",
      "Si1\n",
      "99.44808732933733\n",
      "Si1\n",
      "110.04582986457986\n",
      "Si1\n",
      "118.81486638361643\n",
      "Si1\n",
      "122.74690101565102\n",
      "Si1\n",
      "122.85752511377518\n",
      "Si1\n",
      "125.33546245421243\n",
      "Si1\n",
      "118.22909798534802\n",
      "Si1\n",
      "120.15885989010994\n",
      "Si1\n",
      "124.03808066933071\n",
      "Si1\n",
      "118.01398809523816\n",
      "Si1\n",
      "125.3558115495616\n",
      "Si1\n",
      "125.71455558330561\n",
      "Si1\n",
      "118.53108211233213\n",
      "Si1\n",
      "120.69010642135646\n",
      "Si1\n",
      "111.79519529383664\n",
      "Si1\n",
      "122.12386710511714\n",
      "Si1\n",
      "121.71156551781554\n",
      "Si1\n",
      "119.72192460317464\n",
      "Si1\n",
      "98.88749653124653\n",
      "Si1\n",
      "149.20565198690196\n",
      "Si1\n",
      "135.39345446220446\n",
      "Si1\n",
      "117.35107552471686\n",
      "Si1\n",
      "105.11783286158295\n",
      "Si1\n",
      "120.5745603732017\n",
      "Si1\n",
      "119.37743853368862\n",
      "Si1\n",
      "125.7379502442003\n",
      "Si1\n",
      "123.0778353590854\n",
      "Si1\n",
      "135.61363289488287\n",
      "Si1\n",
      "141.2754016816517\n",
      "Si1\n",
      "135.88545829170826\n",
      "Si1\n",
      "130.66470127095127\n",
      "Si1\n",
      "100.14305208680209\n",
      "Si1\n",
      "131.7404588467088\n",
      "Si1\n",
      "123.70537400401534\n",
      "Si1\n",
      "104.59846334221334\n",
      "Si1\n",
      "134.42614815739813\n",
      "Si1\n",
      "123.83226148851148\n",
      "Si1\n",
      "96.28670288045288\n",
      "Si1\n",
      "113.40175727050726\n",
      "Si1\n",
      "130.4480346042846\n",
      "Si1\n",
      "144.53228230103232\n",
      "Si1\n",
      "131.29046439671438\n",
      "Si1\n",
      "139.02840284715285\n",
      "Si1\n",
      "131.63136793761794\n",
      "Si1\n",
      "137.55327797202804\n",
      "Si1\n",
      "110.67690989565996\n",
      "Si1\n",
      "114.93075049950049\n",
      "Si1\n",
      "124.57471070596075\n",
      "Si1\n",
      "115.22213550338554\n",
      "Si1\n",
      "142.05372197247192\n",
      "Si1\n",
      "136.64656107781107\n",
      "Si1\n",
      "147.60230810855808\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "113.99057955932952\n",
      "Si1\n",
      "126.31237720612722\n",
      "Si1\n",
      "135.16164876789875\n",
      "Si1\n",
      "109.58597444222447\n",
      "Si1\n",
      "131.94882825507824\n",
      "Si1\n",
      "132.36824217449214\n",
      "Si1\n",
      "131.85712551337548\n",
      "Si1\n",
      "131.21470127095125\n",
      "Si1\n",
      "109.3472034909535\n",
      "Si1\n",
      "133.2472104284604\n",
      "Si1\n",
      "130.0218441280941\n",
      "Si1\n",
      "126.61511474636475\n",
      "Si1\n",
      "117.7979763292263\n",
      "Si1\n",
      "134.33533619158615\n",
      "Si1\n",
      "114.03905885780887\n",
      "Si1\n",
      "112.3596937784438\n",
      "Si1\n",
      "134.36781482406482\n",
      "Si1\n",
      "99.17909104784107\n",
      "Si1\n",
      "132.26114926739928\n",
      "Si1\n",
      "115.62819610944607\n",
      "Si1\n",
      "148.2754571817071\n",
      "Si1\n",
      "114.6862505550005\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "126.1298444610945\n",
      "Si1\n",
      "127.9463293650794\n",
      "Si1\n",
      "129.1008123820624\n",
      "Si1\n",
      "134.47376720501717\n",
      "Si1\n",
      "131.21470127095125\n",
      "Si1\n",
      "133.6996219058719\n",
      "Si1\n",
      "111.71257700632704\n",
      "Si1\n",
      "110.32924367299368\n",
      "Si1\n",
      "134.22382825507825\n",
      "Si1\n",
      "127.99900814764949\n",
      "Si1\n",
      "123.52556956931956\n",
      "Si1\n",
      "136.1425567488067\n",
      "Si1\n",
      "113.23700258075255\n",
      "Si1\n",
      "132.24244804108935\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "115.79977314352315\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "131.46952374316507\n",
      "Si1\n",
      "116.02632437007433\n",
      "Si1\n",
      "116.0366418303918\n",
      "Si1\n",
      "95.75733780108781\n",
      "Si1\n",
      "113.26324529938668\n",
      "Si1\n",
      "116.73630605505606\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "118.16387432012435\n",
      "Si1\n",
      "111.15915820290816\n",
      "Si1\n",
      "107.23498792873788\n",
      "Si1\n",
      "101.7742209179709\n",
      "Si1\n",
      "116.06562257187258\n",
      "Si1\n",
      "99.42393231768231\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "112.85974372849378\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "97.42993881118885\n",
      "Si1\n",
      "123.24450202575206\n",
      "Si1\n",
      "115.73233918858928\n",
      "Si1\n",
      "126.39494970609103\n",
      "Si1\n",
      "125.34916264291269\n",
      "Si1\n",
      "138.72701257076253\n",
      "Si1\n",
      "101.48445096570097\n",
      "Si1\n",
      "120.72934773559774\n",
      "Si1\n",
      "97.32016525141525\n",
      "Si1\n",
      "133.27390408504547\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "119.01498987123986\n",
      "Si1\n",
      "113.95701312576311\n",
      "Si1\n",
      "125.33080044955045\n",
      "Si1\n",
      "135.39754342879343\n",
      "Si1\n",
      "96.67003621378622\n",
      "Si1\n",
      "117.45958139083143\n",
      "Si1\n",
      "123.62059121434126\n",
      "Si1\n",
      "119.47854714729714\n",
      "Si1\n",
      "105.73937798312797\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "135.61363289488287\n",
      "Si1\n",
      "138.69315059940058\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "139.4159014596514\n",
      "Si1\n",
      "128.70795523920526\n",
      "Si1\n",
      "132.23696650571645\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "94.59530955155958\n",
      "Si1\n",
      "104.22988469863468\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "100.14305208680209\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "128.09411213786217\n",
      "Si1\n",
      "133.768638999889\n",
      "Si1\n",
      "112.35728230103228\n",
      "Si1\n",
      "131.71470127095125\n",
      "Si1\n",
      "116.90008949383947\n",
      "Si1\n",
      "143.80786366411368\n",
      "Si1\n",
      "133.0356964593377\n",
      "Si1\n",
      "143.5013710625123\n",
      "Si1\n",
      "146.34809239673368\n",
      "Si1\n",
      "119.9505515318016\n",
      "Si1\n",
      "140.69179639804642\n",
      "Si1\n",
      "111.2592562328975\n",
      "Si1\n",
      "156.2837350149849\n",
      "Si1\n",
      "140.73328962703957\n",
      "Si1\n",
      "140.19563513177638\n",
      "Si1\n",
      "128.55209256323388\n",
      "Si1\n",
      "138.2897720335221\n",
      "Si1\n",
      "127.92710275835275\n",
      "Si1\n",
      "145.2015671828172\n",
      "Si1\n",
      "143.0365946553447\n",
      "Si1\n",
      "115.9192481129981\n",
      "Si1\n",
      "150.65716713841707\n",
      "Si1\n",
      "134.25255924630923\n",
      "Si1\n",
      "130.45980477855474\n",
      "Si1\n",
      "136.98257228882235\n",
      "Si1\n",
      "123.39003565878565\n",
      "Si1\n",
      "142.14681034545163\n",
      "Si1\n",
      "142.02786678900807\n",
      "Si1\n",
      "120.87912296037302\n",
      "Si1\n",
      "144.00077353202354\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "114.03429695304693\n",
      "Si1\n",
      "125.45012418137424\n",
      "Si1\n",
      "114.82314144189144\n",
      "Si1\n",
      "116.69675394050397\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "104.71465825840835\n",
      "Si1\n",
      "130.62700285825287\n",
      "Si1\n",
      "132.70954067068195\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "132.70954067068195\n",
      "Si1\n",
      "143.40287420912415\n",
      "Si1\n",
      "128.50795523920527\n",
      "Si1\n",
      "131.49898088023087\n",
      "Si1\n",
      "138.52701257076254\n",
      "Si1\n",
      "145.88778374403367\n",
      "Si1\n",
      "111.71319305694301\n",
      "Si1\n",
      "102.88077547452545\n",
      "Si1\n",
      "136.26363289488293\n",
      "Si1\n",
      "140.64277132891263\n",
      "Si1\n",
      "132.46281378645511\n",
      "Si1\n",
      "132.46281378645511\n",
      "Si1\n",
      "113.88730366855366\n",
      "Si1\n",
      "133.70124896239028\n",
      "Si1\n",
      "147.6017725330226\n",
      "Si1\n",
      "143.89119699744703\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "139.110020746162\n",
      "Si1\n",
      "141.37795836409967\n",
      "Si1\n",
      "135.4002860364274\n",
      "Si1\n",
      "123.28378170742302\n",
      "Si1\n",
      "113.5278353590854\n",
      "Si1\n",
      "107.96247155622156\n",
      "Si1\n",
      "127.60781787656786\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "133.81625804750803\n",
      "Si1\n",
      "127.80056124431121\n",
      "Si1\n",
      "133.17695984570977\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "124.51170010545013\n",
      "Si1\n",
      "127.80056124431121\n",
      "Si1\n",
      "131.58092809967806\n",
      "Si1\n",
      "127.60781787656786\n",
      "Si1\n",
      "121.74958860583862\n",
      "Si1\n",
      "130.76732226107225\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "129.21589403953536\n",
      "Si1\n",
      "132.3055118492618\n",
      "Si1\n",
      "146.28152979267102\n",
      "Si1\n",
      "146.75819388944393\n",
      "Si1\n",
      "109.43739524364524\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "145.70151307026313\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "113.04268023643024\n",
      "Si1\n",
      "143.6303078865579\n",
      "Si1\n",
      "149.25548271173272\n",
      "Si1\n",
      "137.13808066933063\n",
      "Si1\n",
      "133.01780324144454\n",
      "Si1\n",
      "133.24823717948726\n",
      "Si1\n",
      "144.23371510735637\n",
      "Si1\n",
      "135.84058927183926\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "140.74567120681243\n",
      "Si1\n",
      "117.13876332001333\n",
      "Si1\n",
      "116.0460477022977\n",
      "Si1\n",
      "126.56638847263844\n",
      "Si1\n",
      "108.36633158508158\n",
      "Si1\n",
      "141.98033931648058\n",
      "Si1\n",
      "129.94089403953538\n",
      "Si1\n",
      "110.80247877122872\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "136.14042783906916\n",
      "Si1\n",
      "134.47752685116814\n",
      "Si1\n",
      "107.73032869907873\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "122.8295947108447\n",
      "Si1\n",
      "131.29018363882497\n",
      "Si1\n",
      "112.87798382173379\n",
      "Si1\n",
      "122.88515026640025\n",
      "Si1\n",
      "147.14502185616308\n",
      "Si1\n",
      "126.23431450795587\n",
      "Si1\n",
      "122.07734647598781\n",
      "Si1\n",
      "127.18833041958042\n",
      "Si1\n",
      "148.35198898323898\n",
      "Si1\n",
      "113.22651584526582\n",
      "Si1\n",
      "133.97752685116814\n",
      "Si1\n",
      "140.80581709956704\n",
      "Si1\n",
      "131.26666687780812\n",
      "Si1\n",
      "119.45217165081304\n",
      "Si1\n",
      "141.06526459651462\n",
      "Si1\n",
      "119.96616508491508\n",
      "Si1\n",
      "127.73678058053058\n",
      "Si1\n",
      "138.52032758907765\n",
      "Si1\n",
      "150.04502324366456\n",
      "Si1\n",
      "136.64966769341763\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "125.09696158310291\n",
      "Si1\n",
      "128.74782786657784\n",
      "Si1\n",
      "137.29006570120703\n",
      "Si1\n",
      "134.09025765900765\n",
      "Si1\n",
      "149.875095043845\n",
      "Si1\n",
      "127.1127943614357\n",
      "Si1\n",
      "114.69153416028415\n",
      "Si1\n",
      "126.80416181041184\n",
      "Si1\n",
      "147.0748605561106\n",
      "Si1\n",
      "129.86190406815413\n",
      "Si1\n",
      "108.62253926628928\n",
      "Si1\n",
      "134.724944711086\n",
      "Si1\n",
      "122.81595231459367\n",
      "Si1\n",
      "130.895017693659\n",
      "Si1\n",
      "136.98257228882235\n",
      "Si1\n",
      "127.02598117462254\n",
      "Si1\n",
      "141.39840367965365\n",
      "Si1\n",
      "150.7678092740592\n",
      "Si1\n",
      "128.22567453681592\n",
      "Si1\n",
      "104.84394980019987\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "117.63671766035897\n",
      "Si1\n",
      "112.18446345321352\n",
      "Si1\n",
      "124.97919927294932\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "125.21876942501942\n",
      "Si1\n",
      "144.391196997447\n",
      "Si1\n",
      "137.47852494727496\n",
      "Si1\n",
      "140.4743175604588\n",
      "Si1\n",
      "145.402984726626\n",
      "Si1\n",
      "135.96231615606618\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "115.87767024642025\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "124.83895757020761\n",
      "Si1\n",
      "138.00568944943947\n",
      "Si1\n",
      "125.13449536574534\n",
      "Si1\n",
      "138.70643870018876\n",
      "Si1\n",
      "131.64327499191631\n",
      "Si1\n",
      "145.2810039296452\n",
      "Si1\n",
      "143.95719350094348\n",
      "Si1\n",
      "144.25917762792758\n",
      "Si1\n",
      "126.40098117462254\n",
      "Si1\n",
      "123.11711504075635\n",
      "Si1\n",
      "123.39003565878565\n",
      "Si1\n",
      "112.23273462648463\n",
      "Si1\n",
      "123.47004731379732\n",
      "Si1\n",
      "141.37795836409967\n",
      "Si1\n",
      "116.40201118326118\n",
      "Si1\n",
      "123.47004731379732\n",
      "Si1\n",
      "142.76124174738305\n",
      "Si1\n",
      "119.02008706872836\n",
      "Si1\n",
      "142.55129662004668\n",
      "Si1\n",
      "130.23543609168604\n",
      "Si1\n",
      "128.55209256323388\n",
      "Si1\n",
      "118.1610937673438\n",
      "Si1\n",
      "137.07357156732152\n",
      "Si1\n",
      "115.17949897324895\n",
      "Si1\n",
      "147.73971098346092\n",
      "Si1\n",
      "129.06929758043887\n",
      "Si1\n",
      "150.7678092740592\n",
      "Si1\n",
      "127.38112602976734\n",
      "Si1\n",
      "140.95400454014577\n",
      "Si1\n",
      "127.04547327672327\n",
      "Si1\n",
      "148.07582209457206\n",
      "Si1\n",
      "117.99045884670888\n",
      "Si1\n",
      "115.19553016428011\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "148.5258886946387\n",
      "Si1\n",
      "136.9624604562104\n",
      "Si1\n",
      "130.45980477855474\n",
      "Si1\n",
      "143.44829684204677\n",
      "Si1\n",
      "119.00483752358757\n",
      "Si1\n",
      "126.65098117462254\n",
      "Si1\n",
      "127.27946102810238\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "134.15731143856144\n",
      "Si1\n",
      "133.12414044289042\n",
      "Si1\n",
      "122.82420010545015\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "140.33256903121034\n",
      "Si1\n",
      "137.17924922299918\n",
      "Si1\n",
      "141.37795836409967\n",
      "Si1\n",
      "122.16075382950388\n",
      "Si1\n",
      "126.27946102810238\n",
      "Si1\n",
      "136.66679639804642\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "106.33657523032524\n",
      "Si1\n",
      "106.33657523032524\n",
      "Si1\n",
      "106.33657523032524\n",
      "Si1\n",
      "105.83657523032524\n",
      "Si1\n",
      "139.77096583971576\n",
      "Si1\n",
      "139.77096583971576\n",
      "Si1\n",
      "152.56533119658113\n",
      "Si1\n",
      "151.27943376068373\n",
      "Si1\n",
      "151.36347194472188\n",
      "Si1\n",
      "149.88199786324785\n",
      "Si1\n",
      "151.05624028749025\n",
      "Si1\n",
      "151.22888521502648\n",
      "Si1\n",
      "149.88199786324785\n",
      "Si1\n",
      "152.56533119658113\n",
      "Si1\n",
      "141.98247377622377\n",
      "Si1\n",
      "139.41231567345696\n",
      "Si1\n",
      "141.23453789567915\n",
      "Si1\n",
      "138.93612519726645\n",
      "Si1\n",
      "139.29978979353976\n",
      "Si1\n",
      "139.51707757821882\n",
      "Si1\n",
      "140.88666632280763\n",
      "Si1\n",
      "138.766906010656\n",
      "Si1\n",
      "140.1805696417109\n",
      "Si1\n",
      "139.24604583218712\n",
      "Si1\n",
      "140.88666632280763\n",
      "Si1\n",
      "138.02541091155217\n",
      "Si1\n",
      "140.41271249885378\n",
      "Si1\n",
      "140.41271249885378\n",
      "Si1\n",
      "142.0300812412225\n",
      "Si1\n",
      "140.60318868932995\n",
      "Si1\n",
      "139.64698378312502\n",
      "Si1\n",
      "138.31087267201391\n",
      "Si1\n",
      "140.52660138774263\n",
      "Si1\n",
      "140.26985535599664\n",
      "Si1\n",
      "136.13904727518855\n",
      "Si1\n",
      "139.55755376869502\n",
      "Si1\n",
      "153.04144813519807\n",
      "Si1\n",
      "148.35242188367184\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "97.53768336132468\n",
      "Si1\n",
      "97.24720717084851\n",
      "Si1\n",
      "97.53768336132468\n",
      "Si1\n",
      "97.58054050418183\n",
      "Si1\n",
      "99.08054050418183\n",
      "Si1\n",
      "97.19482621846754\n",
      "Si1\n",
      "152.99960803085796\n",
      "Si1\n",
      "103.89706751581753\n",
      "Si1\n",
      "140.82321636696636\n",
      "Si1\n",
      "142.76944375069382\n",
      "Si1\n",
      "146.9548583361083\n",
      "Si1\n",
      "153.90916791541784\n",
      "Si1\n",
      "143.90170038295034\n",
      "Si1\n",
      "145.89737276612274\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "131.97253600867734\n",
      "Si1\n",
      "129.66913295038296\n",
      "Si1\n",
      "138.73600309714433\n",
      "Si1\n",
      "139.1046099733599\n",
      "Si1\n",
      "132.72619068733192\n",
      "Si1\n",
      "135.8042570653983\n",
      "Si1\n",
      "133.73888910003032\n",
      "Si1\n",
      "133.2293652905065\n",
      "Si1\n",
      "133.00268641382763\n",
      "Si1\n",
      "135.98630834744958\n",
      "Si1\n",
      "142.68762647376772\n",
      "Si1\n",
      "127.32400814764947\n",
      "Si1\n",
      "133.2293652905065\n",
      "Si1\n",
      "145.32038863913857\n",
      "Si1\n",
      "131.79094537708664\n",
      "Si1\n",
      "131.80396846510968\n",
      "Si1\n",
      "108.52763694638699\n",
      "Si1\n",
      "120.89531371406379\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "95.33514055389054\n",
      "Si1\n",
      "112.28907550782549\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "126.06666458541464\n",
      "Si1\n",
      "126.2333312520813\n",
      "Si1\n",
      "126.56666458541464\n",
      "Si1\n",
      "126.06666458541464\n",
      "Si1\n",
      "126.06666458541464\n",
      "Si1\n",
      "125.81666458541464\n",
      "Si1\n",
      "98.51625943500943\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "141.12291250416249\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "110.94193237318238\n",
      "Si1\n",
      "111.36415459540461\n",
      "Si1\n",
      "100.44646672771671\n",
      "Si1\n",
      "100.44646672771671\n",
      "Si1\n",
      "100.44646672771671\n",
      "Si1\n",
      "113.34986888111887\n",
      "Si1\n",
      "126.53570804195807\n",
      "Si1\n",
      "128.53689851814855\n",
      "Si1\n",
      "129.7274662837163\n",
      "Si1\n",
      "129.7274662837163\n",
      "Si1\n",
      "128.17822385947386\n",
      "Si1\n",
      "113.34986888111887\n",
      "Si1\n",
      "113.20701173826173\n",
      "Si1\n",
      "127.51638569763573\n",
      "Si1\n",
      "129.5774662837163\n",
      "Si1\n",
      "110.57407523032526\n",
      "Si1\n",
      "110.57407523032526\n",
      "Si1\n",
      "109.3414994727495\n",
      "Si1\n",
      "110.9669323731824\n",
      "Si1\n",
      "110.9669323731824\n",
      "Si1\n",
      "110.9669323731824\n",
      "Si1\n",
      "115.63505452880449\n",
      "Si1\n",
      "146.9446477133977\n",
      "Si1\n",
      "146.8196477133977\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "119.20224012099015\n",
      "Si1\n",
      "133.831558025308\n",
      "Si1\n",
      "131.91409445023575\n",
      "Si1\n",
      "131.91409445023575\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "109.63533064158064\n",
      "Si1\n",
      "105.6828053890554\n",
      "Si1\n",
      "127.1992001054501\n",
      "Si1\n",
      "135.40244915109042\n",
      "Si1\n",
      "142.2119637307137\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "131.3534883896297\n",
      "Si1\n",
      "132.05695159309292\n",
      "Si1\n",
      "129.9392614330114\n",
      "Si1\n",
      "132.5919476356976\n",
      "Si1\n",
      "132.38244325119322\n",
      "Si1\n",
      "131.7919476356976\n",
      "Si1\n",
      "132.5919476356976\n",
      "Si1\n",
      "131.34759476634468\n",
      "Si1\n",
      "131.34759476634468\n",
      "Si1\n",
      "134.35583652458646\n",
      "Si1\n",
      "134.35583652458646\n",
      "Si1\n",
      "131.6230276667776\n",
      "Si1\n",
      "132.5919476356976\n",
      "Si1\n",
      "129.9392614330114\n",
      "Si1\n",
      "98.42146672771672\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "152.54204337329332\n",
      "Si1\n",
      "146.86088238452368\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "129.49728764592894\n",
      "Si1\n",
      "136.11055402930398\n",
      "Si1\n",
      "145.53634719748848\n",
      "Si1\n",
      "148.38389735264732\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "95.61385073260075\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "99.50319749694751\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "94.79507922632922\n",
      "Si1\n",
      "143.90629995004994\n",
      "Si1\n",
      "133.86692821067814\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "148.5850961538461\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "141.06555042180048\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "117.12998182373184\n",
      "Si1\n",
      "116.66073579198577\n",
      "Si1\n",
      "138.72101391965523\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "103.02973207348208\n",
      "Si1\n",
      "91.38334096459097\n",
      "Si1\n",
      "121.73447962062097\n",
      "Si1\n",
      "144.94655969030967\n",
      "Si1\n",
      "144.1386217948718\n",
      "Si1\n",
      "117.13593420468419\n",
      "Si1\n",
      "148.70173507048497\n",
      "Si1\n",
      "137.90588924963927\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "125.70335428460429\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "135.79907106782102\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "0.0\n",
      "Si1\n",
      "111.96975455100453\n",
      "Si1\n",
      "109.05483336108333\n",
      "Si1\n",
      "109.05483336108333\n",
      "Si1\n",
      "123.59714105339108\n",
      "Si1\n",
      "116.71252150627151\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(metabolism_df)):\n",
    "    print (genome)\n",
    "    print (metabolism_df.iloc[i, :-1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cluster_presence_absence = pd.read_csv('/DATA_RAID2/vtracann/shared/db/isolates/anvio/filtered_panpangenome/presence_absence.tsv', sep='\\t', index_col=[0,1])\n",
    "gene_cluster_presence_absence = gene_cluster_presence_absence.reset_index().pivot(index='layer', columns='item', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    #query   \n",
      "0        00000000|gene_cluster:GC_00018106|genome_name:...  \\\n",
      "1        00000001|gene_cluster:GC_00018106|genome_name:...   \n",
      "2        00000002|gene_cluster:GC_00018106|genome_name:...   \n",
      "3        00000003|gene_cluster:GC_00018106|genome_name:...   \n",
      "4        00000004|gene_cluster:GC_00018106|genome_name:...   \n",
      "...                                                    ...   \n",
      "4187810  04294706|gene_cluster:GC_00003108|genome_name:...   \n",
      "4187811  04294707|gene_cluster:GC_00003108|genome_name:...   \n",
      "4187812  04294708|gene_cluster:GC_00003108|genome_name:...   \n",
      "4187813  04294709|gene_cluster:GC_00003108|genome_name:...   \n",
      "4187814  04294710|gene_cluster:GC_00003108|genome_name:...   \n",
      "\n",
      "                       seed_ortholog         evalue  score   \n",
      "0        1335760.ASTG01000033_gene17   6.300000e-14   71.2  \\\n",
      "1        1335760.ASTG01000033_gene17   6.300000e-14   71.2   \n",
      "2        1335760.ASTG01000033_gene17   6.300000e-14   71.2   \n",
      "3        1335760.ASTG01000033_gene17   6.300000e-14   71.2   \n",
      "4        1335760.ASTG01000033_gene17   6.300000e-14   71.2   \n",
      "...                              ...            ...    ...   \n",
      "4187810               190486.XAC1389  2.270000e-203  567.0   \n",
      "4187811               190486.XAC1389  2.270000e-203  567.0   \n",
      "4187812               190486.XAC1389  2.270000e-203  567.0   \n",
      "4187813               190486.XAC1389  2.270000e-203  567.0   \n",
      "4187814            1338011.BD94_0922  1.720000e-166  474.0   \n",
      "\n",
      "                                                eggNOG_OGs   \n",
      "0        2DHCQ@1|root,2ZZ90@2|Bacteria,1PNH0@1224|Prote...  \\\n",
      "1        2DHCQ@1|root,2ZZ90@2|Bacteria,1PNH0@1224|Prote...   \n",
      "2        2DHCQ@1|root,2ZZ90@2|Bacteria,1PNH0@1224|Prote...   \n",
      "3        2DHCQ@1|root,2ZZ90@2|Bacteria,1PNH0@1224|Prote...   \n",
      "4        2DHCQ@1|root,2ZZ90@2|Bacteria,1PNH0@1224|Prote...   \n",
      "...                                                    ...   \n",
      "4187810  COG1131@1|root,COG1131@2|Bacteria,1MY19@1224|P...   \n",
      "4187811  COG1131@1|root,COG1131@2|Bacteria,1MY19@1224|P...   \n",
      "4187812  COG1131@1|root,COG1131@2|Bacteria,1MY19@1224|P...   \n",
      "4187813  COG1131@1|root,COG1131@2|Bacteria,1MY19@1224|P...   \n",
      "4187814  COG1131@1|root,COG1131@2|Bacteria,4NFWM@976|Ba...   \n",
      "\n",
      "                   max_annot_lvl COG_category   \n",
      "0        204457|Sphingomonadales            S  \\\n",
      "1        204457|Sphingomonadales            S   \n",
      "2        204457|Sphingomonadales            S   \n",
      "3        204457|Sphingomonadales            S   \n",
      "4        204457|Sphingomonadales            S   \n",
      "...                          ...          ...   \n",
      "4187810   135614|Xanthomonadales            V   \n",
      "4187811   135614|Xanthomonadales            V   \n",
      "4187812   135614|Xanthomonadales            V   \n",
      "4187813   135614|Xanthomonadales            V   \n",
      "4187814        976|Bacteroidetes            V   \n",
      "\n",
      "                                               Description Preferred_name GOs   \n",
      "0                     Protein of unknown function (DUF968)              -   -  \\\n",
      "1                     Protein of unknown function (DUF968)              -   -   \n",
      "2                     Protein of unknown function (DUF968)              -   -   \n",
      "3                     Protein of unknown function (DUF968)              -   -   \n",
      "4                     Protein of unknown function (DUF968)              -   -   \n",
      "...                                                    ...            ...  ..   \n",
      "4187810                                    ABC transporter           yfiL   -   \n",
      "4187811                                    ABC transporter           yfiL   -   \n",
      "4187812                                    ABC transporter           yfiL   -   \n",
      "4187813                                    ABC transporter           yfiL   -   \n",
      "4187814  ATPases associated with a variety of cellular ...              -   -   \n",
      "\n",
      "         ... KEGG_ko KEGG_Pathway KEGG_Module KEGG_Reaction KEGG_rclass BRITE   \n",
      "0        ...       -            -           -             -           -     -  \\\n",
      "1        ...       -            -           -             -           -     -   \n",
      "2        ...       -            -           -             -           -     -   \n",
      "3        ...       -            -           -             -           -     -   \n",
      "4        ...       -            -           -             -           -     -   \n",
      "...      ...     ...          ...         ...           ...         ...   ...   \n",
      "4187810  ...       -            -           -             -           -     -   \n",
      "4187811  ...       -            -           -             -           -     -   \n",
      "4187812  ...       -            -           -             -           -     -   \n",
      "4187813  ...       -            -           -             -           -     -   \n",
      "4187814  ...       -            -           -             -           -     -   \n",
      "\n",
      "        KEGG_TC CAZy BiGG_Reaction     PFAMs  \n",
      "0             -    -             -    DUF968  \n",
      "1             -    -             -    DUF968  \n",
      "2             -    -             -    DUF968  \n",
      "3             -    -             -    DUF968  \n",
      "4             -    -             -    DUF968  \n",
      "...         ...  ...           ...       ...  \n",
      "4187810       -    -             -  ABC_tran  \n",
      "4187811       -    -             -  ABC_tran  \n",
      "4187812       -    -             -  ABC_tran  \n",
      "4187813       -    -             -  ABC_tran  \n",
      "4187814       -    -             -  ABC_tran  \n",
      "\n",
      "[4187815 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "eggnogg_annot = pd.read_csv('/DATA_RAID2/vtracann/shared/db/isolates/anvio/filtered_panpangenome/eggnogg/filtered_panpangenome.emapper.annotations', sep='\\t', index_col=0, skiprows=[0,1,2,3])\n",
    "eggnogg_annot = eggnogg_annot.iloc[:-3]\n",
    "eggnogg_annot = eggnogg_annot.reset_index()\n",
    "print (eggnogg_annot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35620\n"
     ]
    }
   ],
   "source": [
    "#parse eggnogg annotation. get the GC id from the eggnogg_annot dataframe and store the GCs with an annotation in a set\n",
    "#Iterate over the GCs in the set and get all the annotations from the dataframe for a given GC\n",
    "\n",
    "#\n",
    "eggnogg_index = eggnogg_annot.loc[:, '#query'].values\n",
    "eggnogg_annot_I = eggnogg_annot.set_index('#query')\n",
    "\n",
    "entries = set()\n",
    "for entry in eggnogg_index:\n",
    "    GC = entry.split('|gene_cluster:')[1].split('|')[0]\n",
    "    entries.add(GC)\n",
    "\n",
    "print (len(entries))\n",
    "\n",
    "annotation_dict_KEGG = {entry: [] for entry in entries}\n",
    "annotation_dict_COG = {entry: [] for entry in entries}\n",
    "annotation_dict_PFAM = {entry: [] for entry in entries}\n",
    "annotation_dict_description = {entry: [] for entry in entries}\n",
    "annotation_dict_CAZy = {entry: [] for entry in entries}\n",
    "\n",
    "num_entries = len(eggnogg_annot_I.index)\n",
    "\n",
    "for x in range(len(eggnogg_annot_I.index)):\n",
    "    entry = eggnogg_annot_I.index[x]\n",
    "    GC = entry.split('|gene_cluster:')[1].split('|')[0]\n",
    "    annotation_dict_COG[GC].append(eggnogg_annot_I.loc[entry, 'COG_category'])\n",
    "    annotation_dict_PFAM[GC].append(eggnogg_annot_I.loc[entry, 'PFAMs'])\n",
    "    annotation_dict_description[GC].append(eggnogg_annot_I.loc[entry, 'Description'])\n",
    "    if eggnogg_annot_I.loc[entry, 'CAZy'] != '-':\n",
    "        annotation_dict_CAZy[GC].append(eggnogg_annot_I.loc[entry, 'CAZy'])\n",
    "    if eggnogg_annot_I.loc[entry, 'KEGG_ko'] != '-':\n",
    "        annotation_dict_KEGG[GC].append(eggnogg_annot_I.loc[entry, 'KEGG_ko'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item      GC_00000001  GC_00000002  GC_00000003  GC_00000004  GC_00000005   \n",
      "layer                                                                       \n",
      "CALOFZ02            0            1            1            1            1  \\\n",
      "CALOGA02            1            1            0            0            1   \n",
      "CALOGB02            0            1            0            0            0   \n",
      "CALOGC02            1            1            1            1            1   \n",
      "CALOGD02            1            1            1            1            1   \n",
      "...               ...          ...          ...          ...          ...   \n",
      "S65                 0            1            1            0            1   \n",
      "S7                  0            1            1            0            1   \n",
      "S71                 0            1            1            0            1   \n",
      "S72                 1            1            1            1            1   \n",
      "Si1                 0            1            0            1            0   \n",
      "\n",
      "item      GC_00000006  GC_00000007  GC_00000008  GC_00000009  GC_00000010   \n",
      "layer                                                                       \n",
      "CALOFZ02            1            1            0            1            1  \\\n",
      "CALOGA02            1            1            1            1            1   \n",
      "CALOGB02            1            1            1            1            1   \n",
      "CALOGC02            1            1            0            1            1   \n",
      "CALOGD02            1            1            0            1            1   \n",
      "...               ...          ...          ...          ...          ...   \n",
      "S65                 1            0            0            0            0   \n",
      "S7                  1            1            0            1            1   \n",
      "S71                 1            1            0            1            1   \n",
      "S72                 1            0            0            1            0   \n",
      "Si1                 1            0            0            0            0   \n",
      "\n",
      "item      ...  GC_00038542  GC_00038544  GC_00038545  GC_00038546   \n",
      "layer     ...                                                       \n",
      "CALOFZ02  ...            0            0            0            0  \\\n",
      "CALOGA02  ...            0            0            0            0   \n",
      "CALOGB02  ...            0            0            0            0   \n",
      "CALOGC02  ...            0            0            0            0   \n",
      "CALOGD02  ...            0            0            0            0   \n",
      "...       ...          ...          ...          ...          ...   \n",
      "S65       ...            0            0            0            0   \n",
      "S7        ...            0            0            0            0   \n",
      "S71       ...            0            0            0            0   \n",
      "S72       ...            0            0            0            0   \n",
      "Si1       ...            0            0            0            0   \n",
      "\n",
      "item      GC_00038549  GC_00038550  GC_00038551  GC_00038554  GC_00038559   \n",
      "layer                                                                       \n",
      "CALOFZ02            0            0            0            0            0  \\\n",
      "CALOGA02            0            0            0            0            0   \n",
      "CALOGB02            0            0            0            0            0   \n",
      "CALOGC02            0            0            0            0            0   \n",
      "CALOGD02            0            0            0            0            0   \n",
      "...               ...          ...          ...          ...          ...   \n",
      "S65                 0            0            0            0            0   \n",
      "S7                  0            0            0            0            0   \n",
      "S71                 0            0            0            0            0   \n",
      "S72                 0            0            0            0            0   \n",
      "Si1                 0            0            0            0            0   \n",
      "\n",
      "item      GC_00038560  \n",
      "layer                  \n",
      "CALOFZ02            0  \n",
      "CALOGA02            0  \n",
      "CALOGB02            0  \n",
      "CALOGC02            0  \n",
      "CALOGD02            0  \n",
      "...               ...  \n",
      "S65                 0  \n",
      "S7                  0  \n",
      "S71                 0  \n",
      "S72                 0  \n",
      "Si1                 0  \n",
      "\n",
      "[1260 rows x 37060 columns]\n"
     ]
    }
   ],
   "source": [
    "print (gene_cluster_presence_absence)\n",
    "sphingo_list = list(taxa_df[taxa_df.loc[:, 1] == 'Sphingomonadaceae'].index)\n",
    "non_sphingo_list = [x for x in taxa_df.index if x not in sphingo_list]\n",
    "sphingo_list = [x for x in sphingo_list if x in gene_cluster_presence_absence.index]\n",
    "non_sphingo_list = [x for x in non_sphingo_list if x in gene_cluster_presence_absence.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dict_CAZy_reformat = {}\n",
    "for entry in annotation_dict_CAZy.keys():\n",
    "    if annotation_dict_CAZy[entry] != []:\n",
    "        if len(Counter(annotation_dict_CAZy[entry])) == 1:\n",
    "            annotation_dict_CAZy_reformat[entry] = Counter(annotation_dict_CAZy[entry]).most_common(1)[0][0]\n",
    "        else:\n",
    "            annotation_dict_CAZy_reformat[entry] = Counter(annotation_dict_CAZy[entry]).most_common(1)[0][0]\n",
    "\n",
    "annotation_dict_KEGG_reformat = {}\n",
    "for entry in annotation_dict_KEGG.keys():\n",
    "    if annotation_dict_KEGG[entry] != []:\n",
    "        if len(Counter(annotation_dict_KEGG[entry])) == 1:\n",
    "            annotation_dict_KEGG_reformat[entry] = Counter(annotation_dict_KEGG[entry]).most_common(1)[0][0]\n",
    "        else:\n",
    "            annotation_dict_KEGG_reformat[entry] = Counter(annotation_dict_KEGG[entry]).most_common(1)[0][0]\n",
    "\n",
    "annotation_dict_COG_reformat = {}\n",
    "for entry in annotation_dict_COG.keys():\n",
    "    if annotation_dict_COG[entry] != []:\n",
    "        if len(Counter(annotation_dict_COG[entry])) == 1:\n",
    "            annotation_dict_COG_reformat[entry] = Counter(annotation_dict_COG[entry]).most_common(1)[0][0]\n",
    "        else:\n",
    "            annotation_dict_COG_reformat[entry] = Counter(annotation_dict_COG[entry]).most_common(1)[0][0]\n",
    "\n",
    "annotation_dict_PFAM_reformat = {}\n",
    "for entry in annotation_dict_PFAM.keys():\n",
    "    if annotation_dict_PFAM[entry] != []:\n",
    "        if len(Counter(annotation_dict_PFAM[entry])) == 1:\n",
    "            annotation_dict_PFAM_reformat[entry] = Counter(annotation_dict_PFAM[entry]).most_common(1)[0][0]\n",
    "        else:\n",
    "            annotation_dict_PFAM_reformat[entry] = Counter(annotation_dict_PFAM[entry]).most_common(1)[0][0]\n",
    "\n",
    "annotation_dict_description_reformat = {}\n",
    "for entry in annotation_dict_description.keys():\n",
    "    if annotation_dict_description[entry] != []:\n",
    "        if len(Counter(annotation_dict_description[entry])) == 1:\n",
    "            annotation_dict_description_reformat[entry] = Counter(annotation_dict_description[entry]).most_common(1)[0][0]\n",
    "        else:\n",
    "            annotation_dict_description_reformat[entry] = Counter(annotation_dict_description[entry]).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer\n",
      "CALOFZ02    4631\n",
      "CALOGA02    3356\n",
      "CALOGB02    3305\n",
      "CALOGC02    4729\n",
      "CALOGD02    4700\n",
      "            ... \n",
      "S65         1760\n",
      "S7          1850\n",
      "S71         1850\n",
      "S72         1950\n",
      "Si1         1699\n",
      "Length: 1260, dtype: int64\n",
      "455 805\n",
      "         sphingo_norm  non_sphingo_norm  sphingo  non_sphingo\n",
      "GH31         3.760440          2.008696   1711.0       1617.0\n",
      "GT4          7.969231          4.332919   3626.0       3488.0\n",
      "GT28         2.863736          1.711801   1303.0       1378.0\n",
      "GH3          7.485714          3.385093   3406.0       2725.0\n",
      "CE10         3.400000          0.879503   1547.0        708.0\n",
      "...               ...               ...      ...          ...\n",
      "GT8          0.046154          0.000000     21.0          0.0\n",
      "GT14         0.081319          0.000000     37.0          0.0\n",
      "GT81         0.000000          0.040994      0.0         33.0\n",
      "GH33         0.006593          0.021118      3.0         17.0\n",
      "GT4,GT9      0.109890          0.000000     50.0          0.0\n",
      "\n",
      "[84 rows x 4 columns]\n",
      "SignificanceResult(statistic=1.3986986832713522, pvalue=4.068673460189165e-21)\n",
      "[[1711.0, 1617.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.3741542959180226, pvalue=3.348541001368815e-37)\n",
      "[[3626.0, 3488.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.2499118185230456, pvalue=1.6584373264907607e-08)\n",
      "[[1303.0, 1378.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.6521988419271607, pvalue=8.018376980787265e-79)\n",
      "[[3406.0, 2725.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.8882928983154894, pvalue=6.603623119358295e-128)\n",
      "[[1547.0, 708.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=4.383985660358917e-19)\n",
      "[[0.0, 76.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=1.6666651921056372e-08)\n",
      "[[0.0, 32.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.43527537308524467, pvalue=5.99016376831457e-46)\n",
      "[[353.0, 1072.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.48289207734224143, pvalue=1.2811869192897777e-10)\n",
      "[[99.0, 271.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.1870615549578365, pvalue=0.00044353449469931633)\n",
      "[[819.0, 912.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.6261423586590786, pvalue=2.5744779402521664e-62)\n",
      "[[1926.0, 4066.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.848325928413316, pvalue=8.988200609164738e-09)\n",
      "[[2148.0, 3347.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.3462945606419363, pvalue=3.0473112180846656e-14)\n",
      "[[213.0, 120.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.6624650872169503, pvalue=2.07396360473812e-12)\n",
      "[[431.0, 860.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.5049172915022364, pvalue=3.993612471770661e-27)\n",
      "[[379.0, 200.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.6361443026242593, pvalue=7.562302114693066e-77)\n",
      "[[1045.0, 524.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.00232721142694102, pvalue=2.8277463946497848e-136)\n",
      "[[1.0, 568.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.007468113505663838, pvalue=6.986679305342875e-83)\n",
      "[[2.0, 354.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.008650890644649864, pvalue=9.818770569229186e-176)\n",
      "[[5.0, 764.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.34270343087101834, pvalue=3.6078868372480046e-13)\n",
      "[[49.0, 189.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=3.0339002623773826e-41)\n",
      "[[0.0, 166.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.4749131115080518, pvalue=4.833101353381413e-08)\n",
      "[[424.0, 380.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=3.1444152455892787, pvalue=2.462296304512476e-16)\n",
      "[[157.0, 66.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=4.595661945479278, pvalue=1.536490000518046e-233)\n",
      "[[1714.0, 493.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.22781487732107203, pvalue=7.5528778214825e-49)\n",
      "[[86.0, 499.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.2294682992308192, pvalue=0.006366130028538014)\n",
      "[[346.0, 372.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.4877536846670391, pvalue=1.322882580771352e-69)\n",
      "[[783.0, 2122.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.247155353854249, pvalue=0.05019365930126614)\n",
      "[[17.0, 10.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.3218560905024994, pvalue=0.18455308932660336)\n",
      "[[49.0, 49.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=2.6930380436057554e-27)\n",
      "[[0.0, 109.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.5421654389195825, pvalue=1.584354261806498e-07)\n",
      "[[322.0, 276.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.0574848724019994, pvalue=0.7135146711569798)\n",
      "[[84.0, 105.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.32454778692644487, pvalue=7.399463895539187e-78)\n",
      "[[288.0, 1173.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=9.294994061857482e-09)\n",
      "[[0.0, 33.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=5.202990342103958e-09)\n",
      "[[0.0, 34.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.8199596597386654, pvalue=3.563466098932057e-17)\n",
      "[[192.0, 90.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=inf, pvalue=1.3875691042181627e-25)\n",
      "[[68.0, 0.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.9381118799679445, pvalue=0.06861508894839166)\n",
      "[[1479.0, 2084.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=7.52500963732715e-48)\n",
      "[[0.0, 194.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.123159368037725, pvalue=0.05291810643904457)\n",
      "[[537.0, 632.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.1903219277408565, pvalue=3.122261714827463e-37)\n",
      "[[686.0, 414.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.6561731672278593, pvalue=0.003975859409169636)\n",
      "[[69.0, 139.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.004496109151369046, pvalue=3.1480769376277524e-139)\n",
      "[[2.0, 588.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.2992881714345281, pvalue=3.956352327941195e-09)\n",
      "[[24.0, 106.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=6.205335319671421e-07)\n",
      "[[0.0, 26.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=1.0751009709778008e-20)\n",
      "[[0.0, 82.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0045818235372703615, pvalue=1.3631720125155083e-136)\n",
      "[[2.0, 577.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.7546228256125379, pvalue=0.005929153652917877)\n",
      "[[149.0, 261.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.2807316787979772, pvalue=0.00025835413902585287)\n",
      "[[436.0, 450.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.416702906070759, pvalue=3.447785654627391e-65)\n",
      "[[1022.0, 559.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.1865288715078934, pvalue=6.097654246394024e-13)\n",
      "[[220.0, 133.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.008473436477580124, pvalue=9.654311115702203e-37)\n",
      "[[1.0, 156.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.002443356914052679, pvalue=1.5127423910150918e-257)\n",
      "[[2.0, 1082.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.24403497055430756, pvalue=3.727462164698029e-07)\n",
      "[[12.0, 65.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=inf, pvalue=9.062778434396446e-51)\n",
      "[[137.0, 0.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.47653119250090104, pvalue=1.1179219656751393e-12)\n",
      "[[115.0, 319.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=1.3231842769053232e-14)\n",
      "[[0.0, 57.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=9.294994061857482e-09)\n",
      "[[0.0, 33.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.4695228970090848, pvalue=6.733985219862092e-11)\n",
      "[[617.0, 555.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.31260110248369916, pvalue=1.098466074787877e-11)\n",
      "[[35.0, 148.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0067099293934137026, pvalue=1.0055721865088392e-46)\n",
      "[[1.0, 197.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.014122394129300206, pvalue=4.2892907305604124e-105)\n",
      "[[5.0, 468.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=1.3201922113630887e-23)\n",
      "[[0.0, 94.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=2.643712181004999, pvalue=3.0293865408426337e-05)\n",
      "[[52.0, 26.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.156624079189687, pvalue=0.603208933469552)\n",
      "[[28.0, 32.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=3.0938713479983386e-41)\n",
      "[[0.0, 167.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=1.4643546316922432e-13)\n",
      "[[0.0, 53.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=1.1042056364700888e-11)\n",
      "[[0.0, 45.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.38453995360072707, pvalue=3.9487817699617994e-07)\n",
      "[[32.0, 110.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.25348422375237, pvalue=0.0008131709721922982)\n",
      "[[440.0, 464.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=4.3476337032161e-14)\n",
      "[[0.0, 55.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=17.62474787336666, pvalue=9.677185928413761e-23)\n",
      "[[80.0, 6.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=1.8440127668219919, pvalue=4.577416262042639e-15)\n",
      "[[392.0, 281.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=inf, pvalue=1.2825446844906098e-33)\n",
      "[[90.0, 0.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=25.776193764798737, pvalue=1.5108573723359014e-12)\n",
      "[[39.0, 2.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=3.4200441183808943e-16)\n",
      "[[0.0, 64.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=6.526684671365131e-11)\n",
      "[[0.0, 42.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=2.215435910071532e-24)\n",
      "[[0.0, 97.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=5.202990342103958e-09)\n",
      "[[0.0, 34.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=inf, pvalue=2.0861059667284032e-08)\n",
      "[[21.0, 0.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=inf, pvalue=2.949896013366326e-14)\n",
      "[[37.0, 0.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.0, pvalue=9.294994061857482e-09)\n",
      "[[0.0, 33.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=0.23326872185338224, pvalue=0.011782529715955036)\n",
      "[[3.0, 17.0], [30408.0, 40195.0]]\n",
      "SignificanceResult(statistic=inf, pvalue=5.231110927078918e-19)\n",
      "[[50.0, 0.0], [30408.0, 40195.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vtracann/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sphingo_cazymes = {k: 0 for k in annotation_dict_CAZy_reformat.values()}\n",
    "non_sphingo_cazymes = {k: 0 for k in annotation_dict_CAZy_reformat.values()}\n",
    "sphingo_cazymes_per1k = {k: 0 for k in annotation_dict_CAZy_reformat.values()}\n",
    "non_sphingo_cazymes_per1k = {k: 0 for k in annotation_dict_CAZy_reformat.values()}\n",
    "\n",
    "genes_per_genome = gene_cluster_presence_absence.sum(axis=1)\n",
    "print (genes_per_genome)\n",
    "\n",
    "for genome in sphingo_list:\n",
    "    # get the index of the nonzero values for the genome\n",
    "    nonzero_clusters = gene_cluster_presence_absence.loc[genome, :].to_numpy().nonzero()\n",
    "    nonzero_clusters = gene_cluster_presence_absence.columns[nonzero_clusters]\n",
    "    for cluster in nonzero_clusters:\n",
    "        if cluster in annotation_dict_CAZy_reformat.keys():\n",
    "            sphingo_cazymes_per1k[annotation_dict_CAZy_reformat[cluster]] += (1*1000)/genes_per_genome[genome]\n",
    "            sphingo_cazymes[annotation_dict_CAZy_reformat[cluster]] += 1\n",
    "\n",
    "for genome in non_sphingo_list:\n",
    "    # get the index of the nonzero values for the genome\n",
    "    nonzero_clusters = gene_cluster_presence_absence.loc[genome, :].to_numpy().nonzero()\n",
    "    nonzero_clusters = gene_cluster_presence_absence.columns[nonzero_clusters]\n",
    "    for cluster in nonzero_clusters:\n",
    "        if cluster in annotation_dict_CAZy_reformat.keys():\n",
    "            non_sphingo_cazymes[annotation_dict_CAZy_reformat[cluster]] += 1\n",
    "            non_sphingo_cazymes_per1k[annotation_dict_CAZy_reformat[cluster]] += (1*1000)/genes_per_genome[genome]\n",
    "\n",
    "print (len(sphingo_list), len(non_sphingo_list))\n",
    "\n",
    "norm_sphingo_cazymes = pd.Series(sphingo_cazymes)/len(sphingo_list)\n",
    "norm_non_sphingo_cazymes = pd.Series(non_sphingo_cazymes)/len(non_sphingo_list)\n",
    "\n",
    "chisquare_df = pd.DataFrame([sphingo_cazymes, non_sphingo_cazymes], index=['sphingo', 'non_sphingo'])\n",
    "\n",
    "norm_df = pd.DataFrame([norm_sphingo_cazymes, norm_non_sphingo_cazymes, pd.Series(sphingo_cazymes), pd.Series(non_sphingo_cazymes)], index=['sphingo_norm', 'non_sphingo_norm', 'sphingo', 'non_sphingo']).transpose()\n",
    "print (norm_df)\n",
    "\n",
    "for cazyme in norm_df.index:\n",
    "    fisher_exact = stats.fisher_exact([[norm_df.loc[cazyme, 'sphingo'], norm_df.loc[cazyme, 'non_sphingo']], [norm_df.loc[:, 'sphingo'].sum(), norm_df.loc[:, 'non_sphingo'].sum()]])\n",
    "    print (fisher_exact)\n",
    "    print ([[norm_df.loc[cazyme, 'sphingo'], norm_df.loc[cazyme, 'non_sphingo']], [norm_df.loc[:, 'sphingo'].sum(), norm_df.loc[:, 'non_sphingo'].sum()]])\n",
    "    norm_df.loc[cazyme, 'fisher_odds_ratio'] = fisher_exact[0]\n",
    "    norm_df.loc[cazyme, 'fisher_pvalue'] = fisher_exact[1]\n",
    "\n",
    "adj_pval = multipletests(norm_df.loc[:, 'fisher_pvalue'], alpha=0.05, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "norm_df.loc[:, 'fisher_adj_pval'] = adj_pval[1]\n",
    "\n",
    "norm_df.loc[:, 'log2FoldChange'] = np.log2(norm_df.loc[:, 'sphingo_norm'])-np.log2(norm_df.loc[:, 'non_sphingo_norm'])\n",
    "norm_df.loc[:, 'total'] = norm_df.loc[:, 'sphingo'] + norm_df.loc[:, 'non_sphingo']\n",
    "\n",
    "for cazyme in norm_df.index:\n",
    "    if norm_df.loc[cazyme, 'fisher_adj_pval'] < 0.05 and norm_df.loc[cazyme, 'log2FoldChange'] > 1.5:\n",
    "        if norm_df.loc[cazyme, 'fisher_odds_ratio'] > 1:\n",
    "            norm_df.loc[cazyme, 'enrichment'] = 'enriched'\n",
    "    elif norm_df.loc[cazyme, 'fisher_adj_pval'] < 0.05 and norm_df.loc[cazyme, 'log2FoldChange'] < -1.5:\n",
    "        if norm_df.loc[cazyme, 'fisher_odds_ratio'] < 1:\n",
    "            norm_df.loc[cazyme, 'enrichment'] = 'depleted'\n",
    "    else:\n",
    "        norm_df.loc[cazyme, 'enrichment'] = 'neutral'\n",
    "\n",
    "#print (stats.chisquare(chisquare_df.iloc[0, :], chisquare_df.iloc[1, :]))\n",
    "\n",
    "#print (stats.chisquare(list(sphingo_cazymes.values()), list(non_sphingo_cazymes.values())))\n",
    "\n",
    "#print (stats.ttest_ind(annotation_dict_CAZy_reformat[sphingo_list], annotation_dict_CAZy_reformat[non_sphingo_list]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.scatterplot(data=norm_df, x='sphingo_norm', y='non_sphingo_norm', size='total', hue='enrichment', sizes=(10, 100))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()\n",
    "\n",
    "norm_df.to_csv('cazymes_norm2_df.tsv', sep='\\t')\n",
    "\n",
    "#fig = visuz.GeneExpression.volcano(df=norm_df, lfc='log2FoldChange', pv='fisher_adj_pval', lfc_thr=(1.5,1.5), sign_line=True, figtype='pdf', figname='cazymes_volcano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('{}cazyme_per_genome.tsv'.format(output_dir)):\n",
    "    cazyme_per_genome = pd.DataFrame(0, index=gene_cluster_presence_absence.index, columns=list(set(annotation_dict_CAZy_reformat.values())))\n",
    "\n",
    "    for genome in sphingo_list:\n",
    "        for GC in gene_cluster_presence_absence.columns:\n",
    "            if gene_cluster_presence_absence.loc[genome, GC] == 1:\n",
    "                if GC in annotation_dict_CAZy_reformat.keys():\n",
    "                    cazyme = annotation_dict_CAZy_reformat[GC]\n",
    "                    if cazyme != '-':\n",
    "                        if ',' in cazyme:\n",
    "                            try:\n",
    "                                for caz in cazyme.split(','):\n",
    "                                    cazyme_per_genome.loc[genome, caz] += 1\n",
    "                            except KeyError:\n",
    "                                cazyme_per_genome.loc[genome, cazyme] += 1\n",
    "                        else:\n",
    "                            cazyme_per_genome.loc[genome, cazyme] += 1\n",
    "\n",
    "    for genome in non_sphingo_list:\n",
    "        for GC in gene_cluster_presence_absence.columns:\n",
    "            if gene_cluster_presence_absence.loc[genome, GC] == 1:\n",
    "                if GC in annotation_dict_CAZy_reformat.keys():\n",
    "                    cazyme = annotation_dict_CAZy_reformat[GC]\n",
    "                    if cazyme != '-':\n",
    "                        if ',' in cazyme:\n",
    "                            try:\n",
    "                                for caz in cazyme.split(','):\n",
    "                                    cazyme_per_genome.loc[genome, caz] += 1\n",
    "                            except KeyError:\n",
    "                                cazyme_per_genome.loc[genome, cazyme] += 1\n",
    "                        else:\n",
    "                            cazyme_per_genome.loc[genome, cazyme] += 1\n",
    "\n",
    "\n",
    "    cazyme_per_genome.to_csv('{}cazyme_per_genome.tsv'.format(output_dir), sep='\\t')\n",
    "else:\n",
    "    cazyme_per_genome = pd.read_csv('{}cazyme_per_genome.tsv'.format(output_dir), sep='\\t', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns with all zeros from cazyme_per_genome\n",
    "cazyme_per_genome = cazyme_per_genome.loc[:, (cazyme_per_genome != 0).any(axis=0)]\n",
    "\n",
    "#print (cazyme_per_genome)\n",
    "\n",
    "wilcoxon_ranksum_df = pd.DataFrame(0, index=cazyme_per_genome.columns, columns=['sphingo_average', 'non_sphingo_average', 'pvalue', 'adj_pval' ,'enrichment'])\n",
    "\n",
    "for cazyme in cazyme_per_genome.columns:\n",
    "    wilcoxon_ranksum_df.loc[cazyme, 'sphingo_average'] = cazyme_per_genome.loc[sphingo_list, cazyme].mean()\n",
    "    wilcoxon_ranksum_df.loc[cazyme, 'non_sphingo_average'] = cazyme_per_genome.loc[non_sphingo_list, cazyme].mean()\n",
    "    wilcoxon_ranksum_df.loc[cazyme, 'pvalue'] = stats.mannwhitneyu(cazyme_per_genome.loc[sphingo_list, cazyme], cazyme_per_genome.loc[non_sphingo_list, cazyme])[1]\n",
    "    \n",
    "adj_pval = multipletests(wilcoxon_ranksum_df.loc[:, 'pvalue'], alpha=0.05, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "wilcoxon_ranksum_df.loc[:, 'adj_pval'] = adj_pval[1]\n",
    "\n",
    "for cazyme in wilcoxon_ranksum_df.index:\n",
    "    if wilcoxon_ranksum_df.loc[cazyme, 'adj_pval'] < 0.05:\n",
    "        if wilcoxon_ranksum_df.loc[cazyme, 'sphingo_average'] > wilcoxon_ranksum_df.loc[cazyme, 'non_sphingo_average']:\n",
    "            wilcoxon_ranksum_df.loc[cazyme, 'enrichment'] = 'enriched'\n",
    "        elif wilcoxon_ranksum_df.loc[cazyme, 'sphingo_average'] < wilcoxon_ranksum_df.loc[cazyme, 'non_sphingo_average']:\n",
    "            wilcoxon_ranksum_df.loc[cazyme, 'enrichment'] = 'depleted'\n",
    "    else:\n",
    "        wilcoxon_ranksum_df.loc[cazyme, 'enrichment'] = 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sphingo_average</th>\n",
       "      <th>non_sphingo_average</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>adj_pval</th>\n",
       "      <th>enrichment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA10,CBM73,GH5,GH9</th>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>6.702587e-09</td>\n",
       "      <td>5.295043e-07</td>\n",
       "      <td>enriched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH23</th>\n",
       "      <td>0.947253</td>\n",
       "      <td>1.068323</td>\n",
       "      <td>1.600365e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBM42,GH54</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>1.080342e-04</td>\n",
       "      <td>8.534704e-03</td>\n",
       "      <td>depleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH47</th>\n",
       "      <td>0.037363</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>3.335571e-03</td>\n",
       "      <td>2.635101e-01</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GT2</th>\n",
       "      <td>5.008791</td>\n",
       "      <td>6.382609</td>\n",
       "      <td>1.385080e-06</td>\n",
       "      <td>1.094214e-04</td>\n",
       "      <td>depleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH38</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068323</td>\n",
       "      <td>1.205824e-08</td>\n",
       "      <td>9.526012e-07</td>\n",
       "      <td>depleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH57</th>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.039752</td>\n",
       "      <td>8.126769e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH4,GT4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>7.294710e-07</td>\n",
       "      <td>5.762821e-05</td>\n",
       "      <td>depleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GT35</th>\n",
       "      <td>0.958242</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>1.029089e-49</td>\n",
       "      <td>8.129803e-48</td>\n",
       "      <td>enriched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GT21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240994</td>\n",
       "      <td>4.439490e-24</td>\n",
       "      <td>3.507197e-22</td>\n",
       "      <td>depleted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sphingo_average  non_sphingo_average        pvalue   \n",
       "AA10,CBM73,GH5,GH9         0.114286             0.032298  6.702587e-09  \\\n",
       "GH23                       0.947253             1.068323  1.600365e-02   \n",
       "CBM42,GH54                 0.000000             0.032298  1.080342e-04   \n",
       "GH47                       0.037363             0.012422  3.335571e-03   \n",
       "GT2                        5.008791             6.382609  1.385080e-06   \n",
       "...                             ...                  ...           ...   \n",
       "GH38                       0.000000             0.068323  1.205824e-08   \n",
       "GH57                       0.061538             0.039752  8.126769e-02   \n",
       "GH4,GT4                    0.000000             0.052174  7.294710e-07   \n",
       "GT35                       0.958242             0.559006  1.029089e-49   \n",
       "GT21                       0.000000             0.240994  4.439490e-24   \n",
       "\n",
       "                        adj_pval enrichment  \n",
       "AA10,CBM73,GH5,GH9  5.295043e-07   enriched  \n",
       "GH23                1.000000e+00    neutral  \n",
       "CBM42,GH54          8.534704e-03   depleted  \n",
       "GH47                2.635101e-01    neutral  \n",
       "GT2                 1.094214e-04   depleted  \n",
       "...                          ...        ...  \n",
       "GH38                9.526012e-07   depleted  \n",
       "GH57                1.000000e+00    neutral  \n",
       "GH4,GT4             5.762821e-05   depleted  \n",
       "GT35                8.129803e-48   enriched  \n",
       "GT21                3.507197e-22   depleted  \n",
       "\n",
       "[79 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cazyme_per_genome\n",
    "wilcoxon_ranksum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA10,CBM73,GH5,GH9 5.295043478017259e-07 0.11428571428571428 0.03229813664596273\n",
      "CBM42,GH54 0.008534704249334083 0.0 0.03229813664596273\n",
      "GT2 0.00010942135922865592 5.008791208791209 6.3826086956521735\n",
      "GH37 1.3402707068388432e-66 0.8615384615384616 0.3490683229813665\n",
      "GH8 2.469751244554274e-32 0.26593406593406593 0.8037267080745342\n",
      "GH88 0.018588464552890996 0.026373626373626374 0.08074534161490683\n",
      "GH102 1.8398697959392804e-57 0.9318681318681319 0.4720496894409938\n",
      "PL4 2.1510290117136083e-23 0.0 0.2062111801242236\n",
      "GH28 4.217513997337221e-28 0.17582417582417584 0.007453416149068323\n",
      "PL8 0.000961608179582528 0.0 0.040993788819875775\n",
      "GT26 0.004415501514302022 0.2175824175824176 0.33664596273291925\n",
      "GT30 2.414546741214356e-125 0.002197802197802198 0.7055900621118012\n",
      "GH5 2.1114120381145366e-32 2.465934065934066 1.5167701863354037\n",
      "GT19 3.429320148916535e-129 0.004395604395604396 0.7167701863354037\n",
      "GT4 3.12705947624057e-44 8.854945054945055 5.6645962732919255\n",
      "GT5 6.417304942181728e-67 1.3560439560439561 0.6894409937888198\n",
      "GT20 2.0629079065192559e-47 0.967032967032967 0.5763975155279503\n",
      "GT1 3.226578041638048e-45 0.6329670329670329 1.457142857142857\n",
      "CBM48,GH13 4.546261111779303e-19 3.2505494505494505 2.5888198757763976\n",
      "GH15 4.056422789444167e-59 0.004395604395604396 0.43975155279503103\n",
      "GH20 1.5802296626684122e-27 1.1802197802197802 0.7850931677018633\n",
      "GT73 0.02777460971844411 0.07032967032967033 0.13664596273291926\n",
      "GH105 4.907934437054343e-19 0.4835164835164835 0.16521739130434782\n",
      "GT9 4.274465502897677e-36 0.11428571428571428 0.7304347826086957\n",
      "GH43 4.308402299274977e-140 4.474725274725275 0.9552795031055901\n",
      "GH29 5.7573237289170985e-96 2.2967032967032965 0.6509316770186335\n",
      "GH26 4.8217256763983836e-33 0.46813186813186813 0.14906832298136646\n",
      "GT8 6.355790625606144e-08 0.046153846153846156 0.0\n",
      "GH3 1.8452125951771008e-109 7.485714285714286 3.3850931677018634\n",
      "GH13 6.041613119361571e-29 1.7230769230769232 2.8807453416149067\n",
      "GT56 0.0007038247519951759 0.0 0.0422360248447205\n",
      "GT89 0.0013136780397420814 0.0 0.03975155279503106\n",
      "GH18 6.114804779785769e-34 0.3120879120879121 0.9490683229813665\n",
      "GH5,GH9 6.673037736493556e-27 1.8 1.132919254658385\n",
      "AA10,CBM73 1.762779385124869e-14 0.0 0.13540372670807455\n",
      "GH30 1.0228501135785242e-28 0.0 0.2732919254658385\n",
      "GH30,GH5,GH9 1.7971630639350338e-06 0.0 0.06583850931677018\n",
      "CE1 1.2988952442482073e-167 2.3956043956043955 0.6944099378881987\n",
      "CBM20,GH13 5.6146886784734986e-05 0.25274725274725274 0.39627329192546584\n",
      "CBM50 2.2462244964108263e-05 0.0 0.055900621118012424\n",
      "GH95 3.771482549544025e-22 0.7604395604395604 0.462111801242236\n",
      "GH68 0.007273290687544094 0.1978021978021978 0.11677018633540373\n",
      "CE10 3.0998150029344977e-133 3.4 0.8795031055900621\n",
      "GH94,GT84 5.373165795349375e-08 0.0 0.07950310559006211\n",
      "GT14 1.765360057143852e-14 0.08131868131868132 0.0\n",
      "GH51 2.215634438526031e-84 2.2153846153846155 0.8571428571428571\n",
      "GH103 7.578644674236864e-105 0.004395604395604396 1.3440993788819875\n",
      "GH5,GH8,GH9 1.8291445386302503e-05 0.07692307692307693 0.18385093167701863\n",
      "GH19 1.0311564387949052e-38 0.01098901098901099 0.5813664596273292\n",
      "GH121 0.0007038247519951759 0.0 0.0422360248447205\n",
      "CE1,GH5,GH9 1.4200997669627206e-27 0.14945054945054945 0.0\n",
      "GH31 7.076159125620435e-92 3.7604395604395604 2.008695652173913\n",
      "GH77 3.239474932629465e-31 0.8351648351648352 0.493167701863354\n",
      "GT39 5.790813014326496e-35 0.421978021978022 0.11180124223602485\n",
      "GT28 9.848967162385278e-183 2.8637362637362638 1.711801242236025\n",
      "GT87 0.0017970375698313687 0.0 0.09440993788819876\n",
      "GH16 5.041978889887657e-07 0.0 0.07080745341614907\n",
      "PL11 5.761649849879957e-30 0.34505494505494505 0.08198757763975155\n",
      "GH18,GH5,GH9 6.692965454475328e-45 0.3010989010989011 0.0\n",
      "GH5,GH6,GH9 1.0283963230852409e-13 0.08571428571428572 0.002484472049689441\n",
      "GH65 8.159320912848989e-18 0.002197802197802198 0.1937888198757764\n",
      "GH32 0.0038579584235154682 0.5252747252747253 0.3242236024844721\n",
      "GT85 0.000961608179582528 0.0 0.040993788819875775\n",
      "GH39 1.0431604066514356e-12 0.0 0.12049689440993788\n",
      "GT81 0.000961608179582528 0.0 0.040993788819875775\n",
      "GH94,GT36 1.5417225709977905e-10 0.0 0.10186335403726708\n",
      "GH38 9.526012091455485e-07 0.0 0.06832298136645963\n",
      "GH4,GT4 5.762820963667996e-05 0.0 0.05217391304347826\n",
      "GT35 8.129803372246498e-48 0.9582417582417583 0.5590062111801242\n",
      "GT21 3.5071973867661334e-22 0.0 0.24099378881987576\n"
     ]
    }
   ],
   "source": [
    "wilcoxon_ranksum_df\n",
    "\n",
    "for cazyme in cazyme_per_genome.columns:\n",
    "    if wilcoxon_ranksum_df.loc[cazyme, 'enrichment'] == 'enriched':\n",
    "        print (cazyme, wilcoxon_ranksum_df.loc[cazyme, 'adj_pval'], cazyme_per_genome.loc[sphingo_list, cazyme].mean(), cazyme_per_genome.loc[non_sphingo_list, cazyme].mean())\n",
    "        if not os.path.isfile('{}plots/cazymes/enriched_{}.pdf'.format(output_dir, cazyme)):\n",
    "            plotting_data = pd.DataFrame(pd.concat([cazyme_per_genome.loc[sphingo_list, cazyme], cazyme_per_genome.loc[non_sphingo_list, cazyme]], axis=0))\n",
    "            plotting_data.columns = ['cazyme per genome']\n",
    "            T = ['sphingo'] * len(sphingo_list) + ['non_sphingo'] * len(non_sphingo_list)\n",
    "            plotting_data.loc[:, 'taxa'] = T\n",
    "            \n",
    "            #vertical stacked histogram\n",
    "            g = sns.FacetGrid(plotting_data, row='taxa', sharex=True, sharey=True, hue='taxa', palette='Set1', height=5, aspect=1.5, margin_titles=True)\n",
    "            g.map(sns.histplot, 'cazyme per genome', bins=max(plotting_data.loc[:, 'cazyme per genome'])+1, discrete=True, shrink=0.9)\n",
    "            g.axes.flat[0].axvline(cazyme_per_genome.loc[sphingo_list, cazyme].mean(), ls='--', color='black', lw=3)\n",
    "            g.axes.flat[1].axvline(cazyme_per_genome.loc[non_sphingo_list, cazyme].mean(), ls='--', color='black', lw=3)\n",
    "            #set the xtixks to be integers\n",
    "            for ax in g.axes.flat:\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            #set cazyme as title\n",
    "            g.fig.subplots_adjust(top=0.9)\n",
    "            g.fig.suptitle('{}'.format(cazyme), fontsize=16)\n",
    "\n",
    "        \n",
    "            plt.savefig('{}plots/cazymes/enriched_{}.pdf'.format(output_dir, cazyme), bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "    elif wilcoxon_ranksum_df.loc[cazyme, 'enrichment'] == 'depleted':\n",
    "        print (cazyme, wilcoxon_ranksum_df.loc[cazyme, 'adj_pval'], cazyme_per_genome.loc[sphingo_list, cazyme].mean(), cazyme_per_genome.loc[non_sphingo_list, cazyme].mean())\n",
    "        if not os.path.isfile('{}plots/cazymes/depleted_{}.pdf'.format(output_dir, cazyme)):\n",
    "\n",
    "            plotting_data = pd.DataFrame(pd.concat([cazyme_per_genome.loc[sphingo_list, cazyme], cazyme_per_genome.loc[non_sphingo_list, cazyme]], axis=0))\n",
    "            plotting_data.columns = ['cazyme per genome']\n",
    "            T = ['sphingo'] * len(sphingo_list) + ['non_sphingo'] * len(non_sphingo_list)\n",
    "            plotting_data.loc[:, 'taxa'] = T\n",
    "\n",
    "            #vertical stacked histogram\n",
    "            g = sns.FacetGrid(plotting_data, row='taxa', sharex=True, sharey=True, hue='taxa', palette='Set1', height=5, aspect=1.5, margin_titles=True)\n",
    "            g.map(sns.histplot, 'cazyme per genome', bins=max(plotting_data.loc[:, 'cazyme per genome'])+1, discrete=True, shrink=0.9)\n",
    "            g.axes.flat[0].axvline(cazyme_per_genome.loc[sphingo_list, cazyme].mean(), ls='--', color='black', lw=3)\n",
    "            g.axes.flat[1].axvline(cazyme_per_genome.loc[non_sphingo_list, cazyme].mean(), ls='--', color='black', lw=3)\n",
    "            #set the xtixks to be integers\n",
    "            for ax in g.axes.flat:\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            #set cazyme as title\n",
    "            g.fig.subplots_adjust(top=0.9)\n",
    "            g.fig.suptitle('{}'.format(cazyme), fontsize=16)\n",
    "\n",
    "            plt.savefig('{}plots/cazymes/depleted_{}.pdf'.format(output_dir, cazyme), bbox_inches='tight')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA_RAID2/vtracann/shared/db/isolates/parsed_dbs/kegg_per_genome.tsv already exists\n"
     ]
    }
   ],
   "source": [
    "#repeat cazyme analysis for KEGG\n",
    "if not os.path.isfile('{}parsed_dbs/kegg_per_genome.tsv'.format(output_dir)):\n",
    "    kegg_per_genome.to_csv('{}parsed_dbs/kegg_per_genome.tsv'.format(output_dir), sep='\\t')\n",
    "\n",
    "    kegg_per_genome = pd.DataFrame(0, index=gene_cluster_presence_absence.index, columns=list(set(annotation_dict_KEGG_reformat.values())))\n",
    "    for genome in sphingo_list:\n",
    "        for GC in gene_cluster_presence_absence.columns:\n",
    "            if gene_cluster_presence_absence.loc[genome, GC] == 1:\n",
    "                if GC in annotation_dict_KEGG_reformat.keys():\n",
    "                    kegg = annotation_dict_KEGG_reformat[GC]\n",
    "                    if kegg != '-':\n",
    "                        if ',' in kegg:\n",
    "                            try:\n",
    "                                for k in kegg.split(','):\n",
    "                                    kegg_per_genome.loc[genome, k] += 1\n",
    "                            except KeyError:\n",
    "                                kegg_per_genome.loc[genome, kegg] += 1\n",
    "                        else:\n",
    "                            kegg_per_genome.loc[genome, kegg] += 1\n",
    "\n",
    "\n",
    "    for genome in non_sphingo_list:\n",
    "        for GC in gene_cluster_presence_absence.columns:\n",
    "            if gene_cluster_presence_absence.loc[genome, GC] == 1:\n",
    "                if GC in annotation_dict_KEGG_reformat.keys():\n",
    "                    kegg = annotation_dict_KEGG_reformat[GC]\n",
    "                    if kegg != '-':\n",
    "                        if ',' in kegg:\n",
    "                            try:\n",
    "                                for k in kegg.split(','):\n",
    "                                    kegg_per_genome.loc[genome, k] += 1\n",
    "                            except KeyError:\n",
    "                                kegg_per_genome.loc[genome, kegg] += 1\n",
    "                        else:\n",
    "                            kegg_per_genome.loc[genome, kegg]  += 1\n",
    "\n",
    "    print (kegg_per_genome)\n",
    "    \n",
    "else:\n",
    "    print ('{}parsed_dbs/kegg_per_genome.tsv already exists'.format(output_dir))\n",
    "    kegg_per_genome = pd.read_csv('{}parsed_dbs/kegg_per_genome.tsv'.format(output_dir), sep='\\t', index_col=0)\n",
    "\n",
    "kegg_per_genome_sum = kegg_per_genome.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vtracann/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     sphingo_norm  non_sphingo_norm  sphingo  non_sphingo   \n",
      "ko:K10564                0.000000          0.094410      0.0         76.0  \\\n",
      "ko:K00493                0.936264          0.416149    426.0        335.0   \n",
      "ko:K07643,ko:K07645      0.000000          0.042236      0.0         34.0   \n",
      "ko:K06183                0.000000          0.840994      0.0        677.0   \n",
      "ko:K20331                0.000000          0.109317      0.0         88.0   \n",
      "...                           ...               ...      ...          ...   \n",
      "ko:K10943                0.927473          0.360248    422.0        290.0   \n",
      "ko:K03564                0.890110          1.062112    405.0        855.0   \n",
      "ko:K14051                0.000000          0.055901      0.0         45.0   \n",
      "ko:K18138                1.345055          2.309317    612.0       1859.0   \n",
      "ko:K05396                0.004396          0.515528      2.0        415.0   \n",
      "\n",
      "                     fisher_odds_ratio  fisher_pvalue  fisher_adj_pval   \n",
      "ko:K10564                     0.000000   2.802444e-14     1.505473e-10  \\\n",
      "ko:K00493                     2.469001   2.930321e-35     1.574168e-31   \n",
      "ko:K07643,ko:K07645           0.000000   1.237555e-06     6.648147e-03   \n",
      "ko:K06183                     0.000000  1.084387e-122    5.825330e-119   \n",
      "ko:K20331                     0.000000   2.539933e-16     1.364452e-12   \n",
      "...                                ...            ...              ...   \n",
      "ko:K10943                     2.825341   5.373378e-43     2.886579e-39   \n",
      "ko:K03564                     0.919698   1.712513e-01     1.000000e+00   \n",
      "ko:K14051                     0.000000   9.917286e-09     5.327566e-05   \n",
      "ko:K18138                     0.639188   3.613105e-23     1.940960e-19   \n",
      "ko:K05396                     0.009357   1.850427e-71     9.940491e-68   \n",
      "\n",
      "                     log2FoldChange   total  \n",
      "ko:K10564                      -inf    76.0  \n",
      "ko:K00493                  1.169815   761.0  \n",
      "ko:K07643,ko:K07645            -inf    34.0  \n",
      "ko:K06183                      -inf   677.0  \n",
      "ko:K20331                      -inf    88.0  \n",
      "...                             ...     ...  \n",
      "ko:K10943                  1.364312   712.0  \n",
      "ko:K03564                 -0.254880  1260.0  \n",
      "ko:K14051                      -inf    45.0  \n",
      "ko:K18138                 -0.779801  2471.0  \n",
      "ko:K05396                 -6.873845   417.0  \n",
      "\n",
      "[5372 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "sphingo_kegg = {k: 0 for k in kegg_per_genome_sum.index}\n",
    "non_sphingo_kegg = {k: 0 for k in kegg_per_genome_sum.index}\n",
    "\n",
    "for genome in sphingo_list:\n",
    "    for kegg in kegg_per_genome_sum.index:\n",
    "        sphingo_kegg[kegg] += kegg_per_genome.loc[genome, kegg]\n",
    "\n",
    "for genome in non_sphingo_list:\n",
    "    for kegg in kegg_per_genome_sum.index:\n",
    "        non_sphingo_kegg[kegg] += kegg_per_genome.loc[genome, kegg]\n",
    "\n",
    "norm_sphingo_kegg = pd.Series(sphingo_kegg)/len(sphingo_list)\n",
    "norm_non_sphingo_kegg = pd.Series(non_sphingo_kegg)/len(non_sphingo_list)\n",
    "\n",
    "chisquare_df = pd.DataFrame([sphingo_kegg, non_sphingo_kegg], index=['sphingo', 'non_sphingo'])\n",
    "\n",
    "norm_df = pd.DataFrame([norm_sphingo_kegg, norm_non_sphingo_kegg, pd.Series(sphingo_kegg), pd.Series(non_sphingo_kegg)], index=['sphingo_norm', 'non_sphingo_norm', 'sphingo', 'non_sphingo']).transpose()\n",
    "\n",
    "for kegg in norm_df.index:\n",
    "    #print ([norm_df.loc[kegg, 'sphingo'], norm_df.loc[kegg, 'non_sphingo']], [norm_df.loc[:, 'sphingo'].sum(), norm_df.loc[:, 'non_sphingo'].sum()])\n",
    "    fisher_exact = stats.fisher_exact([[norm_df.loc[kegg, 'sphingo'], norm_df.loc[kegg, 'non_sphingo']], [norm_df.loc[:, 'sphingo'].sum(), norm_df.loc[:, 'non_sphingo'].sum()]])\n",
    "    norm_df.loc[kegg, 'fisher_odds_ratio'] = fisher_exact[0]\n",
    "    norm_df.loc[kegg, 'fisher_pvalue'] = fisher_exact[1]\n",
    "\n",
    "adj_pval = multipletests(norm_df.loc[:, 'fisher_pvalue'], alpha=0.05, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "norm_df.loc[:, 'fisher_adj_pval'] = adj_pval[1]\n",
    "norm_df.loc[:, 'log2FoldChange'] = np.log2(norm_df.loc[:, 'sphingo_norm'])-np.log2(norm_df.loc[:, 'non_sphingo_norm'])\n",
    "norm_df.loc[:, 'total'] = norm_df.loc[:, 'sphingo'] + norm_df.loc[:, 'non_sphingo']\n",
    "\n",
    "print (norm_df)\n",
    "\n",
    "for kegg in norm_df.index:\n",
    "    if norm_df.loc[kegg, 'fisher_adj_pval'] < 0.05:\n",
    "        if norm_df.loc[kegg, 'log2FoldChange'] > 1.5:\n",
    "            norm_df.loc[kegg, 'enrichment'] = 'enriched'\n",
    "        elif norm_df.loc[kegg, 'log2FoldChange'] < -1.5:\n",
    "            norm_df.loc[kegg, 'enrichment'] = 'depleted'\n",
    "        else:\n",
    "            norm_df.loc[kegg, 'enrichment'] = 'neutral'\n",
    "    else:\n",
    "        norm_df.loc[kegg, 'enrichment'] = 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAGxCAYAAACeBVWzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC0f0lEQVR4nOzdd3hU1dbA4d9kMunJhIRUCElogVADoQRQQKqAiKioKIooqCiIgr03FNu1cD9Er4KAiqiggkiVItJD7y2BVAKk92Rmvj+2mTBphDCprPd58sics885e0LuzWLP2mtpTCaTCSGEEEIIIeoZm9qegBBCCCGEEFUhgawQQgghhKiXJJAVQgghhBD1kgSyQgghhBCiXpJAVgghhBBC1EsSyAohhBBCiHpJAlkhhBBCCFEvSSArhBBCCCHqJdvansC1MBqNxMfH4+rqikajqe3pCCGEEKISTCYTGRkZ+Pv7Y2Mja2qi6up1IBsfH09AQEBtT0MIIYQQVRATE0PTpk1rexqiHqvXgayrqyug/ofg5uZWy7MRQgghRGWkp6cTEBBg/j0uRFXV60C2KJ3Azc1NAlkhhBCinpG0QHGtJDFFCCGEEELUSxLICiGEEEKIekkCWSGEEEIIUS/V6xxZIYQQQjRcBoOBgoKC2p6GqGE6nQ6tVlupsRLICiGEEKJOMZlMJCYmkpqaWttTEbXE3d0dX1/fK24IlEBWCCGEEHVKURDr7e2Nk5OTVDe4jphMJrKzs0lKSgLAz8+vwvESyAohhBCizjAYDOYg1tPTs7anI2qBo6MjAElJSXh7e1eYZiCBrBANXUEO5KaBxgacPMGmcnlHQghRG4pyYp2cnGp5JqI2Ff39FxQUSCArxHUpLRaiNkPkt5CwD2xsIWQYtB8Ngb3BQZqICCHqLkknuL5V9u9fAlkhGqLEw7DsETh/0PL4wSXqK2wcDHgNXLxqZ35CCCGEFUgdWSEamoxE+PWx0kHs5fYuhG2fg8lUc/MSQghRJf369WPatGmVGrtx40Y0Gs11U/FBVmSFaGjOboXE/Vcet+2/0HEM+LSv/jkJIYSosqVLl6LT6Wp7GlbRr18/OnfuzCeffGKV+8mKrBANickEB5ZUbqyxEKK3Vu98hBBCVFnRxjcPDw9cXV1reTZ1kwSyQjQk+VkVpxSUlHWh+uYihBDXGZPJxPvvv0/z5s1xdHSkU6dO/Pzzz0DxR/7r168nPDwcJycnevXqxfHjx83Xv/7663Tu3JlvvvmG5s2bY29vj8lkKpVakJeXx7PPPktAQAD29va0atWKr7/+2mIukZGRlXpOs2bNcHFx4bHHHsNgMPD+++/j6+uLt7c377zzjsU909LSmDRpEt7e3ri5uXHTTTexf//+UvdduHAhQUFB6PV67r77bjIyMgAYP348mzZt4tNPP0Wj0aDRaIiOjr6m77kEskI0JFpb0NpVfryNZBcJIYS1vPzyy8ybN485c+Zw+PBhnnrqKe677z42bdpkHvPSSy/x0UcfsXv3bmxtbZkwYYLFPU6dOsWSJUv45Zdf2LdvX5nPuf/++1m8eDGfffYZR48e5YsvvsDFxcVizJWec/r0af78809WrVrFDz/8wDfffMPw4cOJjY1l06ZNzJo1i5dffpnt27cDKkgfPnw4iYmJrFy5ksjISLp06cKAAQNITk62uO+vv/7KihUrWLFiBZs2beK9994D4NNPPyUiIoKJEyeSkJBAQkICAQEBVf5+g+TICtGw2DpAu9vh7w8qN94ntHrnI4QQ14msrCw+/vhj/vrrLyIiIgBo3rw5W7ZsYe7cuUyaNAmAd955h759+wLw/PPPM3z4cHJzc3FwcAAgPz+fhQsX4uVVdlWZEydOsGTJEtauXcvAgQPNzynpSs8xGo188803uLq6EhoaSv/+/Tl+/DgrV67ExsaGkJAQZs2axcaNG+nZsycbNmzg4MGDJCUlYW9vD8CHH37Ir7/+ys8//2x+f0ajkfnz55tTIcaNG8f69et555130Ov12NnZ4eTkhK+v77V/05FAVoiGp9WgygWy+mbQLKL65yOEENeBI0eOkJuby6BBgyyO5+fnExYWZn7dsWNH85+L2q8mJSXRrFkzAAIDA8sNYgH27duHVqs1B6nludJzgoKCLPJufXx80Gq12NjYWBwrahUbGRlJZmZmqW5rOTk5nD592vy65H39/PzM96gOEsgK0dA06QI3vQp/vVn+GBtbuOU/4Ny45uYlhBANmNFoBOCPP/6gSZMmFufs7e3Nwd7l1QeKiv4XXQvg7Oxc4XOK2rdeyZWeU7IKgkajKfNY0TVGoxE/Pz82btxY6lnu7u4V3vfy51qbBLJCNDRaHfR8DJw8YP0bkJNied67HQx+C1oOqJ35CSFEAxQaGoq9vT3nzp0rc7X08lXLa9GhQweMRiObNm0ypxbUhC5dupCYmIitrS1BQUFVvo+dnR0Gg8Fq85JAVoiGyM4Jwh+EVoPh3DZIjwcbLTRuBQE9pT2tEEJYmaurKzNmzOCpp57CaDTSp08f0tPT2bp1Ky4uLgQGBlrlOUFBQTzwwANMmDCBzz77jE6dOnH27FmSkpIYM2aMVZ5RloEDBxIREcGoUaOYNWsWISEhxMfHs3LlSkaNGkV4eHil579jxw6io6NxcXHBw8PDIp3hakkgK0RDpm8CHe6o7VkIIcR14a233sLb25t3332XM2fO4O7uTpcuXXjxxRet+vH6nDlzePHFF5k8eTKXLl2iWbNmvPjii1a7f1k0Gg0rV67kpZdeYsKECVy4cAFfX19uvPFGfHx8Kn2fGTNm8MADDxAaGkpOTg5RUVHXtMKrMZnqb4/K9PR09Ho9aWlpuLnJCpMQQghRH1T0+zs3N5eoqCiCg4PNO+zF9aeyPwdSR1YIIYQQQtRLEsgKIYQQQoh6SQJZIYQQQghRL0kgK4QQQggh6iUJZIUQQgghRL0kgawQQgghhKiXJJAVQgghhBD1kgSyQgghhBCiXpJAVgghhBCimvTr149p06ZZ7X6vv/46nTt3ttr9rkZ0dDQajYZ9+/bVyvPLIoGsEEIIIUQDVReDT2uSQFYIIYQQQtRLEsgKIYQQokEyGE1sO32J3/bFse30JQxGU7U+Lysri/vvvx8XFxf8/Pz46KOPLM7n5+fz7LPP0qRJE5ydnenRowcbN240n58/fz7u7u78+uuvtG7dGgcHBwYNGkRMTEyFz503bx5t27bFwcGBNm3a8H//93/mc8HBwQCEhYWh0Wjo169fpa4D2LlzJ2FhYTg4OBAeHs7evXur+J2pPra1PQEhhBBCCGtbdSiBN5YfISEt13zMT+/Aa7eEMrS9X7U885lnnmHDhg0sW7YMX19fXnzxRSIjI805rQ8++CDR0dEsXrwYf39/li1bxtChQzl48CCtWrUCIDs7m3feeYdvv/0WOzs7Jk+ezN13380///xT5jO/+uorXnvtNWbPnk1YWBh79+5l4sSJODs788ADD7Bz5066d+/OunXraNeuHXZ2dpW6LisrixEjRnDTTTexaNEioqKiePLJJ6vl+3YtJJAVQgghRIOy6lACjy3aQ8n118S0XB5btIc593WxejCbmZnJ119/zYIFCxg0aBAA3377LU2bNgXg9OnT/PDDD8TGxuLv7w/AjBkzWLVqFfPmzWPmzJkAFBQUMHv2bHr06GG+R9u2bc0BaUlvvfUWH330EaNHjwbUCuyRI0eYO3cuDzzwAF5eXgB4enri6+tb6eu+++47DAYD33zzDU5OTrRr147Y2Fgee+wxq37frpUEskIIIYRoMAxGE28sP1IqiAUwARrgjeVHGBTqi9ZGY7Xnnj59mvz8fCIiIszHPDw8CAkJAWDPnj2YTCZat25tcV1eXh6enp7m17a2toSHh5tft2nTBnd3d44ePVoqkL1w4QIxMTE89NBDTJw40Xy8sLAQvV5f7lwrc93Ro0fp1KkTTk5O5vOXv7e6QgJZIYQQQjQYO6OSLdIJSjIBCWm57IxKJqKFZ7njrpbJVHH+rdFoRKvVEhkZiVartTjn4uJi8VqjKR1gl3XMaDQCKk2gaAW3SMlnXO11V3o/dYUEskIIIYSwlB4PcXsgLw00tuDRHPw6ga1dbc/sipIyyg9iqzKuslq2bIlOp2P79u00a9YMgJSUFE6cOEHfvn0JCwvDYDCQlJTEDTfcUO59CgsL2b17t3n19fjx46SmptKmTZtSY318fGjSpAlnzpzh3nvvLfN+RTmxBoPhqq4LDQ1l4cKF5OTk4OjoCMD27dsr8Z2oWRLICiGEEEJJjoLDS2Hr55CTYnmu9c0Q/iC0HAg25a/21TZvVwerjqssFxcXHnroIZ555hk8PT3x8fHhpZdewsZGFYhq3bo19957L/fffz8fffQRYWFhXLx4kb/++osOHTowbNgwAHQ6HVOmTOGzzz5Dp9PxxBNP0LNnzzLzY0E1SJg6dSpubm7cfPPN5OXlsXv3blJSUnj66afx9vbG0dGRVatW0bRpUxwcHNDr9Ve8buzYsbz00ks89NBDvPzyy0RHR/Phhx9a9XtmDVJ+SwghhBBw4RgseQDWv1k6iAU48Sf8cBdEfgtGQ+nzdUT3YA/89A6Ul/2qQVUv6B7sYfVnf/DBB9x4442MHDmSgQMH0qdPH7p27Wo+P2/ePO6//36mT59OSEgII0eOZMeOHQQEBJjHODk58dxzzzF27FgiIiJwdHRk8eLF5T7z4Ycf5n//+x/z58+nQ4cO9O3bl/nz55vLbtna2vLZZ58xd+5c/P39ufXWWyt1nYuLC8uXL+fIkSOEhYXx0ksvMWvWLKt/z66VxlRfkiDKkJ6ejl6vJy0tDTc3t9qejhBCCFE/ZV+CxffCuW2VG3/3D9BmWJUfV9Hv79zcXKKioggODsbBoWqrpkVVCwCLTV9FwW11VC2whvnz5zNt2jRSU1Nreyq1rrI/B7IiK4QQQlzvzu2ofBALsG025GdX33yu0dD2fsy5rwu+essAyFfvUGeDWFE1kiMrhLiylGiI/geSjoLJAI2CIKgPeIdCGTtphRD1iKEQDv50ddec/QfidkPwjdUzJysY2t6PQaG+7IxKJikjF29XlU5gzZJbovZJICuEKJ+hUG38WPEU5GdanrOxhb7PQY9HwUFSe4Sot7IvqvzXq3XxZJ0OZAG0NhqrltiqbuPHj2f8+PG1PY16RVILhBDlO/o7LJ1YOogFMBbChndg23/r9MYPIcQVGAuhsAqlqAz51p+LEFdJAlkhRNkyEmHVC1cet/l9SDxQ/fMRQlQPnRM4Nrr66+xdrjxGiGomgawQomzntkFm4pXHmYxwZlP1z0cIUT2cPCD8oau7xsYW/LtUz3yEuAoSyAohypZytvJj4/dU3zyEENWv1aCrGx82Tm32FKKWSSArhCjH1ZSYll3AQtRrfmFww/TKjXXyVB2+pGKJqAMkkBVClM2jReXHNul65TFCiLrL1g56TYXe0yoe59YE7lkMfp1qZFpCXIkEskKIsjXrCa7+Vx6nsYHgvtU/HyFE9XJ0h34vwP2/Q4/HwNa++JxPRxg5Gx5cCQHda22KwvqCgoL45JNPansaVSZ1ZIUQZXPxhpvfh5/GQUWdrPu/DL4dam5eQojqo3OA5n3VV8TjkJ8BNjpw8ZF60XVEv3796Ny5c70OPq1JVmSFEOVrMxzumF92aR5bBxj8NvR4BGzk/0qEaHDcA9SGrsatJIitZ0wmE4WFhbU9jRohv32EEOWzsYF2o+DRf+D2r+HGZ+GGGXDLp/DIFug1RWpJCiHqLqMBov6Ggz+r/1Zz85Z+/foxdepUnn32WTw8PPD19eX11183n09LS2PSpEl4e3vj5ubGTTfdxP79+83nx48fz6hRoyzuOW3aNPr162c+v2nTJj799FM0Gg0ajYbo6Gg2btyIRqNh9erVhIeHY29vz99//83p06e59dZb8fHxwcXFhW7durFu3bpq/R7UNEktEEJcmb4JdLijtmchhBCVd+R3WPUcpMcXH3Pzh6GzIHRktT3222+/5emnn2bHjh1s27aN8ePH07t3bwYOHMjw4cPx8PBg5cqV6PV65s6dy4ABAzhx4gQeHh5XvPenn37KiRMnaN++PW+++SYAXl5eREdHA/Dss8/y4Ycf0rx5c9zd3YmNjWXYsGG8/fbbODg48O2333LLLbdw/PhxmjVrVm3fg5pUqyuyhYWFvPzyywQHB+Po6Ejz5s158803MRqNtTktIYQQQtRnR36HJfdbBrEA6Qnq+JHfq+3RHTt25LXXXqNVq1bcf//9hIeHs379ejZs2MDBgwf56aefCA8Pp1WrVnz44Ye4u7vz888/V+reer0eOzs7nJyc8PX1xdfXF61Waz7/5ptvMmjQIFq0aIGnpyedOnXikUceoUOHDrRq1Yq3336b5s2b8/vv1ff+a1qtrsjOmjWLL774gm+//ZZ27dqxe/duHnzwQfR6PU8++WRtTk0IIYQQ9ZHRoFZiy6yFbQI0sOp5tQfARlvGmGvTsWNHi9d+fn4kJSURGRlJZmYmnp6eFudzcnI4ffq0VZ4dHh5u8TorK4s33niDFStWEB8fT2FhITk5OZw7d84qz6sLajWQ3bZtG7feeivDhw8HVAmIH374gd27d9fmtIQQQghRX53dWnol1oIJ0uPUuOAbrP54nU5n8Vqj0WA0GjEajfj5+bFx48ZS17i7uwNgY2ODqUSVmIKCgko/29nZ2eL1M888w+rVq/nwww9p2bIljo6O3HHHHeTn51f6nnVdrQayffr04YsvvuDEiRO0bt2a/fv3s2XLlnJLSuTl5ZGXl2d+nZ6eXkMzFUIIIUS9kHneuuOspEuXLiQmJmJra0tQUFCZY7y8vDh06JDFsX379lkEx3Z2dhgMldu09vfffzN+/Hhuu+02ADIzM835tA1FrebIPvfcc9xzzz20adMGnU5HWFgY06ZN45577ilz/Lvvvoterzd/BQQE1PCMhRBCCFGnufhYd5yVDBw4kIiICEaNGsXq1auJjo5m69atvPzyy+ZPom+66SZ2797NggULOHnyJK+99lqpwDYoKIgdO3YQHR3NxYsXK9xX1LJlS5YuXcq+ffvYv38/Y8eObXD7kGo1kP3xxx9ZtGgR33//PXv27OHbb7/lww8/5Ntvvy1z/AsvvEBaWpr5KyYmpoZnLIQQQog6LbCXqk6AppwBGtVqN7BXTc4KjUbDypUrufHGG5kwYQKtW7fm7rvvJjo6Gh8fFVQPGTKEV155hWeffZZu3bqRkZHB/fffb3GfGTNmoNVqCQ0NxcvLq8J81//85z80atSIXr16ccsttzBkyBC6dOlSre+zpmlMJZMxalBAQADPP/88jz/+uPnY22+/zaJFizh27NgVr09PT0ev15OWloabmxRrFkIIIeqDin5/5+bmEhUVRXBwMA4ODlV7QFHVAsBy09e/we2YBdVagktcu8r+HNTqimx2djY2JToCabXaBrfsLYQQQogaFDpSBatufpbH3fwliG1ganWz1y233MI777xDs2bNaNeuHXv37uXjjz9mwoQJtTktIYQQQtR3oSNVia2zW9XGLhcflU5QDSW3RO2p1UD2888/55VXXmHy5MkkJSXh7+/PI488wquvvlqb0xJCCCFEQ2CjrZYSW6LuqNVA1tXVlU8++aTccltCCCGEEEKUp1ZzZIUQQgghhKgqCWSFEEIIIUS9JIGsEEIIIYSolySQFUIIIYQQ9ZIEskIIIYQQol6SQFYIIYQQog7r168f06ZNq9TYjRs3otFoSE1Ntfo8NBoNv/76q9Xvey1qtfyWEEIIIYSo2NKlS9HpdLU9jTpJAlkhhBBCiDqooKAAnU6Hh4dHbU+lzpLUAiGEEEI0SAajgV2Ju1h5ZiW7EndhMBqq9Xkmk4n333+f5s2b4+joSKdOnfj555+B4o/8169fT3h4OE5OTvTq1Yvjx4+br3/99dfp3Lkz33zzDc2bN8fe3h6TyVQqtSAvL49nn32WgIAA7O3tadWqFV9//bXFXCIjI8t9DsDy5cvp2rUrDg4ONG/enDfeeIPCwkLz+ZMnT3LjjTfi4OBAaGgoa9eurYbv2LWTFVkhhBBCNDjrzq7jvZ3vcT77vPmYj5MPz3d/noGBA6vlmS+//DJLly5lzpw5tGrVis2bN3Pffffh5eVlHvPSSy/x0Ucf4eXlxaOPPsqECRP4559/zOdPnTrFkiVL+OWXX9BqtWU+5/7772fbtm189tlndOrUiaioKC5evGgxpqLnrF69mvvuu4/PPvuMG264gdOnTzNp0iQAXnvtNYxGI6NHj6Zx48Zs376d9PT0Sufo1jhTPZaWlmYCTGlpabU9FSGEEEJUUkW/v3NyckxHjhwx5eTkVPn+a6PXmjrM72BqP7+9xVeH+R1MHeZ3MK2NXnst0y9TZmamycHBwbR161aL4w899JDpnnvuMW3YsMEEmNatW2c+98cff5gA83t97bXXTDqdzpSUlGRxj759+5qefPJJk8lkMh0/ftwEmNauLfs9VOY5N9xwg2nmzJkW1y1cuNDk5+dnMplMptWrV5u0Wq0pJibGfP7PP/80AaZly5ZdxXel6ir7cyArskIIIYRoMAxGA+/tfA8TplLnTJjQoGHWzln0D+iP1qbsFc+qOHLkCLm5uQwaNMjieH5+PmFhYebXHTt2NP/Zz88PgKSkJJo1awZAYGCgxQpuSfv27UOr1dK3b98K51PRcyIjI9m1axfvvPOOeYzBYCA3N5fs7GyOHj1Ks2bNaNq0qfl8REREhc+rLRLICiGEEKLB2JO0xyKdoCQTJhKzE9mTtIduvt2s9lyj0QjAH3/8QZMmTSzO2dvbc/r0aQCL6gMajcbiWgBnZ+cKn+Po6Fip+VT0HKPRyBtvvMHo0aNLXefg4IDJVPofAUX3qGskkBVCCCFEg3Eh+4JVx1VWaGgo9vb2nDt3rszV0qJA9lp16NABo9HIpk2bGDiwarm+Xbp04fjx47Rs2bLM86GhoZw7d474+Hj8/f0B2LZtW5XnXJ0kkBVCCCFEg+HlVP7H8lUZV1murq7MmDGDp556CqPRSJ8+fUhPT2fr1q24uLgQGBholecEBQXxwAMPMGHCBPNmr7Nnz5KUlMSYMWMqdY9XX32VESNGEBAQwJ133omNjQ0HDhzg4MGDvP322wwcOJCQkBDuv/9+PvroI9LT03nppZesMn9rk/JbQgghhGgwunh3wcfJBw1lfxSuQYOvky9dvLtY/dlvvfUWr776Ku+++y5t27ZlyJAhLF++nODgYKs+Z86cOdxxxx1MnjyZNm3aMHHiRLKysip9/ZAhQ1ixYgVr166lW7du9OzZk48//tgcbNvY2LBs2TLy8vLo3r07Dz/8sEU+bV2iMZWVCFFPpKeno9frSUtLw83NrbanI4QQQohKqOj3d25uLlFRUQQHB+Pg4FCl+687u46nNz4NYLHpqyi4/bjfx9VWgktYR2V/DmRFVgghhBANysDAgXzc72O8nbwtjvs4+UgQ28BIjqwQQgghGpyBgQPpH9CfPUl7uJB9AS8nL7p4d7FqyS1R+ySQFUIIIUSDpLXRWrXElqh7JLVACCGEEELUSxLICiGEEEKIekkCWSGEEEIIUS9JICuEEEIIIeolCWSFEEIIIUS9JIGsEEIIIYSolySQFUIIIYSoZ8aPH8+oUaNqexq1TgJZIYQQQggr6NevH9OmTav2a0QxCWSFEEIIIUS9JIGsEEIIIcQ1Gj9+PJs2beLTTz9Fo9Gg0WiIjo5m06ZNdO/eHXt7e/z8/Hj++ecpLCys8BqDwcBDDz1EcHAwjo6OhISE8Omnn9byO6ybpEWtEEIIIcQ1+vTTTzlx4gTt27fnzTffBMBgMDBs2DDGjx/PggULOHbsGBMnTsTBwYHXX3+9zGu8vLwwGo00bdqUJUuW0LhxY7Zu3cqkSZPw8/NjzJgxtfk26xwJZIUQQgghrpFer8fOzg4nJyd8fX0BeOmllwgICGD27NloNBratGlDfHw8zz33HK+++mqZ1wBotVreeOMN8+vg4GC2bt3KkiVLJJAtQVILhBBCCCGqwdGjR4mIiECj0ZiP9e7dm8zMTGJjYyu89osvviA8PBwvLy9cXFz46quvOHfuXHVPud6RQFYIIYQQohqYTCaLILboGFDq+OWWLFnCU089xYQJE1izZg379u3jwQcfJD8/v1rnWx9JaoEQQgghhBXY2dlhMBjMr0NDQ/nll18sAtqtW7fi6upKkyZNyrwG4O+//6ZXr15MnjzZfOz06dM18A7qH1mRFUIIIYSwgqCgIHbs2EF0dDQXL15k8uTJxMTEMGXKFI4dO8Zvv/3Ga6+9xtNPP42NjU2Z1xiNRlq2bMnu3btZvXo1J06c4JVXXmHXrl21/O7qJglkhRBCCCGsYMaMGWi1WkJDQ/Hy8qKgoICVK1eyc+dOOnXqxKOPPspDDz3Eyy+/XO41586d49FHH2X06NHcdddd9OjRg0uXLlmszopiGlNRskY9lJ6ejl6vJy0tDTc3t9qejhDXt4xEiN0NOcmgcwL/MPBsUduzEkLUQRX9/s7NzSUqKorg4GAcHBxqaYaitlX250ByZIUQ1yY/Gw7+BH+9DVlJxcd1TtB7KnR9CFy9a29+QgghGixJLRBCVJ3RADu/hOVTLYNYgIJs2PgerH4RclJrZXpCCCEaNglkhRBVl7Af1r9e8ZhDP8GZDTUyHSGEENcXCWSFEFV3ZiNUJs1+/2IolPqHQgghrEsCWSFE1cVWshxM9BbITaneuQghhLjuSCArxNXIy1BfQtFU8v9CNBrk/26EEEJYm1QtEOJKDIVwbiscXQHHVqhj7W6DkJuhWS+wuY4DtKA+xd+TirQeBk4e1T8fIYQQ1xUJZIWoiKEQdn8Dfz5jeXzbbNj+XxjxKYSNu36D2eAbwcYWjIUVj2t/G9hoa2ZOQgghrhvX6W9fISrpzMbSQWwRkwlWPAlnt9TolOoU71C45bOKx0Q8oQJeIYQQwsokkBWiPEYjHF5a8RiTSaUcXK80Guh0N9z1HTTtbnlO3wxu+RT6Pgd2zrUzPyGEEA2aBLJClCcrCQ4vu/K4Qz9D9nW8I99GC21HwLhl8OBKuPs7GPcrTNoAXceDg7SPFkJcH+bMmUPHjh1xc3PDzc2NiIgI/vzzT/N5k8nE66+/jr+/P46OjvTr14/Dhw9b3CMvL48pU6bQuHFjnJ2dGTlyJLGxsRZjUlJSGDduHHq9Hr1ez7hx40hNTa2Jt1jnSCArREVMxsoMqlwt1YbO3gUCe0ObEdCiPzg3ru0ZCSFEjWratCnvvfceu3fvZvfu3dx0003ceuut5mD1/fff5+OPP2b27Nns2rULX19fBg0aREZGcTWcadOmsWzZMhYvXsyWLVvIzMxkxIgRGAwG85ixY8eyb98+Vq1axapVq9i3bx/jxo2r8fdbF2hMpvr7Gzg9PR29Xk9aWhpubrLqI6zMUAA/PQjHllc8rtNYuPW/1++GLyGEuEoV/f7Ozc0lKiqK4OBgHBwcammG1uPh4cEHH3zAhAkT8Pf3Z9q0aTz33HOAWn318fFh1qxZPPLII6SlpeHl5cXChQu56667AIiPjycgIICVK1cyZMgQjh49SmhoKNu3b6dHjx4AbN++nYiICI4dO0ZISEitvVdrquzPgfzmFaI8Wp3K/7ySdrdJECuEEHWMyWRiy5YtPP3009x99908/fTTbNmyhZpavzMYDCxevJisrCwiIiKIiooiMTGRwYMHm8fY29vTt29ftm7dCkBkZCQFBQUWY/z9/Wnfvr15zLZt29Dr9eYgFqBnz57o9XrzmOuJlN8SoiItboIbnoG/Pyj7/E2vQHDfmp2TEEKICplMJj744AOWLFmCjY0NRqORM2fOsHnzZu666y5mzJiBRqOplmcfPHiQiIgIcnNzcXFxYdmyZYSGhpqDTB8fH4vxPj4+nD17FoDExETs7Oxo1KhRqTGJiYnmMd7e3qWe6+3tbR5zPalSIJubm8vnn3/Ohg0bSEpKwmi0zCPcs2ePVSZX2/IKDehsbLCxqZ4fdlEP2DnBDU+DX0fY9x2cXA1oIGQYdB4LLQaCzr62ZymEEOIy//zzD0uWLAEwxyhF//3xxx+JiIigT58+1fLskJAQ9u3bR2pqKr/88gsPPPAAmzZtMp8vGUCbTKYrBtUlx5Q1vjL3aYiqFMhOmDCBtWvXcscdd9C9e/cG9Y0zmUxsP3OJlQcT+fvkBXzdHLi9S1P6t/GmsasELNclOycIHQmth0LmeUADLt5ga1fbMxNCCFGGpUuXmldiS7KxsWHp0qXVFsja2dnRsmVLAMLDw9m1axeffvqpOS82MTERPz8/8/ikpCTzKq2vry/5+fmkpKRYrMomJSXRq1cv85jz58+Xeu6FCxdKrfZeD6oUyP7xxx+sXLmS3r17W3s+te6PAwlMXbwX478pNNGXstkelczN7X15a1R7GrtIMHvdsrUD94DanoUQQogriI+PLzOIBbUyGx8fX2NzMZlM5OXlERwcjK+vL2vXriUsLAyA/Px8Nm3axKxZswDo2rUrOp2OtWvXMmbMGAASEhI4dOgQ77//PgARERGkpaWxc+dOundX9bt37NhBWlqaOdi9nlQpkG3SpAmurq7Wnkuti0nO5oWlB81B7OX+PJTIoFAfRndpWvMTE0IIIUSl+fv7c+bMmXJXZP39/avluS+++CI333wzAQEBZGRksHjxYjZu3MiqVavQaDRMmzaNmTNn0qpVK1q1asXMmTNxcnJi7NixAOj1eh566CGmT5+Op6cnHh4ezJgxgw4dOjBw4EAA2rZty9ChQ5k4cSJz584FYNKkSYwYMaLBVCy4GlXaav3RRx/x3HPPmZOTG4p951LIyCu/Z/yve+NqcDZCCCGEqIrRo0dXuCI7evToannu+fPnGTduHCEhIQwYMIAdO3awatUqBg0aBMCzzz7LtGnTmDx5MuHh4cTFxbFmzRqLxcH//Oc/jBo1ijFjxtC7d2+cnJxYvnw5Wq3WPOa7776jQ4cODB48mMGDB9OxY0cWLlxYLe+prqtSHdkLFy4wZswYNm/ejJOTEzqdzuJ8cnKy1SZYEWvXkf1x1zme++Vguedb+7jw55M3opXNX0IIIUSVVXcd2bKqFhT9t7qrFgjrqOzPQZVSC+655x7i4uKYOXMmPj4+DeaHoZmHU4Xn+7b2liBWCCGEqOM0Gg3PPPMMvXr1YunSpcTHx+Pv78/o0aPp3bt3g4lbRBUD2a1bt7Jt2zY6depk7fnUqs4B7vRr3ZiNJy6WOmdro2Fwu+tvN6AQQghRH2k0Gvr06VNt1QlE3VClHNk2bdqQk5NjlQnExcVx33334enpiZOTE507dyYyMtIq975ajna2vHpLOwa0sSw07OGs4//u7UK3II9amZcQQgghhCitSiuy7733HtOnT+edd96hQ4cOpXJkK5uvmpKSQu/evenfvz9//vkn3t7enD59Gnd396pMyyqae7nw33u7cCA2lXPJ2Tjb2dK5mTt+esdam5MQQgghhCitSoHs0KFDARgwYIDF8aKuEgaDoVL3mTVrFgEBAcybN898LCgoqCpTsioHnZbuwZ50D/as7akIIYQQQohyVCmQ3bBhg1Ue/vvvvzNkyBDuvPNONm3aRJMmTZg8eTITJ060yv2FEEIIIUTDddWBbEFBAa+//jpz586ldevW1/TwM2fOMGfOHJ5++mlefPFFdu7cydSpU7G3t+f+++8vNT4vL4+8vDzz6/T09Gt6vhBCCCGEqL+uOpDV6XQcOnTIKqUrjEYj4eHhzJw5E4CwsDAOHz7MnDlzygxk3333Xd54441rfq4QQgghhKj/qlS14P777+frr7++5of7+fkRGhpqcaxt27acO3euzPEvvPACaWlp5q+YmJhrnoMQQgghhKifqpQjm5+fz//+9z/Wrl1LeHg4zs7OFuc//vjjSt2nd+/eHD9+3OLYiRMnCAwMLHO8vb099vb2VZmyEEIIIYRoYKq0Invo0CG6dOmCm5sbJ06cYO/eveavffv2Vfo+Tz31FNu3b2fmzJmcOnWK77//ni+//JLHH3+8KtMSQgghhKhVV6qPbzKZeP311/H398fR0ZF+/fpx+PBhi3vk5eUxZcoUGjdujLOzMyNHjiQ2NtZiTEpKCuPGjUOv16PX6xk3bhypqak18RbrlFqtWtCtWzeWLVvGCy+8wJtvvklwcDCffPIJ9957r1XuL4QQQghRUypTH//999/n448/Zv78+bRu3Zq3336bQYMGcfz4cVxdXQGYNm0ay5cvZ/HixXh6ejJ9+nRGjBhBZGQkWq0WgLFjxxIbG8uqVasAmDRpEuPGjWP58uU1/r5rk8ZkMpmu5QaxsbFoNBqaNGlirTlVWnp6Onq9nrS0tEo3YRBCCCFE7aro93dubi5RUVEEBwfj4OBQ5Wfk5uaydu1a/vjjDy5duoSnpyfDhw9n0KBB13Tfijz//PP8888//P3332WeN5lM+Pv7M23aNJ577jlArb76+Pgwa9YsHnnkEdLS0vDy8mLhwoXcddddAMTHxxMQEMDKlSsZMmQIR48eJTQ0lO3bt9OjRw8Atm/fTkREBMeOHSMkJKRa3l9NquzPQZVSC4xGI2+++SZ6vZ7AwECaNWuGu7s7b731FkajscqTFkIIIYS4VrGxsdx555288cYbREZGEhUVRWRkJG+88QZ33nlnqY/preX3338nPDycO++8E29vb8LCwvjqq6/M56OiokhMTGTw4MHmY/b29vTt25etW7cCEBkZSUFBgcUYf39/2rdvbx6zbds29Hq9OYgF6NmzJ3q93jzmelGlQPall15i9uzZvPfee+zdu5c9e/Ywc+ZMPv/8c1555RVrz1EIIYQQolJyc3N57LHHSEpKAtQq6OX/TUpK4rHHHiM3N9fqzy6qj9+qVStWr17No48+ytSpU1mwYAEAiYmJAPj4+Fhc5+PjYz6XmJiInZ0djRo1qnCMt7d3qed7e3ubx1wvqpQj++233/K///2PkSNHmo916tTJ3JnrnXfesdoEhRBCCCEqa+3atSQkJJR73mAwkJCQwLp16xgxYoRVn13Z+vgla/GbTKYr1ucvOaas8ZW5T0NTpRXZ5ORk2rRpU+p4mzZtSE5OvuZJCSGEEEJUxR9//HHFYE6j0bBixQqrP/tK9fF9fX0BSq2aJiUlmVdpfX19yc/PJyUlpcIx58+fL/X8CxculFrtbeiqFMh26tSJ2bNnlzo+e/ZsOnXqdM2TEkIIIYSoikuXLnGlfewmk4lLly5Z/dlXqo8fHByMr68va9euNZ/Pz89n06ZN9OrVC4CuXbui0+ksxiQkJHDo0CHzmIiICNLS0ti5c6d5zI4dO0hLSzOPuV5UKbXg/fffZ/jw4axbt46IiAg0Gg1bt24lJiaGlStXWnuOQgghhBCV4unpSXR0dIXBrEajwdPT0+rPfuqpp+jVqxczZ85kzJgx7Ny5ky+//JIvv/zS/Nxp06Yxc+ZMWrVqRatWrZg5cyZOTk6MHTsWAL1ez0MPPcT06dPx9PTEw8ODGTNm0KFDBwYOHAioVd6hQ4cyceJE5s6dC6jyWyNGjGgQFQuuRpVWZPv27cuJEye47bbbSE1NJTk5mdGjR3P8+HFuuOEGa89RCCGEEKJShg8fXqkVWWvnx0JxffwffviB9u3b89Zbb5Wqj//ss88ybdo0Jk+eTHh4OHFxcaxZs8ZcQxbgP//5D6NGjWLMmDH07t0bJycnli9fbq4hC/Ddd9/RoUMHBg8ezODBg+nYsSMLFy60+nuq6665jmxtkjqyQgghRP1TnXVkc3NzufPOO0lKSsJgMJQ6r9Vq8fb25qeffqq2erLi2lX256BKqQUAqamp7Ny5k6SkpFK1Yy/fmSeEEEIIUVMcHByYM2cOjz32GAkJCWg0GvNufpPJhLe3N3PmzJEgtoGoUiC7fPly7r33XrKysnB1dS1VDkICWSGEEELUlqZNm/LTTz+xbt06VqxYYe7sNWLECAYOHChBbANSpUB2+vTpTJgwwZygLIQQQghRlzg4ODBixIhqyYUVdUeVNnvFxcUxdepUCWKFEEIIIUStqVIgO2TIEHbv3m3tuQghhBBCCFFpVUotGD58OM888wxHjhyhQ4cO6HQ6i/OXt64VQgghhBCiOlQpkJ04cSIAb775ZqlzGo2mzHIXQgghhBBCWFOVAtmS5baEEEIIIYSoaVXKka2sDh06EBMTU52PEEIIIYQQ16lqDWSjo6MpKCiozkcIIYQQQojrVLUGskIIIYQQtcFkMrFz505mzZrFK6+8wqxZs9i1axcmk6lan5uRkcG0adMIDAzE0dGRXr16sWvXLot5vf766/j7++Po6Ei/fv04fPiwxT3y8vKYMmUKjRs3xtnZmZEjRxIbG2sxJiUlhXHjxqHX69Hr9YwbN47U1NRqfW91kQSyQgghhGhQDh8+zOjRo5k8eTJLly5l9erVLF26lMcee4zRo0dz5MiRanv2ww8/zNq1a1m4cCEHDx5k8ODBDBw4kLi4OADef/99Pv74Y2bPns2uXbvw9fVl0KBBZGRkmO8xbdo0li1bxuLFi9myZQuZmZmMGDHCYjP92LFj2bdvH6tWrWLVqlXs27ePcePGVdv7qqs0pmr8p4mrqyv79++nefPm1XL/9PR09Ho9aWlpuLm5VcszhBBCCGFdFf3+zs3NJSoqiuDg4Cq1kj18+DCTJk2ioKCgzM3pNjY26HQ6vvzyS9q1a1fl91CWnJwcXF1d+e233xg+fLj5eOfOnRkxYgRvvfUW/v7+TJs2jeeeew5Qq68+Pj7MmjWLRx55hLS0NLy8vFi4cCF33XUXAPHx8QQEBLBy5UqGDBnC0aNHCQ0NZfv27fTo0QOA7du3ExERwbFjxwgJCbHq+6oNlf05kBVZIYQQQjQIJpOJl19+udwgFlTlpYKCAl5++WWrpxkUFhZiMBhKBV6Ojo5s2bKFqKgoEhMTGTx4sPmcvb09ffv2ZevWrQBERkZSUFBgMcbf35/27dubx2zbtg29Xm8OYgF69uyJXq83j7leSCArhBBCiAZh9+7dxMTEXLFMqNFoJCYmhsjISKs+39XVlYiICN566y3i4+MxGAwsWrSIHTt2kJCQQGJiIgA+Pj4W1/n4+JjPJSYmYmdnR6NGjSoc4+3tXer53t7e5jHXi2oNZOfOnVvqL0sIIYQQojr89ddfaLXaSo3VarX89ddfVp/DwoULMZlMNGnSBHt7ez777DPGjh1rMS+NRmNxjclkKnWspJJjyhpfmfs0NFUOZDdt2sQtt9xCy5YtadWqFSNHjuTvv/+2GDN27FicnZ2veZJCCCGEEFeSmZlZ6XQBk8lkscHKWlq0aMGmTZvIzMwkJiaGnTt3UlBQQHBwML6+vgClVk2TkpLMC3++vr7k5+eTkpJS4Zjz58+XevaFCxeuuwXEKgWyixYtYuDAgTg5OTF16lSeeOIJHB0dGTBgAN9//7215yiEEEIIcUUuLi6VXpHUaDS4urpW21ycnZ3x8/MjJSWF1atXc+utt5qD2bVr15rH5efns2nTJnr16gVA165d0el0FmMSEhI4dOiQeUxERARpaWns3LnTPGbHjh2kpaWZx1wvqlS1oG3btkyaNImnnnrK4vjHH3/MV199xdGjR602wYpI1QIhhBCi/qmuqgW7du3iscceq/T4L774gvDw8Kt6xpWsXr0ak8lESEgIp06d4plnnsHe3p4tW7ag0+mYNWsW7777LvPmzaNVq1bMnDmTjRs3cvz4cXNg/dhjj7FixQrmz5+Ph4cHM2bM4NKlS0RGRppTFG6++Wbi4+OZO3cuAJMmTSIwMJDly5db9f3Ulsr+HNhW5eZnzpzhlltuKXV85MiRvPjii1W5pRBCCCHENQkPDycgIIC4uLgKN3zZ2NjQpEkTunbtavU5pKWl8cILLxAbG4uHhwe3334777zzDjqdDoBnn32WnJwcJk+eTEpKCj169GDNmjUWq8P/+c9/sLW1ZcyYMeTk5DBgwADmz59vkWf73XffMXXqVHN1g5EjRzJ79myrv5+6rkorsi1btuSZZ57hkUcesTg+d+5cPvzwQ06ePGm1CVZEVmSFEEKI+qc668geOXKEiRMnXrGO7FdffUVoaGiV34OoXtW6Ijt9+nSmTp3Kvn376NWrFxqNhi1btjB//nw+/fTTKk+6rkrNzmfr6Uvsik7GaDTRNdCDXi09aexiX9tTE0IIIcRlQkND+fLLL3n55ZeJiYlBq9Wad/MbDAaaNGnCO++8I0FsA1GlQPaxxx7D19eXjz76iCVLlgAqb/bHH3/k1ltvteoEa1tyVh5vLD/Cb/vizce+3XaWAW28mXlbB3z0V/+vRSGEEEJUn3bt2rF06VJ2797Nhg0byMjIwNXVlZtuuomuXbtedyWqGrIqBbIAt912G7fddps151InbTpxwSKILbL+WBJ/HTvPPT0Ca2FWos5LOQtRm+Dw75CXCkE3QqtBENADbKQPiRBCVDeNRkO3bt3o1q1bbU9FVKMqB7LXi3VHStdpK/Lznjju7t5M/mUnLCUchJ8egOTTxcdid8E/H8OITyFsnASzQgghhBVUKZBt1KhRmcGbRqPBwcGBli1bMn78eB588MFrnmBty8gtrOBcAUYTaCWOFUXyMmHlM5ZBbBGTCVY8CR7NIfiGmp+bEEII0cBUaVno1VdfxcbGhuHDh/PGG2/w+uuvM3z4cGxsbHj88cdp3bo1jz32GF999ZW151vjBrQtv0PGqM5N0NpIFCsuExcJMdvKP28ywfGVNTcfIYQQogGr0orsli1bePvtt3n00Uctjs+dO5c1a9bwyy+/0LFjRz777DMmTpxolYnWln4hXrTyduFkUqbFcX+9A4NCr682cKISLpWxElvSiVUw8HWwlaoXQgghxLWo0ors6tWrGThwYKnjAwYMYPXq1QAMGzaMM2fOXNvs6oBAT2e+GNeFpwa2xsfNHi9Xex7v35J5D3anlU/1tbYT9ZS2Ev82tHUEjfbK44QQQghRoSqtyHp4eLB8+fJSLWqXL1+Oh4cHAFlZWdXaw7gmtfBy5cmBrkzoHYQJE26OdrU9JVFX+XUCjQ2Yyu8oQ+d7KhfwCiGEEKJCVfpt+sorr/DYY4+xYcMGunfvjkajYefOnaxcuZIvvvgCgLVr19K3b1+rTra2uTrqansKoq7zaQ/dJsLOuWWfd2wELUt/miGEEML60tPT2bt3L9nZ2Tg5OREWFiadQBuYKqUWTJw4kU2bNuHs7MzSpUv5+eefcXJyYtOmTTz00EOA6v71448/WnWyQtR5Nlq44WnoWkbFjkZBcM9i8G5b49MSQojrydmzZ3nrrbcYMmQI06dP55VXXmH69OkMGTKEt956i7Nnz1bLczdv3swtt9yCv78/Go2GX3/91XyuoKCA5557jg4dOuDs7Iy/vz/3338/8fGWterz8vKYMmUKjRs3xtnZmZEjRxIbG2sxJiUlhXHjxqHX69Hr9YwbN47U1FSLMefOneOWW27B2dmZxo0bM3XqVPLz86vlfdemKn++2bt3b3r37m3NuQjRMLj6wrAPIOw+iNsDhnwVxDbrCc6Na3t2QgjRoEVGRjJt2jTy8/MxGAwW5woKClixYgVr1qzhk08+oWvXrlZ9dlZWFp06deLBBx/k9ttvtziXnZ3Nnj17eOWVV+jUqRMpKSlMmzaNkSNHsnv3bvO4adOmsXz5chYvXoynpyfTp09nxIgRREZGotWq/RVjx44lNjaWVatWATBp0iTGjRvH8uXLATAYDAwfPhwvLy+2bNnCpUuXeOCBBzCZTHz++edWfc+1TWMymUxVudBoNHLq1CmSkpIwGi3zAW+88UarTO5K0tPT0ev1pKWlyUcFQgghRD1R0e/v3NxcoqKiCA4OxsHh6trAnz17lvvuu4/c3FwqCm+K6t4vWrSIwMDq6dCp0WhYtmwZo0aNKnfMrl276N69O2fPnqVZs2akpaXh5eXFwoULueuuuwCIj48nICCAlStXMmTIEI4ePUpoaCjbt2+nR48eAGzfvp2IiAiOHTtGSEgIf/75JyNGjCAmJgZ/f38AFi9ezPjx40lKSqoXMVNlfw6qlFqwfft2WrZsSdu2bbnxxhvp16+f+at///5VnrQQQgghRFUtWLCA/Pz8CoNYAJPJRH5+PgsWLKihmZUtLS0NjUaDu7s7oFaTCwoKGDx4sHmMv78/7du3Z+vWrQBs27YNvV5vDmIBevbsiV6vtxjTvn17cxALMGTIEPLy8oiMjKyBd1ZzqhTIPvroo4SHh3Po0CGSk5NJSUkxfyUnJ1t7jkIIIYQQFUpPT2flypWl0gnKYzAYWLlyJRkZGdU8s7Ll5uby/PPPM3bsWPMKaWJiInZ2djRq1MhirI+PD4mJieYx3t7epe7n7e1tMcbHx7LWfaNGjbCzszOPaSiqlCN78uRJfv75Z1q2bGnt+QghhBBCXLW9e/dSUFBwVdcUFBSwd+/eGkuJvPy5d999N0ajkf/7v/+74niTyYRGU9xJ9PI/X8uYhqBKK7I9evTg1KlT1p6LEEIIIUSVZGdnV+m6rKwsK8+kYgUFBYwZM4aoqCjWrl1rka/q6+tLfn4+KSkpFtckJSWZV1h9fX05f/58qfteuHDBYkzJldeUlBQKCgpKrdTWd1UKZKdMmcL06dOZP38+kZGRHDhwwOJLCCGEEKImOTk5Vek6Z2dnK8+kfEVB7MmTJ1m3bh2enp4W57t27YpOp2Pt2rXmYwkJCRw6dIhevXoBEBERQVpaGjt37jSP2bFjB2lpaRZjDh06REJCgnnMmjVrsLe3t3qlhtpWpdSCopISEyZMMB/TaDTmJevK5qcIIYQQQlhDWFgYOp3uqtILdDodYWFhVptDZmamxSfWUVFR7Nu3Dw8PD/z9/bnjjjvYs2cPK1aswGAwmFdNPTw8sLOzQ6/X89BDDzF9+nQ8PT3x8PBgxowZdOjQgYEDVTOdtm3bMnToUCZOnMjcuar5zqRJkxgxYgQhISEADB48mNDQUMaNG8cHH3xAcnIyM2bMYOLEifWiYsHVqFIgGxUVZe15CCGEEEJUmZubG8OGDTMHiVei1WoZNmwYrq6uVpvD7t27Lao3Pf300wA88MADvP766/z+++8AdO7c2eK6DRs20K9fPwD+85//YGtry5gxY8jJyWHAgAHMnz/fXEMW4LvvvmPq1Knm6gYjR45k9uzZFu/tjz/+YPLkyfTu3RtHR0fGjh3Lhx9+aLX3WldUuY5sXSB1ZIVZRiIU5ICzJ9jLz4IQQtRl10MdWXFtKvtzUOkV2d9//52bb74ZnU5n/hdFeUaOHFn5mQpxLZKOwcGfYMcXkJ8JPu2h52Roews4SEArhBDXk8DAQD755JNyO3uBWq20s7Pj008/lSC2Aaj0iqyNjY25dpmNTfl7xGoyR1ZWZK9zScdg8T2QfKb0uYgn4KZXQHd1/5oXQghR/aprRbbI2bNnWbBgAStXrrTImdXpdAwbNoz7779fgtg6zuorspe3oS3ZklaIKrt0Gi6eBBst+HYAV9/KX3t4adlBLMC22RByMwT1sc48hRBC1BuBgYG88sorTJs2jb1795KVlYWzszNhYWFWzYkVta9Km72EuGY5qbB7Hmx+Hwr+rf3n7A1D3oF2o0F7hR/NzAuwY27FY2J2SiArhBDXMVdX1xpvdiBqVpUD2fXr17N+/XqSkpJKrdB+88031zwx0cDt/hrWv2l5LCsJlk4EnaPKca1IYS7kpVU8Jr922g4KIYQQomZUqSHCG2+8weDBg1m/fj0XL14kJSXF4ks0AEYDpMVBesKVx16tS6dh8wfln//nc8i/QqcVJw9o0q3iMe5BVz01IYQQQtQfVVqR/eKLL5g/fz7jxo2z9nxEXRC9BSLnqxxUG1vo8gCE3Qd+naxz/4snVKms8sTugNQY8G5T/hg7Z+g+EWJ3ln3e3k3SCoQQQogGrkorsvn5+eY2aKKBifobFo1WJa2MBijMg51fwqLbIfGQdZ5hc4V/P2k0avPXlbQZDjc+V/q4gx7u/g48W1RtfkIIIYSoF6q0Ivvwww/z/fff88orr1h7PqI2Fear3f6FeaXPZV1QK7S+7a/9Ob4dwNlL3bMsbW+FRkFXvo+dM9w4A1oOhJjtkJcJjQIgsA94BF/7PIUQQjQIJpMJjUZT29MQ1aDSgWxRmzVQ5be+/PJL1q1bR8eOHdHpdBZjP/74Y+vNUNSc1Gg4sar883sXQq+p4Oh+bc9x9YUhM9XGrpJsHaD7JNDqSp8ri60dNOuuvoQQQgjAYDCwdetWfvzxR/bu3UteXh729vaEhYVx11130atXL4uWr6L+qnRqwd69e81f+/fvp3PnztjY2HDo0CGLc/v27avG6YoGo91ouGsRNP03ANVoIHQU3LcUgnrX6tSEEELUX1FRUYwePZqnnnqKXbt2kZenPmXMy8tj165dPPXUU4wePZqoqCirP3vz5s3ccsst+Pv7o9Fo+PXXXy3Ojx8/Ho1GY/HVs2dPizF5eXlMmTKFxo0b4+zszMiRI4mNjbUYk5KSwrhx49Dr9ej1esaNG0dqaqrFmHPnznHLLbfg7OxM48aNmTp1Kvn5+VZ/z7Wt0iuyGzZsqM55iLrAPQha3wwn/iz7fNi4a1+NLaK1VSW2mveHtFiVE9soqPIrsUIIIUQJUVFRPPjgg+TkqA3FJTuNFr1OTEzkwQcfZN68eQQHWy8VLSsri06dOvHggw9y++23lzlm6NChzJs3z/zazs7O4vy0adNYvnw5ixcvxtPTk+nTpzNixAgiIyPNq8hjx44lNjaWVavUp6iTJk1i3LhxLF++3Pw+hw8fjpeXF1u2bOHSpUs88MADmEwmPv/8c6u937rgmhsixMTEoNFoaNq06TXd59133+XFF1/kySef5JNPPrnWaYmqsLWDiMfhzF+l82SdvdQqqrXZu1RcnUAIIYSoBIPBwLRp08jJySkVwJY1Nicnh2nTprF06VKrpRncfPPN3HzzzRWOsbe3x9e37C6WaWlpfP311yxcuJCBAwcCsGjRIgICAli3bh1Dhgzh6NGjrFq1iu3bt9OjRw8AvvrqKyIiIjh+/DghISGsWbOGI0eOEBMTg7+/PwAfffQR48eP55133inVFrg+q1LVgsLCQl555RX0ej1BQUEEBgai1+t5+eWXLXoaV9auXbv48ssv6dixY1WmI6wp+Ab18X6Hu9Qqqa09dH8E7v3FOhu9hBBCiGqwdetW4uLirhjEFjEYDMTFxbFt27ZqnpmljRs34u3tTevWrZk4cSJJSUnmc5GRkRQUFDB48GDzMX9/f9q3b8/WrVsB2LZtG3q93hzEAvTs2RO9Xm8xpn379uYgFmDIkCHk5eURGRlZ3W+xRlVpRfaJJ55g2bJlvP/++0RERADqm/b6669z8eJFvvjii0rfKzMzk3vvvZevvvqKt99+uyrTEdYW1AeaRcDA10BjA25+tT0jIYQQokI//vgjWq220oEsgFarZfHixfTpUzN1x2+++WbuvPNOAgMDiYqK4pVXXuGmm24iMjISe3t7EhMTsbOzo1GjRhbX+fj4kJiYCKi0CG9v71L39vb2thjj4+Njcb5Ro0bY2dmZxzQUVQpkf/jhBxYvXmyxfN6xY0eaNWvG3XfffVWB7OOPP87w4cMZOHDgFQPZvLw8c9I2QHp6+tVPXlSOjRb0TWp7FkIIIUSl7N2796qCWFCrsnv37q2mGZV21113mf/cvn17wsPDCQwM5I8//mD06PLT90qWDyurlFhVxjQEVUotcHBwICgoqNTxoKCgUknLFVm8eDF79uzh3XffrdT4d99917xDT6/XExAQUOlnCSGEEKJhMplMFgtdVyMvLw+TyWTlGVWOn58fgYGBnDx5EgBfX1/y8/NJSUmxGJeUlGReYfX19eX8+fOl7nXhwgWLMSVXXlNSUigoKCi1UlvfVSmQffzxx3nrrbcsfmjy8vJ45513eOKJJyp1j5iYGJ588kkWLVqEg4NDpa554YUXSEtLM3/FxMRUZfpCCCGEaEA0Gg329vZVutbe3r7WVikvXbpETEwMfn4qha9r167odDrWrl1rHpOQkMChQ4fMHVUjIiJIS0tj587iFu07duwgLS3NYsyhQ4dISEgwj1mzZg329vZ07dq1Jt5ajalSasHevXtZv349TZs2pVOnTgDs37+f/Px8BgwYYLE8vnTp0jLvERkZSVJSksU31GAwsHnzZmbPnk1eXl6pXYT29vZV/kEVQgghRMMVFhbGrl27riq9wMbGhi5dulhtDpmZmZw6dcr8Oioqin379uHh4YGHhwevv/46t99+O35+fkRHR/Piiy/SuHFjbrvtNgD0ej0PPfQQ06dPx9PTEw8PD2bMmEGHDh3MVQzatm3L0KFDmThxInPnzgVU+a0RI0YQEhICwODBgwkNDWXcuHF88MEHJCcnM2PGDCZOnNigKhZAFQNZd3f3UvXRrvZj/gEDBnDw4EGLYw8++CBt2rThueeeq7MdN7LyC9l5JpkDsanYajWENWtEeKAHdrZVWtwWQgghhBXcddddbN++/aquMRqNFnmr12r37t3079/f/LqoK+oDDzzAnDlzOHjwIAsWLCA1NRU/Pz/69+/Pjz/+iKurq/ma//znP9ja2jJmzBhycnIYMGAA8+fPt4iLvvvuO6ZOnWqubjBy5Ehmz55tPq/Vavnjjz+YPHkyvXv3xtHRkbFjx/Lhhx9a7b3WFRpTbSWGlKFfv3507ty50nVk09PT0ev1pKWl1ci/MLLzC/l4zQn+t8WyG8jLw9vyYO9gtDYNK4Fa1EFZFyDqbzi+UjWS8O8KrQerKhO2lc9PF0KI2lTR7+/c3FyioqIIDg6udOohqE91R48eTWJiYqVWZbVaLb6+vlatIyusp7I/B1VaRszJySE7O9v8+uzZs3zyySesWbOmKrerN3ZHp5QKYgFmrjzKkQSpoCCqWVoc/Po4/PwgHPwJzm2D7bNhwUjY/n+lm1gIIcR1RKvV8sknn+Do6HjFwFSr1eLo6Mgnn3wiQWw9V6VA9tZbb2XBggUApKam0r17dz766CNuvfVW5syZU+XJbNy4sU539ToYl1bmcaMJDpdzTgir2bsITq4u+9y61+CMtJEWQlzfgoODmTdvnrlzVskgtei1r6+v1dvTitpRpUB2z5493HDDDQD8/PPP+Pr6cvbsWRYsWMBnn31m1QnWJXba8lMHdJIjK6pTyjnYNrviMYeWQd3JFBJCiFoRHBzM0qVL+eSTT+jWrZt5k7i9vT3dunXjk08+YenSpRLENhBV2uyVnZ1tTkxes2YNo0ePxsbGhp49e3L27FmrTrAu6RrYCI2mdKzgoLMhLMC9VuYkrhMZ8ZB3hfSV6L8hPxPsXSseJ4QQDZxWq6VPnz7mjl0NsRGAUKq0jNiyZUt+/fVXYmJiWL16tXnXXFJSUoMr63C5TgGNeHd0B3SXrcw66rR8fk8Yzb1canFmosGzrcSGB3s9aGXDlxBClCRBbMNVpRXZV199lbFjx/LUU08xYMAAIiIiALU6GxYWZtUJ1iVaGw13hQcQFtCIw/FpaG00dGrqTlBj59qemrCWtFhIiQZbe/AOBbs68nfrFQLN+8GZjeWP6fqAmrcQQjQAdaiokqgFlf37r1Ige8cdd9CnTx8SEhLMDRFA1YYtKuoLEBsbi7+/PzY2DSd/VKPREOLrSoivfHzboGQnw75FsPlDyP13415AD+j3ArToX/G1NUHnCL2mQvQWMBaWPu/RHFoOqvl5CSGElel0OkClMTo6OtbybERtKaqOVfTzUJ5qrSPr5ubGvn37aN68ebXcv6bryFpbXoGBAoMRF4eK/5JENTMaYN3rsLWMjYpaOxi3DIL61Pi0ynRyLax/CxL3q9caDbQbDX2mg2+72p2bEEJU0pV+fyckJJCamoq3tzdOTk6SGnAdMZlMZGdnk5SUhLu7u7l9b3mqtCJ7NZMRpWXkFLDqcCKLtp8lMT2Xm9v7cnuXpnRo6l7bU7s+nT9UfkUAQz7sngcBPUFbrf9zqZxWg6BZD0g4oDZ2ufiCT/u6MTchhLCSovJZSUlJtTwTUVvc3d3NPwcVkd9+NcxkMvHl32f4/K/iXszzt55l2d44vn+4J+2a6GtxdtephANgMpZ//vAvMOAVaBRUY1OqkL1b3VkhFkKIaqDRaPDz88Pb25uCgoLano6oYTqdrtKNKiSQrWHHEjOYs/F0qeNpOYWsOpxonUDWaIDEgxC3RwVo/p3ArzNoJYWhTBUFsaDqrcmnC0IIUeO0Wq103hIVkkC2hsUkZ1NoLDso2nT8AtMHh1zbAwwFsOtrWP2CZYDW/2WIeALs6mjifHq8armadQnc/NRGKxfvmnm2zxVyS0OGg1uTmplLdSvIUf/V1dGfAyGEEOIqVGsgK8nZpekdy18Vbe1jhUoIZ7fCqudKH9/wNvi2h5Cbr/0Z1ha9BX4aD1kXio95toTRX0GTLtX/fL9O0PVBiJxX+pzGBro9BLb1vD5rXCQcWwmHflav298OIcOgaXjtzksIIYS4BtVaF0s2e5XWsamePi0bl3lueMeKd+ZVytl/yj93av2139/akqNg8b2WQSzApVOw7FG1QlvdtDro9zz0ecqyDmuj5nDXImhxU/XPoTqdWg/zhsHfH6oauSnR8PdHMH+4qoIghBBC1FPVuiJ75MgR/P39q/MR9Y6jnS2vj2zHh2uOserQeQA8nHW8NCyUG1qVHeBelaIaqGXJPH/t97e2s9sgN7XscxePQ+wOtXJY3Vx9YeDr0OkeFehp7dRKrZNH9T+7OqXFwS8PQWFu6XOFubB0IjyyBdyb1vzchBBCiGtUpUA2KyuL9957j/Xr15OUlITRaLlZ5syZMwAEBARc+wwboJbeLnx2dxeOJaaTnVdIYGNn/PRWyln07VD+ueAbrPMMa8pMvML5Gi694hWivhqKc9sgJ6X88zkpaoz7nTU3JyGEEMJKqhTIPvzww2zatIlx48bh5+cnubBVYGdrQ8fqqBsb3A/8wyB+r+Vxj5bQYoD1n3etnL0qPu90hfOiYhkJlRgTX/3zEEIIIapBlQLZP//8kz/++IPevXtbez7iWrk3hdFfw+GlEPmNKsXV7jZwbwYHf4bAXtAsou4U0A/sBfaukJdR+lyjIGjWvcan1KDYuVRijLRbFkIIUT9VKZpp1KgRHh71PHewBqTnFBB9KQsHnZaWXi7Y2NTQynXjFtD3GQgdBTu+gD3fFpddAhj2EYRPAJtq3etXOZ4tYMxCWHI/5KUXH3f1h9H/u/KKrahYQDewsQVjYdnnbbQQIP9YEEIIUT9pTFUoLbBo0SJ+++03vv32W5ycnKpjXpVypV7Ntenvkxd454+jHEvMwEYDd3RtyuP9WxLo6Vxzk/jnM1j7SunjNlqYtFmV46oNSUchbjcU5oN3W/DvAhmJELNdVS9w9YfACHCTjYLXzGSCfz6Fda+VfX7Aa9B7Wt34R40Q4rpRl39/i/qlSiuyH330EadPn8bHx4egoCB0OsvaqHv27LHK5OqrI/FpTFywm9wCtQnOaIIlu2PJzjfw8ZjO2NnWQNBQkAOR88s+ZzRA/B7rBLKFeapGaewudV+/TtC0GziU8X9MRgPsXQQrp6vGDUXCxsGAV6HT3dc+H2FJo4Huk8DFBzZ/AMn/dpXzaAE3zoDQWyWIFUIIUW9VKZAdNWqUlafRsGw/k2wOYi+34kACk25sXj2bvMpUwWK7NWr85mer1b5N71ke73Q3DH4HnEuUE4veAsunlr7P3oXg1QZ6PXHtcxKl2TlB53ug9RC4dBowqYYT9b20mBBCiOtelQLZ114r52NKAUB6bkG55zJyy8lVLJKXpbpIacvvAFYpOkfo8kDZHynbaFVlg2sVtbl0EAuwfzE06wVdH7A8fnJN+ff65xPoeBe4SE5stXHykOBVCCFEg3JNW9cjIyM5evQoGo2G0NBQwsKsEBw1AK28y94FrnfU0bxxOTmyCQfgwI9w5DdVYaDrg9BmGNhdQ05t6Eg48jvER1oeH/wu+FghreD0uvLPRX6rmgtc3tr14snyx2ddUJu9JJAVQgghRCVVKZBNSkri7rvvZuPGjbi7u2MymUhLS6N///4sXrwYL6/rOxiJaOHB0Ha+rDpcXOxfo4E3RrbDz72Mxgfnj8Ki0cVtWtNiVKvZoe9Cz8lVn4hHc7hrIURthPh94OAOQX1UyStr5EVW1KwgMxEMeZaBrF9HOLm67PGNgmS1UAghhBBXpUqB7JQpU0hPT+fw4cO0bdsWUO1oH3jgAaZOncoPP/xg1UnWtBPnMziakI6jTkvnAHe83RwASEzL4WRSJs52WkL99TjotGVe7+Fsz9u3tWdoe1/2x6Ti6mBLRAtPegR7lv3Ak6uLg9jL/fWOas/aKKjqb0bfBDrfq76srVkvtYJclpDhqj7s5VoNVikEhjJSL/pMB8dGVp+iEEIIIRquKgWyq1atYt26deYgFiA0NJT//ve/DB482GqTqw2/7o3jmZ/3U2BQm6GaeTjy37FdOZ+ew7O/HCA5SwVhN7Xx5pURoQSXkyrQ2MWeUWFNGBXW5MoPjS+nykN+JqTFXVsgW51a3gRuTSA9zvK4zhE6ltHyNKC7qhn7+1TI+nc1V2sHfZ+FdqOqfbpCCCGEaFiqFMgajcZSJbcAdDodRmPp3fr1xYnzGTz78wFzEAtwLjmHz/46wenzmeYgFuCvY0n46R14e1T7a2/R27h12ce1OnAqZxW3LmjcGu75AXZ8CQd+UOW1QoZDxOTyi+yH3AyP/q1a6BryoXEIeLep2XkLIYQQokGoUqLkTTfdxJNPPkl8fHGP9ri4OJ566ikGDBhgtcnVtKMJ6eQbSgfia48k0SHAvdTxH3fFEJuSU+r4VWs1BGztSx/vMRm8Qq58fUEeZJy37N5VU/w6wcjPYcoe9XXnfJWHWxFXXxXQht4qQawQQgghqqxKgezs2bPJyMggKCiIFi1a0LJlS4KCgsjIyOCzzz6z9hxrjFM5Oa9OdlryCksHuCagCo3RSgvoBmOXQNAN6rWDXnVc6jVF7RIrj9EIx/+E7++EzzrDglGqSkFZOajVycZGpT94trDc3CWEEEIIUY2qlFoQEBDAnj17WLduHUePHsVkMhEaGsrAgQOtPb8a1bmZO80bO3PmYpbF8Qd7B7Fw29lS4+/s2pQADyu16G3eT30cn54AOidw87vyNSdWwY9ji5sbxGxXX3d8A+1vt868hBBCCCHqKI2pikuK69evZ/369SQlJZXKi/3mm2+sMrkrqY5ezYfi0piz8RQrDyXipNPySN8WjO3ejN1nk3n2lwOk56iGBn1aNuaNW9vRwsvFKs+9agXZsPB2OLe19LnGreGhteDoXuPTEkIIIa6kOn5/i+tTlVZk33jjDd58803Cw8Px8/O79s1OdUj7Jnoe69uCroGNsNFo6NHck8au9gxt70fHpu6cOJ+Bs50t7Zq44WR3Tf0krk1OKsTuKPvcxROQdVECWSGEEEI0aFWKxL744gvmz5/PuHHjrD2fWrf+6HkeXRRprlxgp7Vh7riu9G/jjb+7I/5lNTSopNwCA0fi00nPLaCltwtNG11DWoK9G3i1hfOHSp9z9ZearEIIIYRo8KoUyObn59OrVy9rz6XWXczM45XfDlmU38o3GHnt90N0DuhDI+eqb2SKvpjF238cYd1RVT/V1d6Wd25rzy2d/Ku2om3vAn2mwS8Plz7X7zlwrsNlu4QQQgghrKBKVQsefvhhvv/+e2vPpdbFJGcTn5pb6vi55BzOJWeVcYWlvAIDh+PSOByXRl6BwXzcZDLxv7/PmINYgIy8Qqb9uI99MalVn3CbW2DU/4FbgHrt7A0j/gPt76j6PYUQQggh6okqrcjm5uby5Zdfsm7dOjp27FiqOcLHH39slcnVNHcnHfa2NqVKbTnobHB3qng19mhCOrNWHWPjcdVqtl+IF88PbUMbPzdikrNZvCum1DVGE0SeTSGsWRXTAHQOqvVsq6Gqxa2TB7h4V+1eVZWdrColZCaBmz807S65uUIIIYSoEVUKZA8cOEDnzp0BOHTIMkezPm/8Cm7swuP9W/Dx2pMWx6fc1IpAz7Jb0QJk5hXy8rKDRJ5LNR/bePwCOfkGvhkfjsEEhnKKQxQarVCH1tmzdlIJzh+CZY9B4oHiYwE9VYMEr3K6lQkhhBBCWEmVAtkNGzZYex51xoO9gvHTO7J0TxwaDdzepSmDQ30qvOZofLpFEFtkR1QyRxMz6NzUnREd/Fh+IKHUmE4BemtNvWYV5MG6Ny2DWFCrs/98AiNnq0YJQgghhBDVpBbrR9VNro467gwP4M7wgEpfU2gs3fWryPHEDHacucTNHfw4lZTJ0cQMALQ2Gl4a1pauzTyuec61IukwnFxd9rn9P0CvqWW3nzUUQmEO6Jwl0BVCCCHENZFA1gra+LrRzMORc8k5FsebNnJkxf4Etp25BMCTA1sybWArcgoMhPi4EeLrio1NPU3FyM8s/5zJCPklNscV5KpOZHsXQtJRCOwNne+B5v0rbsNbHVLOwtl/IC0OnDwhMAK829bsHIQQQghxzarc2asuqEudQXZGJTPlhz2cT88DwMfVniHtfVlQorXtl+O6Mridb/VOJj9HBWrxkYANNA2HZr1AZ2+9Z6TGwhe9ITe19Dn3ZjBxo2Xe7vY5sOp5y3EaG7hrEbQZbr15XUnMTlh8L2QVV5DA1h7umA9thtXcPIQQ4jpWl35/i/pNAlkrSkrP5VBcGgUGIysOJrDiQAIlv7vPDG7N4ze1qr5JFObDlo9h47uWxwe8pj7u11pxET5yPix/svTx27+GDpeVALt4SgW9haVLm+HVBiasrplKBzkp8NVASD5V+pytAzzyt2xSE0KIGlDXfn+L+kuSFK3I282Bm9r60L+NN0lpuRZBbKifG7d29qeZZxndvLIuwdntkHBA5ZBei/i9pYNYgL/K2Jh1rTreA3fOh8A+4OAOLQfC3T9A6CjLcReOlR3EFp1LPmPdeZUndnfZQSyo+Z3bVjPzEEIIIYRVSI5sNbCz1TK+dzA7olOw0cC9PQLZG5PCb/viWXP4PKfjkri/qxcePk3h1F+wYhqknlW5oh3ugv4vQqPAqj088WDZx00mOH8QmnSp8vsqRWcP7W6D1sMgP0O1zbUto96ubQUpDRoNaK2Y8lCRnJQrnE+umXkIIYQQwiokkK0mA0N9+OK+Luw9m8Li3bGk5RQAkFNg4JPN8TjlnmdSh2Ow5D4o+HeTmMkEBxarj9lvnlW1B7v4qA1UMduL71tEV34t3Guis684/9Y/THUfSy/dFII2I2vu43y3JhWf11e+UoUQQgghap+kFlQTndaGoe39CPFzMwexl/visJb8qC2lg02A3V9DcvTVPTAjEbbOhjUvqdJYIcOgzYji8w56aNrt6u5pLc6NYdR/wc7F8nijILhxBmh1ZV5mdU26QOuhZZ9zD4TAXjUzDyGEEEJYhazIVrP8QiMT22sY6HgCvTGNaJtmfBXjx6GLhWA0lH2RsVB9VVZhPvz1FuxdVHzs0C/gHQpBfVRQPGrO1acrpMbC6fUQ/Y9qf9viJmjer+z0gStp3hcmblDVFLIuqNXPoD7gXoOroDpHGDwTbGzh2Iri436d4ZZPVItdIYQQQtQbEshehbwCAwdi0zifkUuQpzNt/dzQXlYH9nx6LscS0nGw09Le3w1nex0DGiVxe+IMdJlxALQBOrYcy/Kg27ErzFQlqEwlGiqE3qZWKysrYb9lEFsk6QiM+EStzLp4Xd2bTY2FpQ9bboDaMQdufh96PHJ19yri1br2qwI0bgG3fwMJ+yA9TgXoTbqo/F4hhBBC1CsSyJYhLiWb/bGpgIbOAe74uzuSkpXP+6uP8cNOledpo4Hnb27L+F5B2Nna8M+pizy5eC8XM/MBuKFVY94Y2Y7g0z+j+TeILeJ/6nvG3tgaUrLgls/gj6fBoK7DOxRumH51ZbIyz5d/zlBw9UEsqJXYsnbxr3kZgvuW3bXrSgwFqo5r7E4ozAPfjurj/JoovXU5nT0061GzzxRCCCGE1UkgW0Lk2RQeWbjbHJB6u9oxd1w45y5lm4NYAKMJZq48SliAOwGeThZBLMDfJy/y/Y6zvBzzd5nPcc07D/2eA88WKnc16YjKIW3S1bKRQGW4NVG7/8sqCezerOxrCvNVoBqzE0wGtSoZ2Bvs/t0QFlX2vDHkq5JZVxvIGgph11ew6gXL4+1uh2HvqzxaIYQQQoirIJu9LpNXYODzv05aBKRJGfnM2Xia2NTsMq85dj6DYwnpFtcU+XFXLBfbjC37YU27qSAWVFDYfjS0Hnz1QSyAbwfo/qjlMX0A3PCM+nPJjWNGI+z6HywYCRveVnVnv7sTNn8EBaozGU4e5T9P53j1c4zfWzqIBTj8C5xcc/X3E0IIIcR1TwLZy1zMzGPj8Quljq8/loS/e9nBWyMnHY46bZnn9I622AX1BJsS5306VrxDPj1BfVWW1hb6Pgu3fApNwqHTPSpQ3vIh/HCX6qq1e576aB/g/CFY+3Lp+2z5COJ2qz+3HFD2sxoFqVXjq1V037Ic+fXq7yeEEEKI654EspfRO9rR2sel1PEQX1dCfFzRO1pmYrTzd6N7kAftmrjRp2Xpj8Yf7dcSt6AucO8v0Gmsygm96RW4cx64+ZWeQMo5WPsqfB4Gn3WGNa9CytnKTd7JA7qOV+1e3ZrC4aXFqQb5marpwpmN6nXSkfIrJpw/pP7bvB8MedeyNJZ7INz6f+r6k+sg7d/cX6NBtaG9eLI4WC6pvOdB8SpwXZWTCqfWw/4f1fcwL7O2ZySEEEIIJEe2lMGhPpxKysT4bwyotdEwrL0fIb5uLHqoJ38cjOdwXDoRLT0Z2s4XbzcHAN68tR2Ltp9lye5Y9I62TO7XkpGd/FXuaov+6qsiRSW0Di4pPrb1U0iPhVFfVL7kVdYF2P7fss+d2QitBoGujDa5RYrO2dpDxGQ176SjqrKC1h6O/wHHVkJKFDg2guEfw/GVcOhndV2bkdDnKWgSZnlfv07lP7PdrZV7b7Uhfi/8NkV1RSsS2AeGfQA+obU3LyGEEEKgMZnK2iFUP6Snp6PX60lLS8PN7drLJ527lMWIz7cwtL0fBQZVEkuntWFn1CV+e6I3escrB5MXMvKws9VUaqyF+H3wZd+yz03aqLpjVUbiYZjbp3RJL4CwB+DWzyA9Hub2hawky/M6J3hkEzS+rERWfpbKp90wEwpz1bEWN6larBoNnD8CaSU6drn6w4Q/LUuIFeTChndg62eWY5v1gtFfgXvTyr2/mpSZBN8MheTTpc8F9oaxS8C+9Aq+EEKIiln797e4fsmK7GU8XOwJauzMkt2Wgdltnf1xta9c9ykv1wpatVYkv4KPq/Myrnx9zC44+BOkxUKrwXBiVekxQb3Vf9384a4F8OvjxUGaqx/c+l/LIBbg+J8q3QGKN6iZjNCouSr7dWJ16edkxKuqB5cHsjoH6PscBPSAMxvUx/PBN6iguK42Iji3rewgFlRjh7jdKgVDCCGEELVCAtnLuNjb8uyQEB5esJvcArWi2chJx+1dm2JzWeODatE4BFybQIZlzVlc/cDrCqWuzm6FRaOL2912vlddl3HZhrEOYyw3cDWLgIfXQeIBVcXApx24+lje12SCfd+rP4eNg7hI2L9YvXbQQ9j95c8pI7H0MXsXaDtCfdUHV9pwdzUb8oQQQghhdRLIlmCj0XBzOz/QqE/O8wqM/Lgrhm7BHtjbll2doCwGo4nj5zNIzcqnuZczvvorlKxy8YJbZ8OP90LBv6W+dE4wcja4eJd/nckEexYVB7EA+76DkGHgdbdaoW0xQHX3cnC1vNbJo+IVRWMhpJ1TQW/MDrh4ovhcbhrkXCr/Wn2T8s/VF1eqbetUhVJpQgghhLAaCWRL2HLqIsv2xZU6/mjfFrRroq/UPVKy8pm94RTz/onCaAIPZx3v39GJgW19Kr6w5U3wyN9q5ROTKnPVuJXa8R+/B+L3qxquAT1Vq1VQOazRm0rf6/hKMORB3B61mloyiK0MrQ7ajYbUc2V3+cpIVKvFF45ZHvdoAUE3XP3z6ppmEeDUGLIvlj7n1QYCutf8nIQQQghhJoFsCcZ/9755u9qTW2AgPbfQ4vjl0nIK2Hs2BaPJRKcAdzxdVH7suqPn+XpLlHlcclYBT3y/h5VTb6C5V4nNQWnxqrOWvqlaAm7cUn0VMZlg7yJY8WRxOS0Hd7hnMQRGqFXbpt3BRqdyYAvzVN3awjzQ2oGTl2qYUFWho2DHF2WfO/2XKtGVEg2R8wATdL4Puk0E94CqP7Ou0DeBMQtgyTjIvmz12T0IRs2p+da6QgghhLAggWwJvVp4kppdwLnkbFzsbfFytSc1O5/WPpYrmjvOXOKTdSfYdiYZgKbuDnxydxjhQR5sPJFU6r65BUaOxKcXB7IZibDra9g2G4wF0OUBiHgcPJpbXhi3V62GdrwLclJUF6zcVFUB4N4lKpANn6ACyb2Liq9zbKQ6e4U/VHGXrivxCVU5tweXWKYvFHHxVmW6+kxTgbbbvyXH6pq8DFU+rLJlzIoE9YZJm9XfQfZFlXvcrCe4+lbPPIUQQghRaRLIlnA0IYPFu4qrFtjaaPjivq7YX9a9KzU7n1/2xJqDWIDY1FzeWnGE7yf2wNOp7MoFzvaXfbt3fQ2b37/s9f8gOxlum1scbJ3dCkseKC6T5eqnAtNd/4Pov1X+a1GVgUO/WD4sJwWiNkL3iVf9PSilWQ8YPBP+eMryeOuhEHyj+nNdrTwQswsOLIETK8HFRzWNaDPi6oJ796bgfme1TVEIIYQQVVOrnb3effddunXrhqurK97e3owaNYrjx4/X2nwS03L4/K9TFscKjSZ2RBV/rHwhI4/f98VhNMGdXZvSq0Xxhp/9sWnEpOQwuJ0PJYscdGyip1OAu3qRFgdJh1VQ1Xms+nJspLpxFeWb5qTA8icta71mJKjgtkkXVTXA7t9V4vNHyn5DJ9dAzHZVw/Vahd0Ldy6AiKnQ41EY+blqhlDRRrTadnYbLBgJu75UQX9cJPw+Bda9AfnZtT07IYQQQlyjWl2R3bRpE48//jjdunWjsLCQl156icGDB3PkyBGcnZ1rfD4FBhM5BQaaN3YmrJk7RpPKg838N082PaeAl389yOrD583XdGyqp1tQI3ZFp+Bib4ubg44QH1e+Gd+NBdvOcuJ8BiM6+nFH16Z4OP+70pp6rrjUltYeHNwg7D7Y/Y2qFABw4bhllYAiSUeg4xi1Cauoza1jOZvQHNxh+/+B3UIY9EbZq6YFuRC7WwXW9q7qY/OS6Q0AB3+G3x8vztMF1W6319Sr/7i+JhgKYeeXxRUgLrdnPnS4vXg1WQghhBD1Uq0GsqtWWRbtnzdvHt7e3kRGRnLjjTUfZDRxd2TqTS3ZF5PKL3tU5QIvV3v69W/JpAW76RvixcHYNItrDsSmcUfXpuyKTuGxfi3wd1dltvqFeHNDKy/yCg042V32bTaZ1Efdkd8UH7PRQvjDapOUV4g6piunXJfGBloMVB/rF2nWE5x9IOu85di2I9SzDPng1xF6TbE8n58Nf38If39UfMyxEdy9GAJ7Fh+7cEKlFZTc8PbXWxDURz2/rslIgCPLyj+feEgCWSGEEKKeq9XUgpLS0lSQ6OFRdv5iXl4e6enpFl/WZGOjwc1Rx4bjF8zHLmTk8cueWGJTcnhp2SFuKqOElpuDLW+PaseDvQMtjmttNJZBLKgGBHu/tTxmNEDCPlVuy+7flWivtqqJQUld7ofQW1Vd1/VvqmDy0im4+ztoc4sa49hIldw6f1hVQ+h0t1rp/fsj+PM5tSksPR7ObbcMYkGlNKwv8dH7+UOqCkJZEg6Ufby2aXVg61D++YrOCSGEEKJeqDObvUwmE08//TR9+vShffv2ZY559913eeONN6p1HicSS7eD3R+bxuiwJhxJSOdAbCotvV04lVTcUnZoO1+6N69kcfycVBW4lpQSpWqWXjipUgbsXeCml9UGpV1fqZXYHo9Bt4dh//ewosTGq5Gz4c55qvPWsRWqXW3nsSrnVucMm963/Ji9eX9oe6vlPezd1Orwua2QfAZ8//17qCjo01WxJW91c/VVK9xbPyt9TmMDTcNrfk5CCCGEsKo6E8g+8cQTHDhwgC1btpQ75oUXXuDpp582v05PTycgwHr1SgsMxjJb0QZ6OGFCfayeX2jAxV5VMLDT2vDS8LaEBTaq/EM8W6jc1dxUy+NNwmHpRNUUIeuS2lDV/EYY8rYqy6XRqOAs5SyseaX0fde8rILTRoFwYhW0vx0OLVWrsxqb0rmiZzYUd/XybAGBvSHrolq5dfEBLvs+NOkCrv6QEW95D1sHaNqj8u+9poWNg9Mb4fxlq8YaDYz4D/iU/Y8lIYQQQtQfdSKQnTJlCr///jubN2+madOm5Y6zt7fH3r76VgB1Whs8Xexo5e3CyX9XXHVaDXeGN+Wrv1WDg3E9g4ho4UlsSg5+egda+Vxlxyx9Uxj5GfzyEBgKio/Zu0J6LOxZoNIHFt8DEzeoZgnpCao4v6svpMdBfmbp++amqkAzsDeM+j9V3SA3VeWwnl5f9lxyUsHZS3UK27PA8pytAwyZqTZyufqq1d5lj6qVY1Crx6P+D7zbXN37r0lerWHsjxC9WW2es3dV3boCuoNNncqqEUIIIUQV1GogazKZmDJlCsuWLWPjxo0EBwfX5nQAVSbrSFw6HZvqMRjByc6G1Ox8nHRapg1sxS2d/HFz1JXu0HU12o6EUV+o/NKsJMhJhgM/Fp/PSVUB7OGlajOWoQBs7WHQW9BigMqjzc+yvKe9mwpyXXxUA4P0BHU8LRYaBatqByXZu6jKAytnlD636yvVhCGgm3rdrCc8vF7l+BoL1YpmUdWEukzvr3KEhRBCCNHg1Gog+/jjj/P999/z22+/4erqSmJiIgB6vR5Hx3J27Vezm9r4YDTB3nMpGE2gd9TRPdiDqQNa4+aou7abZyQCGvUR/u550KgZ7P+h9DgbW5VHm3ymeNW2MA/+fBYeWAEDXlN/vlzEE7D5I0iNhoFvgl9ndTxhn2qKUDKQdfVVwW/cblXVoCzxe8C/s9o4BeDsCS36F5+/dEbVqc3PUoFtky4q4BZCCCGEqAG1GsjOmTMHgH79+lkcnzdvHuPHj6/5CQHpuQVsOXWRhdvPYjJBCy9n+rRqfG1BbFE72nNbwT0IzvylgtXmfeGGGWol9dx29bG9RqPqymrt1KpsSXGRatNXQY76uNzFC+z1qvmBjVY1WUiLgcSD6s+R8+HI72qT2PnD6ll+nVV5r7hdaj4aTenSWqCC4N3zVCBcsu1s9Bb44R7Iu6xyRN/noPdTYFc7/wgRQgghxPVFYzKVFcHUD+np6ej1etLS0nBzc7PKPZfsOsezvxy0ODYo1If/ju2Cne1V5FVmJqlgLz1OBYmHflE1Yi9PIQAVbO5dqFIGnBqDgyucPw7tb1MbsopWOAvz4OjvMHQWBPWGBbeq1dq2I2FvifzWdqMhapPq/tX6ZjUuP0MFxxePq05geekQPgFaD1MNAo6tsLxHs55qpfXCMZi0GXxCi8/lpMI3Q4q7kF3uvmVqw5oQQghRjur4/S2uT3Vis1ddciShdG3azScukJKdj49bJWuPZl6A3x5Xq6QAbk2g7/Ow+oXSY0//pTZbnVyjxrS/XXXgit6svrKT1TjHRtD9ERXEHvoFsi5A21tUHm1JR39XAXJ+lsrB9WkP614rPa7VUJUqYCyExq3UdYZCFcRmX1SrxKBSCC4cUx3A7F3Au61l69zLJeyTQFYIIYQQNUIC2cuYTCbzJ+z2tjaM7OSPwWTCXmvD2YtZlQ9kz24pDmLtnKH1EFU5oKj97OWMhSrNANSY/i+otIHtXxQHsaAaFcTtUl294veqY7YOZVcw8GmvgtgDi9VqcMIB1dVr9zfquINebfJq0R+0ttDmZhUoR/+t5nJ4aXFurndbOPobHFxSfH+NRgXVu74qXRPX5hrziIUQQgghKkkC2ctoNBp89Q70CPYguLEzy/bGkVdoBODnPbH8d2wXBrfzvfKN0i+rt9pykEonsLGFkGGlV1Cb91fNC0Ct3IKqOBC1qfR9Y3fD8ZXQcrBqwZp6FhqHqHSByzXpooLWIhePq9JeNz6j8mQLc9V1tnbFY/w7g4tv6RSDloNKNxUoSpVoMaA4YAdVrzagDteVFUIIIUSDIoFsCf1DvDkcl06BwWgOYgEKDCaW7I6hhZcLLbyvUHrLK6T4z1pdcamsnGSVv3r8DxXYth2p2ssa8tXrFv0hL1OtmJbVgCB8gsq9PbJUldRqNVitnB74UQWQJiOYgOzU0nPKz1KVC4qC5t7TLM/rHGDw2+DeDPZ9D22Gg6OHCk7LknVBNVI4+e9rOxfVaKCoXJcQQgghRDWTQLaENn5uvHlrO95YUbruanpuIZHnUq4cyDaLUNUItnykgldXX1W54MzG4g1YzSLg4gmVHtBhDHgEw9EVkHgEuj8MA16FXx8tvmfIzXBijSrk33pIcdB6ZjME3QgHfwT3QDW2871wYqVaeb2cRnUko9UgtfmrIFcFsEU8gmHouxDYC36eoALsTveU/R61dtD5PrXKnJ8FXm2gURCc/UdtcstNhyZhasXZuXHF3y8hhBBCiCqQ9kZlcLK3pXcLz1LHW3g5cz49t4wrIDU7n5PnM0jPKVB5sf2eh7u+A7cAuPFZ1VUKIDdNrWYe/wN2f60+9ndurDZ9nVoLucmqZFb72+GexSrIbXuLynv1CFYB4/7FcGAJ7PkWQkeojVftbgOdkzpvLCwdgGp1Kvhsd5sKaBeMgh1zoCBPBdkFOWpcdjKsfa24tmz2xeIA+XIRT4Bvewi+UQXZHsFqs9g/n6mV3/3fwy8Pw5/PqSoHQgghhBBWJiuyJZxJymT32WSSMvJ4on8LPJzt+Dkyls4BjdgZncxDvd35+8QFugQ1wtlOffs2Hb/AG8sPceZiNm19XXn1lnZEtPCErEuQeR7WvKQ2VxXkqFSCxINw/pB6YEYiZF9SjQk8W6gasFGbVE3WkJvByRNWTAf/LuDbAbb/X/Fk02Lg9Ca16ntilTqWsE/l0Q55B/y7QnykSnXoNkk1Lzi1XpXe0tqp0mA/jlUrqH6doc9T4OINyaeLn3FyLXS4E3zaqXJg9m7Qa2rpblkXjsGJ1WpDWn42tBygVpsP/Qzt71AbyoQQQgghrEjqyJawbE8M3/xzloNxaYCqXvDmre3Ydy6VAA8nVh9OYH9sOg/1DuLZoW2IS81h+GdbyCko3r3v7qRj3V0uNN70sgokfdqpoK4wD+ycIPHfILYgW+WgdrkfYnZD57Fw4ahaVW0WoVZhjfmw8T0V3BoNpTt0dR6rclpLCrlZBbIXj0FKNHg0h4unVJktACcP1ezg8vQDjQ2M/QkW31O625eTJ4z+Wm0Kc2pkec5ogOVPqnq4l/NortINgm+Erg+qjWT7l0BhDnQcA21G1I82t0IIIaxK6sgKa5EV2csUFBo5eynbHMQC5BUa+WVPHPa2NvywK4Y7uzYl+lIOX/8TzdAOfiSl5VoEsQCp2QXkpl5QQSyogPTAjyoY7D5JbdQqzFP/dfZS+a4Z52HNi2q8Z0u1wpmRqFIEctMgsLeqOFBSWSW9QG0Ky0uDgz+r1+1Gq0YIB35U5bPa3AJBfeDUuuJrTEaI+hvC7rOsegBqnq4+pYNYUPfd913p48lnVE1aB3fY9B5sn1N8Lnanyu8d9V/VyUwIIYQQ4ipJjuxldLY2ZOWXbgubmJZLSy+1weu3ffH0be0FQEpWPqcvllHHFdDlJRe3dTUZVfvY9qNVQHfgRzjyK/zzHyjIUukGJ/4svvjSKZU7m5cBURvVSueOLyyrIRTRB5RdWaBxa5WyACqIPbGmOJ3BZFL5rPauKlXgcpdOqAA6bJwKXnVOauXUOxSS/g2kk47B3u/U14VjqsatyUiZjCa1Mrvji9Lnjv0OsbvKvk4IIYQQ4gokkC0h1N8NWxuNxbEBbb35/UAcAPkGIzYaDQ46Gy5k5rHiQAI3tLLclf9gBzsaHfsBQkaoA1kXYOBbKqWgZCbH8T8h51LpicTsVNUF9i4qPnZsBXR7WJXaahSkcldNGlUhwUZbPK5JF5U3a+cC/V+CDneogLik439CixJduNqMUGW3XHxUd7DOY1WzBJNBBaXH/4Qvb4TfJquvuTeqDWEOZazUgnoPOSml33eRlLNlHxdCCCGEuAJJLSjhlo7+ZOYWsmR3DBcy8hnSzgetBi5lqk5X7fzdyM0v4Iv7urI7OoUT5zNx1Gm5M7wp+YVGXO1tmcRi7E7uAF0fGPaRaoJw6OfiLlyufqBzVB+956RAs17qeLMI1Z42dpfKn81Lt1zpzEiEXf+DLg+oqgFJR1U1gsTDMPxjyElTK6oF2eDRAjrdC57BcOQ3yzfp2VIFw0aDqjYQv1c1V7hhBvzzqSoXdv4gJOwvvsbVTwW2P09QaRFFCvPgj6dhxIfw80OWzwm7D0KGWt6nJFefq/sLEkIIIYT4lwSyJZxKymTvuRRCfNzo19qBqIuZ+Ogd8HC246YQb+4Ib0JbPzf0jnacS84GYH9sGvtjVV7tba3t8En+t3uXs5dqanD2HxW49n9FBZkXjqkV06AbVF1Zt6bQc7Ja7YzZrurCth6idv876FWO7OXsnGDJOPDpoKoHRG+Ewz+rVdTuk1RlgounodeTanxAD5VqcPEE+IepygSX57R2naBKfF04qlIaArrB3hKdxTISVImwojJdl8tJATs3uPcnlfean6FyelsOVKXI/DtD6CiVTnE5/67QtHtV/pqEEEIIISSQLWlnVDJL91p21HqoTxBLH4ugmYczNv+mHRiMJs6n5RDRwpM9Z1MY2coOVwdbbtOfwSYpG3o+pmrAbv9Cde3q+iAYjWDvouqvZl8CNCpFIC1B5ZAWrb5GbVIf17v4qI/2I79VATBYbvry7wxrXy7+2D7zPGycqUpttRwIhjzAVa2wDn4HNr+vKiKUrC4Q+Y1KAbhwTL2+fMX1cud2gL4JXDpd+py9KwRGqG5jJemcVNcw71DY+YXqRtblQVWtwcWror8OIYQQQohySSBbQkpOfqljURez8NE7kGcwsOXYJfaeSwFUdYKWLoV80ms/PgfmgNaWjO5PwaP/gHtTdbFve1U9QGMDJ/6Ac9vAsxW0Glhc/qrP0ypAjf67+KHnD6tqB5HzVfcsRw9w9oajv6kV1S7jwdG9dO6p0QCY4Ps7wNkH+r+oasY2bgV3fgv/fFL2G088qOYFanxZ/MNUCkLJQDb4RvDrWPY16fEqwHbxhX7Pqa5lRoN6D0IIIYQQ10AC2RLa+elLHesW5MH5tFx+3RfPnI2nyStUK6e2Nho+G+KOz9bZENwX8jJw3fgKeDVVZbGSjoBvRxXE7pwLqefUDS+dVM0MQkeqDl075kDf51WQe3k5LY1GfZR/6Bf1us/TatXz+J/qY/4u95f9JkwGsHNVVRI2vK1KcWl10GOyysEti6O7eg/b/k/l8ha11S2ic1TdxhzdVTmtg0vU8Q5j4IanVQpBkUun1XtJPQc7v1SpB06eMPB16HgX2Npf6a9BCCGEEOKKJJAtoXdLT14e3pZ5/0TRu2VjGjnZ0crbldWHEzl7KdscxAIUGk0cuKRhWMgwOPaHymft9jBkpcDcPqp8FsDI/xYHsU26qnJU2cnAv9URCnJUYOvfGWJ3q2PN+xf/GVR6gkcr+OcjSItVH+G7NVHls/LSi8c5NlIpDDc8DZtmFee0Ggpg66eqXa7OqThVAVRgGnwDeLeBcUtVoOwd+m/Hsb3QtCu0ux2a/ZvPOur/4MYZ6s8ezS0rJiQdgx/uhub9IHJe8fHsS/D7FLWy3HZEFf5mhBBCCCEsSSBbgqOdLf1CvNBq4I0VRwGYu/kM93ZvhpOurGplJlWVwFCgVjJ3fgk9Hy8OYv06qRVSjQbCH1Ibvw7+pFY8uz+iSmQ5NlIft/t3BY2t2pxlaw/GAtUu1mSC0FshIVLVmHVspFZIN78PYferj/vPH4Im4eoj/Mh5qjRXWRuzzh9SK7mXTsKFE+DdVm0Ey/l3Q5lPqPqqiI22uENYScdWqNzclKiyzx9eKoGsEEIIIaxCAtkSTiVl8un6k2w9ZVnbdUlkDK+PbIedNo58Q3FqQV+nsyqIvVz2RfXfpuFqtfPsP3Dj87D/u+KV2YxE2PCO2gSm0ahgdf/3qtuWsQB2LVAVCXw6qk1gOge1imvroFZrj61QwW/kPLUy69UW0uNUAG0ylt0kAdT1kfNUMNzudjizAU6ugcO/wqQN1567GvW3SjMoWWmhyOXpCkIIIYQQ10AC2RJ2nLlEY2d70nMtg9MCg4lj8emM7tKEnAIDLnZahnqeJyJhRembFHXLan6TWpk8sRoiphQHsUWMhSqgtLFVG7/yMlQpLkwqiN31NRj+3Xym0ahyWmH3qYBV51R8Lj1OfXm2VPcClRfbKNhyZdRGq9IfCvNUQJmbVjyn9Fi1wexaA1nvUIjerOYfv7f0+dBbr+3+QgghhBD/ks5eJWiAs5cyGd7Bz+J4j2APdp1NYcWBBGxtNGTlG0i28yPHr4eqINBxjArS/DqrDVWeLVWt2IM/QW4qZCaWXQ0gPV6lD2RfULVcHRupa1JjigNVUCu2p9erFVUXH+h8b+l7Bd8I8XvUn0+vh9ZDod1tanxAd+j3QvHGMZ2janlb1KQBwLacagVXI3SkCqYzz4N/F8tzLQZAyPBrf4YQQgghBLIiW0p2gQFfvSPernY83q8FB+PSaefvSnJ2AT/uimFC7yC+3XYWg9HEr/tgSs9uPHl6LrYZsSqNoMejsOVj6PEY7P+h+MYnVqmNYFGbwKcdGApVCkBKFHR/FBqHqPJbKVEqmE2PLz259HhVd3blDNXdq/sjcHarqkgQMkzlxGrt1Iprk66qMcGZjapyQnoc2OvVhi63pmoD19bPi+8ddAP4drr2b2BgBNz3C+z6RuX73jBDBc3eodCsJzh5XPszhBBCCCEAjclUshBp/ZGeno5eryctLQ03Nzer3POrTadxtNeSklVARl4hBYUG8gtNtG/qyi+R8VzIzOPspeId/xoNLA8/QPuD76kDzSLAuz1kJ0HWJTi7pfjmt86BvQtUaSpbewgbp3JgDy5RdWc1NirgW/sq9Jqi2sVeLmycamd79t96sxlJaoU2+ZRqZuDgDr2fVOkDu/6nyn8VaTVI1YHNS4fsNNUd7NQ6VU0g7D4VZJe1gauwQG1W0zlc3TfSaIC8TNUA4vKqBpcxGA2cSTtDTmEOwW7BuNq7Xt0zhBBC1EvV8ftbXJ9kRbYEV0db/rvhNDEpasd/Wz9XPJztcLa3ZULvIGb8fMBivMkEGSbH4gMXjqng7dQ6uOlViN2hNoO5+sOptSqIBbVquut/cOMzKh3g7BZVxzUtDvq/rGqvtrsNji5XgWTrYapl7YqpEP6wCkQB9n1f/OzcVFj/BvSeplY/U6JUekLLQeDRAg4vg4sn1ViNjeq21eFOVeO15Ia1/Cw48jvs/Eo1dOj6IHS4A1x9OZd+jrTcNDydPPF3KacurY0WHEvX5C0SlxHH3ANz+e30bxhNRlrqW/JCjxfo7icta4UQQghRORLIlhB1MdscxAIcTcjgvp7NOH0hAzdHW0Z29mfxzhjz+VaedrTJ3Fl8g6A+EL1FBYqXTqqGAbYO6vipddDpHpVmkKO6g5F1UbV3LchWaQed7oasJLWiqXNSK6W2DqoDWMZ5FXCmx6pasY7ulpMP6KHyYXPT4ejv6mP9C0fVJq7gG8G9WXEgazKqdIb4fbD7a7h4AtrfCZ3vVrVhDyyBFdOK773mJVJs4Gcne1ZHrybPkEeYdxgR/hEMDhyMtpxV17KYTCbmHZ7HslPLzMdOpZ1iyl9T+HHEjwTpgyp9LyGEEEJcvySQLUFbxvY3WxsbtDY2JGflE5uczZQbmrDxdCrhnvmMCcql0d6TKje13Wi1KloUpNo6qLqpHe+BXyao5VuNjQpO9yxQwamzp9oYVcSztdok5tgICgvV7rOjv0NqNLQcqDaU5WeqALT7I+oa58aq69bJtZCwH9qMUKunhXmg0aq82sSD0LgtnFqvas0OfA3QwA93qaAWYPMstWJ82xew8b0S3xgdP2nz+HzvXPOh6PRoknOTaerSlA5eHSr9PT6bfpZfTvxS6nh2YTb7k/ZLICuEEEKISpFAtoQm7k446rTkFBgA8HS240JGHmuOnMdBZ8PN7f3wyTnFcu0HcC4eTqarjVUd74bAXnDw5+KbnVwLg2fCiidVEAsqaNz/g8pZLciFlMtKcgX3hQM/qFVTjQ3c/AH8+UxxoHnsD7Wy6t9VBaQHl0DEVHDxgqTDqjKByQiHlkKTbtDxTtU0oVGwCmZDbobwSPWRv7MXLJ9WfO8i0ZvVBrHsCxaHL7UZxoLTyyhpc+xmQhqF8N7O9xjRYgSDAwfj6ehZ4fc435hPoamwzHO5htwKrxVCCCGEKCKBbAkGo5EpN7XkYmYeWhsN9rZa/rvxFAC5BUY8nHWsifXgDvdWOFw4pi6Ki1Rlt/58TuWduvmr6gBJRyBud+n807wMVWPWBGCCtHOqYkDyKcuP/o/8ptIBUqKLr43aDIG91VebEar5wKrni1vO2jmrzl27v1EBdrdJKsf1zGbV+UvfpPhemUllfxPO7VAtZk+tNx/KcnAlLbl0kwMTJuKz4jlw8QAHLh7gVMopXujxArY25f9oNXNtRg+/HuxI2FHqXKjnFbqKCSGEEEL8S+rIltDWX88Xm0/zzT/RfPV3FBtPJPFE/5bcGd4UdycdmbmF+Hh6ssD9MS71elXVcx3xiequ1XsKxOxQuapnt8L+xarsVckmAx7N4dBPsOP/1EauzIuqa9dlgSOgOoTZl9jNqXOERs3B0RMSDqgOXwXFVRTIz1KBr6ufWlX1DlF5s53uhgvHi1eGAdoMK/0NcGwEOZfUBrDLqhj4Jh6jl19EqeGeDp6k5RUHuD+d+InjKccr/B472DrwZNiT+Dj5mI/ZaGx4sceLEsgKIYQQotJkRbaEf05dJCO3kM4B7hhNJg7EptHax5Vle+N4ZnAIO85cYtPJi0ztF0RWo7Z46l1g40y1uqlzUk0HMhNVQNj2FtA5w8A3YetnaoXWP0yt3kbOUw9MPq1KYtm7lJ5M6K0qlxZUABt6qwqYM+LAPQAwFZfiulxyFNz4rFq9jdkJB35Ux7d+CqPmqKAWVO3ZXlNh+3/V5jI3f/WMnV+prmNBN6jzzo2x8+3M43kXOZ16hvM5KqfX0daRm4Nv5odjxfVyTZhIzU294ve5g1cHFg1bxP4L+8kpyKG1R2vaeLTBprzWukIIIYQQJUgd2RL++9dJLmTmszs6GVcHHW38XCksNLBwRwxtfd3w0dsxq9MFvJJ3Y1OQC7G7IW5X8Q3sXaHfS7D6+eJjfZ5WQWXbEapr1/nDxec63QNHflUroK2HqooH+Zn/lsxqqeq3Jp9Wq7obZhZ3+/IPg1aDIfmMuuflQkep9rA9HlPNGbIuSyFoHAIPrwOHf79fRiNcOIbp1Ho0ZzbAmQ2WebMPrVW5t/9KzEpkb9Jesguyic2I5dsj31JgVKkTthpb+jfrz+iWowlwCyDQLbDqfxFCCCEaLKkjK6xFVmRLaOxqz8mkLJp6OJGSlU9+oRF/vWoGUGg08m778/isfxqyLqh2rBdLfIyelwHnLWvNkrBPrdgmR1kGsaC6fLn4qGoHhXmqIULmedi7UDVXyL6kVmuzky1b1sbvVe1eA3qoYDYuUh3366wC0dSzKsBu1h2Orii+LvkUZCSaA9kjKcf4Lfo3OpmMDIvdBSYjqQHd2RPQkSSXxgRqCuhckIOjTtXK9XX25ebgm/+/vfsOj7LKFzj+nZnMTHojnYQAAZIAIZSACV2QICBiAyyLsJarq6io15VVd8G99z6yFnRVihVZ27oquCpFaaEsHUIPoQUIEBISSC8zmTn3j9cMTBICYkIy8Ps8zzxk3jnnzDnveYb55c15fweA9Nx0/nXgX1gtVryMXtze4XaWZC1h2bFlmA1mHun2CPfF34en0fM3zIgQQgghRP0kkK3FblfsPlnI4TNlAGzKOstTQzsAcFtCCEF739SCWNCunrYfrKXHqhEcpwWfFzqSBre9D5mLtK1la8p3GwcGd21HLrsdNrztXO/kVi3TgE6vLRGo7exhiBkKsbdASBewW7R8sDXtnzumbYRwofZDHOtujxcf5/EVj5Nfkc9XOgP5N9xNb3MYs0v2kZbzs1b+4BdM6jKJx7s/jrub8+5eHQM68vHwj8k8m4lSimkbpmFTWraHKlsVb6e/TaRPpCPwFUIIIYRoTBLI1qbDEcTWyC+1MD4pirPFRRwOHIjOuwcdjn2FoeSklgu2++/g8AotS0DUDdrV0Asl3gOntmqBZ2gXLd+swagtS/AO1zY2KMqmjuh+0GG49nNZvhYQX8gnHH58Gm54TMslW3Rcu6JbWQQFh7X6p7afLx/YXluicGwdJNzF9rzt5FfkA2BTNl7LXsptHW5jy9m9DG87HDedG2cqzvDJ3k8w6o3sPLOTW2NupW9EX1YdX8XHez+mxFLC2E5jCXAPcASxF0rLTpNAVgghhBBNQgLZWoK9zPiY3SipOp/nVCnFzhOFdAj2ZuTWWAAe7JrMkx6v4mOvhsg+ENpVuwHr6/u1G7J6TNCCXDczRA+EHyZrSwNOX7DsoNcD4GaCwmztRqth/6NtMWuvhlYx0HagtnShPB86jdCC2dw9WhDc6/dQcgr8IqAgU1tnWyNhLIQkakGzzQoRPbU6lUWw5QMtAAYqq+vmbPU1+TIsehhLs5ZSaask0juS++Lv43TpaTaf3szW3K38IfEPzNoxy1Hnoz0fcX/8/fWeT5PB5Ph595ndbDq9iRJLCZ0DO9M3oi8+Zp8rmSYhhBBCCAlka8stqWRsUiQ/7sohv7SKIXEh+Hua6Nraj2+2nXCU+2B3NcnDX2Aom+HHJ7WD4z/TbtoqPK6tcQVt2UDbAVp+14oL1rjqdBDUQct0cHaLlrkgdx/c+q62O5dflLbFrUcg6I2w9HkY8mdtM4TqMtjzjba2Nm40rH3deRB7voW+T8G+hZC5RLsCfHw9xAzRlin4aoFs16CuGHQGpyupXm5e/GPfPxzPT5SeYNGRRUzsMhGyoEdID7479F2d83a26ixmg5kqW5XT8cFRgwHYeGojj694HIv9/Dm4J/Yenu39LGaD+TJnRwghhBDiPMl1VMupwko+WX+UuDAfbukWwZ6TxQR4Ggn2NtUpe6bMqgWb8aO1R1EO9J2iBYugBavdxsHSF6D3w86V48dARRGc2Q8Hf4Lc3dD5FshJ1zYtWPc66A1w/D/ajV0Dn9Nu6kqfD0fXQ8pkLWtBfTdSKbuWrqsmL+2+77Rdw/IytMwI7YcAWiD7xqA3CPfUAtu2Pm0prCqs01xhVSG5ZVrKLbPBTEV1RZ0yPx/9mf/t97/EBcQBEGgO5OW+LzOg9QAsNgv/2PcPpyAW4MvML9mbv7dOW0IIIYQQl0OuyNYSFehBoJeJ3u0CMRn0+Lgb6BjqTUZ2AWY3PVXVWmoqs5uehCAdrFsH3e/Vcq8eXqX9yT/xbu3mrVYxsGmutsFAYAwMmqqtk3Uzg1cIlOXCtk+0N7aWa23c+BIU50DSw7D21fMbGJzaDsmPa1d8E8bCir9qx7uNB72bthyhhruftuygJsuBsgMKWnWAm1522t1raPRQeoT2IL88nxDPEL7K/Kre81Jm1dYNb8/dzqj2o/j24LdOr3cM6MiAyAH0b92f3LJc/Mx+BHkGAVBQUcC23G31tptTlnOZMyOEEEII4UyuyNbiaTYwKiGct5Yf5O0VB3EzGPjnpuP0blXBFwPymdjVxMSuJub3Pk6Xqh2Q9JC2e1fXOyCyN2T8G3Z8oe3cVV0FBrN209X+H7WAc/fXkLVWyy5w4dazNSrOartzWcq08hc6e0R7n43vnj+WuRj6PKxtwADYfcK13cZ2fH6+jH8bKD8HvSY5b1H7i0D3QDoFdsLf3Z+UiJQ6f+rvGdKTQ4XaNr2xgbGMiRnDrTG3okMHQEJQAn9O/jNeRi+8Td7EBMQ4glgAH5MPPUN71nu+w73C658IIYQQQohLkCuyteSXWJi/Qcs6UGax8d32E/zXoBje2V6AF5HcF3qcfntf1m6yKgyErNVaRYNRWz5g8oYut2v/Zi7V0nN1GgHf3A9+kXDji9pV1Q3vaFkOarNWAHbY/70WGB9bf/41kxe4B2i7cNWoKoEtH2IbPoMFpYfYbytjlMFEomcrDCWnURE90fX6PYR1hdZaMGmxWVidvZqlR5di0Bm4ue3NDIgagFFvpFtwN+beNJcfjvxA5tlMhkUPY2iboRRVFWFXdjoFdsLL6EVCcAL3d74fi81Ce//2eBm9LnpOTQYTE7tMZHPOZqflBXfH3k2XVl2udKqEEEIIcZ2TQLaW0irnFFLDuoTx5rIDVNu1P/GvPBrCj4kT6BDVWsvz2v1eyNmlXWENjAF0WnaBs1kQc6O2LvXoOvCLhpJcLRg9lQ7tBmv5ZkPitTIAXe8C30htSUFoV7hwzzWjh7YxgrVMC5ItpedfM3lT6Gbkr9mLAPhGp2dElwG0M/pxR7tRBP+yJrbG8mPLeX7t847nS44uYeagmQxrOwyApLAkksKSGjxPbno3YgNjL/u8JocnM+/meWzM2ahlLWilZS0wu8mNXkIIIYS4MhLI1hLu546vuxvFldqaU5NB5whiASqtdg61GkKHjU/BuSztYKfh0HEYLHvplyuqaMsJstZouVvLz8DgqdruXMv/rF1RbTcQfFpDQHvoOFxL2bX5fS0bgd4AkUna8oLgTmDyhYp8LRuCuz8kP6atrS3LQ/mEU97vSRbYzzr6aFd2FuVuoktAHL8L6+40PqvNyqf7Pq0z7q8PfM1N0Teh0+ka83Q66RbcjW7B3ZqsfSGEEEJcXySQraWkwsqwzqEoQAcE+5rR6c7fc+Wm19HGcPZ8EAtw4Cctl6z1grv5j/3nl5u+bLB3gfZn/TOZ55cFZK3RMg6M+BusnwUefhDVG1r3gJCucGSVtp61NA98DND6Bi1f7MbZWqDbYRiEdKY8PJGB2/+H+Fbx9A7rzZbTWwDwdPNkStKzeHkGOo3PpmyOG7cuVGwpxq7sGHSGRjybQgghhBBNRwLZWrzNBnafLOJArvan+zGJ4fzPmC7MW38Us0HPvYn+tGFd3Yp6Y91jBjNU/bJdbclpqJVjFWs5WCogf7/2PHsTRPSAgA5a5oH0z86X7TAUzNoNXdhtcGApHFiKLvkxrHYrO8/sJDZAuxHLpmwMiBhAckRynS65u7kzPnY8M7bMcDp+V6e7MOgliBVCCCGE65BAtpaSKhudQn24vUdr9MCyjFx6A2N7RdLKy0TK4TcxBrZC+YShKzmtVYodqa1Z9QzUlg+AlifWOwR2/BKMKjv4t9WyC1Sc04617qUtFeh5P1jKta1qS/PA3VfLcnChQyu01Fl7v3E6nOfhzdhOYwl0DySnLAebstHGpw026m4XW2NU+1FU26uZt3ceBp2BBxIeYHjb4b/xzAkhhBBCXF0SyNYS6uuOh9HA35ZmotfBo4Ni+GbrCXacKMLf08jrIx8i8se+qJtfhZKTgF7bdnbta9D5NnBzh/BE0Jth8xyt0dgRYPKB4hPa7lp6N23ThMLjcO6IllPWnqPdDBaR+EvaLpNzblidXnseGKPlogXOte3L/KpTVOp9oVLbXvbTDG396wt9XrjoGP3d/ZnYdSK3dbwNHTp8zb5NdDaFEEIIIZqOBLK1lFRa+fqXrWjtCuasPsw9vaM4WViJQa/jbN4p6Honuoqz4BsFXkHwnze1ynsXav9WFcOR1VpAm3gvbJoN3uHgE153O9moZNj28fmrtPt/0NJ4db3z/Da3oO0ctvUjCI6noN9kNhcdYoWtCJO7H0uyFmNTNtr7tWd0+9H8cOQHPtzzId5Gb5LCky6aq9XP7NeYp04IIYQQ4qqSQLYWq105PVcKBkco/lg6D4OtiirfUVBYBiU5v2xqcBxihsLhFecreYdqSw2O/UdLt9VpJIR2gfJ86POItuSg5JS2PtYv8nwQW6OqBIvNglu/KeisFVT7hGE4shrsNvKierHJN5A3D61nQOQAvjv0naPakaIjRHhHEOQRRGV1JUuPLWXtybX8b///xWSou8WuEEIIIYQrk0C2Fm+zgR5R/qRnFwIwskswyXv+gu+JNAB8Tq7RtoUtOwNmHzi1VVsu0P1ebUlAcBx4BGoZC5SCyiIIjodDy+HAkvNv1PshOLwSIurueFXhHcT4st2keEbTIzCJP299jUGhiRAazIrj3zAlOJIbo26korqiTt3Ms5m082tHG582LDqyiEpbJQ8kPEBcYByV1ZW46d1wq71jmBBCCCGEC5KIppYATyPdo/yIbuWFXg83B5/Dd3Xa+QLVVeDRCjKXaLljdTqwWbVHUTa06Qub5kDBIS1N1rD/gZxtcHCpVl9v0LIOFBwGlLbBQcwQLagFlG8kq7y8yMrJIqs4i4K2pYyNHUthVSEAw9oOIyM/A3ejOzH+MXX63y24G/GB8aSdSKPSVokOHVW2Kt7f9T4LDy6knX87JsRPICUipWlPpBBCCCFEE9M3dwdaGrtdcbSgHLObjphgb9LLWvFjr4+pCIzXCpi8tV22ys7AwWUw8g0oOgG7vwZrlZadoOCQVtbdX9vlq9qi5X3tfq92Q1ivSdoGCNWVoDNoWQ+SHsDe72k293uU5w996ejP8mPLsSs7FruFUmsp209vp0doD/LK8zhbeZZJXSZhNmi7YyUGJzIochCfZ3zOnvw9ANwTdw9p2Wm8k/4OJ0pPsPbEWiavmMz+gv1X7ZwKIYQQQjQFuSJbh57CCiudI3yZuewANrsC3Jk2eCb3V3+LIbSzlnVg4HMQlgg7vzy/OYLRXVv7mvw4+IZrW8yWF8C5o+AbATu+OP82g1+A0AQIaIPtwFJm+PlSabCw4fi/nXpzU5ubKLGWsPL4SjzcPBjZbiTl1nLWnlzL2pNr8TZ6c2PUjbjp3bg37l6CPIN4zPYYWUVZdAroRFJoEuMXjXdq02K3sCt/F3Gt4pr0TAohhBBCNCW5IluLpdrG8M6h5BVX/RLEahYfsaEvPwPHN0L2Fu0mro2zzgexvhFaBoOcXXBmP/z8Emz5QNuxq9s4yFzs/Eand2ONH01lVRmqJJdV+dv4/ugihkUPw8voBWhZBToEdOD7w99jtVspthTzz8x/4mH0oE9YHwBKraUsPbqUXfm7iPKJItwrnLvj7uZPN/yJOzvdidVmxd/kX2ecnkbPJjl/QgghhBBXiwSytej1Ot5cfhC9Xud0vH2QJ7rsLbD7X6DXw+ndkLMTovtqBaL7aetmfcLOZzAoPIYt/QuOeAWgvIKd2qv2DuaD0kxy9DZyYwaQW56LXdn5V+a/eLTbo4xqN4qkkCRyynLq9NFis/Bc7+cYFj0Mo95ISngKr/R/BX93f6dy23K3MWHpBAZFDXI6HhsQS6+QXr/tRF0gqyiLz/Z9xlvb3mLxkcUUVRU1WttCCCGEEBcjSwtqsdjsVFXb2ZldyF29ItlzsohOod5Y0VPl2wZzySkttVZlMZg8tWwEPSZo2QqOpIHN4tSe4dwRFuZv46aUh0hcNxsqi6gMS+BQTH8KizLIrTzHZsP5jQ8sdgs6nY5FWYtIDk+mrbltnT7GB8YTFxjH3wb+jXMV5/Az+2F2MzuVUUrxRcYXlFpLWXZsGXd0vAOLzUJ7v/aMaDeCcO/6c8v+WseLj/P48sfJLs12HPtd/O94NulZyY4ghBBCiCYlkUYtdrudUd3CKK20kVNYQY82/hzOK8NXX4mp/JctaT0CtLRZh5ZpN3P5R8OZTEgYC8qmZTJQ2rKEnC638u/czXxeXcZfU//EubOHWFtxkqD8bcT4x5Dl5kmEwUh8YDwFlQWMiRlDW9+2TE+ezheZX7A1dyvD2w5nxfEVuBvcebrX03QP6Q6AUW+kylbFp/s+ZXf+bnqH9ebmtjcT5BmEzW7jUKF209mZijMsOLgA0Hb8ivSJbLTztSlnk1MQmxSaRKm1lL9v+zvRftH0a93vohsyCCGEEEL8FhLI1uJlMtI+yIsT5yrQ63VEBXhyurCSyd1M6PJStXWwFUVQnAP9n9Fu7jJ5Q2AHWPlXLQPBqJlUndnPHp2VT6vzOFdaCMCG8hN8f/JngjyCMHgEcKz4GHd1uIuTZSeZ3H0ye8/uZfGRxXyw+wOeS3qOA+cOANpVz2HRwxjUehBV9ir+b9P/ERsQy+DIwby69VXSstMAWJm9kjPlZ3g66WncDG7c3uF23tj2hmNsep2ezkGdG/V8FVnOLyOID4xHoZw2aegV2os3Br1BK49Wjfq+QgghhBASyNZSYbVRUGpl8e7TBHiaCPNxJ6V9ID7VmbD5fa2QRwCkTNb+LcqGgsMURyXjGzdSS6e1+UNUl1tZXn2aFbm7AEgOT+ZsxVniA+PpHtKdrzK/4sGuD7Lv7D7+b/P/EeUTRUpECtG+0fiafDlResLRp3NV51iStYRwr3A+3vOx43ilrdIRxNb4LOMz7u18L6GeoYyOGY3FZuGL/V8Q6hXKo90epVtQt0Y9X50DzwfGnQI68e/DzlkXtuVuY8eZHQxtM7RR31cIIYQQQgLZWiw2O19sPg7A6eJKftqXy4COQeRXFhLT43faxgchnWHFyxA/Gs4eAZ2eg1X5tK84S8AhbWMD9/z9PDBuPq0CO5FdnsvQqKGcs5zjq/1f8c/9/2R42+FUVVcR7KndBJZdko1vvi8Wm4XOrTrj6eZJlHeU48/2vkZfzlU6b2WbUZCBSW/CYj+/LreVRyvcDe6On/8r8b8YHzcek96Eh9Gj0c9XUlgSL97wIjO3zcSmbPWWqd1vIYQQQojGIIFsLYZa2QoqrTZKKqxERQbDz4ug4twva2HtsO/fVKY8xl5bGSd0NjZHd+Mm/9YEWiqobj+ETXob1egJcA8gozCDCksFbXzb0DOsJ2uy17C0eCnRvtGO9zpWfIyksCTsyk5KRApjOoxh3cl1WG1W2vm14/1d7zOq3Sh0Oh3l1eXsK9jH5B6TmbltJgA6dDzb61n8zH5OY6j9vDGZDCbujrub/q37c6LkBD8d/Qmr3ep4XYeO2MDYJnt/IYQQQly/JJCtxd3NwB+Hd8JqU5jd9Bh0OhIjfYk4/C10TIX9P2rbzAIW/za85+vNhwd+hDOrGNFuBAtD2+BucEdnP8uyfV8RYA4g2jeahXsWMrn7ZJYcXYJd2QEwG8wEugfi4eZBRXUF/Vv3Z1POJmYMmEFCUALfHfqOoqoidp7ZSea5TO7seCdzds7hXNU5fEw+PJf0HKltU0kISuBU6Sna+beja6uuzXLeIn0iifSJ5NWBrzJ9w3SKqorwNnrzpxv+RJdWXZqlT0IIIYS4tumUUurSxZrW7Nmzee2118jJyaFLly689dZbDBgw4JL1iouL8fPzo6ioCF9f30bpy7J9p9hw+Bxny6y4GXR0Cffh5hgPwrMWgrJhM3pg+PklqK5g57CX+N2hfzjVn9p7KiXWEmbtmOU4FuUTRZhXGDp0DI0aysacjeSU5dC/dX++OfgNd3a8Ew83DzzcPBzLCpYdX4Zep+f9Xdq63EifSFLbpHKo8BDeJm9sdht27Lw+6HX0upaVDji3LJdTZacI8QihtU/r5u6OEEKIFqYpvr/F9anZr8h+9dVXTJkyhdmzZ9OvXz/ee+89RowYwb59+2jTps1V70+VVXEwr5S1B/PR66DVwPZ4V5djN3mhryxkc3Uh+1J+h9luo8jshkFncFobWmot5VjxMac2T5ScICEogUpbJbN2zqJXaC+GRg1l1i4t2P1oz0fMGTqH/pH9WXdyHU+ufBJ3N3fa+bVztJESnsLHe8/f6NUpoBMxfjHY7Db0hpYVyIZ6hRLqFdrc3RBCCCHENa7ZI6CZM2fy4IMP8tBDDxEfH89bb71FVFQUc+bMaZb+2JVi7cH8X36GVfvzOKfKKLdb2Ohuwkfnxjsnl/O3U8v5/MDXPJr4KAadAR067up4F6WWUtz0bo4brgB6h/Wm3FqO2WCm2FLMquxVHC056vS+1aqao0VHWXxkMSXWEoqqihwpq3xNvuSW5zqVP3DuAH3C+2A0GJv2hAghhBBCtFDNekXWYrGwbds2pk6d6nQ8NTWV9evXN0ufAtwseBgNVFi1q6ztgryYn72EAT5tmJ7xORPapDK9z4u8v28e3kZvIrwi+EvyXyi1lJJXkcfy48vJK89jTIcxuBvc8TZ6E+0bzZeZX5J2Is3xPp5GT8fPEd4RxAXEse/sPscyAYvdgtVmpVtQN/YV7MPP5HzDlrvBncTgxKY/IUIIIYQQLVSzBrL5+fnYbDZCQ53/DB0aGsrp06frlK+qqqKqqsrxvLi4uNH71M0jn/8eEs2qw8UEeBpJbWfkzexVlAd3p1pVM+/YYv4U8ifGdhyLyWDiVMkp1pxaQ1xAHOhw5H89WnSU9n7tUUbFuzvepW9EX3ae2QnAHR3uoKN/Rx5OeBhvozcDIwcS5h1GoaWQ/QX7GR49nGXHl7EqexVP9niSF294ETt2TpaeZHvedjzcPPhL8l/oGNCx0ccvhBBCCOEqmn2NLIBO55zySilV5xjAK6+8wssvv9ykffGL6cPYyp/p7q7HprOwrHgRZyrO4OcZTJmljM6tOrPw4EJ6hvXEardyovwE/mZ/rMrKuhPrGBMzhmp7NV5GL06VncLP7EdBZQFGvZH/TvpvbHYb2SXZnCo7RZx/HKntUzHqteUBsQGx/KH7H/g843PGdRpHz5CeDIkegtlgBmDWTbM4WnQUP7MfUT5RTXoehBBCCCFaumbNWmCxWPD09OTrr7/m9ttvdxx/6qmn2LFjB6tXr3YqX98V2aioqCa56/FsYQ4rc/9DWnYabf3aokNHQWUBwR7BZBVncU/cPQR7BDN311x8jD5Y7Vb0Oj2rT6wm0juSxOBE/N390aHDbDBTUV1BVmEWCUEJGPQGyqvL6R3Wm4TghDrvXWYtQymFt8m7UcckhBBCtASStUA0lmZPv3XDDTfQq1cvZs+e7TjWuXNnxowZwyuvvNJg3eb4IFirrRjdzt9gpZQivzwfDzcPii3F6NFjUzZMbib83f0pqSrBareilEKhMOlNVNgq8DH5NOlGBUIIIURLJYGsaCzNvrTgmWeeYcKECSQlJZGSksL777/P8ePHefTRR5u7a/W6MIgFbVlEsJe2zay3ue4V1ECPwKvSLyGEEEKI602zB7Ljx4+noKCAv/71r+Tk5NC1a1cWL15MdHT0pSsLIYQQQojrVrMvLfgt5E8TQgghhOuR72/RWJp9QwQhhBBCCCGuhASyQgghhBDCJUkgK4QQQgghXJIEskIIIYQQwiVJICuEEEIIIVySBLJCCCGEEMIlSSArhBBCCCFckgSyQgghhBDCJUkgK4QQQgghXJIEskIIIYQQwiW5NXcHfoua3XWLi4ubuSdCCCGEuFw139s13+NCXCmXDmRLSkoAiIqKauaeCCGEEOLXKikpwc/Pr7m7IVyYTrnwr0N2u51Tp07h4+ODTqdr1LaLi4uJiooiOzsbX1/fRm27JZFxXltknNeO62GMIOO81lzuOJVSlJSUEBERgV4vqxzFlXPpK7J6vZ7IyMgmfQ9fX99r+j+dGjLOa4uM89pxPYwRZJzXmssZp1yJFY1Bfg0SQgghhBAuSQJZIYQQQgjhkiSQvQiz2cy0adMwm83N3ZUmJeO8tsg4rx3XwxhBxnmtuV7GKVoOl77ZSwghhBBCXL/kiqwQQgghhHBJEsgKIYQQQgiXJIGsEEIIIYRwSdd1IDt79mzatWuHu7s7vXr1Yu3atQ2WX716Nb169cLd3Z327dszd+7cq9TTK/PKK6/Qu3dvfHx8CAkJ4bbbbiMzM7PBOmlpaeh0ujqP/fv3X6Ve/3rTp0+v09+wsLAG67jaXAK0bdu23rl5/PHH6y3vKnO5Zs0aRo8eTUREBDqdju+++87pdaUU06dPJyIiAg8PDwYPHszevXsv2e63335L586dMZvNdO7cmYULFzbRCC5PQ+O0Wq08//zzJCQk4OXlRUREBPfffz+nTp1qsM1PPvmk3jmurKxs4tHU71JzOWnSpDp9TU5OvmS7rjSXQL1zotPpeO211y7aZkubS7i875Br5fMpXNd1G8h+9dVXTJkyhRdffJH09HQGDBjAiBEjOH78eL3ls7KyGDlyJAMGDCA9PZ0XXniBJ598km+//fYq9/zyrV69mscff5yNGzeybNkyqqurSU1Npays7JJ1MzMzycnJcTw6dux4FXp85bp06eLU3927d1+0rCvOJcCWLVucxrhs2TIAxo4d22C9lj6XZWVlJCYm8u6779b7+quvvsrMmTN599132bJlC2FhYQwbNsyxRXV9NmzYwPjx45kwYQI7d+5kwoQJjBs3jk2bNjXVMC6poXGWl5ezfft2/vznP7N9+3YWLFjAgQMHuPXWWy/Zrq+vr9P85uTk4O7u3hRDuKRLzSXAzTff7NTXxYsXN9imq80lUGc+Pv74Y3Q6HXfeeWeD7bakuYTL+w65Vj6fwoWp61SfPn3Uo48+6nQsLi5OTZ06td7yf/zjH1VcXJzTsUceeUQlJyc3WR8bW15engLU6tWrL1pm1apVClDnzp27eh37jaZNm6YSExMvu/y1MJdKKfXUU0+pmJgYZbfb633dFecSUAsXLnQ8t9vtKiwsTM2YMcNxrLKyUvn5+am5c+detJ1x48apm2++2enY8OHD1d13393ofb4StcdZn82bNytAHTt27KJl5s2bp/z8/Bq3c42kvjFOnDhRjRkz5le1cy3M5ZgxY9SQIUMaLNOS57JG7e+Qa/XzKVzLdXlF1mKxsG3bNlJTU52Op6amsn79+nrrbNiwoU754cOHs3XrVqxWa5P1tTEVFRUBEBgYeMmyPXr0IDw8nKFDh7Jq1aqm7tpvdvDgQSIiImjXrh133303R44cuWjZa2EuLRYLn332GQ888AA6na7Bsq42lxfKysri9OnTTvNlNpsZNGjQRT+rcPE5bqhOS1NUVIROp8Pf37/BcqWlpURHRxMZGcktt9xCenr61engFUpLSyMkJIROnTrx8MMPk5eX12B5V5/L3NxcFi1axIMPPnjJsi19Lmt/h1zPn0/RclyXgWx+fj42m43Q0FCn46GhoZw+fbreOqdPn663fHV1Nfn5+U3W18ailOKZZ56hf//+dO3a9aLlwsPDef/99/n2229ZsGABsbGxDB06lDVr1lzF3v46N9xwA//4xz/46aef+OCDDzh9+jR9+/aloKCg3vKuPpcA3333HYWFhUyaNOmiZVxxLmur+Tz+ms9qTb1fW6clqaysZOrUqdx7770N7lcfFxfHJ598wvfff8+XX36Ju7s7/fr14+DBg1ext5dvxIgRfP7556xcuZI33niDLVu2MGTIEKqqqi5ax9Xncv78+fj4+HDHHXc0WK6lz2V93yHX6+dTtCxuzd2B5lT7SpZSqsGrW/WVr+94SzR58mR27drFunXrGiwXGxtLbGys43lKSgrZ2dm8/vrrDBw4sKm7eUVGjBjh+DkhIYGUlBRiYmKYP38+zzzzTL11XHkuAT766CNGjBhBRETERcu44lxezK/9rF5pnZbAarVy9913Y7fbmT17doNlk5OTnW6W6tevHz179uSdd97h7bffbuqu/mrjx493/Ny1a1eSkpKIjo5m0aJFDQZ6rjqXAB9//DH33XffJde6tvS5bOg75Hr6fIqW57q8IhsUFITBYKjz219eXl6d3xJrhIWF1Vvezc2NVq1aNVlfG8MTTzzB999/z6pVq4iMjPzV9ZOTk1vMVYHL4eXlRUJCwkX77MpzCXDs2DGWL1/OQw899Kvrutpc1mSf+DWf1Zp6v7ZOS2C1Whk3bhxZWVksW7aswaux9dHr9fTu3dtl5jg8PJzo6OgG++uqcwmwdu1aMjMzr+iz2pLm8mLfIdfb51O0TNdlIGsymejVq5fjru8ay5Yto2/fvvXWSUlJqVP+559/JikpCaPR2GR9/S2UUkyePJkFCxawcuVK2rVrd0XtpKenEx4e3si9azpVVVVkZGRctM+uOJcXmjdvHiEhIYwaNepX13W1uWzXrh1hYWFO82WxWFi9evVFP6tw8TluqE5zqwliDx48yPLly6/olyqlFDt27HCZOS4oKCA7O7vB/rriXNb46KOP6NWrF4mJib+6bkuYy0t9h1xPn0/RgjXHHWYtwT//+U9lNBrVRx99pPbt26emTJmivLy81NGjR5VSSk2dOlVNmDDBUf7IkSPK09NTPf3002rfvn3qo48+UkajUX3zzTfNNYRL+sMf/qD8/PxUWlqaysnJcTzKy8sdZWqP880331QLFy5UBw4cUHv27FFTp05VgPr222+bYwiX5dlnn1VpaWnqyJEjauPGjeqWW25RPj4+19Rc1rDZbKpNmzbq+eefr/Oaq85lSUmJSk9PV+np6QpQM2fOVOnp6Y679WfMmKH8/PzUggUL1O7du9U999yjwsPDVXFxsaONCRMmOGUc+c9//qMMBoOaMWOGysjIUDNmzFBubm5q48aNV318NRoap9VqVbfeequKjIxUO3bscPq8VlVVOdqoPc7p06erpUuXqsOHD6v09HT1+9//Xrm5ualNmzY1xxAbHGNJSYl69tln1fr161VWVpZatWqVSklJUa1bt76m5rJGUVGR8vT0VHPmzKm3jZY+l0pd3nfItfL5FK7rug1klVJq1qxZKjo6WplMJtWzZ0+ntFQTJ05UgwYNciqflpamevTooUwmk2rbtu1F/4NqKYB6H/PmzXOUqT3Ov/3tbyomJka5u7urgIAA1b9/f7Vo0aKr3/lfYfz48So8PFwZjUYVERGh7rjjDrV3717H69fCXNb46aefFKAyMzPrvOaqc1mTJqz2Y+LEiUopLcXPtGnTVFhYmDKbzWrgwIFq9+7dTm0MGjTIUb7G119/rWJjY5XRaFRxcXHNHsA3NM6srKyLfl5XrVrlaKP2OKdMmaLatGmjTCaTCg4OVqmpqWr9+vVXf3C/aGiM5eXlKjU1VQUHByuj0ajatGmjJk6cqI4fP+7UhqvPZY333ntPeXh4qMLCwnrbaOlzqdTlfYdcK59P4bp0Sv1yl4sQQgghhBAu5LpcIyuEEEIIIVyfBLJCCCGEEMIlSSArhBBCCCFckgSyQgghhBDCJUkgK4QQQgghXJIEskIIIYQQwiVJICuEEEIIIVySBLJCCCGEEMIlSSArhLiowYMHM2XKlAbL6HQ6vvvuu6vSHyGEEOJCbs3dASGEa8vJySEgIKC5uyGEEOI6JIGsEOI3CQsLa+4uXBUWiwWTydTc3RBCCHEBWVogxDXum2++ISEhAQ8PD1q1asVNN91EWVkZkyZN4rbbbuPll18mJCQEX19fHnnkESwWi1N9u93OH//4RwIDAwkLC2P69OlOr1+4tODo0aPodDoWLFjAjTfeiKenJ4mJiWzYsMGpzgcffEBUVBSenp7cfvvtzJw5E39/f6cyc+bMISYmBpPJRGxsLJ9++ullj1mn0/Hhhx9y++234+npSceOHfn++++dyqxevZo+ffpgNpsJDw9n6tSpVFdXO14fPHgwkydP5plnniEoKIhhw4aRlpaGTqfjp59+okePHnh4eDBkyBDy8vJYsmQJ8fHx+Pr6cs8991BeXn7Z/RVCCHGFlBDimnXq1Cnl5uamZs6cqbKystSuXbvUrFmzVElJiZo4caLy9vZW48ePV3v27FE//vijCg4OVi+88IKj/qBBg5Svr6+aPn26OnDggJo/f77S6XTq559/dpQB1MKFC5VSSmVlZSlAxcXFqR9//FFlZmaqu+66S0VHRyur1aqUUmrdunVKr9er1157TWVmZqpZs2apwMBA5efn52hzwYIFymg0qlmzZqnMzEz1xhtvKIPBoFauXHlZ4wZUZGSk+uKLL9TBgwfVk08+qby9vVVBQYFSSqkTJ04oT09P9dhjj6mMjAy1cOFCFRQUpKZNm+Y0dm9vb/Xcc8+p/fv3q4yMDLVq1SoFqOTkZLVu3Tq1fft21aFDBzVo0CCVmpqqtm/frtasWaNatWqlZsyYcYWzJoQQ4nJJICvENWzbtm0KUEePHq3z2sSJE1VgYKAqKytzHJszZ47y9vZWNptNKaUFc/3793eq17t3b/X88887ntcXyH744YeO1/fu3asAlZGRoZRSavz48WrUqFFObd53331OgWzfvn3Vww8/7FRm7NixauTIkZc1bkC99NJLjuelpaVKp9OpJUuWKKWUeuGFF1RsbKyy2+2OMrNmzaoz9u7duzu1WxPILl++3HHslVdeUYA6fPiw49gjjzyihg8ffll9FUIIceVkaYEQ17DExESGDh1KQkICY8eO5YMPPuDcuXNOr3t6ejqep6SkUFpaSnZ2tuNYt27dnNoMDw8nLy+vwfe9sE54eDiAo05mZiZ9+vRxKl/7eUZGBv369XM61q9fPzIyMhp834v1wcvLCx8fH0cfMjIySElJQafTObVfWlrKiRMnHMeSkpIu2XZoaCienp60b9/e6dilzpEQQojfTgJZIa5hBoOBZcuWsWTJEjp37sw777xDbGwsWVlZDda7MMAzGo11XrPb7Q3Wv7BOTVs1dZRSTu3XHGuoDxerd7l9qN3vhvpw4XEvL69Ltq3T6a7oHAkhhPjtJJAV4hqn0+no168fL7/8Munp6ZhMJhYuXAjAzp07qaiocJTduHEj3t7eREZGNll/4uLi2Lx5s9OxrVu3Oj2Pj49n3bp1TsfWr19PfHx8o/Shc+fOrF+/3imAXr9+PT4+PrRu3bpR3kMIIUTTk/RbQlzDNm3axIoVK0hNTSUkJIRNmzZx5swZ4uPj2bVrFxaLhQcffJCXXnqJY8eOMW3aNCZPnoxe33S/4z7xxBMMHDiQmTNnMnr0aFauXMmSJUucroQ+99xzjBs3jp49ezJ06FB++OEHFixYwPLlyxulD4899hhvvfUWTzzxBJMnTyYzM5Np06bxzDPPNOnYhRBCNC75H1uIa5ivry9r1qxh5MiRdOrUiZdeeok33niDESNGADB06FA6duzIwIEDGTduHKNHj66TXqux9evXj7lz5zJz5kwSExNZunQpTz/9NO7u7o4yt912G3//+9957bXX6NKlC++99x7z5s1j8ODBjdKH1q1bs3jxYjZv3kxiYiKPPvqoI6AXQgjhOnSqvsVpQohr3qRJkygsLGwR28s+/PDD7N+/n7Vr1zZ3V4QQQrgQWVoghLjqXn/9dYYNG4aXlxdLlixh/vz5zJ49u7m7JYQQwsXI0gIhxFW3efNmhg0bRkJCAnPnzuXtt9/moYceuqy6n3/+Od7e3vU+unTp0sQ9F0II0ZLI0gIhhEspKSkhNze33teMRiPR0dFXuUdCCCGaiwSyQgghhBDCJcnSAiGEEEII4ZIkkBVCCCGEEC5JAlkhhBBCCOGSJJAVQgghhBAuSQJZIYQQQgjhkiSQFUIIIYQQLkkCWSGEEEII4ZIkkBVCCCGEEC7p/wFMYaxlXQTOJAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.scatterplot(data=norm_df, x='sphingo_norm', y='non_sphingo_norm', size='total', hue='enrichment', sizes=(10, 100))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()\n",
    "\n",
    "#fig = visuz.GeneExpression.volcano(df=norm_df, lfc='log2FoldChange', pv='fisher_adj_pval', lfc_thr=(1.5,1.5), sign_line=True, figtype='pdf', figname='kegg_volcano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     sphingo_average  non_sphingo_average         pvalue   \n",
      "ko:K10564                   0.000000             0.094410   1.395971e-11  \\\n",
      "ko:K00493                   0.936264             0.416149   4.178598e-70   \n",
      "ko:K07643,ko:K07645         0.000000             0.042236   8.909174e-06   \n",
      "ko:K06183                   0.000000             0.840994  1.479035e-166   \n",
      "ko:K20331                   0.000000             0.109317   2.681505e-13   \n",
      "...                              ...                  ...            ...   \n",
      "ko:K10943                   0.927473             0.360248   7.082335e-78   \n",
      "ko:K03564                   0.890110             1.062112   2.124166e-21   \n",
      "ko:K14051                   0.000000             0.055901   2.843322e-07   \n",
      "ko:K18138                   1.345055             2.309317   1.000503e-24   \n",
      "ko:K05396                   0.004396             0.515528   1.527691e-55   \n",
      "\n",
      "                          adj_pval enrichment  \n",
      "ko:K10564             7.499155e-08   depleted  \n",
      "ko:K00493             2.244743e-66   enriched  \n",
      "ko:K07643,ko:K07645   4.786008e-02   depleted  \n",
      "ko:K06183            7.945373e-163   depleted  \n",
      "ko:K20331             1.440504e-09   depleted  \n",
      "...                            ...        ...  \n",
      "ko:K10943             3.804630e-74   enriched  \n",
      "ko:K03564             1.141102e-17   depleted  \n",
      "ko:K14051             1.527433e-03   depleted  \n",
      "ko:K18138             5.374702e-21   depleted  \n",
      "ko:K05396             8.206758e-52   depleted  \n",
      "\n",
      "[5372 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# drop the columns with all zeros from kegg_per_genome\n",
    "kegg_per_genome = kegg_per_genome.loc[:, (kegg_per_genome != 0).any(axis=0)]\n",
    "\n",
    "#print (kegg_per_genome)\n",
    "\n",
    "wilcoxon_ranksum_df = pd.DataFrame(0, index=kegg_per_genome.columns, columns=['sphingo_average', 'non_sphingo_average', 'pvalue', 'adj_pval' ,'enrichment'])\n",
    "\n",
    "for kegg in kegg_per_genome.columns:\n",
    "    wilcoxon_ranksum_df.loc[kegg, 'sphingo_average'] = kegg_per_genome.loc[sphingo_list, kegg].mean()\n",
    "    wilcoxon_ranksum_df.loc[kegg, 'non_sphingo_average'] = kegg_per_genome.loc[non_sphingo_list, kegg].mean()\n",
    "    wilcoxon_ranksum_df.loc[kegg, 'pvalue'] = stats.mannwhitneyu(kegg_per_genome.loc[sphingo_list, kegg], kegg_per_genome.loc[non_sphingo_list, kegg])[1]\n",
    "    \n",
    "adj_pval = multipletests(wilcoxon_ranksum_df.loc[:, 'pvalue'], alpha=0.05, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "wilcoxon_ranksum_df.loc[:, 'adj_pval'] = adj_pval[1]\n",
    "\n",
    "for kegg in wilcoxon_ranksum_df.index:\n",
    "    if wilcoxon_ranksum_df.loc[kegg, 'adj_pval'] < 0.05:\n",
    "        if wilcoxon_ranksum_df.loc[kegg, 'sphingo_average'] > wilcoxon_ranksum_df.loc[kegg, 'non_sphingo_average']:\n",
    "            wilcoxon_ranksum_df.loc[kegg, 'enrichment'] = 'enriched'\n",
    "        elif wilcoxon_ranksum_df.loc[kegg, 'sphingo_average'] < wilcoxon_ranksum_df.loc[kegg, 'non_sphingo_average']:\n",
    "            wilcoxon_ranksum_df.loc[kegg, 'enrichment'] = 'depleted'\n",
    "    else:\n",
    "        wilcoxon_ranksum_df.loc[kegg, 'enrichment'] = 'neutral'\n",
    "\n",
    "print (wilcoxon_ranksum_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      sphingo  non_sphingo\n",
      "ko:K10564            0.000000     0.094410\n",
      "ko:K00493            0.936264     0.416149\n",
      "ko:K07643,ko:K07645  0.000000     0.042236\n",
      "ko:K06183            0.000000     0.840994\n",
      "ko:K20331            0.000000     0.109317\n",
      "...                       ...          ...\n",
      "ko:K10943            0.927473     0.360248\n",
      "ko:K03564            0.890110     1.062112\n",
      "ko:K14051            0.000000     0.055901\n",
      "ko:K18138            1.345055     2.309317\n",
      "ko:K05396            0.004396     0.515528\n",
      "\n",
      "[5372 rows x 2 columns]\n",
      "ko:K10564              0.000000\n",
      "ko:K00493              2.249828\n",
      "ko:K07643,ko:K07645    0.000000\n",
      "ko:K06183              0.000000\n",
      "ko:K20331              0.000000\n",
      "                         ...   \n",
      "ko:K10943              2.574536\n",
      "ko:K03564              0.838057\n",
      "ko:K14051              0.000000\n",
      "ko:K18138              0.582447\n",
      "ko:K05396              0.008526\n",
      "Length: 5372, dtype: float64\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "coverage = pd.DataFrame(0, index=kegg_per_genome.columns, columns=['sphingo', 'non_sphingo'])\n",
    "\n",
    "for kegg in kegg_per_genome.columns:\n",
    "    coverage.loc[kegg, 'sphingo'] = kegg_per_genome.loc[sphingo_list, kegg].sum()/len(sphingo_list)\n",
    "    coverage.loc[kegg, 'non_sphingo'] = kegg_per_genome.loc[non_sphingo_list, kegg].sum()/len(non_sphingo_list)\n",
    "\n",
    "print (coverage)\n",
    "\n",
    "divergence = coverage.loc[:, 'sphingo']/coverage.loc[:, 'non_sphingo']\n",
    "print (divergence)\n",
    "\n",
    "average_divergence = divergence.mean()\n",
    "print (average_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{18602: [0], 18510: [1], 17472: [2], 17547: [3], 7469: [4], 6053: [5], 6282: [6, 9], 17540: [7, 941], 12319: [8], 6283: [10], 17032: [11], 6287: [12], 2974: [13], 13647: [14], 18727: [15], 6366: [16], 6320: [17], 2430: [18], 17473: [19], 3979: [20], 12716: [21], 6318: [22], 10435: [23], 18513: [24], 2811: [25], 2288: [26], 15044: [27], 6298: [28], 6360: [29, 190, 267, 272, 275, 280, 283, 286, 287, 288, 290, 293, 294, 3946, 4283], 6753: [30, 59, 199, 210, 7248, 8108, 8111, 8131, 8184, 8263, 8303, 8376, 8411, 8424, 8486], 18470: [31], 10443: [32], 10299: [33], 5839: [34], 6389: [35], 13170: [36, 2126], 18521: [37], 2417: [38], 17033: [39], 18518: [40], 6846: [41], 9146: [42], 13679: [43], 18660: [44], 6291: [45], 18664: [46], 18475: [47], 18739: [48], 13705: [49, 191, 316, 453, 504, 544, 584, 594, 641, 664, 718, 721, 738, 762, 768, 774, 775, 777, 779, 782, 785, 786, 787, 791, 794, 795, 796, 798, 799, 800, 801, 808, 809, 810, 811, 812, 813, 814, 815, 816, 818, 819, 820, 823, 824, 825, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 840, 841, 842, 846, 847, 848, 849, 850, 853, 854, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 869, 871, 872, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 913, 914, 915, 916, 919, 920, 921, 922, 923, 924, 925, 926, 928, 931, 932, 934, 936, 938, 939, 940, 942, 944, 945, 946, 947, 950, 951, 952, 954, 960, 961, 962, 965, 967, 972, 994, 1000, 1002, 1005], 18527: [50], 9787: [51], 18505: [52], 18519: [53], 18737: [54], 12554: [55], 10308: [56], 10252: [57], 19120: [58], 2263: [60], 6382: [61], 6370: [62], 9682: [63], 14308: [64], 13577: [65], 18529: [66], 6254: [67], 18600: [68], 18478: [69], 2259: [70], 18471: [71], 6262: [72], 13201: [73], 18500: [74], 18989: [75], 2297: [76], 6240: [77], 18464: [78], 6345: [79], 10437: [80], 18516: [81], 18528: [82], 12552: [83], 17628: [84], 2279: [85], 18462: [86], 18482: [87], 17561: [88], 4432: [89], 18763: [90], 18511: [91], 18472: [92], 15045: [93], 6257: [94], 10336: [95], 18503: [96], 18506: [97], 13109: [98], 6267: [99], 18508: [100], 18520: [101], 18524: [102], 18501: [103], 10338: [104], 18483: [105], 18495: [106], 18512: [107], 18523: [108], 18517: [109], 18502: [110], 9147: [111], 18488: [112], 18514: [113], 18489: [114], 18492: [115], 18494: [116], 18490: [117], 18480: [118], 18522: [119], 18484: [120], 18525: [121], 18496: [122], 18515: [123], 18465: [124], 18526: [125], 10348: [126], 18504: [127], 18493: [128], 6292: [129], 18509: [130], 18485: [131], 18497: [132], 18491: [133], 18467: [134], 18499: [135], 18479: [136], 18466: [137], 6342: [138], 10339: [139], 19118: [140], 18481: [141], 10346: [142], 18468: [143], 18507: [144], 13775: [145], 18463: [146], 18498: [147], 18469: [148], 10340: [149], 18730: [150], 18473: [151], 18476: [152], 18474: [153], 18486: [154], 18477: [155], 10292: [156], 19119: [157], 13646: [158], 2407: [159], 15832: [160], 10300: [161], 6336: [162], 18487: [163], 18758: [164], 12555: [165], 6301: [166], 10293: [167], 6369: [168], 7096: [169], 12655: [170], 12656: [171], 6407: [172], 12279: [173], 18702: [174], 12553: [175], 10306: [176], 6295: [177], 12278: [178], 12708: [179], 6321: [180], 10301: [181], 10575: [182], 6356: [183], 18715: [184], 6344: [185, 251], 6296: [186], 12275: [187], 6387: [188], 6299: [189], 4326: [192], 12281: [193], 6712: [194], 6376: [195], 13804: [196], 6722: [197, 212], 12280: [198], 6277: [200], 17550: [201], 3981: [202], 6724: [203], 6714: [204], 10454: [205], 6716: [206], 17602: [207], 6715: [208], 6362: [209], 6717: [211], 6720: [213], 13806: [214, 406, 430], 6721: [215], 2283: [216, 1096, 1125], 6325: [217], 13316: [218, 1637], 3157: [219], 6719: [220], 6718: [221], 10351: [222], 6723: [223], 18603: [224], 18759: [225], 6406: [226], 6252: [227, 385], 6713: [228], 6725: [229], 17498: [230], 17497: [231], 6319: [232], 18740: [233], 6300: [234], 6335: [235], 6398: [236], 17562: [237], 18735: [238], 13743: [239], 3919: [240], 6309: [241, 5094, 5247, 5248, 5285, 5321, 5326, 5329, 5360, 5381, 5477], 6297: [242], 6311: [243], 6312: [244], 4375: [245], 6284: [246], 12944: [247], 6404: [248], 6402: [249], 396: [250], 6403: [252, 256], 13788: [253], 18811: [254], 6334: [255, 343], 3935: [257], 6281: [258], 6368: [259], 6399: [260], 6349: [261, 292, 303, 304], 6315: [262], 6397: [263], 6364: [264], 6409: [265], 6400: [266], 18579: [268], 17495: [269], 4373: [270], 6394: [271], 17573: [273], 6317: [274], 13802: [276], 6361: [277, 302, 305], 6395: [278], 13580: [279], 17544: [281], 6343: [282], 6357: [284], 6358: [285], 6651: [289], 2244: [291, 562, 567], 6340: [295], 6268: [296], 13776: [297], 13759: [298], 14302: [299], 18764: [300], 17471: [301], 6350: [306], 18776: [307], 18812: [308], 6353: [309], 6365: [310], 2087: [311], 6355: [312], 6351: [313], 17563: [314], 10341: [315], 6367: [317], 13735: [318], 13777: [319], 13637: [320], 6253: [321], 2293: [322], 6333: [323, 332], 17551: [324], 3953: [325], 17557: [326, 474], 6341: [327], 17549: [328], 17480: [329], 6266: [330], 2805: [331], 2406: [333, 996, 1051], 6352: [334], 13778: [335], 6329: [336], 2498: [337], 6249: [338], 6242: [339], 6264: [340], 13597: [341], 2289: [342], 2708: [344], 6238: [345], 2194: [346], 18658: [347, 371], 9665: [348], 17527: [349], 6326: [350], 6236: [351], 13805: [352, 363], 6338: [353], 18659: [354], 6354: [355], 6265: [356], 13582: [357], 2808: [358], 6653: [359], 6273: [360], 18662: [361], 6255: [362], 13772: [364], 6745: [365], 13687: [366], 6258: [367], 2264: [368], 4387: [369], 13807: [370], 13760: [372], 14212: [373], 6652: [374], 2294: [375, 1097, 1123], 6327: [376], 6289: [377], 6259: [378], 6276: [379], 13779: [380], 18717: [381], 2050: [382], 6286: [383], 14245: [384], 2408: [386], 6371: [387], 2252: [388], 13757: [389], 6328: [390], 6260: [391], 10352: [392], 2418: [393], 6279: [394], 6285: [395], 2520: [396], 2366: [397], 6263: [398], 13739: [399], 13809: [400], 13368: [401, 1114, 1184, 1261, 1288, 1328, 1351, 1426, 1437, 1442, 1446, 1447, 1455, 1458, 1459, 1460, 1468, 1469, 1473, 1478, 1479, 1480, 1481, 1485, 1487, 1488, 1489, 1490, 1491, 1492, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1503, 1504, 1505, 1506, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1520, 1521, 1522, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1544, 1545, 1547, 1548, 1549, 1553, 1555, 1558, 1562, 1565, 1567, 1568, 1569, 1570, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1585, 1586, 1588, 1590, 1591, 1593, 1595, 1596, 1600, 1602, 1604, 1610, 1612, 1613, 1614, 1615, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1627, 1628, 1631, 1634, 1636, 1638, 1639, 1640, 1642, 1643, 1644, 1647, 1649, 1650, 1652, 1655, 1656, 1658, 1659, 1666, 1667, 1671, 1673, 1674, 1675, 1677, 1680, 1681, 1684, 1688, 1689, 1691, 1694, 1695, 1698, 1699, 1701, 1704, 1705, 1710, 1719, 1722, 1724, 1725, 1726, 1736, 1738, 1740, 1744, 1745, 1746, 1748, 1751, 1752, 1753, 1755, 1758, 1759, 1761, 1764, 1766, 1771, 1777, 1780, 1782, 1785, 1790, 1793, 1798, 1803, 1804, 1806, 1812, 1822, 1827, 1830, 1836, 1837, 1845, 1873, 1884, 1899, 1915], 3917: [402], 3891: [403], 18765: [404], 2044: [405], 6261: [407], 13583: [408], 6239: [409], 6288: [410], 3980: [411], 6243: [412], 13796: [413], 13726: [414], 2558: [415], 17558: [416], 17475: [417], 2559: [418], 13756: [419, 429], 13197: [420, 745, 1209], 2275: [421], 13780: [422], 13296: [423], 18718: [424], 6248: [425], 18601: [426], 18777: [427], 13799: [428], 13789: [431], 17519: [432], 17555: [433, 451], 17556: [434, 449, 466, 473], 13748: [435], 18772: [436], 2121: [437], 18661: [438], 6274: [439], 6280: [440], 386: [441], 10349: [442], 17504: [443], 17469: [444], 2124: [445], 13781: [446], 17510: [447], 6275: [448], 13112: [450], 9476: [452, 4576, 5261, 8045, 8899, 9022, 9169, 9305, 9373, 9444, 9573, 9636, 9639, 9640, 9641, 9642, 9643, 9646, 9647, 9648, 9651, 9652, 9684, 9718, 9719, 9721, 9722, 9723, 9724, 9725, 9727, 9728, 9731, 9732, 9733, 9734, 9736, 9737, 9738, 9739, 9741, 9743, 9744, 9745, 9746, 9749, 9750, 9751, 9753, 9754, 9755, 9763, 9845, 9848, 9851, 9852, 9859, 9861, 9869, 9897, 9921, 9938, 9939, 9941, 9942, 9944, 9947, 10020], 13798: [454, 470], 17548: [455], 6373: [456], 13810: [457], 17567: [458], 6271: [459], 13767: [460], 2181: [461, 1027, 1071, 1258, 1299, 1765, 1869, 1875, 1896, 1903, 1955, 1985, 2017, 2018, 2042, 2055, 2056, 2057, 2059, 2068, 2071, 2072, 2076, 2078, 2089, 2091, 2092, 2093, 2104, 2105, 2108, 2109, 2116, 2117, 2118, 2123, 2124, 2127, 2128, 2134, 2139, 2141, 2142, 2145, 2146, 2155, 2156, 2157, 2161, 2165, 2166, 2176, 2177, 2183, 2189, 2191, 2194, 2203, 2204, 2205, 2209, 2223, 2227, 2238, 2266, 2327], 17483: [462], 6272: [463], 17513: [464, 776], 13584: [465], 2183: [467], 13797: [468], 13715: [469], 13611: [471], 17481: [472], 17565: [475], 13808: [476], 4380: [477], 4026: [478], 17545: [479], 6270: [480], 2270: [481], 13800: [482], 7463: [483], 13801: [484], 10350: [485], 6244: [486], 6250: [487], 2071: [488], 2157: [489], 17566: [490], 17604: [491], 13786: [492], 13803: [493], 13439: [494], 17529: [495], 17542: [496], 13784: [497], 18703: [498], 17515: [499], 17554: [500, 515], 13632: [501], 2732: [502], 17511: [503], 13787: [505], 18794: [506], 6269: [507, 519], 13790: [508], 13624: [509], 17470: [510], 2245: [511], 13599: [512], 13066: [513], 6251: [514], 13794: [516, 523], 2144: [517, 1116, 1320, 1332, 1335, 1336, 1387], 13300: [518], 17506: [520], 17535: [521], 13322: [522], 2537: [524], 2413: [525], 2051: [526], 2285: [527], 2021: [528], 13636: [529], 2274: [530], 18614: [531], 13297: [532], 13629: [533], 2146: [534], 6246: [535], 2149: [536], 17584: [537], 17596: [538], 13785: [539, 550], 18736: [540], 13303: [541], 13773: [542], 17564: [543, 558], 13581: [545], 18760: [546], 2290: [547], 14229: [548], 13593: [549], 13733: [551], 18604: [552], 13602: [553], 13613: [554], 13795: [555], 13683: [556], 2255: [557], 17477: [559], 2298: [560], 18767: [561], 13725: [563], 2133: [564, 576, 1144], 17552: [565, 573], 17606: [566], 2269: [568], 13752: [569], 13782: [570], 17507: [571], 18821: [572], 6290: [574], 17569: [575], 13315: [577, 1167, 1441, 1564, 1692], 6241: [578], 13730: [579], 13631: [580, 699, 702, 703, 706, 713, 715, 725], 13600: [581], 13728: [582], 2258: [583], 13682: [585], 13736: [586], 4381: [587], 15037: [588], 17583: [589], 13623: [590], 19074: [591], 17571: [592], 13688: [593], 4379: [595], 17580: [596], 13627: [597, 974], 2421: [598], 17572: [599], 18781: [600], 2402: [601], 17512: [602], 3982: [603], 17537: [604], 13734: [605], 13680: [606], 13720: [607], 3986: [608], 17570: [609], 13727: [610], 13633: [611], 17505: [612], 2414: [613], 13617: [614, 676, 690, 778], 18615: [615], 6245: [616], 13605: [617], 18751: [618], 2137: [619], 13113: [620], 13305: [621], 13783: [622], 17538: [623], 13729: [624], 13698: [625], 2127: [626], 11067: [627], 2286: [628], 18796: [629], 13721: [630], 17508: [631], 2295: [632], 412: [633], 2152: [634], 13603: [635], 17993: [636], 13598: [637], 13586: [638], 2427: [639, 653], 2296: [640], 4371: [642], 2072: [643], 2251: [644, 647], 13152: [645, 2031], 18738: [646], 14230: [648], 2280: [649], 18722: [650], 13298: [651], 13621: [652], 13111: [654], 13073: [655], 398: [656], 17528: [657], 2299: [658], 13604: [659], 12990: [660, 2380, 2409, 2436, 2443, 2455, 2464], 13606: [661], 13601: [662], 13696: [663], 13619: [665], 18768: [666, 672], 13610: [667], 13107: [668], 2118: [669], 2287: [670], 17531: [671], 13686: [673], 1224: [674, 9482, 15369, 17183, 19024, 19025, 19034, 19050, 19053, 19055, 19253, 19267, 19277, 19279, 19280, 19295, 19299, 19304, 19311, 19312, 19315, 19325, 19509, 19510, 19512, 19519, 19522, 19525, 19527, 19540, 19541, 19542, 19544, 19548, 19550, 19551, 19552, 19553, 19554, 19555, 19556, 19558, 19559, 19560, 19562, 19563, 19566, 19567, 19569, 19570, 19573, 19577, 19583, 19587, 19589, 19590, 19591, 19592, 19593, 19594, 19595, 19596, 19597, 19598, 19599, 19600, 19603, 19605, 19607, 19608, 19838], 3207: [675], 2256: [677], 17755: [678], 13307: [679], 13664: [680], 13731: [681], 13697: [682], 13710: [683], 2278: [684], 13608: [685], 13709: [686], 13749: [687], 17484: [688], 13299: [689], 18716: [691], 17514: [692], 18761: [693], 17586: [694], 2136: [695], 13750: [696], 13075: [697], 13751: [698], 13622: [700], 18766: [701], 17553: [704], 2314: [705], 17530: [707], 17616: [708], 17526: [709], 13031: [710, 2457, 2467, 2476, 2477, 2485, 2487, 2497, 2502, 2504, 2515, 2525, 2532, 2536, 2540, 2542, 2544, 2548, 2553, 2563, 2567, 2569, 2578, 2589, 2607, 2618, 2620, 2648, 2666, 2689, 2696, 2697], 13149: [711], 13588: [712], 13589: [714], 13685: [716], 13638: [717], 13910: [719], 13618: [720], 17539: [722], 13708: [723], 13579: [724, 728, 746], 13620: [726], 13701: [727, 822, 892, 937, 955, 975, 978, 980, 990, 997, 1037], 2309: [729], 18769: [730], 13684: [731], 4382: [732], 13609: [733, 763], 18773: [734], 2246: [735], 3007: [736], 2409: [737], 2253: [739], 3467: [740], 13672: [741, 912, 976, 979, 1013, 1017, 1019, 1021, 1024, 1028, 1030, 1036, 1041, 1049, 1067], 17541: [742], 13110: [743], 2249: [744], 2358: [747], 13719: [748], 13648: [749], 13689: [750, 949, 968, 969, 995, 1001, 1004, 1012, 1014, 1039], 13612: [751], 13690: [752], 13738: [753], 13595: [754], 13607: [755], 2125: [756], 17496: [757], 2383: [758], 99: [759, 22885, 22952, 23079, 23081, 23365, 23496], 18770: [760], 13653: [761], 13198: [764, 1815, 1888, 1916, 1927, 1942, 1959, 1962, 1966, 1972, 2010, 2015, 2033], 13174: [765], 18774: [766], 17509: [767], 13681: [769], 17600: [770], 17536: [771], 13635: [772, 991], 13675: [773], 19749: [780], 2282: [781], 13596: [783], 17559: [784], 14224: [788], 18744: [789], 13668: [790], 18721: [792], 14314: [793], 9875: [797], 18775: [802], 17474: [803], 13665: [804], 13587: [805], 13067: [806], 13673: [807], 1996: [817], 13655: [821], 18618: [826], 2429: [837], 13674: [839], 13711: [843], 13640: [844], 14225: [845], 17619: [851], 2291: [852], 13692: [855], 17533: [860], 17479: [866, 964], 2394: [870], 13641: [873], 13737: [917], 13639: [918], 2535: [927], 18663: [929], 2126: [930], 18665: [933], 18771: [935], 13068: [943], 13722: [948], 2266: [953], 17597: [956], 2186: [957], 13713: [958], 13703: [959, 973, 987, 989, 1011], 18779: [963], 13704: [966, 981], 13585: [970], 13304: [971], 18741: [977], 14292: [982], 13200: [983], 13707: [984], 2273: [985, 1058, 1086], 13742: [986], 2191: [988, 2225, 2228], 13702: [992, 998], 13034: [993], 17546: [999], 13063: [1003], 17521: [1006], 18826: [1007], 14144: [1008], 13344: [1009, 1082], 2128: [1010], 13678: [1015], 2375: [1016], 17617: [1018], 13365: [1020, 1244, 1374, 1380, 1391, 1452, 1484, 1526, 1605, 1607, 1611, 1626, 1629, 1630, 1641, 1646, 1651, 1662, 1664, 1665, 1668, 1670, 1672, 1679, 1682, 1683, 1686, 1687, 1696, 1700, 1703, 1706, 1709, 1712, 1715, 1720, 1727, 1728, 1731, 1732, 1733, 1734, 1756, 1767, 1769, 1776, 1787, 1796, 1825, 1833, 1844, 1850, 1851, 1853, 1855, 1858, 1960, 2027], 13257: [1022, 1969, 2004], 2271: [1023], 17532: [1025], 13381: [1026], 13308: [1029], 18827: [1031], 13706: [1032], 2267: [1033, 1104], 1578: [1034], 13084: [1035], 2147: [1038], 13578: [1040], 13235: [1042], 13336: [1043, 1068, 1070, 1311, 1535, 1584, 1598, 1645, 1663, 1669, 1707, 1717, 1718, 1723, 1729, 1730, 1747, 1775, 1781, 1784, 1801, 1849, 1870, 1925, 1981], 17523: [1044], 18746: [1045], 2548: [1046, 1095, 2469, 3144, 3262, 3509, 3546, 3549, 3557, 3558, 3561, 3575, 3576, 3580, 3582, 3584, 3600, 3603, 3605, 3612, 3613, 3616, 3618, 3624, 3636, 3640, 3641, 3643, 3645, 3656, 3657, 3659, 3664, 3672, 3675, 3676, 3688], 13671: [1047, 1048, 1075], 2307: [1050], 2166: [1052], 13699: [1053], 13169: [1054, 1147, 1448, 1867, 2020, 2022, 2069, 2070, 2120, 2149, 2180, 2219], 13064: [1055], 2424: [1056, 1176], 14311: [1057], 13160: [1059], 13182: [1060, 1778], 2171: [1061, 2295], 13746: [1062], 13448: [1063], 13652: [1064], 17485: [1065], 9614: [1066], 18809: [1069], 13654: [1072], 13651: [1073, 1078, 1132], 2300: [1074], 13628: [1076], 13065: [1077], 2284: [1079], 13382: [1080], 13355: [1081, 1422, 1507, 1524, 1563, 1571, 1608, 1617, 1654, 1661, 1708, 1721, 1737, 1742, 1762, 1772, 1783, 1797, 1800, 1809, 1813, 1814, 1839, 1842, 1910], 17517: [1083], 17534: [1084], 13676: [1085], 13677: [1087], 13670: [1088], 18755: [1089], 2506: [1090], 13700: [1091], 13694: [1092], 13691: [1093], 13732: [1094], 13074: [1098], 13309: [1099, 1808], 17543: [1100], 13695: [1101], 17501: [1102], 13693: [1103, 1158], 12980: [1105], 13642: [1106], 13071: [1107], 13723: [1108], 17595: [1109], 13712: [1110], 13590: [1111], 13625: [1112], 9838: [1113], 13666: [1115], 13069: [1117], 18725: [1118], 2292: [1119], 18704: [1120], 13650: [1121, 1189], 13099: [1122], 13493: [1124], 13101: [1126], 17524: [1127], 2247: [1128], 18719: [1129], 14242: [1130], 13095: [1131, 1139, 1170], 2403: [1133], 2254: [1134], 2163: [1135, 2111, 2175, 2231, 2233, 2242, 2251, 2252, 2255, 2269, 2281, 2314, 2324, 2326, 2369, 2393, 2423, 2458], 13320: [1136, 1292, 1340, 1360, 1367, 1376, 1377, 1383, 1384, 1385, 1386, 1388, 1398, 1399, 1400, 1401, 1403, 1404, 1408, 1409, 1412, 1414, 1423, 1428, 1431, 1432, 1463], 2276: [1137], 13669: [1138], 2364: [1140], 2369: [1141], 2135: [1142], 18778: [1143], 9863: [1145], 13070: [1146], 2134: [1148, 1201, 1205], 13649: [1149, 1211], 2277: [1150], 3198: [1151], 2013: [1152], 17518: [1153], 13363: [1154, 1525], 18743: [1155], 13591: [1156], 17476: [1157], 13753: [1159], 13592: [1160], 13314: [1161], 13350: [1162, 1464], 13431: [1163], 19649: [1164], 14239: [1165], 14113: [1166], 13594: [1168], 13085: [1169], 13106: [1171], 2257: [1172], 2308: [1173], 2716: [1174], 18753: [1175], 13301: [1177], 13168: [1178, 2224, 2342], 2691: [1179], 14241: [1180], 2131: [1181], 17578: [1182], 2349: [1183], 13098: [1185, 1215, 1219, 1230], 13792: [1186], 2260: [1187], 2510: [1188], 13811: [1190], 18616: [1191], 14226: [1192], 14167: [1193], 18582: [1194], 2261: [1195], 13630: [1196], 13192: [1197, 1451, 1657, 1871, 1880, 1889, 1936, 1948, 1958, 1967, 2011, 2013, 2083, 2106], 13096: [1198], 13078: [1199], 13644: [1200], 13093: [1202], 2132: [1203], 13717: [1204], 11103: [1206], 17516: [1207], 13127: [1208], 18726: [1210], 2007: [1212], 2411: [1213], 13774: [1214], 13361: [1216, 1375, 1416, 1417, 1443], 17522: [1217], 13083: [1218], 13662: [1220], 13295: [1221], 2419: [1222], 2562: [1223], 14313: [1224, 2846, 2903], 13339: [1225], 18617: [1226], 13616: [1227], 17634: [1228], 13634: [1229], 19418: [1231], 2204: [1232, 3013], 2232: [1233], 2459: [1234], 13108: [1235], 2145: [1236], 13740: [1237], 13791: [1238], 13643: [1239], 13384: [1240], 18762: [1241], 2153: [1242], 18605: [1243], 4440: [1245], 3509: [1246], 9881: [1247], 19722: [1248], 18825: [1249], 2148: [1250], 13211: [1251], 17165: [1252], 13000: [1253], 2426: [1254], 2000: [1255], 13658: [1256], 4115: [1257], 13097: [1259], 2192: [1260], 13473: [1262], 3020: [1263], 17581: [1264], 13667: [1265], 13100: [1266], 13660: [1267], 2123: [1268], 2268: [1269], 13167: [1270], 13714: [1271], 13302: [1272], 2395: [1273], 2714: [1274, 3175, 4707], 18728: [1275], 2187: [1276], 2310: [1277], 2377: [1278], 13094: [1279], 1546: [1280], 9866: [1281], 3113: [1282, 2661, 2996, 3067, 3113, 3119, 3172, 3249, 3468, 3667, 3975, 4077, 4134, 4208, 4244, 4451, 4493, 4545, 4663, 4667, 4676, 4766, 4848, 4981, 5033, 5202, 5316, 5322, 5369, 5411, 5412, 5413, 5422, 5484, 5518, 5546, 5615, 5619, 5657, 5669, 5676, 5679, 5685, 5689, 5702, 5717, 5721, 5722, 5733, 5736, 5737, 5751, 5752, 5755, 5761, 5762, 5764, 5765, 5766, 5770, 5774, 5782, 5785, 5791, 5801, 5804, 5813, 5820, 5823, 5824, 5826, 5828, 5831, 5837, 5841, 5842, 5847, 5848, 5852, 5858, 5860, 5861, 5864, 5865, 5868, 5869, 5880, 5884, 5889, 5893, 5900, 5902, 5907, 5908, 5909, 5910, 5911, 5912, 5913, 5915, 5916, 5917, 5919, 5922, 5923, 5926, 5927, 5929, 5930, 5931, 5933, 5934, 5937, 5938, 5940, 5947, 5953, 5960, 5961, 5962, 5964, 5965, 5966, 5968, 5971, 5977, 5983, 5986, 5987, 5989, 5992, 5993, 5994, 5995, 5996, 5997, 6000, 6003, 6004, 6007, 6010, 6011, 6014, 6021, 6022, 6023, 6024, 6025, 6026, 6027, 6028, 6029, 6030, 6031, 6032, 6033, 6034, 6035, 6036, 6039, 6040, 6041, 6042, 6043, 6044, 6045, 6046, 6047, 6048, 6049, 6050, 6051, 6052, 6054, 6058, 6059, 6061, 6063, 6065, 6067, 6068, 6069, 6070, 6071, 6072, 6074, 6075, 6076, 6080, 6081, 6082, 6083, 6084, 6085, 6088, 6089, 6090, 6091, 6092, 6093, 6098, 6099, 6101, 6103, 6105, 6108, 6109, 6110, 6112, 6113, 6116, 6117, 6120, 6121, 6122, 6124, 6125, 6126, 6128, 6129, 6130, 6133, 6135, 6137, 6138, 6140, 6141, 6144, 6145, 6148, 6149, 6150, 6153, 6154, 6155, 6156, 6158, 6159, 6160, 6162, 6163, 6165, 6166, 6172, 6174, 6175, 6176, 6177, 6178, 6179, 6180, 6181, 6182, 6183, 6184, 6185, 6187, 6188, 6189, 6190, 6191, 6192, 6193, 6194, 6195, 6197, 6198, 6199, 6200, 6201, 6202, 6203, 6204, 6205, 6206, 6207, 6208, 6209, 6210, 6211, 6213, 6214, 6216, 6217, 6218, 6220, 6221, 6222, 6223, 6224, 6225, 6226, 6229, 6230, 6231, 6232, 6234, 6236, 6237, 6238, 6239, 6240, 6241, 6242, 6243, 6244, 6245, 6246, 6248, 6249, 6250, 6251, 6252, 6253, 6257, 6258, 6259, 6260, 6261, 6262, 6263, 6264, 6265, 6266, 6267, 6269, 6270, 6271, 6272, 6273, 6275, 6276, 6277, 6280, 6281, 6283, 6284, 6285, 6286, 6287, 6288, 6289, 6290, 6291, 6292, 6293, 6294, 6295, 6296, 6297, 6298, 6300, 6301, 6303, 6304, 6306, 6307, 6310, 6312, 6313, 6314, 6315, 6316, 6317, 6319, 6320, 6321, 6322, 6325, 6326, 6328, 6329, 6330, 6331, 6332, 6333, 6334, 6336, 6339, 6340, 6341, 6342, 6343, 6344, 6346, 6347, 6348, 6349, 6351, 6353, 6354, 6355, 6356, 6357, 6360, 6361, 6363, 6364, 6365, 6368, 6370, 6371, 6373, 6376, 6378, 6379, 6380, 6381, 6382, 6383, 6384, 6387, 6388, 6389, 6390, 6391, 6392, 6394, 6395, 6396, 6397, 6398, 6399, 6400, 6401, 6404, 6406, 6407, 6408, 6409, 6410, 6411, 6413, 6414, 6415, 6417, 6418, 6419, 6420, 6422, 6425, 6427, 6428, 6429, 6430, 6432, 6433, 6434, 6437, 6439, 6440, 6441, 6442, 6443, 6445, 6446, 6447, 6451, 6453, 6454, 6457, 6459, 6460, 6462, 6463, 6465, 6466, 6467, 6468, 6469, 6470, 6471, 6472, 6481, 6483, 6490, 6500, 6501, 6503, 6505, 6506, 6508, 6509, 6512, 6513, 6533, 6534, 6539, 6544, 6555, 6557, 6573, 6578, 6586, 6613, 6614, 6623, 6626, 6629, 6641, 6657, 6664, 6665, 6667, 6675, 6683, 6685, 6689, 6693, 6697, 6708, 6710, 6728, 6741, 6766, 6784, 6792, 7054], 13313: [1283, 1306, 1312, 1323, 1363], 2208: [1284, 2732, 2775], 4377: [1285], 17525: [1286], 2067: [1287], 13001: [1289], 2158: [1290], 13333: [1291, 1603, 1805, 1891, 1900, 2012], 13351: [1293, 1295], 2180: [1294, 1921, 2043, 2102, 2140, 2162, 2163, 2164, 2178, 2195, 2265, 2278, 2336], 14888: [1296], 18712: [1297], 1988: [1298], 13456: [1300], 18733: [1301], 2155: [1302], 2447: [1303], 2329: [1304], 13340: [1305], 13656: [1307], 13362: [1308], 13105: [1309], 13405: [1310], 13102: [1313], 13332: [1314, 1750, 1757, 1863, 1878, 1953, 1995, 2088], 2281: [1315, 1329], 13311: [1316], 13371: [1317], 12992: [1318], 13375: [1319], 2156: [1321], 18813: [1322], 2040: [1324], 2151: [1325], 4363: [1326], 2415: [1327], 2154: [1330], 2041: [1331], 13378: [1333], 13329: [1334], 13370: [1337], 13090: [1338], 13072: [1339], 13349: [1341], 4340: [1342], 17502: [1343], 13104: [1344], 6346: [1345, 4533, 4547], 2130: [1346], 2173: [1347], 13204: [1348], 1993: [1349], 2185: [1350], 13744: [1352], 13426: [1353], 2129: [1354, 1368], 13716: [1355], 13184: [1356], 13327: [1357, 1366], 2109: [1358], 14340: [1359], 13645: [1361], 13103: [1362], 2448: [1364], 2262: [1365], 13079: [1369], 13542: [1370, 2724], 13379: [1371], 12993: [1372], 1633: [1373], 13464: [1378], 13163: [1379], 13039: [1381, 1390], 12998: [1382], 17579: [1389], 1533: [1392], 2412: [1393], 2231: [1394], 13659: [1395], 13435: [1396], 17601: [1397], 17585: [1402, 1421], 18581: [1405], 2521: [1406], 13626: [1407], 13091: [1410], 18822: [1411], 13195: [1413], 19055: [1415], 2495: [1418], 2114: [1419], 2122: [1420], 13086: [1424], 13661: [1425], 2143: [1427, 1493], 18780: [1429], 13318: [1430, 1434, 1438, 1453, 1465, 1472], 2070: [1433], 13210: [1435], 13741: [1436], 9882: [1439], 18731: [1440], 13747: [1444], 9876: [1445], 2433: [1449, 1483], 18580: [1450], 14220: [1454], 14316: [1456, 1476], 14127: [1457], 2049: [1461], 2170: [1462], 3201: [1466], 6247: [1467], 13364: [1470], 2165: [1471], 17629: [1474], 13509: [1475], 2229: [1477], 13040: [1482], 2224: [1486], 13202: [1499], 18747: [1502], 13337: [1514], 12981: [1519], 17591: [1523], 14221: [1527], 13356: [1543, 1779, 1792, 1795, 1857, 1877, 1919], 13147: [1546], 2243: [1550], 18734: [1551], 13466: [1552], 13312: [1554], 13328: [1556], 13161: [1557], 18757: [1559], 9864: [1560], 17077: [1561], 13020: [1566], 13663: [1587], 4634: [1589], 13357: [1592], 13319: [1594, 1678], 13377: [1597], 13280: [1599, 2132], 18752: [1601], 13203: [1606, 2170], 13133: [1609], 13194: [1616, 1716, 1741, 1774, 1799, 1810, 1829, 1856, 1865, 1886, 1940, 2050], 2926: [1632], 17630: [1633], 13189: [1635], 13190: [1648], 13208: [1653], 2710: [1660], 13372: [1676], 2213: [1685], 13347: [1690, 1768, 1811, 1820, 1821, 1824, 1831, 1832, 1861, 1862, 1904, 1905, 1950, 1977, 1993], 12907: [1693, 1791], 17576: [1697], 2168: [1702], 18795: [1711], 14234: [1713], 2167: [1714], 13325: [1735], 2709: [1739], 13207: [1743, 1893, 1968, 1970, 1971, 1982, 1984, 2001, 2003, 2021, 2034, 2040, 2041, 2053, 2075, 2077, 2079, 2080, 2085, 2096, 2098, 2101, 2136, 2138, 2147, 2148, 2167, 2196, 2232, 2271, 2274, 2294], 13193: [1749, 1840, 1860, 1864, 1876, 1885, 1887, 1890, 1892, 1894, 1897, 1907, 1911, 1920, 1922, 1944, 1951, 1952, 1954, 1988, 1994, 1997, 2026, 2035, 2082], 13394: [1754, 2785, 2842], 13058: [1760], 13145: [1763, 1918, 1926, 1946, 2000, 2009, 2054, 2129], 2228: [1770], 2248: [1773], 9867: [1786], 17478: [1788], 6237: [1789], 2178: [1794, 1974], 2301: [1802], 9455: [1807], 13213: [1816, 1847], 4370: [1817], 4378: [1818], 13341: [1819], 13258: [1823, 1841, 1859, 1933, 1991], 13504: [1826], 13284: [1828, 1846, 1866, 1913, 1956, 1975, 1996], 13317: [1834], 2169: [1835, 1895], 13548: [1838], 13755: [1843], 2184: [1848], 13358: [1852, 1949, 2192], 13080: [1854], 2438: [1868], 12995: [1872], 410: [1874], 13367: [1879], 14061: [1881], 13338: [1882], 18724: [1883], 13164: [1898], 2450: [1901], 13330: [1902], 2223: [1906, 2337], 9880: [1908], 13277: [1909, 1912, 2037, 2039], 18818: [1914], 18816: [1917], 1990: [1923], 13342: [1924], 13178: [1928, 2019, 2060], 13087: [1929], 2621: [1930], 13369: [1931], 13025: [1932], 12982: [1934, 2063], 13282: [1935, 2061], 13132: [1937], 13256: [1938, 2005], 13283: [1939, 2014, 2029], 13354: [1941, 2038, 2058], 13055: [1943], 18713: [1945], 3987: [1947], 13321: [1957], 13265: [1961, 2095], 13547: [1963], 13615: [1964], 2431: [1965], 2160: [1973], 13278: [1976, 2097], 13267: [1978], 2713: [1979, 4109], 413: [1980], 13359: [1983, 2045], 13279: [1986, 2152], 2311: [1987], 11098: [1989], 13310: [1990], 13657: [1992], 13334: [1998], 14231: [1999], 13154: [2002], 13331: [2006, 2245], 2313: [2007], 2491: [2008, 2503, 3677, 3819, 3982, 4012, 4020, 4052, 4054, 4056, 4085, 4087, 4090, 4093, 4100, 4104, 4117, 4129, 4132, 4138, 4155], 2437: [2016], 14059: [2023], 13272: [2024], 13179: [2025], 13081: [2028], 13183: [2030], 12977: [2032], 2189: [2036], 13360: [2044, 2112], 1537: [2046], 13209: [2047], 12997: [2048], 13123: [2049], 4040: [2051], 13206: [2052, 2119, 2213, 2215, 2220, 2237], 13285: [2062], 13191: [2064, 2081, 2173], 13082: [2065], 14341: [2066], 2445: [2067], 13366: [2073], 13273: [2074], 13249: [2084, 2201, 2210, 2330], 13146: [2086, 2121, 2292], 13254: [2087, 2133, 2154], 2159: [2090], 13176: [2094, 2179], 13236: [2099, 2153], 13274: [2100], 13181: [2103, 2125, 2135], 13414: [2107], 17499: [2110], 13253: [2113, 2261], 13391: [2114], 14235: [2115], 13352: [2122], 13259: [2130, 2172], 12989: [2131, 2199, 2279, 2305, 2333, 2355], 13374: [2137], 13754: [2143], 1535: [2144], 13187: [2150, 2257, 2260], 13281: [2151], 13390: [2158, 2246, 2366], 12986: [2159], 13373: [2160], 18810: [2168], 13269: [2169, 2218], 2454: [2171], 14332: [2174, 2217], 2312: [2181], 4430: [2182], 2486: [2184], 13335: [2185], 2193: [2186], 17503: [2187], 13162: [2188, 2254, 2264, 2301, 2302, 2343, 2391], 13348: [2190], 3093: [2193], 13232: [2197], 13449: [2198, 2418], 13432: [2200], 2428: [2202, 2344], 2265: [2206], 13614: [2207], 2011: [2208], 13157: [2211], 13266: [2212], 13185: [2214, 2240], 13545: [2216], 13222: [2221, 2360], 2513: [2222], 2138: [2226], 2177: [2229, 2448], 13270: [2230], 2516: [2234], 13376: [2235], 13292: [2236], 2179: [2239, 2291], 2464: [2241, 3418, 3521], 17582: [2243], 13264: [2244, 2329], 2214: [2247], 18797: [2248], 17598: [2249], 13418: [2250, 2309, 2356, 2375, 2382], 17603: [2253], 12978: [2256], 12984: [2258], 13141: [2259, 2273, 2285, 2289, 2290, 2303, 2322, 2323, 2352, 2440, 2452], 2019: [2262, 3196, 3219, 3232, 3268, 3290, 3296, 3311, 3331, 3357, 3359, 3378, 3410], 13447: [2263], 13076: [2267], 13495: [2268], 13345: [2270], 2786: [2272], 13255: [2275], 2182: [2276], 13260: [2277], 18365: [2280], 13238: [2282], 2518: [2283], 2304: [2284], 13177: [2286, 2332, 2446], 13173: [2287], 13402: [2288, 2700, 2741], 2175: [2293, 2297, 2432], 2174: [2296, 2338], 13419: [2298], 12996: [2299], 12969: [2300], 13294: [2304], 13172: [2306], 13494: [2307], 13276: [2308], 13186: [2310], 13275: [2311], 14139: [2312], 13199: [2313], 13437: [2315], 2068: [2316], 13159: [2317], 13216: [2318], 13188: [2319], 13413: [2320], 18783: [2321], 13165: [2325, 2389], 13237: [2328], 2162: [2331, 2398, 2463], 13166: [2334, 2348], 18742: [2335], 2047: [2339], 17638: [2340], 17560: [2341], 13451: [2345], 14250: [2346], 13430: [2347], 13140: [2349], 13286: [2350], 14307: [2351], 13205: [2353, 2364], 13148: [2354], 13353: [2357], 3927: [2358], 13220: [2359], 13526: [2361], 12987: [2362], 13261: [2363], 17482: [2365], 13346: [2367], 6757: [2368], 18720: [2370], 13180: [2371], 12999: [2372], 12988: [2373, 2459], 13135: [2374, 2461], 12974: [2376], 2522: [2377], 13250: [2378], 13030: [2379, 2417, 2442, 2474, 2512, 2516, 2518], 2372: [2381], 14294: [2383, 3469, 3564], 13223: [2384], 13268: [2385], 2449: [2386], 2064: [2387], 2812: [2388], 12985: [2390], 2689: [2392], 13247: [2394], 2043: [2395], 13171: [2396], 2164: [2397], 13233: [2399], 13137: [2400], 13196: [2401], 2379: [2402, 3096], 13077: [2403], 18594: [2404, 2449], 13263: [2405], 4339: [2406], 4424: [2407], 4211: [2408, 4162, 5963, 7035, 7348, 7410, 7451, 7514, 7534, 7608, 7641, 7643, 7697, 7739, 7740, 7747, 7749, 7764, 7767, 7779, 7782, 7791, 7811, 7851, 7854, 7858, 7887, 7890, 7901, 7982, 8090, 8095, 8217, 8345], 13262: [2410], 13221: [2411], 13290: [2412], 13492: [2413], 2423: [2414], 2432: [2415], 17500: [2416], 12943: [2419], 13239: [2420], 14213: [2421], 13291: [2422], 13062: [2424], 13438: [2425], 12983: [2426], 2410: [2427], 2531: [2428], 14317: [2429], 13433: [2430], 13527: [2431], 18596: [2433], 13240: [2434], 13138: [2435], 2458: [2437], 1742: [2438], 2172: [2439], 2845: [2441, 5451, 7379, 7482, 7575, 7591, 7712, 7810, 7821, 7903, 7985, 8002, 8030], 13224: [2444], 13380: [2445], 2141: [2447], 6278: [2450], 13242: [2451], 13036: [2453], 2176: [2454], 13287: [2456], 13288: [2460], 2924: [2462], 14306: [2465], 14236: [2466], 17599: [2468], 13129: [2470], 14209: [2471], 13092: [2472], 13243: [2473], 2052: [2475], 2511: [2478], 13422: [2479, 2571], 2478: [2480], 14196: [2481, 3802, 3866, 3881, 3906, 3927, 3953, 3957, 3977, 3984, 3986, 3988, 4004, 4005, 4011, 4013, 4023, 4033, 4038, 4039, 4043, 4055, 4060, 4112, 4120], 13453: [2482], 2965: [2483], 17494: [2484], 13136: [2486], 13293: [2488], 13271: [2489], 13442: [2490, 2496, 2500, 2550, 2594, 2596, 2646], 12994: [2491], 13155: [2492], 13244: [2493], 2462: [2494, 2734], 4376: [2495], 13024: [2498], 14123: [2499], 2150: [2501], 2042: [2505, 2654, 2655, 2726], 13142: [2506], 13392: [2507], 17631: [2508], 2227: [2509, 2513, 2537, 2539, 2577], 13088: [2510], 13175: [2511], 2222: [2514], 2217: [2517, 2703], 13289: [2519], 13434: [2520], 13234: [2521], 2425: [2522, 2644], 18754: [2523], 2850: [2524], 2242: [2526], 17625: [2527], 17613: [2528], 2112: [2529], 13143: [2530], 13484: [2531, 2829, 2833, 2845, 2856, 2864, 2873, 2907, 2908, 2912, 2915, 2917, 2921, 2922, 2923, 2927, 2931, 2932, 2933, 2945, 2950, 3020, 3022], 13452: [2533], 2328: [2534, 2543, 2637], 19491: [2535], 2690: [2538, 2587], 2422: [2541], 13510: [2545], 12885: [2546], 13400: [2547, 2551, 2556, 2570, 2582, 2593, 2616, 2623, 2632, 2638], 13251: [2549], 2048: [2552], 1770: [2554], 13028: [2555, 2629], 13245: [2557], 13443: [2558], 12875: [2559, 2664], 13248: [2560], 13241: [2561], 14264: [2562], 18595: [2564], 13417: [2565], 13158: [2566], 14227: [2568], 13450: [2572], 406: [2573], 13023: [2574, 2715], 14138: [2575], 13423: [2576], 4384: [2579], 13010: [2580], 17627: [2581], 12877: [2583], 13153: [2584], 13059: [2585], 12991: [2586], 14326: [2588], 2241: [2590], 2210: [2591], 17520: [2592], 12975: [2595], 13412: [2597], 13002: [2598], 13421: [2599, 2608], 4374: [2600], 13014: [2601, 2605, 2634, 2642, 2650, 2728], 2140: [2602, 2652], 13226: [2603], 13134: [2604], 13420: [2606], 14107: [2609], 14328: [2610], 2238: [2611], 2386: [2612], 13009: [2613, 2615], 2218: [2614], 13436: [2617], 13139: [2619], 13246: [2621], 13343: [2622], 17607: [2624], 13015: [2625], 13018: [2626], 13228: [2627], 13489: [2628], 2795: [2630], 13411: [2631, 2647, 2704], 13130: [2633], 2206: [2635], 14323: [2636], 2225: [2639, 2651, 2656, 2670], 13503: [2640], 13444: [2641, 2765], 2436: [2643], 14342: [2645], 3199: [2649], 13227: [2653], 9878: [2657], 1991: [2658], 2302: [2659], 13543: [2660], 2401: [2662], 13131: [2663], 2065: [2665], 18732: [2667], 2045: [2668], 1989: [2669], 13013: [2671], 13229: [2672], 13724: [2673], 14168: [2674], 13491: [2675], 2226: [2676, 2707], 3970: [2677], 13144: [2678], 13306: [2679], 13440: [2680], 2113: [2681], 13033: [2682], 1984: [2683], 13499: [2684], 13027: [2685, 2691], 6304: [2686], 14080: [2687], 18819: [2688], 13125: [2690], 4631: [2692, 9001, 10393], 1997: [2693], 13469: [2694], 2219: [2695], 13395: [2698, 2706, 2745], 13383: [2699, 2751], 4368: [2701], 2705: [2702], 2388: [2705], 12979: [2708], 13424: [2709], 13500: [2710], 13393: [2711, 2795], 13225: [2712], 13252: [2713], 2161: [2714], 13513: [2716], 13032: [2717], 13124: [2718], 2686: [2719, 3179, 3187], 2956: [2720], 13401: [2721], 2770: [2722, 3097, 4786, 4825], 2215: [2723], 13403: [2725], 13472: [2727, 2851], 9970: [2729], 17488: [2730], 18639: [2731, 4019, 4718], 13470: [2733], 2069: [2735], 1987: [2736], 14325: [2737, 2744, 3042, 3086, 3093], 13427: [2738], 13003: [2739], 13550: [2740], 16629: [2742], 13766: [2743], 13768: [2746], 2552: [2747], 2397: [2748, 2902], 2305: [2749], 13026: [2750], 13012: [2752, 2764, 2790], 13089: [2753], 13049: [2754], 4372: [2755], 1995: [2756], 13428: [2757], 2066: [2758], 13475: [2759, 2880, 2891, 3002], 14315: [2760], 13514: [2761], 13053: [2762], 2220: [2763], 13445: [2766], 13409: [2767, 2773, 2792], 2001: [2768], 17910: [2769], 14329: [2770], 2700: [2771], 14327: [2772], 4736: [2774], 17636: [2776], 17626: [2777], 2396: [2778], 13017: [2779, 2940], 13415: [2780], 13016: [2781], 2055: [2782, 2925], 2046: [2783], 13770: [2784], 18597: [2786], 2303: [2787, 2983], 13323: [2788], 13004: [2789], 14237: [2791], 2058: [2793, 3148], 2441: [2794], 13156: [2796], 13485: [2797], 15040: [2798], 4385: [2799], 13006: [2800], 2398: [2801], 14286: [2802], 2515: [2803], 13005: [2804], 12930: [2805], 13410: [2806], 18708: [2807], 13231: [2808], 14296: [2809], 2199: [2810, 2871], 13404: [2811], 13029: [2812], 2024: [2813], 13465: [2814], 1536: [2815], 2209: [2816], 12970: [2817], 2399: [2818], 2361: [2819], 2233: [2820], 13483: [2821, 2841, 2859, 2865, 2884, 2895], 13474: [2822], 2874: [2823, 4772], 2452: [2824], 2519: [2825], 3197: [2826, 2894], 13525: [2827], 2108: [2828], 4401: [2830], 13501: [2831], 13446: [2832], 13214: [2834], 12905: [2835], 17568: [2836], 2810: [2837], 18707: [2838], 2533: [2839, 3379], 18723: [2840, 2850, 2879, 2888], 14303: [2843, 3369], 14232: [2844], 13056: [2847], 2022: [2848], 13398: [2849], 3964: [2852], 2769: [2853, 4058, 4871, 5057, 5103, 5140, 5151, 5208], 2416: [2854], 19157: [2855], 13324: [2857], 13399: [2858], 2059: [2860, 2934, 2939, 2986, 2997, 3005, 3015, 3018, 3019, 3027, 3033, 3043, 3044, 3074, 3106], 3966: [2861], 2014: [2862], 13416: [2863], 14268: [2866], 18709: [2867], 9666: [2868], 13515: [2869, 2959, 2976, 3011, 3045, 3066], 2435: [2870, 2874], 13441: [2872], 2798: [2875], 2212: [2876], 18586: [2877], 3989: [2878], 12942: [2881], 13476: [2882], 4348: [2883], 2885: [2885, 4124, 5250, 5303, 5368, 5372, 5375, 5453, 5498, 5511, 5520, 5529, 5536, 5585], 14909: [2886], 13551: [2887], 2234: [2889], 3963: [2890], 3049: [2892, 6079, 6123, 6345, 6649, 6655, 6711, 6735, 6739, 6772, 6794, 6810, 6813, 6835, 6844, 6849, 6884, 6902, 6911, 6915, 6917, 7144, 7275], 13519: [2893], 2216: [2896, 3051], 14240: [2897], 13486: [2898], 13544: [2899], 13487: [2900], 3974: [2901], 2356: [2904], 6742: [2905, 5256, 5576, 8478, 8828, 8877, 8958], 13520: [2906], 14330: [2909], 2056: [2910], 2503: [2911], 13230: [2913], 13560: [2914], 2439: [2916], 2818: [2918], 1450: [2919, 7242, 10951], 14338: [2920], 18590: [2924], 4386: [2926], 13385: [2928], 4161: [2929], 13516: [2930], 13425: [2935], 2335: [2936], 2039: [2937], 14228: [2938], 18583: [2941, 2974], 4404: [2942], 13502: [2943], 2512: [2944], 1994: [2946], 13061: [2947], 4153: [2948], 4388: [2949], 2230: [2951], 13021: [2952], 13518: [2953, 2984], 13488: [2954], 14136: [2955], 13042: [2956], 9949: [2957], 289: [2958], 13477: [2960], 2092: [2961], 13007: [2962], 3983: [2963], 14251: [2964], 2806: [2965], 13507: [2966], 14290: [2967], 14320: [2968], 13396: [2969], 14335: [2970], 14062: [2971], 12938: [2972], 2062: [2973], 13771: [2975], 13019: [2977], 13471: [2978, 3016, 3077, 3080, 3091, 3149], 4158: [2979], 2080: [2980, 4212, 4287], 3510: [2981], 2060: [2982], 15041: [2985], 13397: [2987], 2139: [2988], 13150: [2989], 13536: [2990], 2205: [2991], 2561: [2992], 14565: [2993, 5228], 14238: [2994, 3038], 2057: [2995, 3049, 3087], 14333: [2998], 13480: [2999, 3012, 3058], 13041: [3000], 14109: [3001], 14318: [3003], 2796: [3004], 2200: [3006, 3105], 2203: [3007], 18591: [3008], 13151: [3009], 13219: [3010], 12892: [3014], 2030: [3017], 18631: [3021, 5612, 5982], 12900: [3023], 6256: [3024], 13057: [3025], 3033: [3026, 3842], 13060: [3028], 13522: [3029, 3048, 3115, 3126, 3127], 14077: [3030], 1521: [3031], 14920: [3032], 2116: [3034], 2239: [3035], 13718: [3036], 13389: [3037], 6411: [3039], 13482: [3040, 3055], 13481: [3041, 3101, 3131], 13011: [3046], 13455: [3047], 9848: [3050], 12915: [3052], 15035: [3053], 13008: [3054], 2784: [3056], 16466: [3057], 15033: [3059], 13523: [3060, 3064, 3130, 3154, 3174, 3177, 3229, 3233, 3240], 2117: [3061], 14222: [3062], 2500: [3063], 18627: [3065], 14297: [3068], 2560: [3069, 3111], 13035: [3070], 13406: [3071], 397: [3072], 2799: [3073], 2211: [3075], 13052: [3076, 3209], 13490: [3078], 2236: [3079], 17592: [3081, 3134], 2221: [3082], 15039: [3083], 19750: [3084], 13215: [3085], 17635: [3088], 2015: [3089], 13461: [3090], 13534: [3092], 15034: [3094], 14336: [3095], 14121: [3098], 287: [3099], 17106: [3100], 14301: [3102, 3180], 2455: [3103], 2685: [3104, 3123], 13975: [3107], 13217: [3108], 13218: [3109], 19492: [3110], 19075: [3112], 2514: [3114], 2061: [3116], 2400: [3117], 2541: [3118], 2575: [3120], 14134: [3121, 3189, 3282], 2017: [3122, 3198], 14223: [3124], 13043: [3125], 14132: [3128], 5740: [3129, 5725], 2517: [3132], 2306: [3133], 2446: [3135], 14273: [3136], 13497: [3137], 13535: [3138], 18584: [3139, 4404, 4613], 19462: [3140], 14147: [3141], 2036: [3142, 3346], 17574: [3143], 13386: [3145], 12876: [3146], 13762: [3147], 354: [3150], 14470: [3151], 2688: [3152], 13911: [3153], 2542: [3155], 2797: [3156, 3237], 2917: [3157], 12976: [3158], 14018: [3159], 13463: [3160], 2779: [3161], 14180: [3162], 9612: [3163], 2240: [3164], 17620: [3165], 18756: [3166], 14337: [3167], 13457: [3168], 19751: [3169, 4041], 2363: [3170], 2457: [3171], 801: [3173], 2362: [3176], 2012: [3178], 18690: [3181], 3200: [3182], 12903: [3183], 13128: [3184], 13506: [3185, 3300], 12897: [3186], 12971: [3188], 13054: [3190], 13546: [3191], 14305: [3192], 11145: [3193, 3274, 6617, 6717], 1744: [3194], 4410: [3195], 2188: [3197], 14140: [3199], 4431: [3200], 4323: [3201], 12887: [3202], 13496: [3203], 18820: [3204], 17724: [3205], 12899: [3206], 17621: [3207], 18593: [3208], 13521: [3210, 3312], 14179: [3211], 17486: [3212], 9667: [3213], 10876: [3214, 10304], 12670: [3215, 17391], 14133: [3216], 3383: [3217], 3977: [3218], 2063: [3220], 3959: [3221], 4351: [3222], 12890: [3223], 3034: [3224], 13407: [3225], 1522: [3226], 14172: [3227], 4022: [3228], 2006: [3230], 19467: [3231], 14291: [3234, 3363, 3386, 3405], 1542: [3235], 2707: [3236], 9850: [3238], 2802: [3239], 3110: [3241, 6899, 7053], 13387: [3242], 14244: [3243], 14233: [3244], 14309: [3245], 18830: [3246], 13912: [3247], 15038: [3248], 18619: [3250], 19483: [3251], 2434: [3252], 2539: [3253], 13538: [3254], 2809: [3255], 13120: [3256], 13478: [3257], 2523: [3258], 6330: [3259], 4624: [3260], 14922: [3261], 14248: [3263], 9705: [3264], 12902: [3265, 3518], 2468: [3266], 2456: [3267], 2404: [3269, 3404, 3593, 3633], 13758: [3270], 13050: [3271], 2460: [3272], 14287: [3273], 17075: [3275], 14614: [3276], 13326: [3277], 2009: [3278], 3984: [3279], 4405: [3280], 2025: [3281], 13524: [3283], 14281: [3284], 2800: [3285], 415: [3286], 9707: [3287], 13212: [3288, 3310], 2053: [3289], 2195: [3291], 13408: [3292], 2534: [3293], 14312: [3294], 2590: [3295], 2008: [3297], 14130: [3298], 14339: [3299], 16928: [3301], 2578: [3302], 2555: [3303], 14304: [3304], 12967: [3305], 13769: [3306], 2482: [3307], 14210: [3308], 13479: [3309], 2235: [3313], 13126: [3314], 2509: [3315], 14298: [3316], 18653: [3317], 11144: [3318], 12931: [3319], 2738: [3320, 4142], 19134: [3321], 2002: [3322], 14190: [3323], 12924: [3324], 14169: [3325], 14334: [3326], 2470: [3327], 14135: [3328], 370: [3329], 10072: [3330], 12891: [3332], 2553: [3333], 3192: [3334], 17593: [3335], 4361: [3336], 14176: [3337], 4128: [3338], 13429: [3339], 2717: [3340], 2367: [3341], 915: [3342, 15508, 15880, 15883, 16208, 16349, 16350], 2370: [3343], 1779: [3344, 3464], 2037: [3345], 12881: [3347], 17608: [3348], 2272: [3349], 13388: [3350], 3193: [3351], 3922: [3352, 3835, 3868, 3876, 3878], 2035: [3353], 13044: [3354], 4425: [3355], 12878: [3356], 13745: [3358], 13537: [3360, 3488], 18782: [3361], 14128: [3362], 401: [3364], 10579: [3365], 10482: [3366], 18651: [3367], 13122: [3368], 2207: [3370], 2237: [3371], 2033: [3372, 3375, 3449], 13508: [3373], 17912: [3374, 4342], 17618: [3376], 4791: [3377], 14178: [3380], 2687: [3381], 17575: [3382], 14142: [3383], 2332: [3384], 3127: [3385], 828: [3387], 2720: [3388], 2801: [3389], 15031: [3390], 1992: [3391], 2373: [3392], 14118: [3393], 394: [3394], 14965: [3395], 2501: [3396], 4163: [3397], 3918: [3398], 2532: [3399], 15042: [3400], 2003: [3401], 2378: [3402], 13459: [3403], 3191: [3406], 2027: [3407, 3695], 2201: [3408], 14116: [3409, 3461, 3471], 13460: [3411], 13046: [3412], 14129: [3413], 2551: [3414], 2545: [3415, 3703, 3804], 2357: [3416], 4700: [3417], 3965: [3419], 2018: [3420, 3478], 14293: [3421, 3431, 3484], 17072: [3422], 13539: [3423], 2371: [3424], 1788: [3425, 6845, 7326], 2697: [3426], 14289: [3427, 3473], 14282: [3428], 14566: [3429], 17070: [3430], 2034: [3432, 3485, 3507, 3590], 2106: [3433], 4254: [3434], 4438: [3435], 13505: [3436], 2728: [3437], 12904: [3438], 14154: [3439], 18598: [3440], 4245: [3441, 6817, 7302, 7312, 7470, 7471, 7666, 7963, 8059, 8061, 8065, 8077, 8083, 8088, 8189, 8199, 8200, 8202, 8207, 8208, 8210, 8213, 8220, 8223, 8319, 8320, 8321, 8324, 8325, 8328, 8329, 8332, 8338, 8340, 8342, 8343, 8346, 8347, 8348, 8349, 8356, 8362, 8372, 8436, 8438, 8440, 8456, 8457, 8459, 8462, 8516, 8519, 8533, 8540, 8541, 8618, 8641, 8663, 8709, 8853], 1986: [3442, 3477], 2028: [3443], 13517: [3444], 14274: [3445, 3505, 3626], 7822: [3446], 2504: [3447], 3949: [3448], 18998: [3450], 2496: [3451], 2250: [3452], 2190: [3453], 14126: [3454], 2750: [3455], 2536: [3456], 1998: [3457], 13512: [3458], 4394: [3459], 4007: [3460], 18599: [3462], 2016: [3463], 409: [3465], 2935: [3466], 4391: [3467], 2461: [3470], 18850: [3472], 9569: [3474], 2023: [3475], 4224: [3476], 13454: [3479, 3523, 3551, 3592, 3623], 13022: [3480], 14256: [3481], 14175: [3482], 9693: [3483, 3583], 2054: [3486], 3512: [3487], 13118: [3489], 18852: [3490], 14299: [3491], 14243: [3492], 14319: [3493], 5827: [3494, 15475, 15982, 15984, 16141, 16147, 16148, 16284, 16304, 16318, 16370, 16475, 16476, 16477, 16484, 16485, 16590, 16604, 16612, 16624, 16645, 16647, 16659, 16661, 16662, 16666, 16667, 16668, 16670, 16671, 16672, 16673, 16674, 16676, 16677, 16678, 16680, 16681, 16683, 16684, 16685, 16686, 16688, 16689, 16690, 16691, 16692, 16693, 16695, 16697, 16699, 16703, 16704, 16707, 16788, 16851, 16883, 16898, 16900, 16904, 17139, 17160, 17383, 17395, 17418], 2549: [3495], 3069: [3496, 5268, 5565], 2467: [3497], 14060: [3498], 12940: [3499], 3103: [3500, 3761, 4771, 5293, 5452, 5455, 5750, 5829, 5830, 5855, 5870, 5871, 5873, 5890, 5892, 5901, 5918, 5936, 5976, 6006, 6064, 6087, 6095, 6096, 6102, 6111, 6114, 6134, 6173, 6219, 6227, 6233, 6247, 6282, 6299, 6318, 6327, 6337, 6352, 6359, 6362, 6366, 6372, 6385, 6402, 6405, 6421, 6455, 6456, 6464, 6474, 6479, 6482, 6495, 6496, 6499, 6517, 6519, 6520, 6521, 6522, 6527, 6550, 6554, 6559, 6564, 6569, 6574, 6575, 6576, 6579, 6581, 6582, 6587, 6588, 6592, 6605, 6606, 6608, 6609, 6627, 6651, 6668, 6692, 6712, 6773, 6812, 6832, 7010], 2550: [3501], 2706: [3502], 3009: [3503], 1534: [3504], 9865: [3506], 18638: [3508], 13935: [3510], 2031: [3511], 13051: [3512], 14331: [3513], 18851: [3514], 14602: [3515], 2508: [3516], 2348: [3517], 2469: [3519], 2020: [3520], 13121: [3522], 13556: [3524], 14249: [3525], 2556: [3526], 13554: [3527], 2571: [3528], 10116: [3529], 9514: [3530, 3995, 10568, 10861], 17076: [3531], 14204: [3532], 2524: [3533], 4411: [3534], 2038: [3535], 13045: [3536], 13467: [3537], 13561: [3538], 3195: [3539], 6762: [3540, 4179, 4823, 5128, 5709, 6107, 6686, 6720, 6793, 7029, 7030, 7064, 7186, 7234, 7318, 7331, 7363, 7436, 7596, 7605, 7705, 7708, 7832, 7838, 7909, 7910, 7913, 7927, 7937, 7992, 7993, 8004, 8008, 8010, 8013, 8018, 8024, 8026, 8029, 8036, 8049, 8051, 8057, 8105, 8106, 8110, 8115, 8130, 8136, 8142, 8157, 8158, 8162, 8172, 8240, 8245, 8248, 8252, 8255, 8256, 8257, 8261, 8265, 8279, 8291, 8304, 8307, 8310, 8314, 8385, 8389, 8393, 8406, 8407, 8417, 8483, 8592, 8672], 18805: [3541], 14207: [3542], 14112: [3543], 12658: [3544, 17390], 4409: [3545], 4019: [3547], 2502: [3548], 2385: [3550], 12908: [3552, 3607], 1733: [3553], 2359: [3554], 286: [3555, 7503, 8042], 9482: [3556], 14923: [3559], 4439: [3560], 2807: [3562], 2346: [3563], 14181: [3565], 6684: [3566], 2538: [3567], 3051: [3568, 4481, 4767, 5527, 5656, 5691, 5719, 5805, 5815, 5839, 5857, 5874, 5881, 5985, 6001, 6009, 6015, 6097, 6100, 6444, 6458, 6461, 6556, 6624, 6647, 6660, 6674, 6694, 6698, 6724, 6729, 6730, 6731, 6732, 6733, 6736, 6740, 6746, 6749, 6750, 6751, 6753, 6755, 6757, 6759, 6760, 6762, 6764, 6765, 6767, 6771, 6775, 6776, 6777, 6788, 6791, 6807, 6808, 6811, 6814, 6816, 6821, 6825, 6826, 6837, 6848, 6850, 6855, 6856, 6865, 6880, 6890, 6892, 6897, 6898, 6903, 6907, 6912, 6914, 7056], 13037: [3569], 4392: [3570], 13511: [3571], 13558: [3572], 12965: [3573], 2374: [3574, 3725], 2115: [3577], 13048: [3578], 13462: [3579], 3073: [3581], 18784: [3585], 1769: [3586], 18349: [3587], 6755: [3588, 3598, 3994, 4101, 4558, 4637, 5713, 5942, 6060, 6681, 6954, 6971, 7362, 7494, 7579, 7585, 7594, 7698, 7701, 7814, 7815, 7816, 7830, 7833, 7912, 7926, 7928, 7929, 7933, 7994, 7995, 7996, 7997, 7998, 7999, 8005, 8011, 8014, 8032, 8038, 8052, 8112, 8113, 8116, 8118, 8120, 8122, 8123, 8127, 8128, 8137, 8143, 8145, 8150, 8156, 8161, 8182, 8236, 8239, 8246, 8251, 8254, 8282, 8297, 8382, 8421, 8577, 8760, 8814], 2026: [3589, 3620, 3674], 4298: [3591], 13900: [3594], 13907: [3595], 14203: [3596], 2344: [3597], 9702: [3599], 13763: [3601], 17611: [3602], 3016: [3604, 5651, 5788, 6094], 14255: [3606], 18609: [3608, 3744], 12893: [3609], 14283: [3610], 14131: [3611], 1745: [3614], 17487: [3615], 4170: [3617, 3642], 2453: [3619], 4788: [3621], 2336: [3622], 14090: [3625], 2699: [3627], 2479: [3628], 2744: [3629], 13468: [3630], 4201: [3631, 7397, 7406, 7453, 7465, 7760, 7769, 7773, 7790, 7812, 7849, 7942, 7945, 7951, 7968, 7973, 8058, 8069, 8080, 8081, 8201, 8212, 8225], 13552: [3632], 13498: [3634], 18646: [3635], 14189: [3637], 14110: [3638], 3920: [3639, 4068, 4168], 14188: [3644, 3715], 14037: [3646], 13549: [3647, 3792, 3793, 3806], 12939: [3648], 14171: [3649], 2466: [3650, 3687, 3693, 3705, 3730, 3734], 9959: [3651], 14115: [3652, 3690], 17725: [3653], 2347: [3654], 14174: [3655, 3719], 14615: [3658], 2701: [3660, 3823, 4183], 12894: [3661], 2741: [3662], 2380: [3663], 2443: [3665, 3943], 14120: [3666], 2090: [3668], 2098: [3669], 3988: [3670], 17624: [3671], 2091: [3673], 14193: [3678], 14202: [3679], 2547: [3680, 3760], 9365: [3681, 11763, 11945, 12035, 12036], 2698: [3682, 3706], 2004: [3683, 3821], 3967: [3684], 12946: [3685, 3972], 18729: [3686], 14162: [3689], 6675: [3691], 2964: [3692], 4358: [3694], 13531: [3696], 2196: [3697], 14279: [3698], 17632: [3699], 6408: [3700], 14208: [3701], 14170: [3702], 12880: [3704], 2084: [3707], 14524: [3708], 19752: [3709], 2554: [3710], 9604: [3711, 3753], 17080: [3712], 4044: [3713, 8231], 12884: [3714], 2543: [3716, 3768, 3797], 14163: [3717], 2751: [3718], 14321: [3720], 14117: [3721], 9668: [3722], 9519: [3723, 8972, 9236, 10101, 10435, 10440, 10471, 10484, 10487, 10489, 10494, 10550, 10554, 10555, 10558, 10561, 10562, 10563, 10566, 10569, 10570, 10572, 10573, 10574, 10575, 10576, 10579, 10582, 10586, 10624, 10645, 10647, 10649, 10652, 10654, 10655, 10658, 10659, 10661, 10662, 10673, 10680, 10746, 10749, 10752, 10757, 10759, 11058, 11064, 11065], 14889: [3724], 2082: [3726], 3863: [3727, 5581], 4362: [3728], 2499: [3729], 2922: [3731, 7142], 12945: [3732], 2742: [3733], 14280: [3735], 15347: [3736], 2988: [3737, 3925, 4902, 5754, 6367, 6595, 6706, 6883, 6906, 6918, 6936, 6941, 6945, 6947, 6948, 6950, 6952, 6965, 6992, 6999, 7002, 7003, 7004, 7005, 7043, 7058, 7063, 7093, 7100, 7121, 7124, 7153, 7180, 7225, 7289], 11105: [3738], 9492: [3739], 11065: [3740], 4063: [3741, 4003, 8089, 9121, 9324, 9332, 9409], 14278: [3742, 3850], 12964: [3743, 3771], 358: [3745], 17908: [3746], 18626: [3747], 416: [3748], 19484: [3749], 1740: [3750], 14253: [3751], 2702: [3752], 3880: [3754], 17909: [3755], 13937: [3756], 12972: [3757], 2840: [3758, 8235, 8476, 8613, 8673, 9016], 2829: [3759], 2569: [3762], 2722: [3763], 2544: [3764, 3824], 2081: [3765], 2695: [3766], 2086: [3767], 3971: [3769], 12973: [3770], 14484: [3772], 2916: [3773], 14192: [3774], 14275: [3775], 14194: [3776], 3912: [3777], 13761: [3778], 14211: [3779], 2803: [3780], 14284: [3781], 2420: [3782], 780: [3783], 9618: [3784], 2546: [3785, 3808], 4408: [3786], 2718: [3787], 17615: [3788], 17637: [3789], 14620: [3790], 14300: [3791], 4427: [3794], 14195: [3795, 3840, 3928], 13566: [3796], 14310: [3798], 2497: [3799], 2694: [3800], 4359: [3801], 12888: [3803], 2847: [3805], 4021: [3807], 14199: [3809], 14270: [3810], 14119: [3811], 18831: [3812], 2483: [3813], 14151: [3814, 4640], 2914: [3815, 4216], 4365: [3816], 4196: [3817], 3960: [3818], 17590: [3820], 14877: [3822], 2573: [3825], 19393: [3826], 2440: [3827], 3892: [3828], 4398: [3829], 12879: [3830], 14205: [3831, 3930], 2360: [3832], 2392: [3833], 4093: [3834], 12936: [3836], 13898: [3837], 14276: [3838], 2739: [3839], 2907: [3841], 14063: [3843], 2029: [3844], 2010: [3845], 15261: [3846], 2540: [3847], 14182: [3848], 14295: [3849], 2726: [3851, 3871, 4046], 1737: [3852], 13993: [3853], 12916: [3854], 12886: [3855], 2719: [3856], 4356: [3857], 4215: [3858, 3892, 4802, 5443, 6876, 6940, 7214, 7258, 7303, 7305, 7339, 7345, 7346, 7349, 7399, 7407, 7408, 7412, 7414, 7422, 7443, 7447, 7448, 7449, 7450, 7452, 7454, 7458, 7460, 7462, 7464, 7472, 7478, 7480, 7481, 7511, 7513, 7515, 7516, 7517, 7519, 7521, 7522, 7523, 7524, 7525, 7528, 7530, 7531, 7532, 7533, 7535, 7536, 7538, 7539, 7540, 7541, 7543, 7544, 7546, 7547, 7549, 7550, 7551, 7554, 7556, 7558, 7559, 7561, 7562, 7563, 7564, 7565, 7566, 7569, 7574, 7576, 7577, 7580, 7607, 7610, 7612, 7614, 7617, 7621, 7622, 7623, 7625, 7626, 7627, 7629, 7631, 7632, 7633, 7634, 7635, 7637, 7638, 7639, 7642, 7646, 7650, 7652, 7653, 7660, 7661, 7665, 7668, 7673, 7678, 7679, 7680, 7682, 7684, 7688, 7695, 7732, 7733, 7741, 7742, 7744, 7745, 7748, 7752, 7753, 7757, 7780, 7787, 7793, 7794, 7795, 7806, 7809, 7852, 7855, 7860, 7861, 7862, 7867, 7873, 7881, 7889, 7943, 7944, 7969, 8082, 8339], 2142: [3859], 12966: [3860], 2696: [3861], 9834: [3862], 16618: [3863], 2528: [3864], 6337: [3865], 3985: [3867], 2813: [3869], 13540: [3870], 2526: [3872], 13902: [3873], 2991: [3874], 12895: [3875], 9879: [3877], 14177: [3879], 2202: [3880], 2913: [3882], 14137: [3883], 14076: [3884], 19463: [3885], 403: [3886], 9603: [3887, 4084], 12665: [3888, 7731, 13750, 15298, 15958, 16457, 16911, 17055, 17396], 13793: [3889], 4200: [3890, 7396, 7413, 7455, 7457, 7542, 7552, 7581, 7611, 7616, 7636, 7645, 7648, 7654, 7656, 7671, 7694, 7734, 7738, 7743, 7751, 7756, 7762, 7847, 7850, 7857, 7880, 7884, 7885, 7939, 8070, 8096], 4789: [3891], 2100: [3893], 17594: [3894, 3895, 3958], 2101: [3896], 19449: [3897, 4648, 10001, 10469, 10733, 10958, 11130, 11222, 11289, 11301], 14206: [3898], 14002: [3899], 13936: [3900, 4221], 14173: [3901], 12292: [3902], 14033: [3903], 14067: [3904], 4366: [3905, 6995], 4349: [3907], 12882: [3908], 14016: [3909], 18637: [3910], 12883: [3911], 14254: [3912], 2933: [3913], 2727: [3914], 19679: [3915], 2465: [3916], 3878: [3917], 4008: [3918], 2032: [3919], 17911: [3920, 4197], 12968: [3921], 4399: [3922], 18606: [3923], 14910: [3924], 3925: [3926], 784: [3929], 2107: [3931], 7470: [3932], 18698: [3933], 3950: [3934], 2078: [3935], 3972: [3936], 4422: [3937], 4393: [3938], 12932: [3939], 9877: [3940], 14186: [3941], 9258: [3942], 2692: [3944], 6776: [3945], 4209: [3947, 7469, 7537, 7553, 7568, 7619, 7630, 7644, 7649, 7659, 7662, 7672, 7674, 7675, 7676, 7755, 7775, 7785, 7803, 7804, 7808, 7853, 7864, 7878, 7883, 7888, 7891, 7895, 7952, 7958, 7972, 7989, 8060, 8075, 8076, 8198, 8211, 8218, 8350], 4347: [3948], 13116: [3949], 12898: [3950], 2490: [3951, 4014], 6779: [3952], 3923: [3954], 2527: [3955], 3951: [3956], 2376: [3959], 12865: [3960], 4383: [3961], 2737: [3962], 9704: [3963, 4048], 9559: [3964], 14155: [3965], 14271: [3966], 13563: [3967], 2345: [3968, 4353, 4468, 4652, 4688, 4796], 4436: [3969], 3921: [3970], 4417: [3971], 3909: [3973], 18625: [3974], 14075: [3976], 19481: [3978], 2485: [3979, 4161, 4231, 4259], 2463: [3980], 14111: [3981], 10683: [3983], 14914: [3985], 3189: [3987], 1743: [3989, 4276], 18710: [3990], 14214: [3991], 298: [3992], 19464: [3993], 3101: [3996, 5526], 4406: [3997], 1421: [3998], 13119: [3999], 2505: [4000], 2351: [4001], 12864: [4002], 2365: [4006], 19486: [4007], 6332: [4008], 14108: [4009], 18623: [4010], 12855: [4015], 14964: [4016, 4835], 2734: [4017, 4335], 14157: [4018, 4275], 17491: [4021], 2451: [4022], 14159: [4024], 14262: [4025], 425: [4026], 395: [4027], 728: [4028], 407: [4029], 414: [4030], 7079: [4031], 4181: [4032], 2110: [4034], 4337: [4035], 13532: [4036], 2487: [4037], 6105: [4040, 5821, 11771, 15692], 1722: [4042], 14191: [4044, 4238], 18648: [4045], 6401: [4047, 4440, 4989], 11074: [4049], 14141: [4050], 12858: [4051, 4150], 4416: [4053], 12913: [4057], 14618: [4059], 2331: [4061], 1464: [4062], 2896: [4063], 14277: [4064], 11090: [4065], 2903: [4066], 2494: [4067], 4267: [4069, 9795, 9797], 14160: [4070], 14183: [4071], 2088: [4072], 4324: [4073], 8167: [4074], 2102: [4075], 16621: [4076], 655: [4078], 2785: [4079], 3005: [4080], 2693: [4081], 2488: [4082], 18711: [4083], 3954: [4086], 4420: [4088], 14610: [4089], 12911: [4091], 12853: [4092], 13906: [4094], 1731: [4095], 381: [4096], 2444: [4097], 2729: [4098], 17492: [4099], 2391: [4102, 4170], 2724: [4103, 4225, 4269, 4328], 7630: [4105], 15279: [4106], 4226: [4107], 4369: [4108], 18999: [4110], 4428: [4111], 2330: [4113, 4172, 4175], 13933: [4114], 19480: [4115], 9694: [4116], 2764: [4118], 2530: [4119], 2075: [4121], 2337: [4122], 14156: [4123, 4178, 4288, 4302, 4323, 4367], 15197: [4125], 17986: [4126], 2529: [4127], 2766: [4128], 13903: [4130], 14607: [4131], 10958: [4133], 3908: [4135], 4396: [4136], 2712: [4137], 13047: [4139], 2492: [4140], 1725: [4141], 14586: [4143], 14124: [4144, 4154], 2442: [4145], 355: [4146], 2368: [4147], 2723: [4148], 9589: [4149], 2507: [4151], 4360: [4152], 2740: [4153], 2319: [4156], 9670: [4157], 9672: [4158], 14049: [4159, 4180, 4193, 4256], 5714: [4160], 13114: [4163], 2083: [4164], 17916: [4165], 4338: [4166], 4002: [4167], 12896: [4169], 3037: [4171], 2005: [4173], 6728: [4174], 14197: [4176], 14605: [4177], 2861: [4181], 9282: [4182], 2884: [4184, 5186, 5218, 5365, 5406], 9457: [4185], 12937: [4186], 2353: [4187, 4362], 6765: [4188], 6310: [4189], 1520: [4190], 14272: [4191], 13934: [4192], 9856: [4194], 15245: [4195], 3957: [4196], 17622: [4198], 4389: [4199], 2778: [4200], 14161: [4201], 15026: [4202], 19469: [4203], 14285: [4204], 14095: [4205], 14184: [4206], 2384: [4207], 4364: [4209, 4230], 4080: [4210, 8778, 9132, 9181, 9184, 9185, 9192, 9195, 9255, 9264, 9319, 9321, 9326, 9327, 9328, 9341, 9384, 9387, 9463], 4345: [4211], 7465: [4213], 17623: [4214], 2111: [4215], 12941: [4217], 1070: [4218], 14198: [4219], 2480: [4220, 4223], 6706: [4222], 4708: [4224], 12935: [4226], 2089: [4227], 2765: [4228], 4257: [4229], 4357: [4232], 3952: [4233], 2973: [4234], 2962: [4235], 17680: [4236], 2862: [4237], 14200: [4239], 16626: [4240], 9676: [4241], 4255: [4242], 3898: [4243], 18587: [4245], 2872: [4246], 2525: [4247], 12859: [4248], 18592: [4249], 2858: [4250], 2814: [4251], 14324: [4252], 2771: [4253, 4304, 4473, 4631, 4636, 4655, 4737, 4768, 4770, 4787, 4798, 4815, 4818, 4821, 4830, 4836, 4837, 4843, 4849, 4850, 4858, 4868, 4880, 4882, 4884, 4887, 4894, 4901, 4903, 4905, 4906, 4907, 4909, 4911, 4912, 4914, 4926, 4929, 4935, 4936, 4938, 4942, 4943, 4945, 4949, 4950, 4952, 4955, 4956, 4957, 4964, 4965, 4966, 4967, 4969, 4971, 4972, 4975, 4976, 4977, 4980, 4982, 4983, 4986, 4988, 4990, 4991, 4997, 4999, 5002, 5004, 5005, 5006, 5007, 5008, 5009, 5010, 5011, 5013, 5014, 5016, 5017, 5018, 5019, 5020, 5021, 5022, 5024, 5026, 5034, 5035, 5037, 5039, 5041, 5042, 5045, 5046, 5050, 5051, 5053, 5059, 5060, 5095, 5124, 5234], 14122: [4254], 14031: [4255], 3158: [4257], 2592: [4258], 2387: [4260], 2327: [4261], 9438: [4262], 9683: [4263], 6744: [4264], 19048: [4265], 4227: [4266, 7360, 7456, 7560], 4068: [4267], 13921: [4268], 15036: [4270], 13565: [4271, 4354], 13533: [4272], 13541: [4273], 12889: [4274], 2721: [4277], 14148: [4278, 4322], 13901: [4279], 2493: [4280], 19416: [4281], 9560: [4282], 18610: [4284], 3996: [4285], 4689: [4286], 12958: [4289], 6789: [4290, 9522, 9991, 10075, 10077, 10095, 10227, 10275], 6363: [4291], 2865: [4292], 4222: [4293], 2076: [4294], 3903: [4295], 2096: [4296], 4065: [4297, 8790, 8850, 8851, 8909, 8910, 8985, 8998, 8999, 9051, 9052, 9122, 9125, 9130], 3893: [4298], 2904: [4299], 12950: [4300], 14201: [4301], 6359: [4303], 2320: [4305], 9487: [4306], 2947: [4307, 4594], 9619: [4308], 3955: [4309, 4358], 4350: [4310], 3196: [4311], 2576: [4312], 14070: [4313], 14259: [4314], 14288: [4315], 12914: [4316], 2902: [4317], 4352: [4318], 3961: [4319], 3035: [4320], 15268: [4321], 2961: [4324], 9655: [4325], 19487: [4326], 3902: [4327, 4339, 4341, 4355, 4359, 4361, 4374, 4383, 4386, 4402, 4431, 4510], 4801: [4329], 4643: [4330], 6331: [4331, 4596], 14632: [4332], 14263: [4333], 2999: [4334], 10280: [4336], 6372: [4337], 2776: [4338], 3940: [4340], 2703: [4343], 14900: [4344], 14185: [4345], 4225: [4346], 14876: [4347], 2735: [4348], 2475: [4349], 14086: [4350], 14145: [4351], 14114: [4352], 3915: [4356], 12927: [4357], 14925: [4360], 2489: [4363], 14105: [4364], 1042: [4365], 2333: [4366], 9857: [4368], 13938: [4369], 13904: [4370], 19454: [4371], 6339: [4372], 14050: [4373, 4618], 2905: [4375], 4223: [4376], 2971: [4377], 18714: [4378], 3786: [4379], 2909: [4380], 3115: [4381], 10347: [4382], 2120: [4384], 2966: [4385], 3926: [4387], 4395: [4388], 18630: [4389, 4702], 3904: [4390], 18705: [4391], 2976: [4392, 4395, 4442, 4811, 5149, 5954, 5967, 6104, 6278, 6358, 6403, 6516, 6656, 6670, 6673, 6682, 6684, 6695, 6699, 6713, 6722, 6723, 6734, 6747, 6748, 6761, 6770, 6778, 6787, 6795, 6798, 6809, 6824, 6828, 6834, 6842, 6843, 6847, 6851, 6853, 6858, 6861, 6866, 6900, 6904, 6910, 6916, 6919, 6923, 6926, 6953, 6959, 6963, 6966, 7015, 7068, 7070, 7139], 12955: [4393], 2390: [4394], 1422: [4396], 3018: [4397], 9853: [4398], 16628: [4399], 16603: [4400], 2736: [4401], 3097: [4403, 4729, 5502, 5584, 5816, 5862, 5887, 5888, 5920, 5943, 5999, 6012, 6062, 6077, 6078, 6131, 6186, 6196, 6215, 6256, 6274, 6302, 6309, 6338, 6374, 6416, 6449, 6480, 6485, 6486, 6489, 6491, 6492, 6493, 6497, 6502, 6504, 6510, 6514, 6515, 6523, 6525, 6531, 6532, 6535, 6536, 6537, 6538, 6540, 6543, 6546, 6549, 6560, 6565, 6566, 6568, 6570, 6571, 6585, 6590, 6599, 6600, 6603, 6607, 6625, 6631, 6640, 6644, 6646, 6662, 6666, 6669, 6676, 6678, 6687, 6688, 6691, 6703, 6714, 6742, 6769, 6800, 6830, 6836, 6839, 6840, 6863], 4241: [4405, 7898, 8331, 8333, 8335, 8341, 8375, 8435, 8441, 8444, 8455, 8526, 8527, 8544, 8546, 8562, 8563, 8619, 8620, 8630, 8631, 8696, 8805], 3043: [4406], 2760: [4407], 12961: [4408], 14911: [4409], 3067: [4410], 3071: [4411, 5544], 13929: [4412], 18806: [4413], 14621: [4414], 3905: [4415, 4480, 4496, 4508, 4509], 2960: [4416], 4096: [4417, 8993, 9198, 9334, 9343, 9385, 9405, 9530, 9544], 12926: [4418], 2484: [4419], 14525: [4420], 13924: [4421], 14260: [4422], 14322: [4423], 6792: [4424, 6801, 10280], 19485: [4425], 1781: [4426, 4941, 5144], 9849: [4427], 2341: [4428], 1735: [4429], 4412: [4430], 17678: [4432], 4294: [4433], 3190: [4434], 13559: [4435], 3062: [4436], 9835: [4437], 2572: [4438], 2908: [4439], 2804: [4441], 6293: [4443], 9143: [4444], 3947: [4445], 18647: [4446], 4402: [4447], 14269: [4448], 4637: [4449, 10609], 12856: [4450], 18607: [4452], 19470: [4453], 17793: [4454], 14000: [4455], 2405: [4456], 6654: [4457], 2815: [4458], 18624: [4459], 12860: [4460, 4563], 2733: [4461, 4500], 4421: [4462], 18706: [4463], 3958: [4464], 4663: [4465], 3128: [4466], 17614: [4467], 12933: [4469], 12912: [4470], 9883: [4471], 13568: [4472], 12863: [4474], 13964: [4475], 359: [4476], 1736: [4477], 411: [4478], 14218: [4479], 4790: [4482], 2987: [4483, 5741, 5866, 6152, 6268, 6324, 6679, 6715, 6744, 6799, 6820, 6831, 6846, 6875, 6882, 6889, 6894, 6913, 6924, 6946, 6985], 12959: [4484], 2870: [4485, 4748, 4842, 4861, 4996], 12909: [4486], 3900: [4487, 4552, 4577], 2780: [4488], 2389: [4489, 4519], 13930: [4490, 4555], 6699: [4491], 16397: [4492], 3990: [4494], 15262: [4495], 4328: [4497], 2912: [4498], 3513: [4499], 4320: [4501], 12960: [4502], 2725: [4503], 3025: [4504], 4321: [4505], 13976: [4506], 3906: [4507], 2197: [4511, 4513], 17577: [4512], 2866: [4514], 16619: [4515], 16627: [4516], 3094: [4517], 2817: [4518], 2767: [4520], 17348: [4521], 16468: [4522], 4197: [4523], 2864: [4524, 4630, 4669, 4701], 3941: [4525], 3956: [4526], 17587: [4527], 4575: [4528], 2911: [4529], 14030: [4530], 13557: [4531], 3914: [4532], 16561: [4534], 19327: [4535], 6308: [4536], 9671: [4537], 3061: [4538], 9854: [4539], 6743: [4540, 5409, 8035], 9830: [4541], 6759: [4542, 4904, 6972, 7195, 7726, 7924, 7935, 8007, 8121, 8126, 8164, 8178, 8183, 8244, 8259, 8267, 8280, 8309, 8312, 8394, 8400, 8467, 8498, 8600, 8606, 8668, 8674], 6388: [4543], 3023: [4544, 5507, 7446], 4390: [4546], 2085: [4548], 4327: [4549], 4311: [4550, 10043], 2963: [4551], 12934: [4553], 13981: [4554], 2898: [4556], 14158: [4557], 9708: [4559], 2773: [4560], 14081: [4561], 13117: [4562], 13977: [4564], 517: [4565], 1545: [4566], 1491: [4567], 14003: [4568], 14102: [4569], 14150: [4570], 14046: [4571, 4675], 14149: [4572], 2476: [4573], 1462: [4574], 19556: [4575], 2867: [4578], 4344: [4579], 1750: [4580], 12957: [4581], 12857: [4582], 14152: [4583], 1532: [4584, 4617, 4626], 2570: [4585], 19122: [4586], 13965: [4587], 14065: [4588, 4732], 2743: [4589], 13925: [4590], 14622: [4591], 17605: [4592], 16060: [4593], 7471: [4595], 2473: [4597, 4788], 18640: [4598], 2869: [4599, 4924, 5190], 12951: [4600], 2600: [4601], 4397: [4602], 3002: [4603], 14084: [4604], 14074: [4605], 14098: [4606], 13899: [4607], 14028: [4608, 4657], 2955: [4609], 435: [4610], 4400: [4611], 19314: [4612, 17670, 17682, 17852, 17856, 17899], 2894: [4614], 2574: [4615], 3924: [4616], 14216: [4619], 12956: [4620], 18697: [4621], 3076: [4622], 3159: [4623], 3015: [4624, 5366], 13857: [4625], 2958: [4627], 399: [4628], 18788: [4629], 4418: [4632], 4184: [4633], 4069: [4634], 4525: [4635], 2577: [4638], 19477: [4639], 2936: [4641, 4665], 19092: [4642], 2079: [4643], 2774: [4644], 3875: [4645, 5203], 13968: [4646], 18611: [4647], 14924: [4649], 17633: [4650], 2334: [4651], 14072: [4653], 14509: [4654], 1782: [4656], 16550: [4658], 11106: [4659], 1999: [4660], 3946: [4661], 3889: [4662], 17913: [4664], 3934: [4666], 3901: [4668, 4711], 14125: [4670], 18588: [4671], 2910: [4672, 4789], 1518: [4673], 2474: [4674], 2982: [4677], 9424: [4678], 1472: [4679, 10223, 10459, 10474], 6673: [4680], 15323: [4681], 2948: [4682], 19474: [4683], 408: [4684], 9248: [4685, 12496, 12507, 12518], 10875: [4686], 3968: [4687], 2093: [4689], 2753: [4690], 13931: [4691], 12851: [4692], 1738: [4693], 18817: [4694], 14092: [4695], 2761: [4696], 17955: [4697], 6396: [4698], 4426: [4699], 2873: [4700], 2095: [4703], 14073: [4704], 14096: [4705], 14623: [4706], 18589: [4708], 12917: [4709], 2755: [4710], 18864: [4712], 6158: [4713], 14071: [4714], 2876: [4715], 2618: [4716], 17102: [4717, 36182, 36704], 18684: [4719], 18650: [4720], 14926: [4721], 17723: [4722, 4828], 14619: [4723], 2077: [4724], 13562: [4725], 15246: [4726], 12850: [4727], 2711: [4728, 4755], 2777: [4730], 2900: [4731], 299: [4733], 2598: [4734], 3099: [4735], 2781: [4736], 9185: [4738], 4774: [4739, 8923, 9687, 10328, 10453, 10512, 10519, 10594, 10623, 10684, 10690, 10691, 10714, 10808, 10814, 10892, 10912, 11096], 3931: [4740, 5440, 5467, 5468, 5516, 5517, 5543, 5637], 2715: [4741], 17679: [4742], 3042: [4743], 12928: [4744], 12861: [4745], 15043: [4746], 12854: [4747], 2617: [4749], 14471: [4750], 2601: [4751], 16623: [4752], 19557: [4753], 1655: [4754], 2970: [4756], 9563: [4757], 11142: [4758], 3907: [4759], 14164: [4760, 5040], 2704: [4761], 2957: [4762], 2915: [4763], 17089: [4764], 12947: [4765], 18865: [4769], 6710: [4773], 2557: [4774], 1724: [4775], 14019: [4776, 4875], 18745: [4777], 2934: [4778], 6322: [4779], 14968: [4780], 3068: [4781], 3890: [4782], 3895: [4783], 3122: [4784], 2968: [4785], 2890: [4790], 9889: [4791], 2481: [4792], 2819: [4793, 4852, 4860, 4867, 4891], 13926: [4794], 3123: [4795], 2881: [4797], 18666: [4799], 2754: [4800, 4863, 5243], 9861: [4801], 14066: [4803], 2730: [4804, 4946], 4403: [4805], 9663: [4806], 4050: [4807, 8861, 9196, 9597, 10054, 10135, 10321, 10390, 10516], 17612: [4808], 12852: [4809], 2946: [4810, 4970, 4978], 19478: [4812], 12949: [4813], 3038: [4814], 1772: [4816], 3100: [4817, 5530, 5728, 5767], 13553: [4819], 2471: [4820], 2906: [4822], 13567: [4824], 14973: [4826], 13905: [4827], 3997: [4829], 12862: [4831], 2959: [4832], 2340: [4833], 4695: [4834], 14485: [4838], 14091: [4839], 19475: [4840], 14029: [4841], 3004: [4844], 2868: [4845], 13884: [4846], 17673: [4847], 3975: [4851], 4802: [4853], 2477: [4854], 4185: [4855], 2954: [4856], 4020: [4857], 3978: [4859], 4567: [4862, 12358, 12361, 12454, 12459, 12466, 12562, 12633, 12635, 12645], 14726: [4864], 2897: [4865], 2768: [4866, 5391], 2860: [4869], 14606: [4870], 6777: [4872], 2350: [4873, 4931], 1465: [4874], 11069: [4876], 382: [4877], 6305: [4878], 19406: [4879], 1729: [4881, 4923], 2899: [4883], 14017: [4885], 3916: [4886], 2816: [4888], 14051: [4889], 13927: [4890, 4944], 13555: [4892], 19394: [4893], 2979: [4895], 9669: [4896, 5397], 14153: [4897], 2762: [4898, 5194, 5232], 18419: [4899], 3268: [4900], 4419: [4908], 4006: [4910], 14963: [4913], 4049: [4915, 10523], 18612: [4916], 14896: [4917], 14187: [4918], 12901: [4919], 13858: [4920], 4673: [4921, 11116, 11354], 3021: [4922, 4948, 5172], 3058: [4925, 5924, 6785, 6823, 6878, 6967, 6990, 6991, 7111], 19007: [4927], 9690: [4928], 6752: [4930, 7484, 7606], 9859: [4932], 13861: [4933], 3078: [4934, 5281, 5300], 2901: [4937], 3109: [4939, 5608, 5690, 5835, 5891, 5941, 5957, 5988, 5998, 6106, 6127, 6151, 6157, 6377, 6450, 6473, 6498, 6511, 6528, 6541, 6545, 6548, 6561, 6563, 6577, 6589, 6602, 6671, 6677, 6702, 6716, 6796, 7034], 2097: [4940], 3991: [4947], 14257: [4951], 14106: [4953], 2940: [4954], 18641: [4958], 657: [4959], 432: [4960], 9605: [4961], 16459: [4962], 15247: [4963], 2950: [4968], 4367: [4973], 4322: [4974], 2856: [4979, 5649, 6786], 19388: [4984], 2887: [4985], 2772: [4987], 2941: [4992], 2863: [4993], 2591: [4994], 2944: [4995], 2875: [4998, 5304, 5394, 5523], 10901: [5000, 5212], 9591: [5001, 5604], 3873: [5003], 1734: [5012], 3998: [5015], 4354: [5023], 4168: [5025], 4070: [5027], 2893: [5028], 4027: [5029], 15027: [5030], 2094: [5031], 2951: [5032], 6427: [5036], 19123: [5038], 19488: [5043], 1752: [5044], 9521: [5047], 16467: [5048], 7072: [5049, 10025], 4033: [5052], 4172: [5054], 4169: [5055], 19496: [5056], 19479: [5058, 5109, 5184], 1787: [5061], 16061: [5062], 1771: [5063], 6347: [5064], 14020: [5065], 16981: [5066], 9494: [5067], 3874: [5068], 3896: [5069], 3866: [5070], 17589: [5071], 2949: [5072], 3897: [5073], 1602: [5074, 11296], 13115: [5075], 1792: [5076], 2952: [5077], 830: [5078], 14496: [5079], 19149: [5080], 13994: [5081], 417: [5082], 2381: [5083], 3044: [5084, 5132, 5225], 2749: [5085], 9243: [5086, 8287], 4335: [5087], 18585: [5088], 3045: [5089], 4690: [5090], 1423: [5091], 3910: [5092], 13916: [5093, 5255, 5457], 12962: [5096], 2119: [5097], 14887: [5098], 14796: [5099], 2879: [5100], 14915: [5101], 12925: [5102], 2757: [5104, 5286, 5419], 13917: [5105], 9673: [5106], 14261: [5107], 14266: [5108], 400: [5110], 2892: [5111], 3046: [5112], 15316: [5113], 6778: [5114], 9711: [5115], 7564: [5116, 10977, 14045, 14623, 20793, 21094, 21171, 21191, 21357, 21402, 21417, 21442, 21479, 21508, 21627, 21628, 21630, 21643, 21644, 21649, 21654, 21656, 21657, 21658, 21659, 21663, 21665, 21666, 21667, 21668, 21670, 21672, 21673, 21674, 21675, 21676, 21685, 21692, 21694, 21696, 21697, 21699, 21700, 21701, 21702, 21703, 21706, 21708, 21709, 21712, 21715, 21716, 21717, 21718, 21719, 21722, 21723, 21724, 21726, 21735, 21736, 21743, 21747, 21752, 21753, 21754, 21757, 21761, 21762, 21763, 21764, 21766, 21770, 21773, 21775, 21777, 21779, 21782, 21791, 21795, 21799, 21801, 21806, 21808, 21813, 21814, 21817, 21818, 21822, 21824, 21827, 21831, 21832, 21834, 21837, 21846, 21853, 21860, 21866, 21868, 21874, 21876, 21879, 21882, 21883, 21884, 21885, 21886, 21891, 21892, 21896, 21897, 21899, 21900, 21901, 21902, 21903, 21905, 21907, 21910, 21911, 21915, 21919, 21921, 21922, 21923, 21924, 21925, 21929, 21934, 21935, 22133, 22185], 11100: [5117], 4024: [5118, 5174], 3003: [5119], 15269: [5120], 9858: [5121], 16995: [5122], 12952: [5123], 3121: [5125], 2931: [5126], 17862: [5127], 19374: [5129], 13932: [5130], 2756: [5131], 10682: [5133], 19175: [5134], 7031: [5135], 16074: [5136], 18652: [5137], 6711: [5138], 16413: [5139], 4407: [5141], 4346: [5142], 3994: [5143], 4341: [5145], 4152: [5146], 14916: [5147], 1519: [5148], 3969: [5150], 10868: [5152], 19721: [5153], 1512: [5154], 13971: [5155], 2888: [5156], 18803: [5157], 3008: [5158], 14103: [5159], 13865: [5160], 13966: [5161, 5415], 1460: [5162], 19132: [5163], 368: [5164], 7467: [5165], 469: [5166], 843: [5167], 9615: [5168], 9677: [5169], 4159: [5170], 4253: [5171], 3930: [5173, 5337], 1657: [5175, 6949], 4060: [5176, 8193, 8452, 8532, 8557, 8558, 8621, 8632, 8633, 8646, 8690, 8702, 8703, 8718, 8737, 8770, 8776, 8781], 4167: [5177], 3047: [5178], 12847: [5179], 14901: [5180], 3120: [5181], 14094: [5182], 14624: [5183, 5595], 2925: [5185], 14544: [5187, 5188], 2783: [5189], 3135: [5191], 6730: [5192], 14217: [5193], 4423: [5195], 13920: [5196], 4014: [5197], 4106: [5198, 6637, 7990, 8996, 9148, 9267, 9348, 9401, 9592, 9596, 9659, 9660, 9664, 9679, 9683, 9695, 9768, 9774, 9775, 9776, 9782, 9783, 9785, 9787, 9788, 9793, 9798, 9800, 9812, 9878, 9884, 9885, 9886, 9887, 9889, 9890, 9891, 9904, 9908, 9964, 9967, 9975, 10039, 10058], 3936: [5199], 2920: [5200, 5641, 5775], 3913: [5201], 13961: [5204], 13564: [5205], 2937: [5206], 3117: [5207], 3070: [5209], 14479: [5210], 2886: [5211], 6348: [5213], 17762: [5214], 4154: [5215, 5240], 3992: [5216], 4342: [5217], 15243: [5219], 14267: [5220], 2198: [5221], 14630: [5222], 829: [5223], 2943: [5224, 5545], 1790: [5226], 14093: [5227], 2877: [5229, 5258], 14612: [5230], 19276: [5231, 14406], 1784: [5233, 5282], 2752: [5235, 5257, 5267, 5290, 5379], 6405: [5236], 2972: [5237], 4039: [5238], 1985: [5239], 14918: [5241], 2980: [5242], 15194: [5244], 4003: [5245], 4709: [5246], 6612: [5249], 9491: [5251], 3072: [5252, 5423], 14508: [5253], 14613: [5254], 366: [5259], 19397: [5260], 7076: [5262], 9616: [5263], 6587: [5264], 7061: [5265, 7510, 9105, 9318, 10505, 10581, 10589, 10590, 10681, 10768, 10866, 10874, 10879, 10880, 10979, 10981, 10987, 11071, 11164, 11165, 11243], 13571: [5266], 3075: [5269], 14522: [5270], 17914: [5271], 19753: [5272], 4000: [5273], 3091: [5274], 14781: [5275], 16620: [5276], 2634: [5277], 13829: [5278], 2382: [5279], 1656: [5280], 14608: [5283], 14435: [5284], 2759: [5287], 2594: [5288], 2599: [5289], 9911: [5291, 5465, 5575], 9963: [5292], 12526: [5294], 3999: [5295, 5414, 5519], 3116: [5296], 3993: [5297], 2596: [5298], 13764: [5299], 14917: [5301], 5724: [5302], 2871: [5305], 1433: [5306], 2953: [5307], 2568: [5308], 6754: [5309, 5476, 6386, 7078, 7150, 7584, 7592, 7829, 8006, 8104, 8109, 8117, 8138, 8180, 8253, 8270, 8378, 8380, 8481, 8566], 356: [5310], 6620: [5311], 19396: [5312, 5393], 2889: [5313], 2393: [5314], 292: [5315], 3040: [5317, 5528], 2099: [5318], 4031: [5319], 1778: [5320], 14948: [5323], 14165: [5324], 6681: [5325, 7055, 7324, 8767, 9017, 9081, 9109, 9156, 9244, 9245], 17609: [5327], 14042: [5328], 14609: [5330], 6390: [5331], 14047: [5332], 1447: [5333], 19465: [5334, 5449, 5510, 5622], 1751: [5335], 7758: [5336], 19421: [5338], 3118: [5339], 4787: [5340], 3876: [5341], 2563: [5342], 4173: [5343], 4023: [5344], 3894: [5345], 2316: [5346], 4029: [5347], 9885: [5348], 14265: [5349], 12848: [5350], 19398: [5351], 15055: [5352], 14523: [5353], 917: [5354], 2731: [5355], 19407: [5356], 17739: [5357], 19412: [5358], 3102: [5359, 5512, 5660], 420: [5361], 18654: [5362], 1761: [5363], 4059: [5364, 8616, 8628, 8704, 8710, 8864, 8926, 8932, 9067], 14902: [5367], 14966: [5370], 18633: [5371], 17683: [5373], 3086: [5374], 1455: [5376], 18695: [5377, 9832], 2967: [5378], 9613: [5380], 9606: [5382], 3932: [5383, 5675], 4018: [5384], 4353: [5385], 3995: [5386], 3039: [5387, 5427, 5580], 19727: [5388, 12115], 15276: [5389], 653: [5390], 300: [5392], 10906: [5395, 11959, 12255, 12324, 12512, 12590, 12599, 12749, 12768, 12778, 12800, 12910, 13110, 13129, 13141], 2595: [5396], 3022: [5398], 14535: [5399], 13928: [5400, 5587], 14068: [5401], 13909: [5402, 5720], 2782: [5403], 17956: [5404], 3088: [5405, 5609, 5617, 5646, 5705, 5769, 5787, 5882, 5886, 5899, 5981], 3125: [5407, 6335], 9840: [5408], 6772: [5410], 4001: [5416], 4632: [5417], 12948: [5418], 3168: [5420, 7202, 7354], 2073: [5421], 2747: [5424], 2622: [5425], 18828: [5426], 3041: [5428], 14626: [5429], 9873: [5430], 13914: [5431, 5482], 19437: [5432], 18678: [5433], 360: [5434], 6294: [5435], 6374: [5436], 1471: [5437], 4091: [5438, 9139, 9186, 9253, 9284], 4355: [5439], 4329: [5441], 4182: [5442], 3976: [5444], 4785: [5445], 4119: [5446, 10212, 10260, 10404, 10529, 10615], 19466: [5447], 14097: [5448], 379: [5450], 17753: [5454, 5684], 14104: [5456], 14048: [5458], 19431: [5459], 2938: [5460], 3019: [5461, 5470, 5474, 5485, 5487, 5524], 2472: [5462], 6412: [5463], 9678: [5464], 9592: [5466], 1576: [5469], 19124: [5471], 4325: [5472], 14027: [5473], 9871: [5475], 14101: [5478], 14611: [5479, 5588], 13986: [5480], 14057: [5481], 14396: [5483], 7184: [5486], 19208: [5488], 19423: [5489], 462: [5490], 9488: [5491], 6732: [5492], 12923: [5493], 12953: [5494, 5674], 3864: [5495], 4336: [5496], 13528: [5497], 2923: [5499], 2758: [5500], 473: [5501], 14099: [5503, 5711], 14215: [5504], 3028: [5505, 5618, 7239], 14567: [5506], 13992: [5508], 2883: [5509, 5642], 402: [5513], 1523: [5514], 9955: [5515], 4164: [5521], 2321: [5522], 16931: [5525], 6746: [5531], 2930: [5532, 6601], 13939: [5533], 14069: [5534], 2775: [5535], 2978: [5537], 11101: [5538], 365: [5539], 11066: [5540], 6302: [5541, 6933], 6797: [5542], 4792: [5547], 4330: [5548], 4693: [5549], 4028: [5550], 14100: [5551], 2927: [5552], 4561: [5553], 18613: [5554], 3060: [5555], 3877: [5556], 3106: [5557, 5667], 1463: [5558], 2939: [5559], 3089: [5560], 6314: [5561], 14166: [5562], 2342: [5563], 13839: [5564], 1704: [5566, 5872, 9619, 12146, 12149, 12170, 12269, 12309, 12357, 12397, 12586], 1510: [5567, 5832], 19468: [5568], 2942: [5569], 2880: [5570], 3050: [5571, 5903, 5949, 5980, 6038, 6228, 6484, 6530, 6547, 6594, 6598, 6628, 6632, 6663, 6672, 6704, 6727, 6789, 6977], 1511: [5572, 7706, 7922], 1448: [5573], 9435: [5574], 7080: [5577], 2929: [5578], 2745: [5579], 3933: [5582], 3092: [5583, 5951], 12849: [5586], 3114: [5589], 4972: [5590], 14653: [5591, 21517, 21542, 21552, 21953, 21961, 21972, 21977, 21978, 21984, 21986, 21988, 21989, 21990, 21991, 21993, 21994, 22000, 22001, 22002, 22003, 22005, 22006, 22010, 22011, 22012, 22014, 22016, 22020, 22021, 22025, 22390, 22405, 22419, 22436, 22445], 19126: [5592], 14625: [5593], 2932: [5594], 17349: [5596], 19430: [5597], 9574: [5598], 2619: [5599], 3065: [5600], 19432: [5601], 288: [5602], 367: [5603], 1399: [5605, 5707, 9786, 9815, 9818, 9876, 9877, 9931], 1768: [5606, 5623], 3899: [5607], 3861: [5610], 3104: [5611], 14930: [5613], 17588: [5614], 3014: [5616, 5671, 5706, 5740, 5811], 3095: [5620, 5729], 3017: [5621], 2986: [5624, 7106, 7237], 1051: [5625], 404: [5626], 6756: [5627], 6391: [5628], 9860: [5629], 11960: [5630], 5488: [5631], 6760: [5632, 7165, 7335, 7437, 7595, 8033, 8044, 8174, 8237, 8242, 8247, 8264, 8299, 8387, 8401, 8409, 8427, 8497, 8500, 8586, 8605, 8666, 8836], 4178: [5633], 3948: [5634], 15260: [5635], 4155: [5636], 13765: [5638], 3001: [5639, 5773, 5810], 19415: [5640], 3074: [5643], 18636: [5644], 1461: [5645], 1543: [5647], 4741: [5648], 3119: [5650], 14497: [5652], 13941: [5653], 14603: [5654], 2981: [5655], 1785: [5658], 3096: [5659, 5814], 14021: [5661], 3105: [5662], 419: [5663, 6616], 2969: [5664], 6137: [5665], 14946: [5666], 4171: [5668], 4413: [5670], 14713: [5672], 3872: [5673], 13876: [5677], 2882: [5678], 18808: [5680], 2975: [5681, 5876], 3052: [5682], 14474: [5683], 6585: [5686], 13958: [5687], 18692: [5688], 11104: [5692], 4025: [5693], 1513: [5694], 14082: [5695], 3911: [5696], 4696: [5697], 4177: [5698], 14898: [5699], 4331: [5700], 3942: [5701, 6494], 15471: [5703], 2763: [5704, 5825], 9310: [5708], 9950: [5710], 2921: [5712, 6833, 7044, 7097, 7140, 7264], 14500: [5714], 14616: [5715], 19033: [5716], 2891: [5718], 18649: [5723], 518: [5724], 14912: [5726], 3928: [5727, 5771, 5898], 4030: [5730, 5806], 2104: [5731], 4231: [5732, 8536, 8707, 8774, 8905, 8917, 8990], 4296: [5734], 4151: [5735], 4232: [5738, 9127, 9325], 14913: [5739], 3111: [5742, 5818, 5849, 5877, 5946, 5990], 14246: [5743], 15320: [5744], 13919: [5745], 13918: [5746], 290: [5747], 2878: [5748, 6008], 2842: [5749, 7057, 7274, 7340, 7352, 7598, 7825], 19205: [5753, 6610, 10478, 10548], 6586: [5756], 9561: [5757], 9468: [5758], 9564: [5759], 10924: [5760], 4256: [5763, 5914], 9874: [5768], 19408: [5772], 19720: [5776], 4601: [5777], 9832: [5778], 6313: [5779], 14511: [5780], 18749: [5781], 12929: [5783], 1648: [5784], 1669: [5786], 2837: [5789], 19410: [5790], 16635: [5792], 10363: [5793], 842: [5794], 405: [5795], 249: [5796], 9334: [5797], 17087: [5798], 14892: [5799], 14899: [5800], 4252: [5802], 4037: [5803], 2994: [5807], 4333: [5808], 1262: [5809], 15167: [5812], 2977: [5817], 19747: [5819], 6383: [5822], 14503: [5827, 6002], 18785: [5833], 16456: [5834], 1773: [5836], 18168: [5838], 2821: [5840], 9436: [5843], 8509: [5844], 4179: [5845], 4687: [5846], 4793: [5850], 3882: [5851], 4414: [5853], 2074: [5854], 2317: [5856], 2322: [5859], 3108: [5863], 9872: [5867], 2859: [5875], 2989: [5878], 15331: [5879], 19133: [5883], 6689: [5885], 17489: [5894], 9695: [5895], 16070: [5896], 18643: [5897], 4180: [5904], 13529: [5905], 4192: [5906, 7081, 7463, 7737, 7761, 7770, 7777, 7783, 7799, 7868, 7869, 7870, 7882, 7899, 7940, 7947, 7948, 7950, 7953, 7964, 7971, 8054, 8055, 8066, 8067, 8071, 8072, 8074, 8078, 8084, 8087, 8102, 8191, 8192, 8205, 8209, 8215, 8216, 8330, 8336, 8354, 8359, 8363, 8466], 9430: [5921, 7129, 7304, 7615, 7846, 7930, 7932, 7934, 7936, 7974, 7979, 8041, 8043, 8047, 8048, 8160, 8165, 8167, 8169, 8170, 8171, 8173, 8175, 8176, 8181, 8221, 8233, 8285, 8286, 8288, 8289, 8290, 8292, 8293, 8294, 8295, 8296, 8305, 8306, 8308, 8311, 8313, 8370, 8404, 8412, 8416, 8418, 8419, 8420, 8422, 8423, 8426, 8504, 8506, 8508, 8509, 8510, 8589, 8591, 8595, 8599, 8603, 8607, 8684, 8689, 8764, 8766, 8832, 8900], 14969: [5925], 3087: [5928], 2945: [5932], 3155: [5935], 9597: [5939], 1667: [5944], 310: [5945], 7504: [5948], 3013: [5950], 2822: [5952], 2343: [5955], 2995: [5956], 11102: [5958], 6303: [5959], 4220: [5969, 6737], 471: [5970], 4166: [5972], 4415: [5973], 19511: [5974], 4641: [5975, 11711], 13530: [5978], 14507: [5979], 1041: [5984, 6552], 3090: [5991], 9422: [6005], 19482: [6013], 19207: [6016], 9855: [6017], 5173: [6018], 9495: [6019], 11117: [6020], 4109: [6037], 4038: [6053], 4174: [6055, 6841], 2105: [6056], 3868: [6057], 4635: [6066], 1414: [6073], 13575: [6086], 2990: [6115], 19497: [6118], 2824: [6119], 1780: [6132, 6369, 6862], 14252: [6136], 17873: [6139], 10690: [6142], 13840: [6143], 19473: [6146], 6741: [6147, 9224], 1789: [6161], 1783: [6164], 15938: [6167], 424: [6168, 6782], 9421: [6169], 5031: [6170], 10775: [6171, 7391, 7508, 10313, 10443, 10876, 11339, 12431, 13011, 13365, 13964, 14179, 14310, 14453, 14468, 14635, 14799, 14838, 15120, 15291, 15294, 15440, 15441, 16424, 16449, 17556, 17756, 17964, 18015, 18079, 18170, 18495, 19146, 19165, 19685, 19691, 19701, 19726, 19784, 20208, 20494, 20602, 20617, 20909, 20924, 21121, 21125, 21204, 21382, 21396, 21410, 21413, 21431, 21432, 21443, 21449, 21457, 21497, 21502, 21677, 21690, 21729, 21731, 21759, 21783, 21854, 21858, 21863, 21881, 21889, 21927, 22162, 22177, 22178, 22194, 22200, 22204, 22206, 22208, 22214, 22218, 22220, 22226, 22245, 22251, 22254, 22262, 22275, 22276, 22310, 22318, 22325, 22332, 22349, 22583, 22586, 22605, 22606, 22611, 22615, 22619, 22621, 22624, 22632, 22635, 22638, 22640, 22643, 22645, 22655, 22659, 22681, 22701, 22702, 22710, 22713, 22714, 22724, 22728, 22729, 22733, 22736, 22737, 22749, 22754, 22757, 22778, 22783, 22784, 22792, 22794, 22795, 22804, 22814, 23054, 23064, 23082, 23124, 23130, 23134, 23140, 23143, 23153, 23157, 23163, 23166, 23180, 23193, 23194, 23196, 23197, 23207, 23209, 23215, 23221, 23222, 23229, 23231, 23240, 23241, 23244, 23254, 23255, 23256, 23267, 23278, 23282, 23286, 23290, 23293, 23296, 23297, 23307, 23308, 23311, 23312, 23321, 23442, 23529, 23536, 23538, 23540, 23551, 23558, 23564, 23569, 23578, 23584, 23588, 23593, 23595, 23599, 23601, 23609, 23612, 23614, 23620, 23624, 23625, 23626, 23658, 23661, 23665, 23670, 23681, 23687, 23691, 23693, 23694, 23697, 23714, 23720, 23733, 23735, 23742, 23747, 23752, 23757, 23759, 23763, 23771, 23783, 23793, 23891, 23893, 23903, 23906, 23946, 23951, 23983, 24004, 24040, 24076, 24078, 24091, 24101, 24104, 24108, 24116, 24119, 24121, 24123, 24128, 24129, 24133, 24134, 24138, 24139, 24140, 24142, 24143, 24146, 24148, 24149, 24151, 24154, 24156, 24161, 24166, 24181, 24182, 24183, 24184, 24186, 24194, 24199, 24200, 24204, 24207, 24208, 24209, 24211, 24213, 24218, 24221, 24222, 24225, 24226, 24227, 24228, 24229, 24234, 24241, 24245, 24246, 24248, 24250, 24254, 24261, 24262, 24263, 24264, 24266, 24271, 24277, 24280, 24281, 24283, 24286, 24289, 24290, 24298, 24299, 24301, 24304, 24307, 24312, 24313, 24316, 24317, 24323, 24332, 24336, 24349, 24350, 24352, 24365, 24369, 24370, 24386, 24387, 24389, 24390, 24391, 24392, 24393, 24398, 24408, 24412, 24427, 24441, 24445, 24448, 24450, 24459, 24463, 24465, 24473, 24476, 24481, 24486, 24487, 24491, 24501, 24516, 24523, 24531, 24534, 24535, 24556, 24579, 24585, 24598, 24602, 24627, 24792, 24793, 24797, 24798, 24800, 24806, 24811, 24818, 24821, 24829, 24836, 24850, 24853, 24855, 24858, 24865, 24879, 24884, 24885, 24886, 24889, 24893, 24894, 24895, 24900, 24902, 24903, 24905, 24907, 24909, 24911, 24912, 24914, 24916, 24919, 24921, 24922, 24925, 24926, 24927, 24928, 24929, 24930, 24931, 24932, 24934, 24936, 24937, 24938, 24940, 24941, 24942, 24943, 24946, 24948, 24949, 24950, 24951, 24953, 24954, 24955, 24957, 24958, 24959, 24964, 24965, 24967, 24968, 24969, 24970, 24972, 24973, 24975, 24976, 24977, 24978, 24980, 24982, 24983, 24985, 24987, 24988, 24989, 24991, 24992, 24994, 24996, 24997, 24998, 25000, 25001, 25005, 25006, 25008, 25009, 25010, 25011, 25013, 25015, 25017, 25019, 25020, 25021, 25023, 25024, 25026, 25027, 25028, 25033, 25034, 25035, 25036, 25039, 25040, 25041, 25042, 25043, 25045, 25046, 25047, 25048, 25050, 25051, 25053, 25056, 25057, 25058, 25061, 25062, 25063, 25065, 25067, 25068, 25070, 25073, 25075, 25076, 25078, 25080, 25081, 25082, 25083, 25084, 25085, 25088, 25089, 25090, 25091, 25092, 25093, 25095, 25096, 25097, 25098, 25099, 25100, 25102, 25103, 25104, 25105, 25108, 25110, 25112, 25113, 25114, 25115, 25117, 25118, 25120, 25122, 25123, 25124, 25125, 25126, 25127, 25129, 25130, 25133, 25137, 25140, 25142, 25143, 25144, 25145, 25146, 25147, 25149, 25150, 25151, 25152, 25153, 25155, 25156, 25157, 25161, 25162, 25163, 25164, 25167, 25168, 25169, 25171, 25172, 25173, 25174, 25175, 25176, 25177, 25178, 25181, 25184, 25186, 25192, 25201, 25210, 25225, 25238, 25245, 25248, 25251, 25258, 25264, 25268, 25269, 25271, 25276, 25283, 25290, 25303, 25304, 25312, 25316, 25319, 25331, 25332, 25333, 25335, 25338, 25347, 25357, 25365, 25373, 25374, 25399, 25400, 25406, 25408, 25409, 25666, 25813, 25818, 25854, 25896, 25897, 25903, 25922, 26038, 26071], 4082: [6212, 8780], 4288: [6235], 3604: [6254], 3107: [6255, 6583, 6622, 6630, 6658, 6725, 6790, 6838], 4742: [6279], 4047: [6305, 9425], 4677: [6308], 17610: [6311], 15028: [6323], 4183: [6350], 1466: [6375], 6751: [6393], 14495: [6412], 13812: [6423], 13962: [6424], 14143: [6426], 14247: [6431], 14004: [6435], 250: [6436], 14520: [6438], 3181: [6448], 13922: [6452], 342: [6475], 436: [6476], 6159: [6477], 12243: [6478], 4332: [6487], 14897: [6488, 6874], 4334: [6507], 14947: [6518], 14921: [6524], 17339: [6526], 13573: [6529], 19505: [6542], 13942: [6551], 6705: [6553, 6620], 423: [6558], 1777: [6562], 1786: [6567], 2609: [6572, 8962, 9021, 9072, 9163, 9289, 9353, 9365, 9366], 2748: [6580], 14083: [6584], 1760: [6591], 14040: [6593], 6696: [6596], 15324: [6597], 3066: [6604], 3176: [6611], 3026: [6612], 369: [6615], 757: [6618], 9469: [6619], 9509: [6621], 6821: [6633], 4199: [6634], 4176: [6635], 4005: [6636], 4264: [6638, 6822], 4015: [6639, 7087], 3030: [6642, 7012, 7032, 7037], 4524: [6643], 1591: [6645], 4665: [6648], 4429: [6650], 18634: [6652], 13572: [6653], 4126: [6654], 1732: [6659], 3888: [6661], 3098: [6680, 7033, 7190], 13940: [6690, 7226], 13979: [6696, 6852, 6960], 13819: [6700], 2823: [6701], 15339: [6705], 3133: [6707], 2993: [6709, 7009, 7013, 7019], 18374: [6718], 10345: [6719], 12845: [6721], 2996: [6726, 6815, 6909, 6925, 7042, 7045], 4688: [6738], 3112: [6743, 6964], 18608: [6745], 15281: [6752], 14951: [6754], 2565: [6756], 2895: [6758], 3036: [6763], 3079: [6768, 7359], 13980: [6774], 345: [6779], 13915: [6780], 14502: [6781], 19471: [6783], 1508: [6797], 10440: [6802, 9238], 710: [6803], 11070: [6804], 9833: [6805], 16595: [6806], 4156: [6818], 4160: [6819], 4798: [6827], 1473: [6829], 6697: [6854], 6638: [6857], 309: [6859], 6180: [6860, 13012, 13347, 13379, 13420, 13426, 13433, 13473, 13599, 13600, 13785], 1592: [6864], 16625: [6867], 658: [6868], 327: [6869], 19696: [6870, 7206, 7243, 7288, 7292, 7323], 9632: [6871, 10671], 6410: [6872], 7068: [6873], 2746: [6877], 4204: [6879], 13967: [6881], 4613: [6885, 12627, 12827, 13052], 4013: [6886], 4162: [6887, 7137], 14890: [6888], 1411: [6891, 10206, 10215, 10335, 10339], 3883: [6893], 15021: [6895], 14970: [6896], 13823: [6901], 3929: [6905], 2849: [6908], 17744: [6920], 1168: [6921], 2928: [6922], 1762: [6927], 19413: [6928], 765: [6929], 6740: [6930], 9528: [6931], 9912: [6932], 5734: [6934], 3187: [6935], 4213: [6937, 7306, 7477], 3884: [6938], 4032: [6939], 3031: [6942, 7018, 7149, 7170, 7175, 7194, 7375], 4597: [6943], 4598: [6944], 16622: [6951], 14504: [6955, 7061, 7367], 14510: [6956, 7062], 14436: [6957], 14475: [6958], 15340: [6961], 2998: [6962, 6980, 7016, 7171, 7181, 7228, 7427], 19561: [6968], 17493: [6969], 9478: [6970, 8761, 9310, 9524, 9526, 9638, 9729, 9735, 9756, 9757, 9808, 9842, 9843, 9844, 9847, 9854, 9855, 9856, 9857, 9858, 9863, 9865, 9872, 9874, 9945, 9957, 10021, 10034], 10368: [6973], 10925: [6974], 10375: [6975], 6758: [6976], 4216: [6978], 4691: [6979], 4165: [6981], 4258: [6982], 3129: [6983, 7284, 7418, 7475], 4761: [6984], 4194: [6986], 14478: [6987], 3085: [6988, 6993, 7147, 7290], 17754: [6989], 18632: [6994], 12867: [6996, 7047, 7143], 15278: [6997], 4116: [6998], 3057: [7000, 7141, 7172], 4004: [7001], 15570: [7006], 1621: [7007, 13534], 1297: [7008], 16631: [7011], 16455: [7014, 7439], 2997: [7017, 7120, 7158, 7178, 7185], 2620: [7020], 1514: [7021], 19414: [7022], 18561: [7023], 9419: [7024, 7127], 9686: [7025], 426: [7026], 16013: [7027], 18642: [7028], 14905: [7031], 4175: [7036, 7176, 7260], 3602: [7038], 3973: [7039], 4586: [7040], 4249: [7041], 4143: [7046], 9884: [7048], 14483: [7049], 15270: [7050], 3077: [7051, 8250], 14617: [7052], 14521: [7059], 3353: [7060], 15472: [7065], 2338: [7066], 3048: [7067, 7218], 3083: [7069, 8234], 19404: [7071], 18686: [7072], 421: [7073], 16076: [7074], 10685: [7075], 6662: [7076], 6795: [7077], 17915: [7079], 2992: [7080], 3865: [7082], 4303: [7083], 4111: [7084], 4745: [7085], 4157: [7086], 4105: [7088, 7571, 9780, 9892, 9971, 10046, 10065, 10126], 4012: [7089], 3175: [7090], 13038: [7091], 4238: [7092, 8614, 8617, 8625, 8804, 8847, 9057], 4229: [7094], 3084: [7095, 7246, 7267], 15280: [7096], 3131: [7098, 7188, 7280], 4219: [7099, 7182], 1544: [7101], 14258: [7102], 3126: [7103], 6737: [7104], 2844: [7105, 7329, 7376, 7383, 7411, 7428, 7493, 7497, 7600, 7689, 7721, 7831], 2839: [7107], 645: [7108], 14735: [7109], 14501: [7110], 19728: [7112], 15332: [7113, 7717], 18748: [7114], 13959: [7115], 1478: [7116], 6623: [7117], 14015: [7118], 19506: [7119], 19428: [7122], 2593: [7123], 661: [7125], 9637: [7126], 7669: [7128], 6766: [7130], 15029: [7131], 4088: [7132], 3944: [7133], 3886: [7134], 4228: [7135], 4205: [7136, 7400, 7512, 7526, 7555, 7583, 7624, 7658, 7670, 7746, 7754, 7758, 7763, 7768, 7774, 7778, 7784, 7786, 7788, 7798, 7802, 7848, 7863, 7865, 7874, 7876, 7877, 7879, 7886, 7908, 7946, 7955, 7991, 8093, 8222, 8334, 8351], 4036: [7138], 4726: [7145], 4748: [7146], 2339: [7148], 1528: [7151], 17756: [7152], 19411: [7154], 1741: [7155], 2616: [7156], 14146: [7157], 15325: [7159], 16993: [7160], 1767: [7161], 16982: [7162], 1774: [7163], 2597: [7164], 523: [7166], 9851: [7167], 9190: [7168], 18972: [7169, 14318], 4319: [7173], 4198: [7174, 7221, 7223, 7263], 4493: [7177], 14953: [7179], 3081: [7183], 9311: [7184], 1429: [7187], 6614: [7189], 16557: [7191], 6767: [7192, 7293, 7923, 8159, 8241, 8386, 8398, 8425, 8579, 8741], 1449: [7193], 14012: [7196], 1250: [7197], 17991: [7198], 9956: [7199], 14034: [7200], 6672: [7201], 2820: [7203, 7647, 7691, 7700, 7704, 7715, 7724, 7835], 361: [7204], 6377: [7205], 9617: [7207, 7294], 9641: [7208], 9917: [7209], 11146: [7210], 6678: [7211], 10438: [7212], 11133: [7213], 15257: [7215], 4705: [7216, 8694], 4221: [7217], 4090: [7219, 9262, 9266, 9323, 9337, 9386, 9388, 9394, 9406, 9407, 9460, 9474, 9488], 4729: [7220], 3134: [7222], 4633: [7224], 3170: [7227], 15114: [7229], 3937: [7230], 13891: [7231], 18807: [7232], 3194: [7233], 9691: [7235], 3000: [7236], 13878: [7238], 14476: [7240, 7255, 7370, 7987], 13947: [7241], 13868: [7244], 2851: [7245], 19376: [7247], 3056: [7249, 7270], 433: [7250], 9486: [7251], 9951: [7252], 10446: [7253], 10344: [7254], 14906: [7256], 3059: [7257], 3887: [7259], 2835: [7261], 4016: [7262], 2852: [7265, 7286], 3869: [7266], 14972: [7268], 13813: [7269], 12866: [7271, 7315, 7692, 7807], 12846: [7272], 15229: [7273], 14518: [7276, 8019], 1515: [7277], 14022: [7278], 14041: [7279], 14089: [7281], 14056: [7282], 14517: [7283], 16998: [7285], 2352: [7287], 1739: [7291], 357: [7295], 364: [7296], 19056: [7297], 9924: [7298], 6316: [7299], 7074: [7300], 7523: [7301, 17295, 17919, 18174, 18382, 18384, 18385, 18501, 18656, 18887], 4784: [7307], 14078: [7308], 4203: [7309], 4706: [7310], 14904: [7311, 7421, 7776], 4282: [7313], 1509: [7314], 14545: [7316, 7826], 246: [7317], 13982: [7319, 7486], 14506: [7320, 7590], 13869: [7321], 14519: [7322], 19035: [7325], 17992: [7327], 19171: [7328], 1726: [7330, 7827, 8086, 8144], 10359: [7332], 18655: [7333], 10444: [7334], 6588: [7336], 6924: [7337], 4034: [7338], 3885: [7341], 3938: [7342], 2846: [7343], 1394: [7344], 4250: [7347], 3879: [7350], 4794: [7351], 18635: [7353], 4141: [7355], 14874: [7356], 14054: [7357, 7371, 8022], 2838: [7358, 7369, 7381, 7409, 7430, 7433, 7711, 8031], 19790: [7361], 13815: [7364], 1430: [7365], 391: [7366], 13820: [7368], 14055: [7372], 18407: [7373], 12954: [7374], 1629: [7377, 13766, 13908], 19368: [7378], 14023: [7380], 3167: [7382, 7813, 7834, 8001, 8204, 8495], 3169: [7384], 1434: [7385], 3152: [7386], 9567: [7387, 7388, 7440], 9193: [7389], 320: [7390], 6750: [7392, 8565, 8677], 7075: [7393], 6773: [7394], 18392: [7395], 4202: [7398, 7959, 8053, 8091, 8661], 4207: [7401], 14949: [7402], 15252: [7403], 1392: [7404], 4208: [7405, 8194, 8622], 3881: [7415], 17917: [7416], 17681: [7417], 15233: [7419], 3962: [7420], 4146: [7423, 8515, 8551, 8552, 8559, 8609, 8611, 8612, 8643, 8644, 8652, 8654, 8655, 8656, 8660, 8691, 8693, 8711, 8719, 8720, 8721, 8722, 8726, 8727, 8728, 8730, 8731, 8769, 8786, 8787, 8788, 8789, 8792, 8795, 8798, 8855, 8876, 8907, 8913, 8933, 8934, 8935, 8937, 9000], 15187: [7424], 4113: [7425], 14891: [7426], 2832: [7429], 14026: [7431], 13851: [7432], 10581: [7434], 2579: [7435], 19681: [7438], 9674: [7441], 2843: [7442], 15241: [7444], 13458: [7445], 4786: [7459], 4017: [7461], 4704: [7466], 4287: [7467, 7871], 4694: [7468], 3153: [7473], 4800: [7474], 3862: [7476], 2836: [7479], 6761: [7483, 7702, 7727, 7843, 7925, 7941, 8025, 8039, 8119, 8124, 8186, 8249, 8272, 8276, 8298, 8315, 8410, 8428, 8502, 8503, 8512], 14043: [7485], 14491: [7487], 3053: [7488], 19426: [7489], 1457: [7490], 19472: [7491], 2985: [7492], 2830: [7495, 8950], 1632: [7496], 19448: [7498, 10739, 10740, 10849, 10899, 10947, 10955, 10968, 10973, 10992, 10993, 11030, 11036, 11037, 11042, 11044, 11046, 11117, 11131, 11176, 11203, 11204, 11219, 11292, 11306, 11378, 11487], 19242: [7499, 13435, 13573, 14407], 362: [7500], 6685: [7501], 8485: [7502], 10238: [7504, 31434, 35129, 35345, 35390, 35394, 35489, 36231, 36705], 11112: [7505], 6775: [7506], 9957: [7507], 10917: [7509, 12247, 12436, 12687, 12712, 12789, 12917, 12976, 13015, 13021, 13024, 13028, 13144, 13257], 19386: [7518], 3160: [7520, 8439, 8549, 8564], 4214: [7527, 7529, 7570, 7613, 7651, 7655, 7667, 7735, 7765, 7771, 7772, 7781, 7789, 7801, 7856, 7859, 7866, 7875, 7893, 7962, 7967, 7970, 7976, 8232], 3943: [7545, 8451], 4206: [7548, 7657, 7750, 7759, 7792, 7796, 7961, 7977, 8068, 8206, 8226, 8227, 8454], 4799: [7557], 4299: [7567], 14903: [7572], 1658: [7573], 1590: [7578], 3185: [7582], 6764: [7586], 3166: [7587, 7683, 7685, 7699, 7836, 8094], 14515: [7588], 14505: [7589], 19417: [7593, 8754], 7802: [7597], 3010: [7599, 8574, 8675, 8748], 14058: [7601], 9431: [7602], 9562: [7603], 6392: [7604], 4057: [7609, 7628], 15266: [7618], 15335: [7620], 1757: [7640], 4746: [7663], 4697: [7664], 2983: [7669], 4084: [7677], 12869: [7681], 1253: [7686], 3870: [7687], 4149: [7690], 3082: [7693], 3063: [7696], 1728: [7703, 7722], 14516: [7707], 756: [7709], 13849: [7710], 17813: [7713], 3024: [7714], 9868: [7716], 19375: [7718], 15586: [7719], 2841: [7720, 8871], 3080: [7723], 3029: [7725], 9363: [7728], 10842: [7729], 10419: [7730], 14971: [7736], 4066: [7766], 2614: [7797], 4317: [7800], 14893: [7805], 2635: [7817], 13862: [7818], 856: [7819], 19442: [7820], 2826: [7822, 8747, 8822, 8823, 8824, 8825, 8963, 8964, 8966, 9096], 14498: [7823], 2589: [7824], 14440: [7828], 6187: [7837], 6701: [7839], 12285: [7840, 11326, 11666, 11674, 11767], 8170: [7841], 9839: [7842], 6769: [7844], 11108: [7845], 4343: [7872], 4291: [7892, 11101], 2103: [7894], 4148: [7896], 4244: [7897, 7960, 8326, 8352, 8445, 8447, 8518, 8623, 8624, 8664, 8773], 4067: [7900], 14955: [7902], 4145: [7904], 12868: [7905], 14967: [7906], 18628: [7907], 18829: [7911], 1674: [7914, 11919], 13814: [7915], 13963: [7916], 1393: [7917], 13850: [7918], 14547: [7919], 13879: [7920], 15336: [7921], 6590: [7931], 6796: [7938], 4248: [7949], 4242: [7954], 4304: [7956, 8517, 8538], 4692: [7957], 14895: [7965], 4035: [7966], 1389: [7975, 10165, 10389], 13985: [7978], 15267: [7980], 17922: [7981], 10133: [7983], 2567: [7984], 14628: [7986], 1524: [7988], 3164: [8000, 8103, 8132, 8195, 8391, 8493, 8665, 8890], 6664: [8003], 3054: [8009], 3156: [8012], 1432: [8015], 3184: [8016, 8777], 16593: [8017], 14477: [8020], 14087: [8021], 15317: [8023], 2834: [8027], 2354: [8028], 6655: [8034], 19459: [8037], 6734: [8040], 18350: [8046], 9531: [8050], 12910: [8056], 4276: [8062], 4236: [8063, 8446, 8449, 8522, 8524, 8535, 8543, 8548, 8610, 8629, 8701, 8708, 8712, 8713, 8716, 8771, 8775, 8779], 4092: [8064], 2355: [8073], 14465: [8079], 4783: [8085], 3055: [8092], 12922: [8097], 4577: [8098], 2833: [8099, 8101, 8699], 12870: [8100], 3182: [8107], 3183: [8114, 8388], 15573: [8125], 6683: [8129], 19746: [8133, 8479], 14696: [8134], 14513: [8135, 8395, 8482, 8555, 8560, 8783, 8810, 8862, 8922, 8930, 8943, 9024, 9083, 9152, 9157, 9223], 19083: [8139], 579: [8140], 1396: [8141, 8739, 8806], 3032: [8146], 15337: [8147], 16929: [8148], 13888: [8149], 2612: [8151, 8750, 8755, 8784, 8813, 8818, 8820, 9211], 18169: [8152], 19403: [8153], 1517: [8154], 2827: [8155, 8273, 8494], 10367: [8163, 9037, 9440, 9644, 9653, 10107], 26: [8166], 9493: [8168], 7519: [8177], 7727: [8179], 9565: [8185], 16398: [8187], 10873: [8188], 6161: [8190, 9371], 4475: [8196], 4195: [8197, 8360, 8433, 8529, 8627, 8640, 8714], 4239: [8203, 8214, 8224, 8322, 8327, 8355, 8520, 8521, 8531, 8556, 8662, 8724, 8995], 4085: [8219], 18325: [8228], 4139: [8229], 4140: [8230], 6763: [8238], 13859: [8243], 14035: [8258], 14536: [8260], 2315: [8262, 8373, 8550], 16967: [8266], 19489: [8268], 16633: [8269], 2918: [8271, 10824], 14024: [8274], 14038: [8275], 10843: [8277], 2853: [8278, 8670, 8671], 9836: [8281], 6637: [8283], 9100: [8284, 13582, 16575, 16584, 16606, 16630, 16787, 16796, 16858, 16975, 16976, 16977, 16978, 16979, 16980, 16982, 16983, 16984, 16985, 16987, 16991, 16992, 16995, 16996, 16998, 16999, 17000, 17001, 17003, 17004, 17005, 17006, 17007, 17008, 17009, 17010, 17011, 17012, 17013, 17014, 17015, 17018, 17019, 17020, 17021, 17023, 17025, 17028, 17029, 17030, 17032, 17035, 17036, 17038, 17042, 17043, 17045, 17046, 17047, 17048, 17052, 17059, 17062, 17065, 17066, 17068, 17073, 17074, 17077, 17082, 17088, 17105, 17211, 17245, 17258, 17271, 17316, 17322, 17346, 17499, 17720], 9415: [8300], 9144: [8301], 10421: [8302], 18700: [8316], 12527: [8317], 7274: [8318], 15230: [8323], 15101: [8337], 4701: [8344], 4307: [8353], 4089: [8357, 9412, 9663, 9682, 9697, 9784, 9796], 4315: [8358, 9336, 9528, 9532, 9600, 9779, 9974], 19558: [8361, 12676], 4117: [8364], 4573: [8365], 1541: [8366], 14085: [8367], 12920: [8368], 15256: [8369], 2648: [8371], 3186: [8374], 3154: [8377], 14052: [8379], 4114: [8381], 2326: [8383], 4131: [8384], 1435: [8390], 13824: [8392], 13991: [8396], 1791: [8397], 6148: [8399, 9019], 16632: [8402], 19330: [8403], 1299: [8405, 15875, 16523], 3165: [8408, 8738], 324: [8413], 7645: [8414], 6774: [8415], 9852: [8429], 12871: [8430], 4749: [8431], 14919: [8432], 4737: [8434], 4112: [8437], 4210: [8442], 4309: [8443, 8849, 9049, 9116, 9134, 9256, 9258, 9268, 9286, 9330, 9342, 9344, 9400, 9616, 9686], 4064: [8448, 8539, 8791], 4053: [8450], 4710: [8453], 4769: [8458, 8717, 9674, 11090, 11106, 11182, 11189, 11256, 11259, 11263, 11370, 11437], 4698: [8460], 13830: [8461], 4246: [8463], 12918: [8464], 4318: [8465], 2566: [8468], 1577: [8469], 4212: [8470, 8649], 4707: [8471], 12873: [8472], 4142: [8473], 14962: [8474], 656: [8475], 1525: [8477], 3147: [8480, 8811], 18804: [8484], 15481: [8485], 19125: [8487], 6629: [8488, 10419], 6429: [8489], 2602: [8490], 17745: [8491], 18172: [8492], 6738: [8496], 470: [8499], 9348: [8501, 9450, 10098, 13357, 14628, 14935, 15249, 15280, 15429, 15448, 15549, 15551, 15552, 15556, 15559, 15560, 15563, 15565, 15566, 15570, 15572, 15573, 15576, 15581, 15582, 15583, 15585, 15586, 15590, 15591, 15593, 15598, 15604, 15605, 15616, 15630, 15739, 15752, 15754, 15758, 15769, 15777, 15782, 15910], 329: [8505], 10898: [8507, 12048, 12603, 12622, 12803, 12871, 12876, 12914, 12915, 13147, 13488], 16469: [8511], 8445: [8513], 10878: [8514], 14944: [8523], 15174: [8525], 4533: [8528, 11975], 4300: [8530], 4237: [8534, 8920], 4686: [8537], 4434: [8542], 4086: [8545], 14512: [8547, 8576, 8812], 5531: [8553], 14950: [8554], 4728: [8561], 9638: [8567], 3161: [8568, 8746, 8757], 1935: [8569], 2615: [8570], 19704: [8571, 12096], 13983: [8572], 13978: [8573], 13923: [8575], 3174: [8578, 9136], 3146: [8580], 17957: [8581], 1263: [8582], 1686: [8583], 19405: [8584], 840: [8585], 6736: [8587], 6464: [8588, 10761], 427: [8590], 18691: [8593], 9706: [8594], 10201: [8596, 10314, 13136, 13255, 14149, 16431, 17763, 18125, 18390, 19141, 19147, 19622, 19625, 19629, 19741, 20144, 20194, 20418, 20447, 20681, 21043, 21304, 21371, 21387, 22104, 22493, 22579, 23023, 23458, 23504, 23549, 24993, 25933, 26262, 26298, 26328, 26357, 26394, 26430, 26445, 26452, 26475, 26872, 26879, 26907, 26954, 27112, 27599, 27701, 28200, 28364, 28732, 28740, 28758, 28770, 28841, 28844, 28847, 28873, 28902, 28917, 28921, 28955, 29384, 29425, 29454, 29459, 29487, 29493, 29495, 29509, 29531, 29560, 29609, 29612, 29679, 30898, 31001, 31504, 31506, 31595, 31613, 31625, 31703, 31704, 31708, 31710, 31711, 31754, 32124, 32158, 32210, 32213, 32215, 32216, 32217, 32218, 32219, 32220, 32221, 32222, 32225, 32226, 32227, 32229, 32230, 32231, 32232, 32235, 32238, 32239, 32240, 32242, 32243, 32247, 32248, 32249, 32251, 32254, 32255, 32257, 32258, 32263, 32264, 32266, 32268, 32270, 32272, 32275, 32276, 32277, 32278, 32280, 32281, 32282, 32283, 32284, 32285, 32286, 32287, 32288, 32289, 32290, 32291, 32293, 32294, 32295, 32296, 32297, 32298, 32300, 32301, 32302, 32303, 32304, 32305, 32306, 32307, 32308, 32309, 32312, 32313, 32314, 32315, 32316, 32317, 32318, 32319, 32320, 32321, 32322, 32324, 32325, 32326, 32327, 32328, 32329, 32330, 32332, 32333, 32334, 32335, 32336, 32337, 32338, 32339, 32340, 32341, 32342, 32343, 32345, 32346, 32347, 32349, 32350, 32351, 32352, 32353, 32354, 32355, 32356, 32358, 32359, 32360, 32361, 32362, 32363, 32364, 32365, 32366, 32367, 32368, 32369, 32370, 32371, 32373, 32374, 32375, 32376, 32377, 32378, 32379, 32381, 32382, 32383, 32384, 32385, 32386, 32387, 32388, 32390, 32391, 32393, 32394, 32395, 32396, 32397, 32399, 32400, 32402, 32403, 32404, 32405, 32406, 32407, 32409, 32410, 32411, 32412, 32414, 32415, 32416, 32418, 32419, 32421, 32422, 32423, 32424, 32425, 32426, 32427, 32428, 32429, 32430, 32431, 32432, 32433, 32434, 32436, 32438, 32440, 32443, 32445, 32446, 32447, 32448, 32449, 32450, 32451, 32452, 32455, 32456, 32458, 32459, 32460, 32462, 32463, 32464, 32470, 32471, 32472, 32473, 32475, 32477, 32478, 32479, 32481, 32482, 32484, 32485, 32486, 32487, 32488, 32489, 32490, 32491, 32493, 32496, 32497, 32498, 32499, 32500, 32503, 32505, 32507, 32508, 32509, 32510, 32512, 32513, 32516, 32517, 32519, 32520, 32521, 32523, 32525, 32526, 32527, 32530, 32532, 32535, 32537, 32538, 32539, 32540, 32544, 32548, 32551, 32552, 32554, 32555, 32556, 32557, 32558, 32559, 32560, 32561, 32562, 32563, 32564, 32565, 32567, 32569, 32570, 32571, 32572, 32573, 32577, 32578, 32579, 32580, 32581, 32582, 32583, 32585, 32586, 32590, 32591, 32592, 32593, 32594, 32599, 32600, 32602, 32603, 32605, 32606, 32607, 32611, 32612, 32613, 32614, 32615, 32619, 32620, 32621, 32623, 32624, 32625, 32626, 32627, 32630, 32631, 32633, 32636, 32637, 32638, 32640, 32641, 32642, 32643, 32644, 32645, 32646, 32647, 32648, 32650, 32651, 32652, 32655, 32656, 32658, 32659, 32660, 32663, 32666, 32667, 32670, 32672, 32673, 32674, 32675, 32677, 32679, 32680, 32682, 32683, 32684, 32686, 32687, 32692, 32694, 32695, 32696, 32698, 32700, 32701, 32702, 32705, 32706, 32707, 32708, 32709, 32710, 32711, 32712, 32715, 32716, 32717, 32718, 32720, 32721, 32722, 32723, 32725, 32726, 32727, 32729, 32731, 32733, 32735, 32736, 32737, 32738, 32739, 32740, 32741, 32742, 32743, 32744, 32745, 32746, 32747, 32748, 32749, 32750, 32751, 32753, 32754, 32756, 32757, 32758, 32759, 32760, 32761, 32762, 32763, 32764, 32766, 32767, 32768, 32769, 32770, 32771, 32772, 32773, 32774, 32779, 32781, 32782, 32783, 32785, 32786, 32787, 32789, 32790, 32793, 32794, 32795, 32797, 32798, 32799, 32800, 32801, 32802, 32803, 32804, 32806, 32807, 32808, 32809, 32811, 32813, 32814, 32815, 32817, 32821, 32822, 32823, 32825, 32826, 32828, 32829, 32830, 32831, 32832, 32833, 32834, 32835, 32836, 32837, 32839, 32840, 32841, 32843, 32844, 32845, 32846, 32847, 32848, 32849, 32850, 32852, 32853, 32854, 32855, 32856, 32857, 32858, 32859, 32860, 32861, 32862, 32863, 32864, 32867, 32868, 32870, 32871, 32872, 32874, 32875, 32876, 32877, 32878, 32879, 32880, 32881, 32885, 32886, 32887, 32888, 32889, 32890, 32892, 32893, 32894, 32896, 32897, 32898, 32899, 32900, 32901, 32902, 32903, 32904, 32905, 32906, 32907, 32908, 32909, 32910, 32911, 32912, 32913, 32914, 32915, 32916, 32917, 32918, 32920, 32921, 32922, 32923, 32924, 32925, 32926, 32927, 32929, 32930, 32932, 32933, 32936, 32938, 32939, 32940, 32941, 32943, 32944, 32946, 32947, 32948, 32949, 32951, 32952, 32954, 32955, 32956, 32958, 32959, 32960, 32961, 32963, 32964, 32966, 32967, 32968, 32969, 32970, 32971, 32972, 32973, 32976, 32977, 32978, 32979, 32980, 32981, 32982, 32983, 32984, 32987, 32988, 32989, 32990, 32992, 32993, 32994, 32996, 32997, 32998, 33000, 33001, 33002, 33004, 33005, 33006, 33009, 33010, 33011, 33012, 33014, 33015, 33016, 33017, 33019, 33020, 33021, 33022, 33023, 33024, 33025, 33027, 33028, 33029, 33030, 33032, 33033, 33034, 33035, 33038, 33039, 33040, 33041, 33044, 33046, 33047, 33048, 33049, 33050, 33051, 33054, 33055, 33057, 33059, 33060, 33062, 33064, 33066, 33068, 33069, 33070, 33071, 33072, 33073, 33074, 33075, 33077, 33079, 33080, 33082, 33084, 33085, 33086, 33087, 33088, 33089, 33091, 33093, 33094, 33095, 33096, 33097, 33098, 33100, 33101, 33102, 33103, 33104, 33106, 33107, 33108, 33110, 33111, 33113, 33114, 33115, 33116, 33117, 33118, 33119, 33120, 33121, 33122, 33123, 33124, 33125, 33127, 33129, 33130, 33131, 33132, 33133, 33134, 33137, 33138, 33140, 33141, 33142, 33144, 33145, 33146, 33147, 33149, 33150, 33151, 33153, 33155, 33156, 33158, 33159, 33160, 33161, 33162, 33163, 33164, 33166, 33167, 33168, 33169, 33170, 33172, 33173, 33175, 33176, 33177, 33178, 33179, 33181, 33183, 33184, 33185, 33187, 33188, 33190, 33191, 33193, 33194, 33195, 33196, 33197, 33198, 33201, 33202, 33203, 33204, 33207, 33208, 33209, 33211, 33212, 33213, 33215, 33216, 33217, 33218, 33219, 33221, 33222, 33223, 33224, 33225, 33227, 33228, 33229, 33230, 33231, 33232, 33233, 33234, 33235, 33236, 33238, 33239, 33240, 33241, 33243, 33244, 33245, 33246, 33247, 33248, 33249, 33250, 33251, 33252, 33253, 33254, 33255, 33256, 33258, 33259, 33261, 33262, 33263, 33264, 33265, 33266, 33267, 33269, 33270, 33271, 33273, 33274, 33275, 33276, 33277, 33279, 33280, 33281, 33282, 33283, 33284, 33285, 33286, 33288, 33289, 33292, 33293, 33297, 33298, 33299, 33301, 33307, 33308, 33309, 33310, 33311, 33312, 33313, 33314, 33315, 33316, 33317, 33319, 33320, 33321, 33322, 33324, 33325, 33326, 33327, 33328, 33331, 33332, 33334, 33335, 33336, 33337, 33338, 33339, 33340, 33341, 33342, 33343, 33344, 33345, 33346, 33347, 33348, 33349, 33350, 33351, 33352, 33353, 33354, 33356, 33357, 33358, 33360, 33361, 33362, 33363, 33364, 33365, 33370, 33371, 33373, 33375, 33376, 33377, 33378, 33380, 33381, 33382, 33387, 33388, 33391, 33392, 33394, 33404, 33412, 33414, 33415, 33416, 33419, 33420, 33423, 33425, 33426, 33428, 33429, 33431, 33432, 33440, 33443, 33445, 33446, 33459, 33464, 33467, 33469, 33473, 33477, 33479, 33480, 33484, 33491, 33495, 33498, 33509, 33523, 33526, 33529, 33531, 33534, 33542, 33546, 33549, 33567, 33923, 34433], 9675: [8597], 7868: [8598], 9831: [8601], 6729: [8602], 6700: [8604], 5741: [8608], 4243: [8615, 8735], 17682: [8626], 4275: [8634], 3867: [8635, 8994], 4098: [8636, 9587, 9607, 9609, 9888], 4218: [8637], 4703: [8638], 3939: [8639], 4189: [8642, 8653], 14907: [8645], 4217: [8647], 4777: [8648], 4702: [8650], 3162: [8651, 8669, 8809, 8949], 15189: [8657], 14957: [8658, 8794, 8799, 8938, 8987, 9003, 9011], 15250: [8659], 14064: [8667], 346: [8676], 6749: [8678, 8901], 14032: [8679], 6739: [8680, 8997], 6149: [8681], 295: [8682], 16410: [8683], 9549: [8685], 9420: [8686], 9696: [8687], 11646: [8688], 4572: [8692], 4719: [8695], 4630: [8697], 1412: [8698], 6794: [8700], 4058: [8705, 8782, 8916, 8989], 4648: [8706], 4747: [8715], 12921: [8723], 15108: [8725], 4138: [8729], 4137: [8732, 9062, 9063, 9064, 9135, 9141, 9199, 9206, 9207, 9208, 9215, 9279, 9350, 9354, 9421], 9870: [8733], 2828: [8734, 8816, 8880, 8881, 8885, 8889, 8892, 8942, 8946, 9075], 4278: [8736, 10626], 1746: [8740], 6171: [8742], 2611: [8743], 14549: [8744, 8807], 1436: [8745], 19568: [8749], 1706: [8751, 11814, 11821, 11890, 11900, 11913, 11979, 11980, 11990, 12011, 12017, 12060, 12062, 12075, 12093, 12095, 12100, 12101, 12110, 12112, 12113, 12116, 12117, 12147, 12150, 12162, 12182, 12198, 12203, 12275, 12296, 12305, 12383, 12468, 12481], 1644: [8752, 10456, 12181, 12864, 13074, 13209, 13345, 13429, 13434, 13529, 13626, 13631, 13650, 13679, 13770, 13772, 13774, 13778, 13791, 13799, 13853, 13856, 13858, 13859, 13860, 13863, 13864, 13865, 13872, 13873, 13874, 13875, 13885, 13887, 13888, 13891, 13896, 13897, 13907, 13909, 14005, 14121], 2325: [8753], 1261: [8756], 1668: [8758], 1424: [8759], 344: [8762], 9121: [8763], 6559: [8765], 14937: [8768], 4193: [8772], 14952: [8785, 9009], 4188: [8793, 8860], 13984: [8796, 8953], 4133: [8797, 10208], 1688: [8800], 4144: [8801, 8858, 8875, 8906, 8936, 9069, 9070, 9071, 9074, 9142], 15249: [8802], 15204: [8803], 3173: [8808], 14395: [8815], 18791: [8817], 14438: [8819], 9699: [8821], 6703: [8826, 8981, 9079, 9080, 9088, 9174], 19476: [8827], 18973: [8829], 9222: [8830], 9503: [8831], 9679: [8833], 9418: [8834, 9108, 9229, 9230, 9248, 9308, 9312, 9374, 9381], 758: [8835], 9533: [8837], 7021: [8838], 4776: [8839, 9059, 9146, 10048, 10263, 10329, 10388, 10396, 10507, 10513, 10514, 10592, 10685, 10687, 10694, 10699, 10701, 10774, 10780, 10784, 10786, 10787, 10788, 10789, 10791, 10794, 10795, 10796, 10797, 10801, 10802, 10803, 10805, 10806, 10811, 10812, 10813, 10815, 10821, 10827, 10828, 10834, 10838, 10840, 10883, 10885, 10886, 10891, 10893, 10895, 10900, 10905, 10911, 10916, 10918, 10920, 10923, 10925, 10928, 10930, 10938, 10990, 10995, 10996, 11002, 11004, 11100, 11172, 11178], 19457: [8840], 4062: [8841, 9115, 9117, 9118], 4711: [8842], 4313: [8843, 9329, 9529, 9557, 9778], 1793: [8844], 4642: [8845, 11976, 12265, 12348, 12375, 12552], 4735: [8846], 4302: [8848, 8908, 8924, 8983, 9015], 4781: [8852, 9467, 9777, 10133, 10336, 10451, 10598, 10703, 10819, 10820, 10914, 11008, 11010, 11103, 11267], 4240: [8854], 4795: [8856], 4308: [8857, 9880], 1413: [8859], 15109: [8863], 14927: [8865], 2564: [8866], 9416: [8867], 15191: [8868], 14783: [8869], 1637: [8870, 13532, 13648, 13893, 13916, 13994, 14010, 14017], 13569: [8872], 4730: [8873], 3027: [8874], 7185: [8878], 1867: [8879, 12951], 13825: [8882], 13987: [8883], 1156: [8884, 15198], 6449: [8886], 15277: [8887], 6143: [8888], 1417: [8891], 17978: [8893], 18693: [8894], 19429: [8895], 14039: [8896], 331: [8897], 9428: [8898, 8970, 9041, 9100], 9496: [8902], 10436: [8903], 10945: [8904], 4009: [8911], 3163: [8912], 4078: [8914, 9054, 9249, 9390, 9478, 9558, 9699], 4247: [8915], 4043: [8918], 4081: [8919, 8982, 8991, 9046, 9050, 9068, 9073, 9190, 9254, 9347, 9352], 4750: [8921], 4110: [8925], 3130: [8927, 9252, 9297], 4087: [8928], 4684: [8929], 3871: [8931], 14526: [8939], 2984: [8940], 14345: [8941], 14546: [8944], 1879: [8945], 2855: [8947], 6731: [8948], 19427: [8951], 14514: [8952, 9092, 9293, 9431], 13908: [8954], 13960: [8955], 14492: [8956], 6306: [8957], 1730: [8959], 3011: [8960], 16822: [8961], 2831: [8965, 9145], 1419: [8967], 6768: [8968], 9485: [8969], 9203: [8971, 12772, 13135, 13490, 13829, 13931], 6618: [8973], 9101: [8974], 9837: [8975], 6707: [8976], 9405: [8977], 6793: [8978], 12274: [8979], 17672: [8980], 4079: [8984, 9045, 9053, 9112, 9113, 9114, 9133, 9182, 9183, 9197, 9203, 9250, 9251, 9257, 9259, 9273, 9402, 9413, 9461], 4640: [8986], 9432: [8988], 4233: [8992, 9123], 4301: [9002, 9462], 9465: [9004], 15517: [9005], 4136: [9006, 9200], 4574: [9007], 15251: [9008], 15102: [9010], 1415: [9012], 15188: [9013], 19718: [9014], 2580: [9018], 13818: [9020], 6323: [9023], 14702: [9025], 13913: [9026, 9086], 13847: [9027], 6682: [9028], 1727: [9029], 3124: [9030], 2642: [9031, 10320, 10354], 2585: [9032], 1660: [9033], 3847: [9034], 10474: [9035, 9635], 13880: [9036], 9505: [9038, 11316, 11317, 11319, 11405, 11490, 11493, 11506, 11583], 9522: [9039], 16558: [9040], 6726: [9042], 7627: [9043], 9460: [9044], 4041: [9047, 9129, 9274, 9331], 4310: [9048], 3484: [9055], 4306: [9056], 4727: [9058], 4752: [9060], 4506: [9061, 13752, 13854, 13857, 14097], 4435: [9065], 1630: [9066], 4134: [9076], 858: [9077], 6747: [9078], 6660: [9082, 10246, 10946], 849: [9084], 2854: [9085, 9359], 3438: [9087], 4797: [9089], 14703: [9090], 14530: [9091], 2848: [9093], 14577: [9094], 11139: [9095], 16898: [9097], 16066: [9098], 457: [9099], 9473: [9101], 371: [9102], 7147: [9103], 6384: [9104], 6589: [9106], 9659: [9107], 12309: [9110], 10374: [9111], 1438: [9119], 4273: [9120], 4077: [9124, 9189, 9333, 9339], 343: [9126], 4099: [9128, 9191, 9194, 9459, 9471, 9547, 9588, 9603, 9667], 3506: [9131], 3544: [9137], 14538: [9138], 15244: [9140], 15179: [9143], 14894: [9144], 4576: [9147], 4622: [9149], 1468: [9150, 11279], 15628: [9151], 1427: [9153, 9389], 3132: [9154], 13816: [9155], 11092: [9158], 15477: [9159], 19443: [9160], 468: [9161], 1479: [9162], 1398: [9164], 6698: [9165], 2644: [9166], 6806: [9167], 13969: [9168], 19562: [9170], 9307: [9171], 325: [9172], 472: [9173], 6223: [9175, 13530, 13876, 13890, 13920, 14189, 14534, 14872, 14882, 14891, 14892, 15045, 15052, 15083, 15131, 15133, 15191, 15204, 15207, 15208, 15211, 15232, 15363], 9703: [9176], 9635: [9177], 6450: [9178], 17219: [9179], 5828: [9180, 15317, 15821, 15988, 16143, 16307], 4097: [9187, 9320], 1439: [9188], 4661: [9193], 14928: [9201], 4714: [9202, 9963, 9970, 10045, 10116, 10249, 10257, 10326], 4503: [9204, 9275, 9804, 10037, 12148, 13160, 13281], 18324: [9205], 1418: [9209], 4054: [9210, 9550, 9613], 4699: [9212, 9556], 4262: [9213], 2318: [9214], 15494: [9216], 13988: [9217], 13848: [9218], 1723: [9219], 2857: [9220], 251: [9221], 18789: [9222], 14568: [9225], 9433: [9226], 19499: [9227, 9629], 1395: [9228], 18176: [9231], 9489: [9232], 6733: [9233], 296: [9234], 1814: [9235], 6665: [9237], 9692: [9239], 17163: [9240], 19748: [9241], 9715: [9242], 7171: [9243], 6380: [9246], 12139: [9247, 19001], 14959: [9260], 19039: [9261], 4272: [9263, 9595, 9769, 9770, 9966, 9982, 10038, 10059], 4685: [9265], 4754: [9269], 4046: [9270, 9335, 9398, 9489, 9537, 9585], 3144: [9271], 4611: [9272, 13161], 3178: [9276], 4186: [9277], 240: [9278], 9434: [9280], 293: [9281], 14936: [9282], 4118: [9283, 9476, 9543, 9548, 9608, 9681, 9688, 9689, 9803, 10073], 19719: [9285], 4147: [9287], 247: [9288], 1516: [9290], 16820: [9291], 3149: [9292, 9303], 1713: [9294], 19131: [9295], 13843: [9296], 13844: [9298], 10076: [9299], 3787: [9300], 1765: [9301], 13860: [9302], 19697: [9304], 9206: [9306, 14425, 14770], 378: [9307], 248: [9309], 9189: [9311], 9225: [9313], 6641: [9314], 6610: [9315], 7032: [9316], 11134: [9317], 4712: [9322], 4305: [9338, 9396, 9527, 9545, 9771, 9773, 9881, 9882], 4775: [9340, 10593], 4773: [9345, 10387, 10908, 10909, 10910, 11099, 11255, 11260, 11349], 4259: [9346, 10123], 4230: [9349, 9534], 14875: [9351], 4187: [9355], 4190: [9356], 2587: [9357, 10078, 10157, 10161, 10344], 6633: [9358, 9618], 14533: [9360], 6748: [9361], 13882: [9362], 19494: [9363], 1431: [9364], 1402: [9367], 762: [9368], 516: [9369], 596: [9370], 10370: [9372], 17241: [9375], 9376: [9376], 10102: [9377], 10281: [9378], 9634: [9379], 6735: [9380], 17164: [9382], 14025: [9383], 4234: [9391], 4061: [9392, 9541, 9894], 14929: [9393], 4010: [9395], 4045: [9397, 10124], 4314: [9399, 9468, 9470, 9472, 9589], 4757: [9403], 4715: [9404, 9599, 9903, 9962, 10041, 10132, 10196, 10202, 10250], 15254: [9408], 4664: [9410], 14782: [9411], 4281: [9414], 2613: [9415], 18629: [9416], 4562: [9417], 13574: [9418], 4135: [9419, 9542, 9691], 18863: [9420], 14587: [9422], 4150: [9423], 4274: [9424], 12294: [9426], 17749: [9427], 2658: [9428], 13817: [9429], 6704: [9430, 10013], 841: [9432], 9953: [9433], 766: [9434], 1711: [9435], 6226: [9436], 19433: [9437, 10009], 6634: [9438], 9971: [9439], 7628: [9441], 853: [9442], 10342: [9443], 244: [9445], 9118: [9446, 16251, 16407], 9474: [9447], 6636: [9448], 9124: [9449], 486: [9451, 12173], 6626: [9452], 18694: [9453], 11143: [9454], 18667: [9455], 7305: [9456, 19706], 8812: [9457], 11072: [9458], 2663: [9464], 4316: [9465], 4504: [9466], 4042: [9469], 4560: [9473], 3179: [9475], 4738: [9477], 4485: [9479], 4011: [9480], 4123: [9481, 10262], 3143: [9483, 10074], 14960: [9484], 14958: [9485, 9553, 10137], 15242: [9486], 19490: [9487], 4280: [9490, 10272], 17090: [9491], 328: [9492], 4191: [9493], 297: [9494], 1454: [9495], 1721: [9496], 13841: [9497, 9922], 19510: [9498], 17695: [9499], 3177: [9500], 1654: [9501], 15328: [9502], 1666: [9503], 1086: [9504], 15376: [9505], 1613: [9506, 15050, 15176], 1391: [9507], 3142: [9508], 3180: [9509], 13885: [9510], 18536: [9511], 6426: [9512], 6160: [9513], 437: [9514], 9425: [9515], 9429: [9516], 9417: [9517], 10448: [9518, 9758, 12679, 13242, 13454, 13463, 13477], 9544: [9519], 10323: [9520, 10556, 12328, 12417, 12906, 14566, 15082, 15090, 15248, 15901, 16057, 16362, 16409, 16551, 16580, 16625, 17269, 17519, 17702, 17703, 17716, 18124, 18136, 18137, 18430, 18610, 18837, 18844, 18919, 19080, 19112, 19390, 19395, 19405, 19619, 19623, 19627, 19630, 19646, 19648, 19659, 19675, 19703, 19852, 19873, 19874, 19875, 19876, 19878, 19879, 19880, 19881, 19882, 19883, 19884, 19885, 19886, 19887, 19889, 19890, 19891, 19896, 19899, 19900, 19901, 19902, 19903, 19906, 19908, 19909, 19910, 19911, 19913, 19914, 19915, 19917, 19918, 19919, 19920, 19921, 19922, 19923, 19924, 19925, 19926, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935, 19936, 19937, 19938, 19939, 19940, 19941, 19942, 19943, 19944, 19945, 19946, 19947, 19948, 19949, 19950, 19951, 19952, 19953, 19954, 19955, 19956, 19957, 19958, 19959, 19960, 19961, 19963, 19964, 19965, 19966, 19967, 19968, 19969, 19970, 19971, 19972, 19973, 19974, 19975, 19976, 19978, 19981, 19982, 19985, 19986, 19988, 19990, 19991, 19992, 19993, 19994, 19995, 19999, 20000, 20001, 20002, 20004, 20006, 20007, 20008, 20009, 20010, 20013, 20014, 20016, 20018, 20019, 20020, 20021, 20022, 20023, 20024, 20025, 20026, 20027, 20028, 20031, 20033, 20034, 20035, 20036, 20037, 20038, 20039, 20041, 20042, 20043, 20045, 20046, 20047, 20048, 20050, 20051, 20053, 20054, 20057, 20058, 20059, 20063, 20064, 20065, 20066, 20067, 20068, 20069, 20070, 20072, 20073, 20074, 20075, 20076, 20077, 20084, 20085, 20086, 20088, 20091, 20092, 20094, 20096, 20098, 20099, 20102, 20103, 20105, 20109, 20110, 20111, 20112, 20114, 20117, 20119, 20124, 20127, 20129, 20131, 20132, 20134, 20135, 20136, 20137, 20138, 20139, 20140, 20142, 20143, 20145, 20146, 20148, 20150, 20152, 20153, 20154, 20155, 20156, 20160, 20161, 20162, 20163, 20164, 20167, 20170, 20172, 20173, 20174, 20177, 20180, 20181, 20182, 20183, 20184, 20185, 20188, 20189, 20190, 20192, 20195, 20197, 20199, 20200, 20201, 20202, 20204, 20207, 20210, 20211, 20212, 20391, 20394, 20397, 20398, 20400, 20402, 20405, 20410, 20417, 20419, 20426, 20427, 20438, 20448, 20459, 20469, 20476, 20479, 20480, 20487, 20503, 20504, 20505, 20511, 20513, 20525, 20545, 20728, 20777, 20834], 10431: [9521], 10468: [9523], 10869: [9525], 4658: [9531, 10782, 11098, 11428], 4055: [9533], 4720: [9535], 4500: [9536], 19647: [9538], 4662: [9539], 4603: [9540, 10052], 4636: [9546], 3507: [9549], 4578: [9551], 14938: [9552], 15192: [9554], 14961: [9555], 17979: [9559], 3148: [9560, 9612, 9704, 9705, 9819, 9895, 9916, 9919, 9995], 1871: [9561, 10625, 10719], 2664: [9562, 11881, 11894], 6617: [9563, 9632], 5030: [9564], 17757: [9565], 3145: [9566], 6817: [9567, 11550, 11732], 6307: [9568], 1068: [9569], 1588: [9570], 1403: [9571], 3151: [9572], 9913: [9574], 604: [9575], 6771: [9576], 16418: [9577], 9518: [9578, 10238], 17789: [9579], 10365: [9580, 9849], 6770: [9581], 18644: [9582], 10858: [9583, 13298, 13455, 13457, 13562, 13595, 13604, 13612, 13740, 13840, 13842, 13967], 5772: [9584], 1593: [9586], 4263: [9590], 4094: [9591, 9790, 9791, 9816, 9976, 10130, 10194, 10195], 4751: [9593], 4733: [9594, 10036, 10125, 10198, 10199, 10254, 10270, 10331, 10333], 4724: [9598, 10056, 10204, 10253, 10255, 10322, 10337, 10386, 10394, 10448, 10520, 10525, 10602], 4780: [9601, 10115, 10332, 10392, 10775, 10785, 10790, 10817, 10818, 10884, 10887, 10888, 10889, 10897, 10898, 10906, 10907, 10913, 10926, 10991, 10998, 11000, 11006, 11014, 11016, 11017, 11023, 11181, 11443], 4266: [9602, 9675, 9766, 10200, 10256], 4595: [9604], 19436: [9605], 19564: [9606], 4539: [9610], 3419: [9611], 1241: [9614], 4596: [9615], 1714: [9617], 14631: [9620], 13856: [9621, 9622, 9994], 1166: [9623], 14480: [9624], 857: [9625], 2610: [9626], 16895: [9627], 1390: [9628], 3064: [9630], 2649: [9631], 9846: [9633], 6810: [9634], 10986: [9637], 9427: [9645, 9650], 7859: [9649, 10638, 11415, 11507, 12438, 14188, 14443, 14796, 14966, 15631, 15768, 16149, 16262, 16481, 17522, 17724, 18231, 18437, 18948, 19708, 20087, 20471, 20725, 20801, 20891, 21661, 21880, 22535, 22612, 22613, 22698, 22766, 22768, 22791, 23048, 23108, 23160, 23170, 23220, 23228, 23253, 23257, 23269, 23439, 23513, 23515, 23528, 23544, 23582, 23597, 23635, 23652, 23683, 23719, 23738, 23741, 23746, 23761, 23765, 23895, 23922, 23929, 23931, 23942, 23960, 23965, 23976, 23986, 23992, 23993, 23994, 23996, 23998, 23999, 24000, 24001, 24003, 24008, 24009, 24010, 24012, 24013, 24015, 24016, 24018, 24019, 24020, 24021, 24023, 24024, 24025, 24027, 24028, 24029, 24030, 24033, 24035, 24038, 24041, 24042, 24043, 24045, 24046, 24047, 24048, 24049, 24050, 24051, 24052, 24054, 24058, 24060, 24062, 24063, 24064, 24065, 24067, 24068, 24069, 24071, 24074, 24075, 24077, 24079, 24080, 24081, 24085, 24086, 24093, 24094, 24100, 24106, 24110, 24112, 24114, 24115, 24117, 24118, 24124, 24135, 24141, 24144, 24145, 24153, 24155, 24157, 24159, 24165, 24176, 24178, 24180, 24185, 24187, 24189, 24195, 24197, 24201, 24202, 24203, 24220, 24232, 24243, 24253, 24258, 24260, 24268, 24272, 24273, 24278, 24279, 24291, 24292, 24294, 24295, 24302, 24306, 24309, 24311, 24319, 24325, 24333, 24337, 24338, 24339, 24341, 24342, 24343, 24344, 24347, 24348, 24351, 24353, 24355, 24356, 24364, 24366, 24371, 24375, 24377, 24378, 24381, 24385, 24388, 24394, 24395, 24400, 24401, 24406, 24410, 24413, 24415, 24419, 24420, 24421, 24425, 24432, 24435, 24440, 24442, 24446, 24451, 24453, 24455, 24460, 24461, 24462, 24464, 24466, 24467, 24468, 24469, 24470, 24474, 24477, 24479, 24489, 24492, 24494, 24495, 24497, 24498, 24502, 24504, 24505, 24506, 24507, 24508, 24509, 24511, 24512, 24514, 24517, 24518, 24519, 24520, 24521, 24522, 24524, 24525, 24526, 24529, 24533, 24536, 24539, 24540, 24542, 24543, 24546, 24548, 24552, 24554, 24555, 24559, 24561, 24562, 24565, 24567, 24568, 24569, 24570, 24571, 24576, 24578, 24580, 24581, 24584, 24586, 24588, 24589, 24590, 24591, 24593, 24594, 24600, 24601, 24603, 24607, 24608, 24609, 24610, 24613, 24614, 24617, 24618, 24622, 24625, 25395, 25737, 26104], 9196: [9654], 9640: [9655], 9386: [9656], 10788: [9657], 10671: [9658], 14787: [9661], 17340: [9662], 4051: [9665], 1583: [9666], 4103: [9668, 9781], 4753: [9669], 4716: [9670], 4269: [9671, 10035, 10397], 3945: [9672], 4740: [9673], 4271: [9676, 10334], 4743: [9677], 1426: [9678, 10465], 4052: [9680], 19456: [9685], 14908: [9690], 1504: [9692], 15022: [9693, 9810], 15030: [9694], 2606: [9696], 16616: [9698], 15547: [9700, 20677, 21006, 21267], 1691: [9701], 1880: [9702], 14472: [9703], 1477: [9706], 1458: [9707], 1425: [9708, 10410], 6691: [9709], 2588: [9710], 17751: [9711, 10085], 429: [9712], 3150: [9713, 10361], 2919: [9714], 2607: [9715], 1579: [9716], 1600: [9717], 18689: [9720], 10844: [9726], 422: [9730], 8166: [9740], 9516: [9742], 8488: [9747], 9568: [9748], 11107: [9752, 9860], 10455: [9759], 11723: [9760, 18444, 18706, 18709, 18942, 18957, 18969, 19489], 16551: [9761], 12674: [9762, 16879, 17381], 9481: [9764], 5738: [9765], 1486: [9767], 4713: [9772], 4650: [9789], 4762: [9792], 2653: [9794], 4104: [9799, 10057], 4075: [9801], 4768: [9802], 4739: [9805], 4124: [9806, 9813, 9978], 1775: [9807, 9965], 15259: [9809], 15227: [9811], 4484: [9814], 15583: [9817], 27: [9820], 14537: [9821, 9823], 14088: [9822], 1670: [9824], 2645: [9825], 6670: [9826, 10008], 14600: [9827], 782: [9828, 9838], 6598: [9829], 1404: [9830], 6692: [9831], 1397: [9833], 2640: [9834, 10225], 1409: [9835, 9909], 19439: [9836], 19453: [9837], 336: [9839], 10441: [9840], 9076: [9841, 14267, 17738, 17903, 17981, 18394], 264: [9846], 15751: [9850], 9499: [9853], 9414: [9862, 10174], 307: [9864], 6393: [9866], 837: [9867], 9542: [9868], 10081: [9870], 9566: [9871], 7062: [9873, 10244, 10445, 10492, 10500, 10587, 10650, 10657, 10672, 10679, 10771, 10867, 11153], 12432: [9875], 1685: [9879], 15178: [9883, 9906], 4235: [9893], 4251: [9896], 4638: [9898, 10400], 1689: [9899], 3255: [9900], 4283: [9901], 15124: [9902], 15180: [9905], 1747: [9907], 3256: [9910], 4744: [9911], 4512: [9912], 13846: [9913], 13989: [9914], 5008: [9915, 16727, 16739, 16741, 16795, 17458], 340: [9917], 3386: [9918], 13990: [9920], 1857: [9923], 487: [9924], 18814: [9925], 2662: [9926], 563: [9927], 19508: [9928], 19507: [9929], 2581: [9930], 2608: [9932], 2603: [9933, 10004], 8810: [9934], 19441: [9935], 18562: [9936], 6676: [9937], 9475: [9940, 10175, 10376], 16548: [9943], 17982: [9946], 9224: [9948], 6214: [9949, 12311], 18420: [9950], 9178: [9951, 14810, 15775], 6609: [9952], 9545: [9953], 12519: [9954], 12672: [9955], 11094: [9956], 8467: [9958], 7173: [9959], 4071: [9960, 10146], 14935: [9961], 4652: [9968, 10510, 10607], 4295: [9969], 4732: [9972], 4731: [9973, 10055, 10122, 10127], 1420: [9977], 14797: [9979], 16396: [9980], 4796: [9981], 15255: [9983], 15258: [9984], 4616: [9985], 4552: [9986], 4125: [9987], 19440: [9988], 6645: [9989], 19695: [9990, 10006], 2638: [9992], 14529: [9993, 10287], 1753: [9996], 319: [9997], 15343: [9998], 6448: [9999], 16624: [10000], 19444: [10002], 838: [10003], 17930: [10005], 19509: [10007], 17791: [10010], 1580: [10011], 6446: [10012], 10897: [10014, 13122, 13137, 13268, 13390], 11141: [10015], 243: [10016], 16071: [10017], 9620: [10018, 10026], 10294: [10019], 10877: [10022], 19523: [10023], 9546: [10024], 4873: [10027, 36034, 36243, 36343, 36688, 36733], 7300: [10028], 7134: [10029], 10390: [10030], 7071: [10031, 10439], 5773: [10032, 12540, 14087, 14477, 14481, 14485, 14486, 14487, 14616, 14643, 15010], 12667: [10033, 17352], 4649: [10040], 4265: [10042, 10136, 10203, 10325], 15016: [10044], 1547: [10047], 4293: [10049, 10117, 10188], 4722: [10050, 10605], 4653: [10051], 4667: [10053], 15193: [10060], 4122: [10061, 10112, 10189, 10205], 16404: [10062], 4100: [10063], 4074: [10064, 10340], 15177: [10066, 10141, 10341], 12872: [10067], 13826: [10068], 15273: [10069], 15228: [10070], 17803: [10071], 4279: [10072], 14481: [10076], 19451: [10079], 1575: [10080], 2647: [10081], 13834: [10082], 19434: [10083, 10859], 14457: [10084], 9820: [10086], 9954: [10087], 3138: [10088], 18068: [10089], 1564: [10090, 13082, 15035, 15212], 2646: [10091], 1766: [10092], 353: [10093], 6822: [10094], 10863: [10096], 28: [10097], 10248: [10099, 19103, 21339, 23577, 26901, 27004, 28871, 29392, 30767, 30833, 31483, 31511, 32502, 32545, 32934, 33090, 33206, 33302, 33941, 33943, 33944, 33945, 33946, 33947, 33948, 33950, 33952, 33953, 33956, 33959, 33960, 33961, 33962, 33963, 33964, 33966, 33969, 33970, 33971, 33973, 33974, 33979, 33980, 33981, 33982, 33983, 33984, 33985, 33987, 33989, 33990, 33991, 33992, 33994, 33995, 33996, 33998, 33999, 34001, 34003, 34004, 34005, 34006, 34008, 34009, 34011, 34013, 34020, 34023, 34024, 34025, 34027, 34032, 34033, 34036, 34037, 34038, 34040, 34044, 34045, 34046, 34047, 34049, 34050, 34051, 34052, 34054, 34055, 34057, 34059, 34064, 34071, 34073, 34074, 34075, 34076, 34078, 34080, 34085, 34086, 34087, 34090, 34093, 34094, 34096, 34097, 34099, 34101, 34103, 34104, 34105, 34106, 34108, 34109, 34110, 34111, 34113, 34115, 34116, 34117, 34118, 34119, 34120, 34136, 34140, 34147, 34149, 34151, 34160, 34164, 34166, 34183, 34189, 34194, 34201, 34202, 34213, 34214, 34216, 34223, 34224, 34228, 34231, 34232, 34234, 34236, 34238, 34239, 34240, 34241, 34246, 34248, 34251, 34253, 34255, 34259, 34264, 34266, 34267, 34268, 34271, 34273, 34275, 34278, 34279, 34281, 34286, 34287, 34295, 34297, 34299, 34300, 34306, 34311, 34314, 34319, 34320, 34322, 34323, 34327, 34332, 34334, 34339, 34342, 34343, 34344, 34345, 34346, 34348, 34352, 34355, 34357, 34365, 34368, 34371, 34372, 34374, 34379, 34382, 34383, 34384, 34386, 34388, 34390, 34398, 34399, 34401, 34402, 34406, 34408, 34409, 34416, 34418, 34422, 34423, 34427, 34429, 34432, 34437, 34438, 34439, 34440, 34441, 34443, 34447, 34449, 34451, 34452, 34455, 34457, 34459], 9714: [10100], 9156: [10102], 6635: [10103], 9656: [10104], 9557: [10105], 16525: [10106], 12515: [10108], 12776: [10109], 5725: [10110], 7019: [10111, 13146, 13260], 15190: [10113], 12919: [10114], 4514: [10118], 4718: [10119], 4056: [10120], 15054: [10121], 4312: [10128], 4107: [10129], 3528: [10131], 4723: [10134, 10258, 10330, 10611, 10696, 10799], 1690: [10138], 1197: [10139], 848: [10140, 10226], 14940: [10142], 15248: [10143, 10214], 1437: [10144], 2586: [10145, 10213, 10222, 10229, 10604], 6627: [10147], 1874: [10148], 6182: [10149, 12651, 12840, 12958, 13059, 13183, 13207, 13217, 13305, 13312, 13314, 13326, 13378, 13430, 13458], 6561: [10150], 2583: [10151], 1758: [10152], 14439: [10153], 1748: [10154], 14704: [10155], 13832: [10156], 15329: [10158], 1710: [10159, 10192], 18801: [10160, 10919], 2582: [10162], 17752: [10163], 16077: [10164], 1526: [10166], 1406: [10167, 11120], 18790: [10168], 662: [10169], 13972: [10170, 10357], 6679: [10171], 16367: [10172], 9548: [10173], 306: [10176], 10903: [10177, 11684, 12408, 12424, 12497, 12513, 12534, 12575, 12607, 12613, 12614, 12617, 12693, 12707, 12773, 12775, 12791, 12801, 12809, 12996, 13097], 9517: [10178, 10438, 10490], 9508: [10179], 9217: [10180, 13111, 13112, 13226, 13233, 13236, 13354, 13360, 13580, 13692, 13707], 16045: [10181], 9186: [10182], 18670: [10183], 6594: [10184], 16075: [10185], 9426: [10186], 7081: [10187, 11344, 12143], 1440: [10190], 17859: [10191], 4546: [10193], 4725: [10197], 4721: [10201, 10251, 10455, 10522, 10524, 10591, 10603, 10706, 10713], 3136: [10207], 18676: [10209], 4083: [10210], 4579: [10211], 1136: [10216], 14493: [10217], 19109: [10218], 1487: [10219], 19424: [10220], 14482: [10221], 1113: [10224], 17926: [10228, 10425], 1428: [10230], 2584: [10231], 19422: [10232], 9700: [10233], 6424: [10234], 285: [10235, 10370], 783: [10236], 11109: [10237], 9484: [10239], 9305: [10240], 7069: [10241], 9529: [10242, 11952], 5737: [10243], 6790: [10245], 5824: [10247, 12248, 14204, 16316, 16487, 16665, 16675, 16698, 16706, 16834, 16880, 16885, 16890, 16892, 16893, 16895, 16899, 16901, 16906, 17127, 17145], 7070: [10248], 4647: [10252], 15222: [10259, 10323], 3603: [10261], 4277: [10264, 10614], 4620: [10265], 15264: [10266, 10319], 15274: [10267], 14943: [10268], 14934: [10269, 10528, 10610, 10612, 10707], 4285: [10271], 4297: [10273], 1540: [10274, 10343], 14534: [10276], 4836: [10277], 1875: [10278, 11375, 11724], 3376: [10279], 1484: [10281], 6805: [10282, 11731], 13833: [10283], 6419: [10284], 18792: [10285], 17347: [10286], 14539: [10288], 1756: [10289], 1489: [10290], 15613: [10291], 6381: [10292], 258: [10293], 6172: [10294], 9763: [10295], 19034: [10296], 19447: [10297, 11309], 10681: [10298], 466: [10299], 654: [10300], 9079: [10301], 9607: [10302, 10432, 10497, 10501], 9145: [10303], 7629: [10305], 9477: [10306], 9256: [10307], 6693: [10308], 6138: [10309], 9479: [10310], 9252: [10311], 6709: [10312], 9680: [10315], 9590: [10316], 10428: [10317], 9444: [10318], 4461: [10324], 4268: [10327], 1692: [10338], 15126: [10342], 1480: [10345], 659: [10346], 1603: [10347], 18699: [10348], 1405: [10349], 1482: [10350], 2604: [10351, 10356], 18823: [10352], 14384: [10353], 242: [10355, 10571], 308: [10358], 19409: [10359], 1359: [10360], 6453: [10362, 10872, 10962, 11028, 11398], 16937: [10363], 2643: [10364], 10922: [10365], 1254: [10366], 19135: [10367], 16630: [10368], 1821: [10369], 9497: [10371, 10982], 9639: [10372], 10361: [10373, 10436], 10366: [10374, 10567, 10653, 10676], 9952: [10375], 6619: [10377], 10369: [10378], 8984: [10379, 16803, 16810], 9862: [10380], 11215: [10381], 9527: [10382], 17220: [10383], 16121: [10384], 4668: [10385], 4654: [10391], 4669: [10395], 3543: [10398], 15100: [10399], 4101: [10401], 18798: [10402], 4581: [10403], 15205: [10405], 4270: [10406], 6169: [10407], 6663: [10408, 10541, 10853], 17714: [10409], 6668: [10411], 14584: [10412], 3139: [10413], 1442: [10414], 6812: [10415], 14531: [10416], 13845: [10417, 11467], 19493: [10418, 11024], 1400: [10420], 15326: [10421], 1717: [10422], 7009: [10423], 6791: [10424], 2605: [10426], 17836: [10427], 9470: [10428], 6163: [10429], 9716: [10430], 10918: [10431, 12515, 12526, 12529, 12600, 12659, 12682, 12685, 12785, 12993, 13013, 13386], 19281: [10433], 9480: [10434], 11068: [10437], 6727: [10441], 6798: [10442], 12542: [10444], 16441: [10446], 15265: [10447], 4758: [10449, 10700, 10823, 10882, 11007, 11012, 11013, 11082, 11086, 11088, 11089, 11092, 11102, 11174, 11175, 11180, 11185, 11186, 11199, 11251, 11261, 11262], 4717: [10450], 4488: [10452, 12065, 12347], 4756: [10454], 1451: [10457], 4121: [10458], 17354: [10460], 4108: [10461], 1469: [10462], 1557: [10463], 1652: [10464], 1048: [10466], 1416: [10467], 1410: [10468], 1981: [10470], 1483: [10472], 16443: [10473], 19450: [10475], 1687: [10476], 1452: [10477], 2650: [10479, 10847, 10851], 16457: [10480], 18363: [10481], 17750: [10482], 6694: [10483], 10445: [10485], 6813: [10486, 10642], 558: [10488], 9498: [10491], 9223: [10493], 6465: [10495], 10672: [10496], 12276: [10498], 18668: [10499], 9437: [10502], 10955: [10503], 5836: [10504], 7574: [10506], 14627: [10508], 1582: [10509], 14437: [10511], 4660: [10515], 4507: [10517], 4675: [10518, 11350, 11356, 11433, 11523, 11537, 11546, 11600, 11603, 11604, 11605, 11613, 11615, 11617, 11618, 11619, 11629, 11694, 11701, 11703, 11707, 11708, 11716, 11794], 4657: [10521, 10606, 10822, 11015], 14939: [10526, 10530], 14941: [10527], 4120: [10531, 10618], 19081: [10532], 4645: [10533], 8868: [10534], 18799: [10535], 1647: [10536], 6107: [10537], 13945: [10538, 16531, 16738], 6708: [10539], 6649: [10540], 1649: [10542], 1759: [10543], 1372: [10544], 13877: [10545], 1678: [10546], 17927: [10547, 10954, 11302], 10874: [10549], 660: [10551], 6628: [10552], 6430: [10553], 9717: [10557, 10738], 12287: [10559], 9188: [10560, 10980], 9513: [10564], 9712: [10565], 11756: [10577, 18214], 9233: [10578], 6820: [10580], 6563: [10583], 9443: [10584, 12046], 9627: [10585, 10767], 12698: [10588], 4656: [10595], 4558: [10596], 4520: [10597], 4644: [10599, 11608, 11695, 11699, 11702, 11868, 11873, 11968], 4095: [10600], 4770: [10601], 4570: [10608], 4102: [10613], 4580: [10616, 11109], 15236: [10617], 14785: [10619], 14942: [10620], 1754: [10621], 6421: [10622], 6823: [10627], 6621: [10628], 18859: [10629], 1407: [10630, 10717], 6819: [10631], 1696: [10632, 10949], 9925: [10633], 14451: [10634], 14571: [10635], 14551: [10636], 1047: [10637], 19495: [10639], 1749: [10640], 1361: [10641], 6695: [10643], 1982: [10644], 9246: [10646], 135: [10648], 6630: [10651], 10885: [10656], 294: [10660], 458: [10663], 6447: [10664], 12530: [10665], 9547: [10666], 8590: [10667], 10130: [10668], 9387: [10669], 11136: [10670], 7073: [10674], 6702: [10675], 10920: [10677], 18251: [10678], 12545: [10682], 18786: [10683], 15263: [10686, 11446], 4519: [10688, 10809, 11097, 11168], 15049: [10689], 4292: [10692], 4755: [10693, 10800, 11191], 4670: [10695], 4672: [10697, 11610], 4517: [10698, 10705], 4759: [10702], 4779: [10704, 10716, 10792, 10807, 10902, 10904, 10994, 10997, 11009, 11085, 11094, 11108, 11173, 11179], 15338: [10708], 1506: [10709], 15315: [10710, 11352], 12963: [10711], 4771: [10712, 10894, 10924, 11355], 2641: [10715], 1682: [10718], 1872: [10720], 6643: [10721], 16599: [10722], 14456: [10723], 14441: [10724], 14473: [10725], 6818: [10726, 11050], 13997: [10727], 15574: [10728], 1453: [10729, 11294, 11381], 15380: [10730], 15453: [10731], 1640: [10732, 13315, 14006, 14140], 19365: [10734], 16899: [10735], 7823: [10736], 455: [10737], 6631: [10741], 767: [10742], 17890: [10743], 6680: [10744], 8489: [10745], 15928: [10747], 11726: [10748, 18470, 18474, 18480, 18691, 18696, 18960, 19175], 284: [10750], 9554: [10751], 9719: [10753], 16762: [10754], 16073: [10755], 10442: [10756], 9257: [10758], 6428: [10760], 6378: [10762], 19078: [10763], 9556: [10764], 12398: [10765], 11796: [10766], 5732: [10769], 5752: [10770], 5770: [10772, 13979, 15314], 5777: [10773], 15181: [10776, 10837, 10901, 11368], 15224: [10777], 14775: [10778], 15271: [10779], 4651: [10781, 11257], 12289: [10783], 4655: [10793], 14884: [10798], 2665: [10804], 4541: [10810, 12624, 12825], 3526: [10816], 1715: [10825], 4260: [10826], 4782: [10829, 10915, 10917, 10931, 10940, 11005, 11258, 11427], 9255: [10830], 15020: [10831], 3508: [10832], 15237: [10833, 11190], 15198: [10835], 14789: [10836], 9642: [10839], 13973: [10841], 3140: [10842], 3141: [10843], 1235: [10844], 852: [10845], 1653: [10846], 6648: [10848], 17758: [10850], 15495: [10852], 9355: [10854], 1443: [10855, 10935], 1137: [10856], 11527: [10857], 6418: [10858], 9504: [10860, 10896, 11052], 463: [10862, 10865], 9841: [10863], 326: [10864], 17954: [10868], 9312: [10869, 11068], 8165: [10870], 7626: [10871], 6570: [10873], 7207: [10875], 9087: [10877], 9441: [10878, 11503], 4522: [10881, 11348, 11700, 11798], 4556: [10890, 11270, 11547, 11705, 12155], 1074: [10903], 4593: [10921], 4571: [10922, 10932, 11020, 11021, 11188], 1698: [10927], 15216: [10929], 4073: [10933], 4582: [10934], 17942: [10936], 3172: [10937], 4538: [10939], 14010: [10941], 3171: [10942], 1675: [10943], 6613: [10944], 14079: [10945], 1877: [10948], 14532: [10950], 13842: [10952], 6644: [10953], 14467: [10956], 1676: [10957], 464: [10959], 1507: [10960], 19455: [10961], 2637: [10963], 1684: [10964], 1445: [10965], 6811: [10966], 17082: [10967], 19435: [10969], 12844: [10970], 6593: [10971, 11032], 6602: [10972], 9389: [10974], 5109: [10975], 262: [10976], 678: [10978], 9593: [10983], 11119: [10984], 10439: [10985], 7042: [10986, 11328, 11504, 11595, 11765], 10865: [10988, 14982], 6954: [10989, 26088], 14557: [10999], 14933: [11001, 11266], 4494: [11003], 14956: [11011], 4441: [11018, 12559, 12631, 12634, 12641, 12725], 15184: [11019], 1701: [11022], 6185: [11025, 12087, 12793, 12838, 12894, 12947, 12949, 12950, 13000, 13057, 13084, 13184, 13186, 13187, 13190, 13191, 13205, 13254, 13259, 13302, 13306, 13377, 13469, 13525, 13527, 13561], 496: [11026], 1538: [11027], 13886: [11029], 4076: [11031], 14014: [11033], 1527: [11034], 14541: [11035], 19745: [11038], 15330: [11039], 14013: [11040], 1485: [11041], 18405: [11043], 1071: [11045, 11133], 9826: [11047], 16925: [11048], 19581: [11049], 9520: [11051], 9623: [11053], 321: [11054], 10453: [11055], 514: [11056], 332: [11057], 17042: [11059], 9633: [11060], 318: [11061], 9295: [11062, 13813, 13814], 16927: [11063, 11083, 11206], 9439: [11066], 15693: [11067], 6671: [11069], 18675: [11070], 9643: [11072], 8813: [11073], 12533: [11074], 9226: [11075, 11236], 12517: [11076], 9423: [11077], 5723: [11078], 7518: [11079], 5756: [11080], 5754: [11081], 4523: [11084], 3443: [11087, 17836, 17837, 17839, 18055, 18056, 18057, 18059, 18060, 18062, 18272, 18522, 18523, 18524, 18526, 18529], 4261: [11091], 4659: [11093, 11169, 11432, 11538], 4515: [11095, 11535], 14036: [11104], 4594: [11105], 4734: [11107], 6827: [11110], 15175: [11111], 14788: [11112], 15221: [11113], 4591: [11114, 11193, 11360, 11623, 11712, 11713, 11718, 11797, 11801, 11803, 11806, 11877, 11893, 11985, 11987, 12071], 4483: [11115], 1870: [11118], 2660: [11119], 1695: [11121], 1441: [11122, 11363], 16932: [11123], 341: [11124], 14548: [11125], 2675: [11126], 14494: [11127], 14552: [11128], 19500: [11129], 19565: [11132], 19452: [11134], 1058: [11135], 19204: [11136, 11220, 11673], 8940: [11137], 303: [11138], 9490: [11139], 6686: [11140], 19582: [11141], 1719: [11142], 330: [11143], 12305: [11144], 6808: [11145], 16238: [11146], 11110: [11147], 9512: [11148, 11151, 11232, 11239, 11676], 7472: [11149], 16285: [11150, 35600, 36858], 333: [11152], 6553: [11154], 8490: [11155], 6824: [11156], 6414: [11157], 6121: [11158], 4825: [11159], 9461: [11160], 10422: [11161], 7517: [11162], 7029: [11163], 14886: [11166], 6444: [11167], 4681: [11170, 11202, 11254, 11264, 11346, 11351, 11424, 11435, 11436, 11438, 11441, 11521, 11525, 11529, 11602, 11698], 4490: [11171], 19202: [11177, 11252, 11253, 11291, 11574, 11653, 11659, 11662, 11729], 4605: [11183], 4778: [11184], 4521: [11187], 15123: [11192], 15275: [11194], 14786: [11195], 15206: [11196], 15218: [11197], 15113: [11198], 2661: [11200], 4284: [11201, 11357], 1873: [11205], 1467: [11207, 11631], 13970: [11208], 14556: [11209], 14716: [11210], 19504: [11211], 1716: [11212, 11396], 1677: [11213], 1240: [11214, 11918], 1967: [11215], 1804: [11216], 16991: [11217], 13870: [11218], 850: [11221], 3792: [11223], 291: [11224, 11494], 18750: [11225], 19367: [11226, 11307], 6632: [11227], 9191: [11228], 9471: [11229], 392: [11230], 6690: [11231, 11577], 6661: [11233], 10891: [11234, 12691, 12700, 12710, 12774, 12786, 12821, 12826, 12879, 12883, 12907, 13125, 13151], 18917: [11235], 6639: [11237], 6600: [11238], 7805: [11240], 16549: [11241], 12671: [11242, 16459, 17362], 5821: [11244, 16494, 16887, 16894, 16903, 16905, 17124, 17140, 17149, 17159, 17372], 5743: [11245], 5755: [11246], 9362: [11247], 1619: [11248, 11907], 4682: [11249], 4680: [11250, 11430, 11431, 11522, 11524, 11527, 11609, 11612, 11790, 11791, 11876], 1683: [11265, 11454, 11647, 11785, 11831, 11915, 11923, 11977, 12001, 12088, 12102], 1680: [11268, 11358, 11359, 11458, 11476, 11526, 11539, 11552, 11561], 15234: [11269], 4583: [11271], 19537: [11272], 15223: [11273, 11540, 11544, 11599, 11696], 4289: [11274], 4569: [11275], 4452: [11276], 4826: [11277], 15138: [11278, 14227], 1167: [11280], 1694: [11281], 19501: [11282], 6599: [11283], 2651: [11284, 11471, 11735], 1495: [11285, 11380, 11457, 11548, 11633, 11656, 11751], 851: [11286], 14011: [11287], 1707: [11288], 5025: [11290], 6647: [11293], 15345: [11295], 1681: [11297], 1708: [11298], 1679: [11299], 17924: [11300], 6640: [11303], 1611: [11304], 1401: [11305], 6445: [11308], 18322: [11310], 10295: [11311], 17020: [11312], 6687: [11313], 245: [11314], 9192: [11315], 501: [11318], 8342: [11320], 260: [11321], 9472: [11322], 9657: [11323], 12283: [11324], 10112: [11325], 6551: [11327], 909: [11329], 6622: [11330], 6413: [11331], 890: [11332], 10578: [11333], 6677: [11334], 6379: [11335], 12710: [11336], 7027: [11337], 9442: [11338, 12142], 12777: [11340], 5720: [11341, 11686, 11783], 7039: [11342, 12055], 10689: [11343], 6982: [11345], 17670: [11347, 12059], 4676: [11353], 4286: [11361], 15107: [11362, 11627], 15099: [11364], 15176: [11365], 15062: [11366], 15294: [11367], 18860: [11369], 1869: [11371, 11372, 11456], 6454: [11373, 11566, 11636], 13836: [11374, 11638, 11639], 2323: [11376, 11966, 11992, 12081], 18888: [11377], 14499: [11379], 2656: [11382, 11829, 11830], 17096: [11383], 1597: [11384], 483: [11385], 846: [11386], 17763: [11387], 1190: [11388], 2324: [11389, 11390, 11395], 10411: [11391], 2636: [11392, 11664, 12015], 18673: [11393], 775: [11394], 3012: [11397], 6443: [11399], 18696: [11400], 19425: [11401], 19606: [11402, 18111, 18258, 18262, 18342, 18346, 18560, 18827], 6674: [11403], 12286: [11404], 9287: [11406, 12129, 13353, 14038, 14577, 14582, 14601, 14613, 14690, 14717, 14718, 14723, 14727, 14728, 14729, 14732, 14734, 14735, 14736, 14737, 14742, 14744, 14746, 14749, 14750, 14751, 14752, 14754, 14755, 14756, 14757, 14758, 14760, 14761, 14763, 14765, 14766, 14767, 14771, 14772, 14773, 14774, 14780, 14781, 14784, 14786, 14787, 14789, 14792, 14794, 14795, 14798, 14812, 14813, 14830, 14931, 14941, 14946, 15100, 15271], 16414: [11407], 12307: [11408, 12903], 12288: [11409], 9534: [11410], 9610: [11411], 7757: [11412], 17490: [11413], 1858: [11414], 9687: [11416], 9398: [11417], 10131: [11418], 9650: [11419], 7064: [11420], 11135: [11421, 11502], 7063: [11422], 19387: [11423], 4678: [11425, 11965, 11995], 4674: [11426, 11520, 11530, 11533, 11534, 11536, 11607, 11704, 11706, 11709, 11789, 11869], 14931: [11429], 4604: [11434], 4492: [11439], 4459: [11440], 4772: [11442], 4537: [11444], 16922: [11445], 4592: [11447], 15018: [11448], 4765: [11449], 15333: [11450], 2825: [11451], 3417: [11452], 13999: [11453], 13875: [11455], 3354: [11459], 14583: [11460, 11549], 1651: [11461], 19698: [11462, 11757], 1697: [11463, 11468, 11553, 11557, 11621], 1446: [11464], 18861: [11465], 13835: [11466], 13831: [11469, 11641, 11642], 14486: [11470], 14543: [11472], 15443: [11473], 15578: [11474, 11723, 11745], 15318: [11475, 11744], 274: [11477], 1673: [11478], 1671: [11479], 911: [11480], 19566: [11481], 1499: [11482], 375: [11483], 16900: [11484], 2639: [11485], 754: [11486], 440: [11488, 11671], 9187: [11489, 11581, 11582], 467: [11491], 9315: [11492], 9624: [11495], 9515: [11496], 363: [11497], 9254: [11498], 18674: [11499], 16078: [11500], 9228: [11501], 7058: [11505], 12282: [11508, 12029], 18677: [11509], 7638: [11510], 9972: [11511], 16098: [11512], 8443: [11513], 11124: [11514], 9803: [11515], 11764: [11516], 5721: [11517], 7065: [11518], 17671: [11519, 12057], 15272: [11528], 4557: [11531], 14453: [11532], 4626: [11541], 4666: [11542], 15182: [11543], 15203: [11545], 14490: [11551], 1617: [11554], 6615: [11555], 1699: [11556, 11565, 11569], 4048: [11558], 1664: [11559], 15344: [11560], 304: [11562], 1599: [11563], 15482: [11564], 477: [11567], 1444: [11568], 1488: [11570, 11733, 11834], 1476: [11571], 2792: [11572], 10896: [11573, 11764, 12610, 12686, 12812, 12813, 12984, 13077, 13114, 13116, 13117], 18656: [11575], 498: [11576], 17958: [11578], 14044: [11579], 6646: [11580], 17923: [11584], 633: [11585, 17435], 11099: [11586], 10371: [11587], 16079: [11588], 8477: [11589], 9611: [11590], 17237: [11591], 9653: [11592], 5489: [11593], 10787: [11594], 7066: [11596], 7036: [11597], 5775: [11598, 13156, 13984, 14088, 14202, 14207, 14292, 14303, 14322, 14482, 14483, 14649, 14652], 4501: [11601, 11982], 12284: [11606], 3529: [11611], 4683: [11614], 4763: [11616, 11872, 11971, 12067, 12083], 2679: [11620], 4760: [11622], 4584: [11624], 15220: [11625], 14983: [11626], 15473: [11628], 3208: [11630], 646: [11632], 8336: [11634], 6601: [11635], 19711: [11637], 13881: [11640], 14550: [11643], 1494: [11644, 11720], 19536: [11645], 17746: [11646], 1052: [11648], 1659: [11649, 12290], 1626: [11650], 15321: [11651], 19400: [11652, 12118, 12673], 1481: [11654], 6611: [11655], 9961: [11657], 19199: [11658], 19288: [11660], 17931: [11661], 13887: [11663], 6425: [11665], 19371: [11667, 11921], 16403: [11668], 6162: [11669], 504: [11670, 13096, 13106], 7508: [11672], 9253: [11675], 8469: [11677], 9360: [11678], 10706: [11679], 9141: [11680], 8989: [11681], 6624: [11682], 15913: [11683], 5718: [11685, 11857], 5719: [11687, 12249], 5829: [11688], 7052: [11689], 12094: [11690], 4529: [11691], 19535: [11692, 11697, 11710, 11714, 12089, 12312], 1625: [11693], 4559: [11715], 19000: [11717], 15231: [11719], 3257: [11721], 1776: [11722], 14563: [11725], 847: [11726], 1607: [11727, 15376], 18858: [11728], 15571: [11730], 15476: [11734], 14007: [11736], 6562: [11737], 14554: [11738], 15569: [11739], 16971: [11740], 19401: [11741], 14540: [11742], 6422: [11743], 19680: [11746], 17928: [11747], 18893: [11748], 2659: [11749], 13883: [11750], 19201: [11752, 12016, 12018], 19366: [11753], 337: [11754], 844: [11755], 19544: [11756], 9313: [11758], 6125: [11759], 10907: [11760, 12229, 12500, 12701, 12781, 12799, 12872, 12873, 12875, 12881, 12890, 12891, 12892, 12897, 12966, 12982, 12991, 12999, 13026, 13367], 9213: [11761, 11846, 11936, 14166], 17381: [11762], 12293: [11766], 9511: [11768, 11772], 10921: [11769], 7631: [11770], 6423: [11773], 10372: [11774], 8664: [11775], 15903: [11776], 16116: [11777], 12755: [11778, 19769, 20594], 9652: [11779], 7373: [11780], 6416: [11781], 12669: [11782, 15462, 16126, 16488, 16648, 16711, 17117], 15130: [11784], 4679: [11786, 11878], 1712: [11787], 4489: [11788], 4608: [11792, 12066], 4460: [11793], 15209: [11795], 1497: [11796, 12379], 15225: [11799], 14954: [11800, 11809, 11810, 11863], 4590: [11802, 11978], 4588: [11804], 4563: [11805], 14784: [11807], 19196: [11808], 19705: [11811], 4553: [11812, 12268, 12353, 12362], 4129: [11813], 6188: [11815], 1049: [11816, 11817], 14469: [11818], 17341: [11819], 13995: [11820], 1252: [11822, 12373], 19563: [11823], 19445: [11824, 12120], 16955: [11825], 15478: [11826], 19280: [11827], 19203: [11828, 11922], 1581: [11832, 11920], 1239: [11833], 6455: [11835], 430: [11836], 18321: [11837, 11838, 12121], 697: [11839], 19629: [11840], 19560: [11841], 19053: [11842], 6625: [11843], 6452: [11844], 9011: [11845], 9524: [11847], 434: [11848], 7192: [11849], 16102: [11850], 8563: [11851], 10713: [11852], 6642: [11853], 11064: [11854], 9483: [11855], 9263: [11856], 9411: [11858], 9123: [11859], 12544: [11860], 12829: [11861], 7057: [11862, 11961, 12244], 15072: [11864], 1618: [11865], 1500: [11866], 4072: [11867], 4530: [11870], 4555: [11871, 12068], 4536: [11874, 12352, 12355, 12451], 3525: [11875], 4639: [11879], 1475: [11880, 12064, 12109], 15327: [11882], 15183: [11883], 14880: [11884], 15215: [11885], 15067: [11886], 15063: [11887], 15575: [11888], 4671: [11889, 11993, 12462], 3385: [11891], 1608: [11892, 11981], 1876: [11895, 12469], 13852: [11896], 16789: [11897], 1459: [11898], 6417: [11899], 15485: [11901], 17233: [11902], 3420: [11903], 14578: [11904], 14488: [11905], 845: [11906], 1561: [11908, 15058], 15576: [11909], 6816: [11910, 12310], 17463: [11911], 18412: [11912], 1623: [11914, 12286, 12955, 13198, 13334, 13400, 13408, 13437, 13438, 13500, 13501, 13510, 13511, 13514, 13521, 13533, 13548, 13550, 13624, 13628, 13632, 13690], 16919: [11916], 18685: [11917], 513: [11924], 772: [11925], 2655: [11926, 12014, 12580, 12670], 877: [11927], 716: [11928], 19438: [11929], 515: [11930], 1043: [11931], 6415: [11932], 44: [11933], 9523: [11934], 9116: [11935, 15400, 15411], 1914: [11937, 18581, 19631, 20003, 20079], 6059: [11938, 14454, 22134], 16068: [11939], 10886: [11940], 9202: [11941, 14602], 15811: [11942], 16095: [11943], 7067: [11944], 6385: [11946], 18645: [11947], 10572: [11948], 10951: [11949], 6814: [11950], 10467: [11951], 5715: [11953], 9501: [11954], 9500: [11955], 18295: [11956], 19154: [11957], 7054: [11958], 10900: [11960], 7103: [11962], 12906: [11963], 4554: [11964], 15992: [11967], 3496: [11969], 3517: [11970], 4437: [11972], 4543: [11973], 4482: [11974], 1635: [11983], 1609: [11984], 15238: [11986], 15131: [11988], 19377: [11989], 14806: [11991], 16054: [11994], 1503: [11996, 12104, 12369], 17361: [11997], 1045: [11998], 3252: [11999], 2678: [12000], 7135: [12002], 17824: [12003], 13837: [12004, 12009], 18824: [12005], 1755: [12006], 14579: [12007], 5021: [12008], 1650: [12010], 15502: [12012], 15447: [12013], 1493: [12019, 12084, 12293], 10103: [12020], 17929: [12021], 1408: [12022], 460: [12023], 352: [12024], 19628: [12025], 9536: [12026], 526: [12027], 10256: [12028], 9506: [12030], 267: [12031, 12082], 30: [12032], 9507: [12033], 10919: [12034], 6669: [12037], 6091: [12038], 6436: [12039], 6815: [12040], 7557: [12041], 7026: [12042, 12123], 9463: [12043], 10943: [12044], 12607: [12045], 7168: [12047], 17229: [12049], 12543: [12050], 9535: [12051], 7041: [12052, 12343], 7017: [12053], 5735: [12054], 12528: [12056], 15195: [12058, 12278], 15132: [12061], 4606: [12063], 4487: [12069, 12720], 3505: [12070], 1496: [12072], 14006: [12073], 1614: [12074], 4625: [12076, 12557], 4585: [12077, 12156, 12157, 12158, 12159, 12163, 12166, 12171, 12172, 12273, 12276, 12277, 12365, 12637], 15164: [12078], 15064: [12079], 1615: [12080], 19240: [12085], 14719: [12086, 12471, 12554], 1529: [12090, 12291, 12654], 16786: [12091, 13879], 14454: [12092], 19502: [12094], 259: [12097], 14053: [12098], 13827: [12099], 481: [12103], 15479: [12105], 15567: [12106], 2676: [12107], 19498: [12108], 19538: [12111, 12164, 12195], 3137: [12114], 1693: [12119, 12202], 6173: [12122, 12382], 819: [12124, 12230], 527: [12125], 19578: [12126], 536: [12127], 9459: [12128, 13007], 7623: [12130], 823: [12131], 18113: [12132], 12518: [12133], 10296: [12134], 9399: [12135], 6666: [12136, 12206], 16541: [12137], 7059: [12138], 8901: [12139], 10899: [12140], 7043: [12141], 15214: [12144], 15253: [12145], 15089: [12151], 771: [12152], 4547: [12153, 12261, 12354], 4518: [12154], 4132: [12160], 15069: [12161], 15110: [12165], 19200: [12167], 4764: [12168], 14841: [12169], 19654: [12174], 16918: [12175], 1763: [12176], 14452: [12177], 3468: [12178], 11410: [12179], 18862: [12180], 16920: [12183], 19391: [12184], 19249: [12185], 17091: [12186], 14585: [12187], 14008: [12188], 10364: [12189], 387: [12190], 14489: [12191], 18400: [12192], 16617: [12193], 15474: [12194], 10483: [12196], 17359: [12197], 502: [12199, 12855, 13049, 13318, 13355, 13445], 1569: [12200, 15373, 15537], 18055: [12201], 2787: [12204], 1672: [12205, 12380], 17775: [12207], 5174: [12208, 12329, 19015, 19152], 6153: [12209], 6578: [12210], 19579: [12211], 17953: [12212], 6830: [12213], 16080: [12214], 10902: [12215, 12326], 465: [12216], 10373: [12217], 431: [12218], 605: [12219], 9276: [12220], 16072: [12221], 9525: [12222], 9361: [12223], 8223: [12224], 10908: [12225, 12509, 12609, 12681, 12779, 12787, 12790, 12792, 12861, 12893, 12901, 12942, 13002, 13102], 9231: [12226], 10916: [12227, 12783, 12877, 13017], 9283: [12228], 5225: [12231], 9015: [12232], 17952: [12233, 12234, 12331], 7725: [12235], 10480: [12236], 7206: [12237, 12525], 6558: [12238], 9630: [12239], 8380: [12240, 20774], 6809: [12241], 764: [12242], 6201: [12243], 16458: [12245], 12122: [12246], 15056: [12250, 12251, 12254], 15112: [12252], 15125: [12253], 15059: [12256], 15207: [12257], 4496: [12258, 12264, 12446, 12449], 3548: [12259], 4535: [12260, 12545, 12549, 12719, 12822], 4545: [12262, 12349], 4462: [12263], 4486: [12266, 12721], 3524: [12267], 1055: [12270], 4534: [12271, 12443, 12447, 12550, 12551, 12734], 17674: [12272, 12548], 15073: [12274], 3516: [12279], 15239: [12280], 15170: [12281, 12829], 13854: [12282, 12297, 12573], 4589: [12283], 4130: [12284], 4290: [12285], 14487: [12287], 19370: [12288, 12319, 12577], 1601: [12289, 12747], 1646: [12292], 18890: [12294], 14445: [12295], 17696: [12298], 14385: [12299], 6186: [12300], 15579: [12301], 388: [12302], 15346: [12303], 19630: [12304], 9456: [12306], 4869: [12307], 724: [12308], 19446: [12313], 19206: [12314], 12313: [12315], 778: [12316], 16411: [12317, 13119], 7890: [12318, 16232], 61: [12320, 19979, 20986], 9261: [12321], 9077: [12322], 9211: [12323], 497: [12325], 11137: [12327], 8709: [12330], 522: [12332], 11218: [12333], 12291: [12334], 781: [12335], 9644: [12336], 9760: [12337, 13846], 10378: [12338], 17228: [12339], 17314: [12340], 9136: [12341], 9449: [12342], 5748: [12344], 14780: [12345], 4628: [12346], 4549: [12350], 4612: [12351, 12621], 4614: [12356], 14665: [12359], 4646: [12360], 3490: [12363], 15151: [12364, 15644, 15651, 15660, 15831, 15833, 15838, 15839, 15843, 15994, 15995, 15996, 15997, 16002, 16004, 16005, 16007, 16008, 16009, 16010, 16012, 16013, 16014, 16015, 16019, 16020, 16021, 16152, 16153, 16157, 16158, 16159, 16163, 16165, 16166, 16169, 16171, 16172, 16173, 16174, 16175, 16176, 16177, 16179, 16180, 16181, 16183, 16184, 16185, 16186, 16187, 16188, 16189, 16192, 16495, 16503, 16507], 1539: [12366], 19197: [12367], 15235: [12368], 4766: [12370], 19577: [12371], 2673: [12372], 4481: [12374], 19648: [12376], 1610: [12377], 5155: [12378, 15073, 16602, 17648, 17699, 17707, 17875, 18159, 21058, 21066, 21250, 21737, 21997, 22415, 22943, 22996, 23142, 23360, 23853, 23855, 23874, 23885, 23905, 23932, 24687, 24691, 24692, 24697, 24702, 24709, 24720, 24721, 24773, 24870, 24913, 25469, 25470, 25471, 25472, 25473, 25474, 25475, 25476, 25477, 25478, 25479, 25480, 25481, 25482, 25483, 25485, 25488, 25489, 25490, 25491, 25492, 25495, 25497, 25498, 25499, 25500, 25504, 25505, 25507, 25510, 25512, 25513, 25514, 25516, 25520, 25521, 25523, 25524, 25525, 25526, 25527, 25528, 25529, 25531, 25533, 25536, 25537, 25540, 25541, 25544, 25545, 25546, 25547, 25550, 25552, 25555, 25562, 25564, 25566, 25568, 25569, 25570, 25571, 25574, 25575, 25586, 25591, 25592, 25594, 25595, 25599, 25601, 25603, 25604, 25605, 25606, 25607, 25608, 25609, 25611, 25613, 25615, 25617, 25619, 25623, 25625, 25626, 25630, 25631, 25632, 25633, 25634, 25636, 25637, 25642, 25643, 25647, 25648, 25651, 25652, 25653, 25655, 25656, 25657, 25659, 25662, 25663, 25664, 25665, 25667, 25668, 25669, 25672, 25678, 25680, 25682, 25683, 25684, 25687, 25697, 25698, 25702, 25705, 25718, 25723, 25724, 25733, 25735, 25739, 25740, 25741, 25747, 25751, 25754, 25757, 25764, 25765, 25766, 25770, 25774, 25775, 25781, 25782, 25783, 25788, 25789, 25792, 25795, 25796, 25797, 25799, 25801, 25804, 25805, 25814, 25821, 25825, 25830, 25852, 25857, 25859, 25868, 25872, 25873, 25877, 25880, 25881, 25892, 25894, 25901, 25906, 25908, 25917, 25925, 25931], 1595: [12381], 9367: [12384, 12503], 14700: [12385], 14575: [12386], 18857: [12387], 14572: [12388], 14442: [12389], 14353: [12390], 15756: [12391], 1844: [12392], 1548: [12393], 1700: [12394], 17360: [12395], 16996: [12396], 348: [12398, 12499], 1921: [12399, 16770, 18109, 18129, 18291, 18577, 18846, 19371], 12290: [12400], 349: [12401], 19402: [12402], 19592: [12403], 19580: [12404], 723: [12405], 12583: [12406, 16258, 17592], 6507: [12407], 16559: [12409], 9194: [12410], 10893: [12411], 10887: [12412], 8168: [12413], 6451: [12414], 643: [12415], 17691: [12416], 339: [12418], 376: [12419], 9628: [12420], 16014: [12421], 9216: [12422, 12869, 13086, 13356, 13366, 13450, 13565, 13578, 13591, 13593, 13941], 8508: [12423], 9661: [12425], 16723: [12426], 10426: [12427], 9713: [12428, 12495], 10382: [12429], 6603: [12430], 15748: [12432], 10379: [12433], 9302: [12434], 7053: [12435], 11083: [12437], 5722: [12439], 5863: [12440], 4495: [12441], 14932: [12442], 4607: [12444, 12628], 4548: [12445], 4516: [12448], 4497: [12450], 3532: [12452], 14885: [12453], 15019: [12455, 12560], 15232: [12456], 15060: [12457], 15208: [12458, 12642], 4566: [12460, 12930, 13179], 1069: [12461], 15480: [12463], 1075: [12464], 12840: [12465], 14560: [12467], 1085: [12470], 1046: [12472], 6472: [12473, 14543], 14573: [12474, 12571], 2666: [12475], 1594: [12476, 12483, 12484, 12486, 12488, 12490, 12668], 9869: [12477], 19724: [12478], 15334: [12479], 1596: [12480], 15186: [12482], 2657: [12485], 1073: [12487], 1531: [12489], 18320: [12491, 12860], 17110: [12492], 9761: [12493], 10894: [12494, 13382], 10915: [12498], 9466: [12501], 9550: [12502], 8164: [12504, 13493], 10360: [12505], 738: [12506], 7639: [12508], 19419: [12510], 7020: [12511], 11058: [12514], 17044: [12516], 12272: [12517], 9247: [12519], 785: [12520], 10684: [12521], 11499: [12522], 12516: [12523], 9462: [12524], 9973: [12527], 10871: [12528], 17160: [12530], 8491: [12531], 5484: [12532], 11086: [12533], 7308: [12535], 12757: [12536], 9249: [12537, 12981], 7040: [12538], 5703: [12539, 18234], 7035: [12541], 7034: [12542, 12919], 5736: [12543], 15066: [12544], 2672: [12546], 19725: [12547], 15048: [12553], 15068: [12555], 15023: [12556], 172: [12558], 10909: [12561], 2623: [12563], 1645: [12564], 6606: [12565], 19657: [12566], 1705: [12567], 1072: [12568], 16821: [12569], 19001: [12570], 1624: [12572], 1620: [12574, 12970, 13194], 624: [12576], 13838: [12578], 17376: [12579], 1661: [12581], 17812: [12582], 19743: [12583], 14045: [12584], 8163: [12585], 6564: [12587], 10860: [12588, 12684, 13238, 13261, 13267, 13371, 13372, 13383, 13384, 13388, 13485, 13495, 13617], 18535: [12589, 12594], 6386: [12591], 804: [12592], 10451: [12593], 9092: [12595, 18128, 18149, 18358], 9412: [12596], 16044: [12597], 10854: [12598, 13716, 13810, 13969], 875: [12601], 6457: [12602], 6596: [12604], 16612: [12605, 13460], 6142: [12606], 8349: [12608], 8710: [12611], 12724: [12612], 9148: [12615], 5474: [12616], 8866: [12618], 10376: [12619], 7018: [12620], 19316: [12623, 17471, 17665, 17698, 17898, 17935, 18053, 18072, 18085, 18088, 18092, 18099, 18104, 18127, 18325, 18330, 18570], 4526: [12625, 13037, 13159, 13162, 13296], 3481: [12626], 12843: [12629], 14443: [12630], 2674: [12632], 15580: [12636], 15456: [12638], 4550: [12639], 15213: [12640, 12923], 13570: [12643], 4450: [12644], 1598: [12646], 6168: [12647], 1868: [12648], 1878: [12649], 3849: [12650], 6565: [12652], 1165: [12653], 14642: [12655], 14542: [12656], 19660: [12657], 6136: [12658], 15470: [12660], 18842: [12661], 6093: [12662], 1663: [12663], 19189: [12664], 19567: [12665], 17925: [12666], 1568: [12667], 2677: [12669], 32: [12671, 19316, 20374, 20740, 20956, 20959, 20963, 20988, 21050, 21064], 6804: [12672, 12740], 6189: [12674], 562: [12675], 19576: [12677], 10679: [12678], 698: [12680], 9372: [12683], 10566: [12688], 9306: [12689], 9250: [12690, 12770, 12878, 12884, 12888], 10946: [12692], 9403: [12694], 9368: [12695], 9219: [12696, 13118, 13705], 9558: [12697], 6972: [12698], 6420: [12699], 6566: [12702], 10277: [12703], 8811: [12704], 9555: [12705], 10491: [12706], 9602: [12708], 16526: [12709, 13619, 13736], 12271: [12711, 20230], 10965: [12713], 6983: [12714], 11138: [12715], 16563: [12716], 17230: [12717], 7060: [12718], 15088: [12722], 18150: [12723], 15201: [12724], 15226: [12726], 15087: [12727], 15047: [12728, 13284], 4564: [12729], 15046: [12730, 13170], 15240: [12731], 15196: [12732, 12925, 12936, 13172], 488: [12733, 12764, 12990, 13055, 13062, 13107, 13113, 13425], 4565: [12735, 12835, 12946, 13288], 4531: [12736], 19543: [12737, 12865], 1470: [12738], 6456: [12739], 1492: [12741, 12834, 13075, 13202, 13206], 1589: [12742], 15469: [12743], 6550: [12744], 3842: [12745], 774: [12746, 12752], 6604: [12748], 722: [12750], 1276: [12751], 19086: [12753], 1236: [12754], 1490: [12755], 19399: [12756, 13070], 19320: [12757], 6210: [12758], 10110: [12759], 5150: [12760], 384: [12761], 627: [12762], 19545: [12763], 11216: [12765], 19028: [12766], 372: [12767], 8515: [12769], 9214: [12771], 495: [12776], 10895: [12777, 12911, 12992, 12998, 13071, 13148, 13496, 13584], 350: [12780], 859: [12782], 508: [12784], 16234: [12788], 5730: [12794, 12922], 6557: [12795, 13128], 9080: [12796], 8872: [12797], 10019: [12798], 10914: [12802, 13614], 9445: [12804], 10712: [12805], 5490: [12806], 7419: [12807, 16097, 16410, 16415, 16452], 5751: [12808], 9570: [12810, 13030], 7501: [12811], 12753: [12814], 11430: [12815], 5731: [12816, 12918, 12920, 13023, 13093, 13154], 12779: [12817], 7044: [12818], 10923: [12819], 1586: [12820, 13063, 13078, 13303, 13325], 3530: [12823], 4528: [12824], 1498: [12828], 15185: [12830], 15070: [12831], 15032: [12832], 15053: [12833], 1362: [12836], 490: [12837, 13444], 1585: [12839, 13678], 482: [12841], 2652: [12842], 6437: [12843], 557: [12844], 1096: [12845], 1196: [12846], 6828: [12847], 14381: [12848], 19716: [12849], 17734: [12850], 6568: [12851], 1628: [12852, 13918, 14239, 14255], 11091: [12853], 15446: [12854, 12963], 15401: [12856], 15319: [12857], 10228: [12858, 18357, 19414, 23497, 27568, 27758, 28900, 28939, 29448, 29591, 30134, 30753, 30776, 30836, 31436, 31464, 31585, 31591, 31624, 32483, 32529, 32851, 33174, 33942, 34018, 34161, 34218, 34373, 35003, 35004, 35006, 35007, 35010, 35012, 35013, 35016, 35017, 35019, 35024, 35026, 35030, 35031, 35032, 35033, 35036, 35038, 35039, 35042, 35046, 35047, 35048, 35049, 35050, 35051, 35053, 35058, 35059, 35061, 35065, 35066, 35067, 35068, 35069, 35070, 35072, 35074, 35075, 35078, 35079, 35080, 35081, 35082, 35083, 35085, 35086, 35087, 35088, 35089, 35091, 35093, 35094, 35095, 35096, 35097, 35101, 35102, 35103, 35104, 35105, 35106, 35111, 35112, 35113, 35115, 35116, 35117, 35118, 35121, 35122, 35123, 35124, 35125, 35126, 35127, 35128, 35130, 35133, 35135, 35137, 35140, 35142, 35143, 35145, 35146, 35147, 35148, 35149, 35150, 35153, 35154, 35155, 35156, 35157, 35158, 35159, 35161, 35163, 35165, 35166, 35168, 35169, 35173, 35191, 35194, 35196, 35200, 35201, 35205, 35208, 35219, 35234, 35236, 35243, 35247, 35248, 35250, 35251, 35255, 35257, 35258, 35263, 35265, 35267, 35269, 35270, 35272, 35276, 35280, 35282, 35284, 35288, 35289, 35292, 35294, 35297, 35298, 35299, 35305, 35308, 35310, 35311, 35312, 35313, 35314, 35316, 35317, 35318, 35322, 35323, 35324, 35325, 35327, 35331, 35334, 35337, 35339, 35340, 35342, 35344, 35349, 35351, 35352, 35355, 35356, 35359, 35360, 35363, 35364, 35367, 35371, 35373, 35377, 35384, 35387, 35388, 35391, 35393, 35397, 35398, 35402, 35406, 35408, 35409, 35410, 35412, 35417, 35418, 35420, 35422, 35423, 35424, 35425, 35426, 35427, 35429, 35430, 35431, 35432, 35435, 35438, 35439, 35440, 35441, 35443, 35444, 35445, 35448, 35450, 35451, 35452, 35455, 35460, 35466, 35468, 35469, 35471, 35473, 35474, 35475, 35481, 35485, 35488, 35492, 35493, 35494, 35496, 35500, 35501, 35572, 36286, 36306], 16591: [12859], 305: [12862], 520: [12863], 13998: [12866], 6095: [12867], 7505: [12868], 9162: [12870, 15101], 11140: [12874], 9260: [12880, 12989], 9068: [12882], 253: [12885], 10427: [12886], 17712: [12887], 9366: [12889], 9625: [12895], 9526: [12896], 5530: [12898, 13133], 6468: [12899], 9553: [12900], 6184: [12902], 10716: [12904], 18065: [12905], 7077: [12908], 15994: [12909], 9688: [12912], 11631: [12913], 1805: [12916], 7172: [12921], 16974: [12924], 1702: [12926], 4498: [12927], 4470: [12928], 4532: [12929], 1237: [12931], 4587: [12932], 15111: [12933], 15061: [12934], 254: [12935], 15090: [12937], 14790: [12938], 19244: [12939], 3652: [12940], 15210: [12941], 3258: [12943], 1584: [12944, 13035, 13051, 13072, 13192, 13553], 4568: [12945], 19503: [12948], 12874: [12952], 1840: [12953, 13309], 6431: [12954], 6164: [12956, 15698], 1054: [12957], 6462: [12959], 18793: [12960], 1836: [12961], 9922: [12962], 9819: [12964], 1232: [12965], 17795: [12967], 10117: [12968], 1238: [12969], 380: [12971], 3855: [12972], 644: [12973], 9821: [12974], 347: [12975], 7116: [12977], 16049: [12978], 10904: [12979], 10147: [12980], 9300: [12983], 8533: [12985], 9293: [12986, 13831, 14422, 14731, 14743, 14779, 14915, 14916, 14918, 14919, 14921, 14922, 14924, 14925, 14927, 14928, 14929, 14930, 14933, 14934, 14936, 14938, 14939, 14940, 14942, 14943, 14944, 14947, 14949, 14950, 14952, 14954, 14956, 14961, 14962, 14963, 14964, 14968, 14973, 14980, 14985, 14993, 14996, 14997, 15119, 15238, 15250, 15256, 15260, 15419], 7473: [12987], 505: [12988, 13767, 14128], 6438: [12994], 10573: [12995], 9198: [12997, 13251, 13253], 7045: [13001], 7024: [13003], 6832: [13004], 10580: [13005], 10465: [13006], 10959: [13008], 6324: [13009], 10890: [13010, 13029, 13142, 13270, 13359, 13452, 13616], 8949: [13014], 16787: [13016], 9631: [13018], 9916: [13019], 10889: [13020, 13269, 13364], 11755: [13022, 17795, 18152], 10905: [13025, 13243], 12786: [13027], 10956: [13031], 7624: [13032], 12680: [13033, 16135, 16374, 16652, 17118], 11084: [13034, 13109], 1587: [13036, 13316, 13658], 3554: [13038], 1616: [13039, 13509, 13659, 13681, 13683, 13878, 14011], 3444: [13040], 15052: [13041], 19736: [13042], 15057: [13043, 13413], 15133: [13044], 15212: [13045, 13047, 13167], 14804: [13046], 16975: [13048], 19744: [13050], 3488: [13053, 14661], 1202: [13054, 18571, 18817], 10077: [13056], 2669: [13058], 338: [13060], 1634: [13061], 9242: [13064], 14574: [13065], 14555: [13066], 14580: [13067], 6183: [13068, 13214, 13301, 13333, 13419, 13526, 13536, 13542, 13563, 13588, 13880], 5235: [13069, 15899, 19040, 21981, 23848, 26810, 28170, 28261, 28611, 28614, 28616, 28621, 28625, 28627, 28629, 28636, 28639, 28640, 28643, 28647, 28649, 28653, 28671, 28676, 28678, 28685, 28705, 28713, 28718, 28719, 28729, 28735, 28855, 28865, 28879, 28884, 28895, 28901], 418: [13073], 3274: [13076], 1044: [13079], 18856: [13080], 1639: [13081], 1474: [13083, 13294], 10913: [13085, 13448], 6439: [13087], 768: [13088], 6569: [13089, 13570, 13959], 718: [13090], 428: [13091], 17050: [13092], 10449: [13094], 8382: [13095], 16310: [13098], 16081: [13099], 7030: [13100], 459: [13101], 191: [13103], 9212: [13104], 16083: [13105], 351: [13108], 8092: [13115], 448: [13120, 13686], 17693: [13121], 3006: [13123], 8918: [13124], 11033: [13126], 6560: [13127], 10856: [13130, 13145, 13228, 13271, 13361, 13566], 6667: [13131], 10838: [13132], 18620: [13134], 9135: [13138], 9241: [13139], 10576: [13140], 7573: [13143], 12640: [13149, 16448, 17770], 10857: [13150, 13700, 14030], 11480: [13152], 7025: [13153], 9896: [13155], 12657: [13157, 17600], 18787: [13158], 4480: [13163], 3523: [13164], 1642: [13165, 13297], 15065: [13166], 19726: [13168], 15171: [13169], 14873: [13171], 14883: [13173], 13576: [13174], 15152: [13175], 15128: [13176, 13414], 14772: [13177, 13396, 13746, 13748], 15599: [13178], 4767: [13180], 19559: [13181], 6177: [13182], 17932: [13185], 15322: [13188], 2667: [13189], 14358: [13193], 14446: [13195], 13863: [13196], 16062: [13197], 18154: [13199], 14714: [13200], 19723: [13201, 13756], 1200: [13203], 13892: [13204], 1050: [13208, 13321], 1251: [13210], 1665: [13211], 1622: [13212, 13505, 13538, 13549, 13551, 13552, 13630, 13652, 13657, 13674, 13675, 13754, 13790], 19420: [13213], 16426: [13215, 13258], 17053: [13216], 334: [13218], 10840: [13219], 10870: [13220], 6608: [13221], 17821: [13222], 6432: [13223], 5693: [13224], 9502: [13225], 19382: [13227], 15963: [13229], 9157: [13230], 9992: [13231], 302: [13232], 1: [13234], 5172: [13235], 506: [13237], 9697: [13239], 10862: [13240], 6656: [13241], 9629: [13244], 9303: [13245], 18915: [13246], 16727: [13247], 6508: [13248], 9251: [13249], 16381: [13250], 10892: [13252], 6460: [13256], 11111: [13262], 9215: [13263], 6556: [13264], 8565: [13265], 10888: [13266], 8528: [13272], 9440: [13273], 5742: [13274], 7509: [13275], 12075: [13276], 15096: [13277], 4618: [13278], 4544: [13279], 4619: [13280], 3462: [13282], 15604: [13283], 15071: [13285, 13292], 3489: [13286], 15584: [13287], 15199: [13289], 15086: [13290], 15137: [13291], 14664: [13293], 6650: [13295], 15581: [13299], 14690: [13300], 19717: [13304], 14468: [13307], 4502: [13308], 283: [13310], 15381: [13311], 503: [13313, 13456, 13464, 13575], 14527: [13317], 14582: [13319], 1703: [13320], 13948: [13322], 14701: [13323], 6133: [13324, 18380], 5121: [13327], 17342: [13328], 709: [13329], 16968: [13330], 15448: [13331], 15572: [13332], 15582: [13335], 1144: [13336], 17825: [13337], 6658: [13338], 1631: [13339], 14629: [13340], 1643: [13341, 13519, 13625, 13649, 13757, 13758, 13760, 13769, 13850, 13889, 13912], 7819: [13342], 19458: [13343], 13828: [13344], 18020: [13346], 6807: [13348], 451: [13349, 13522], 6220: [13350], 15914: [13351], 6567: [13352], 8407: [13358], 6835: [13362], 9392: [13363], 9296: [13368, 13447, 13583], 10450: [13369], 18439: [13370], 7882: [13373], 8492: [13374], 10380: [13375], 949: [13376], 7491: [13380], 9400: [13381], 9244: [13385], 7761: [13387], 19140: [13389], 17120: [13391], 7104: [13392, 14059], 5727: [13393, 14478, 15008], 7046: [13394], 15168: [13395], 17677: [13397], 15091: [13398], 4469: [13399], 3453: [13401], 4510: [13402, 13403], 15084: [13404], 4527: [13405], 3519: [13406, 14667], 19460: [13407], 14343: [13409], 4623: [13410], 15080: [13411], 4491: [13412], 3209: [13415], 15577: [13416], 441: [13417, 13459], 492: [13418], 6206: [13421], 564: [13422], 18657: [13423], 13949: [13424], 9582: [13427], 18066: [13428], 17747: [13431], 15629: [13432], 19737: [13436], 19225: [13439, 20698, 21578], 10089: [13440], 16921: [13441], 7466: [13442], 5686: [13443], 7530: [13446], 9299: [13449], 9369: [13451], 7820: [13453], 16604: [13461], 10859: [13462, 13592, 13691, 13712, 13737], 16065: [13465], 15932: [13466], 9308: [13467], 964: [13468, 15396, 30319], 11093: [13470], 9608: [13471], 6829: [13472], 9245: [13474], 16082: [13475], 6595: [13476], 6833: [13478], 6190: [13479], 9081: [13480], 7180: [13481], 8075: [13482], 7721: [13483], 11097: [13484], 10676: [13486], 6476: [13487], 11746: [13489], 5552: [13491], 11525: [13492], 16594: [13494], 12711: [13497], 5437: [13498], 5733: [13499], 1505: [13502], 4615: [13503], 15211: [13504], 4508: [13506], 3521: [13507, 14093, 14103, 14213, 14339], 4499: [13508], 15500: [13512], 15136: [13513], 511: [13515], 1135: [13516, 13540], 3377: [13517], 1155: [13518], 19596: [13520], 1709: [13523], 3326: [13524], 16916: [13528], 1566: [13531], 1501: [13535], 6440: [13537], 14564: [13539], 17355: [13541], 19087: [13543], 1957: [13544], 5333: [13545], 19282: [13546], 15451: [13547], 17972: [13554], 18406: [13555], 4966: [13556], 6458: [13557], 19274: [13558], 6533: [13559], 561: [13560], 6139: [13564, 13589, 13687], 10910: [13567], 9182: [13568], 3188: [13569], 10850: [13571, 14169, 14199, 14277], 241: [13572], 10328: [13574], 9718: [13576, 13577], 1185: [13579], 484: [13581], 690: [13585], 9464: [13586], 16405: [13587], 19383: [13590], 10343: [13594], 10330: [13596], 9298: [13597], 962: [13598], 10119: [13601], 12297: [13602], 6576: [13603], 12712: [13605], 12314: [13606], 5726: [13607, 13744, 13980], 8953: [13608], 10035: [13609], 8487: [13610, 13823], 16069: [13611, 13720], 17148: [13613], 10377: [13615], 6616: [13618], 11082: [13620], 7176: [13621], 5868: [13622], 7082: [13623], 4467: [13627, 14102, 14215], 4627: [13629, 13638], 15076: [13633, 13999], 1502: [13634], 4551: [13635], 18802: [13636], 15158: [13637], 15127: [13639, 14513], 14945: [13640], 12748: [13641], 15165: [13642], 15202: [13643], 1053: [13644, 13903], 3344: [13645], 3520: [13646], 19742: [13647, 13802], 5040: [13651], 1141: [13653], 494: [13654], 19646: [13655], 6825: [13656], 16935: [13660], 1764: [13661], 6154: [13662], 1612: [13663, 13905, 14009], 14581: [13664], 6088: [13665], 14644: [13666], 18158: [13667], 479: [13668, 13818], 7526: [13669], 14720: [13670, 13894, 14395], 13821: [13671], 13864: [13672], 1067: [13673], 15939: [13676], 17343: [13677], 6140: [13680, 15606], 19279: [13682], 18323: [13684], 7821: [13685], 15750: [13688], 14005: [13689], 9314: [13693], 9025: [13694], 29: [13695], 489: [13696], 6466: [13697], 8026: [13698], 480: [13699], 17170: [13701], 16011: [13702], 9828: [13703], 452: [13704, 13926, 13935, 14032, 14144, 14158, 14276], 676: [13706], 8817: [13708], 9393: [13709], 31: [13710], 5802: [13711], 16056: [13713], 7779: [13714, 16296, 19235, 21852, 25227, 25776, 25837, 25841, 25927, 26343, 26379, 26390, 26439, 26599, 26634, 26663, 26685, 27178], 15899: [13715], 9510: [13717], 18393: [13718], 8192: [13719], 16427: [13721], 12613: [13722], 7759: [13723], 10851: [13724], 6474: [13725], 12308: [13726, 13843], 5481: [13727], 7169: [13728], 17156: [13729, 14079], 7051: [13730, 14642], 6176: [13731], 5749: [13732], 12211: [13733], 11762: [13734, 15810], 10948: [13735], 15900: [13738], 8818: [13739], 8071: [13741], 7002: [13742], 5750: [13743], 5747: [13745], 15083: [13747], 4465: [13749, 13855, 14096, 14104], 14779: [13751], 4511: [13753], 4463: [13755, 13851, 13991, 14223], 15050: [13759], 15134: [13761], 15079: [13762], 15129: [13763, 14672], 1066: [13764, 14107], 14846: [13765], 720: [13768, 14028, 14261, 14556, 14873, 14958, 15081, 15098, 15104, 15108], 19270: [13771], 1563: [13773], 15457: [13775], 6459: [13776], 1456: [13777], 493: [13779], 14009: [13780, 14013, 14014], 6174: [13781, 14021], 13957: [13782], 14392: [13783], 4821: [13784], 13872: [13786, 14240], 13974: [13787], 1662: [13788], 5315: [13789], 14569: [13792], 16903: [13793], 17933: [13794], 2788: [13795], 2654: [13796], 13871: [13797], 13855: [13798], 1360: [13800], 1530: [13801], 6800: [13803], 312: [13804], 19549: [13805, 24711], 19729: [13806], 19542: [13807], 10911: [13808], 16771: [13809], 491: [13811], 9209: [13812, 13934], 9370: [13815, 13839], 9107: [13816], 9264: [13817, 13932], 8719: [13819, 18940], 445: [13820], 9388: [13821], 10331: [13822], 17052: [13824], 11085: [13825], 17989: [13826], 17010: [13827], 16480: [13828], 6605: [13830], 10574: [13832], 7756: [13833], 6597: [13834], 11498: [13835], 8608: [13836], 8347: [13837], 19049: [13838], 8665: [13841], 5485: [13844], 7762: [13845], 12330: [13847], 5716: [13848], 15200: [13849], 15172: [13852], 4505: [13861], 15078: [13862, 13866, 13868, 13871, 14090, 14209, 14211, 14212, 14217, 14224, 14228, 14230, 14231, 14326, 14328, 14329, 14330, 14331, 14334, 14335, 14336, 14337, 14338, 14340, 14344, 14347, 14348, 14349, 14350, 14351, 14353, 14355, 14356, 14357, 14358, 14359, 14360, 14361, 14362, 14364, 14366, 14367, 14368, 14369, 14371, 14372, 14492, 14502, 14523, 14841, 14842], 15120: [13867], 15097: [13869], 14881: [13870], 15445: [13877], 6536: [13881], 7571: [13882], 6607: [13883], 1139: [13884], 7037: [13886], 6218: [13892], 3848: [13895], 16901: [13898], 1076: [13899, 13917, 14404], 1605: [13900, 14008, 14018, 14133], 18889: [13901], 19283: [13902], 1162: [13904], 14715: [13906], 1289: [13910], 19088: [13911], 19730: [13913], 1164: [13914], 16926: [13915], 2671: [13919], 373: [13921], 19572: [13922], 16923: [13923], 17920: [13924], 696: [13925], 8174: [13927], 9167: [13928, 14275], 16067: [13929, 14764], 9102: [13930, 14434, 16603, 16776, 16790, 17060, 17070, 17092, 17096, 17222, 17223, 17225, 17229, 17230, 17231, 17233, 17235, 17240, 17242, 17251, 17252, 17253, 17255, 17256, 17257, 17260, 17261, 17263, 17267, 17270, 17272, 17273, 17274, 17275, 17278, 17279, 17280, 17281, 17288, 17294, 17297, 17300, 17302, 17308, 17311, 17312, 17313, 17325, 17342, 17350, 17353, 17355, 17366, 17371, 17503, 17520, 17523, 17525, 17549, 17597], 836: [13933], 10391: [13936, 14041], 9205: [13937, 14604], 499: [13938], 509: [13939], 9413: [13940], 8047: [13942], 8510: [13943], 9467: [13944], 17987: [13945], 17950: [13946], 7175: [13947], 9158: [13948], 9324: [13949], 9709: [13950], 8478: [13951], 9402: [13952], 770: [13953], 16412: [13954], 11042: [13955], 12547: [13956, 17801], 16401: [13957, 21738], 9277: [13958], 8149: [13960], 6542: [13961], 6052: [13962], 6124: [13963], 10570: [13965, 17617], 16406: [13966], 10466: [13968], 18622: [13970], 10882: [13971], 9408: [13972], 11744: [13973], 11551: [13974], 15828: [13975], 17316: [13976], 8721: [13977], 18249: [13978], 7208: [13981], 7118: [13982], 10708: [13983], 6018: [13985], 14773: [13986], 15077: [13987, 14108], 4478: [13988, 13989, 13990, 14100], 15141: [13992], 3624: [13993, 21959], 15095: [13995], 15219: [13996, 14525], 1157: [13997, 14241, 14669], 4542: [13998], 15163: [14000], 15092: [14001, 14327, 14333, 14488, 14490, 14498, 14499, 14506, 14511, 14521, 14526, 14527, 14680], 531: [14002], 14692: [14003], 6193: [14004, 14802], 9595: [14007], 17350: [14012], 15600: [14015, 14110, 14402], 1636: [14016], 6092: [14019], 1567: [14020], 252: [14022], 18278: [14023], 7143: [14024], 18927: [14025], 16597: [14026], 4958: [14027], 9170: [14029], 7971: [14031], 7620: [14033], 6461: [14034], 9297: [14035, 14266, 14435], 9284: [14036, 14170, 14576, 14579, 14581, 14586, 14588, 14593, 14594, 14603, 14606, 14614, 14730, 14745, 14748, 14775, 14788, 14975, 15138], 9218: [14037], 510: [14039], 4973: [14040], 9259: [14042], 94: [14043], 10476: [14044], 10090: [14046], 8339: [14047], 12612: [14048], 9122: [14049], 16609: [14050], 6433: [14051], 9114: [14052], 824: [14053], 9309: [14054], 10412: [14055], 7503: [14056], 10785: [14057], 5249: [14058, 17176, 18077, 18551, 19023, 21620, 24761, 27372, 28054, 28309, 28327, 28609, 28637, 28672, 28684, 28687, 28730, 29200, 29201, 29203, 29204, 29209, 29211, 29218, 29222, 29224, 29227, 29235, 29236, 29243, 29247, 29266, 29267, 29270, 29271, 29273, 29275, 29276, 29278, 29281, 29286, 29288, 29292, 29295, 29297, 29313, 29316, 29326, 29329, 29334, 29336, 29338, 29340, 29341, 29342, 29349, 29352, 29357, 29359, 29365, 29366, 29367, 29378, 29381, 29421, 29426, 29444, 29457, 29465, 29474, 29494, 29498, 29502, 29504, 29508, 29510, 29511, 29517, 29523, 29530, 29534, 29545, 29564, 29566, 29571, 29573, 29574, 29577, 29588, 29596, 29608, 29625, 29626], 10567: [14060], 6178: [14061], 8296: [14062], 6546: [14063], 9446: [14064], 9621: [14065], 16099: [14066], 7047: [14067], 10564: [14068], 6903: [14069, 21796, 21859], 8320: [14070], 12117: [14071], 910: [14072], 11432: [14073], 10478: [14074], 9947: [14075], 7022: [14076], 12124: [14077, 19796], 7083: [14078], 16237: [14080, 15000], 7646: [14081], 5528: [14082], 5533: [14083], 5534: [14084], 6974: [14085], 5549: [14086], 7028: [14089], 1606: [14091, 14563], 1191: [14092], 15015: [14094], 3522: [14095], 3482: [14098], 3533: [14099], 19461: [14101], 4479: [14105], 15160: [14106], 1638: [14109], 14988: [14111], 15093: [14112, 14113, 14210, 14218, 14509, 14653, 14655, 14656, 14670, 14671, 14673, 14674, 14675, 14676, 14678, 14679, 14843, 14860, 14865], 15587: [14114], 15159: [14115], 15085: [14116], 3491: [14117], 335: [14118], 17811: [14119], 15550: [14120, 21252, 22029, 22385, 22388, 22389, 22392, 22408, 22409, 22410, 22411, 22413, 22414, 22418, 22421, 22422, 22423, 22425, 22427, 22429, 22434, 22435, 22437, 22438, 22447, 22448, 22449, 22458, 22463, 22499, 22875, 22880, 22914, 22931, 22961, 22963], 1298: [14122], 14686: [14123], 13853: [14124], 14447: [14125], 14687: [14126], 14397: [14127], 1154: [14129], 1947: [14130], 24: [14131], 6181: [14132], 10129: [14134], 1158: [14135], 1142: [14136], 1260: [14137, 14139], 1551: [14138], 15668: [14141], 19677: [14142], 10307: [14143], 19575: [14145], 18532: [14146], 11080: [14147], 311: [14148], 255: [14150], 752: [14151], 9636: [14152], 9018: [14153, 20563], 652: [14154], 7990: [14155], 9234: [14156], 8497: [14157], 275: [14159], 9201: [14160, 14951], 9646: [14161, 14285], 9278: [14162], 281: [14163], 529: [14164], 10309: [14165], 10949: [14167], 9793: [14168], 6503: [14171], 524: [14172], 9344: [14173], 11071: [14174], 16989: [14175], 18894: [14176], 5042: [14177], 7507: [14178], 10472: [14180], 16614: [14181, 14281], 5255: [14182, 21648], 8734: [14183], 16461: [14184, 20187], 9551: [14185], 15646: [14186, 14195], 7102: [14187], 10861: [14190], 16391: [14191], 11078: [14192], 16057: [14193], 11127: [14194], 11497: [14196], 16460: [14197], 11493: [14198], 8566: [14200], 7558: [14201], 7048: [14203], 12148: [14205], 5884: [14206], 1570: [14208, 14896, 15013, 15015, 15017, 15018, 15028, 15034, 15042, 15047, 15177], 2: [14214], 4476: [14216, 14235, 14237, 14345, 14376, 14377, 14532], 4466: [14219], 4509: [14220], 5774: [14221, 14462, 14476, 14644, 14814], 15082: [14222, 14489, 14494, 14500, 14507, 14508, 14512, 14517, 14518, 14520, 14522, 14657, 14668, 14682, 14844, 14859], 14791: [14225], 15161: [14226], 13889: [14229], 1213: [14232, 19309], 16930: [14233, 14531], 3375: [14234], 1138: [14236], 14807: [14238], 14709: [14242], 15601: [14243, 14252, 14392, 14403], 19655: [14244], 14455: [14245], 17851: [14246, 14542, 15041], 13955: [14247], 19583: [14248, 14906, 15224, 15231], 3739: [14249], 1980: [14250], 15608: [14251], 1247: [14253], 16880: [14254], 301: [14256, 14545, 15043], 2790: [14257], 918: [14258], 777: [14259, 14567, 14569], 6179: [14260], 19209: [14262], 3791: [14263], 442: [14264], 10456: [14265, 16993], 11056: [14268], 16894: [14269], 672: [14270, 16514, 16564], 8591: [14271], 15934: [14272, 16254, 16406], 9173: [14273], 537: [14274], 507: [14278], 9210: [14279, 14578], 17437: [14280], 16573: [14282], 7490: [14283, 15311], 7527: [14284], 11118: [14286], 9540: [14287], 6221: [14288, 14721, 14875, 14900, 15091, 15193, 15195, 15286, 15358, 15422], 11081: [14289], 790: [14290, 18412, 24774, 24843, 25602], 6572: [14291], 8605: [14293], 18916: [14294], 6175: [14295], 10879: [14296, 14620], 6657: [14297], 10565: [14298], 16400: [14299], 11827: [14300, 17732, 18190], 5258: [14301], 8190: [14302], 16100: [14304], 10423: [14305], 10420: [14306], 16058: [14307], 10855: [14308], 11808: [14309], 11306: [14311], 11095: [14312], 7681: [14313], 9364: [14314], 10809: [14315], 9651: [14316], 15937: [14317], 7078: [14319], 7011: [14320], 7049: [14321], 5792: [14323, 17157, 17412, 17613, 17614, 17619, 18024], 5440: [14324], 5717: [14325], 19540: [14332], 3497: [14341, 14342], 4513: [14343], 4472: [14346, 14495, 14501], 15094: [14352, 14654, 14839, 14840, 14855, 14861, 14863, 14866, 15322], 15122: [14354], 14805: [14363], 14882: [14365], 15153: [14370], 478: [14373], 15568: [14374], 15379: [14375], 694: [14378, 14917, 15037, 15064, 15218, 15228, 15361], 15461: [14379], 700: [14380, 15057, 15186, 15357, 15384, 15415, 15424, 15587], 15173: [14381], 553: [14382], 443: [14383], 2670: [14384], 15585: [14385], 1296: [14386, 14555], 5119: [14387], 14747: [14388], 18681: [14389], 1077: [14390, 15352], 14724: [14391, 14687, 15201], 14561: [14393], 14698: [14394], 18143: [14396], 14576: [14397], 6469: [14398], 10707: [14399], 3746: [14400], 17900: [14401], 19183: [14405], 9204: [14408], 16994: [14409], 450: [14410, 14412, 14599], 3854: [14411], 19712: [14413], 17792: [14414], 9235: [14415], 17005: [14416], 1125: [14417, 16401], 19627: [14418], 13890: [14419], 5776: [14420], 9340: [14421, 14978, 15416], 9371: [14423], 9285: [14424], 692: [14426, 14529, 14536, 14877, 14953, 14987], 18025: [14427], 9353: [14428], 10393: [14429], 532: [14430], 9350: [14431], 665: [14432], 314: [14433], 10852: [14436], 95: [14437], 8512: [14438], 8137: [14439], 6991: [14440], 9083: [14441, 16070, 17717, 17723, 17736, 17921, 17927, 17931, 17938, 18147, 18360], 16428: [14442], 9396: [14444], 16036: [14445], 6591: [14446], 9645: [14447], 9220: [14448], 6579: [14449], 8737: [14450], 7987: [14451], 10132: [14452], 18621: [14455], 15792: [14456], 6554: [14457], 18969: [14458], 10433: [14459], 10883: [14460, 14608], 9664: [14461], 9397: [14463], 11647: [14464], 9292: [14465, 14609], 11494: [14466, 14641, 15153], 8597: [14467], 10829: [14469], 18899: [14470], 10577: [14471], 11763: [14472], 10880: [14473], 12549: [14474, 16853], 8814: [14475], 5819: [14479], 5753: [14480], 5729: [14484], 4468: [14491], 3601: [14493], 4474: [14496], 3555: [14497], 2681: [14503, 14541], 14588: [14504], 15155: [14505], 1056: [14510], 14792: [14514], 15142: [14515], 15024: [14516], 3253: [14519], 15135: [14524], 15492: [14528], 18571: [14530], 1554: [14533, 14660, 14693], 14444: [14535], 6834: [14537], 706: [14538], 8351: [14539], 15602: [14540], 5027: [14544, 20810, 21553], 14721: [14546], 16634: [14547, 14893], 19392: [14548], 19296: [14549], 1961: [14550], 3247: [14551], 533: [14552, 14726], 14748: [14553], 1641: [14554], 14731: [14557, 15890], 6831: [14558], 19271: [14559], 17796: [14560], 19018: [14561], 19326: [14562], 10167: [14564, 25671, 30247, 31365, 31370, 31397, 31399, 31403, 31407, 31413, 31417, 31428, 31454, 31494, 31505, 31520, 31522, 31542, 31547, 31550, 31552, 31560, 31580, 31582, 31584, 31589, 31594, 31602, 31603, 31609, 31628, 31644, 31650, 31669, 31680, 31821, 32214, 33395], 256: [14565], 525: [14568], 1834: [14570, 15279], 16689: [14571], 16826: [14572, 14914], 16590: [14573], 268: [14574], 265: [14575], 9301: [14580], 1944: [14583], 666: [14584], 461: [14585, 15220, 15263], 19738: [14587], 16041: [14589], 282: [14590], 10866: [14591, 15112], 9115: [14592], 9168: [14595], 17336: [14596], 10912: [14597], 13895: [14598], 9169: [14600, 14733, 14769, 15275], 19129: [14605], 8169: [14607], 6191: [14610], 9609: [14611], 10383: [14612], 7716: [14615], 7736: [14617, 22142, 27043, 27254, 27611, 27619, 27625, 27628, 27673, 27682, 27686, 27729, 27736, 27738, 27739, 27756, 27775, 27789, 27819, 27838, 27848, 27856, 27905, 27907, 27911, 27925, 27937, 27943, 27959, 27966, 27981, 27984, 27990, 28500, 28538], 15740: [14618], 18682: [14619], 9681: [14621], 10944: [14622], 9166: [14624], 10678: [14625], 6839: [14626], 16055: [14627], 12702: [14629, 16140, 16638, 16655, 17156], 10884: [14630], 11753: [14631], 11476: [14632], 11702: [14633], 12740: [14634], 9221: [14636], 11717: [14637], 12339: [14638], 16440: [14639], 12639: [14640, 16839, 17370], 11057: [14645], 5852: [14646], 5823: [14647, 16700, 16897, 17133, 17419, 17623], 5844: [14648], 8735: [14650], 5757: [14651], 4473: [14658, 14662, 14666, 14849, 14850, 14852, 14856, 14857, 14858, 14869, 15021], 15169: [14659], 3494: [14663], 4457: [14664], 3546: [14665], 1555: [14677, 15531], 9818: [14681, 15069], 4621: [14683], 15505: [14684, 23871, 24658, 24666, 24675, 24682, 25598], 6535: [14685], 6219: [14686], 15475: [14688], 15558: [14689, 14889, 21253, 21973, 22393, 22395, 22396, 22401, 22404, 22433, 22452, 22839, 22841, 22842, 22843, 22845, 22846, 22847, 22848, 22849, 22851, 22853, 22854, 22856, 22857, 22858, 22860, 22861, 22862, 22863, 22864, 22866, 22867, 22868, 22869, 22870, 22871, 22872, 22873, 22874, 22876, 22877, 22878, 22881, 22882, 22886, 22887, 22888, 22889, 22890, 22891, 22893, 22895, 22896, 22897, 22898, 22899, 22900, 22901, 22902, 22904, 22905, 22906, 22907, 22909, 22910, 22912, 22913, 22917, 22918, 22919, 22920, 22921, 22923, 22928, 22929, 22933, 22934, 22936, 22940, 22944, 22946, 22947, 22948, 22951, 22953, 22954, 22956, 22959, 22965, 22966, 22968, 22971, 22972, 22973, 22974, 22975, 22977, 22978, 22980, 22983, 22984, 22985, 22988, 22989, 23343], 14558: [14691], 9710: [14692], 19299: [14694], 6434: [14695], 3841: [14696], 1242: [14697], 19395: [14698], 3355: [14699], 15588: [14700], 17421: [14701], 1627: [14702], 1264: [14703], 18116: [14704], 18050: [14705], 16010: [14706], 3839: [14707], 6688: [14708], 6192: [14709, 15385], 6504: [14710], 19321: [14711], 19574: [14712], 9262: [14713], 9286: [14714, 14945, 14957, 14995, 15105, 15121, 15134], 19623: [14715], 6170: [14716], 272: [14719, 15095], 834: [14720], 3843: [14722], 7636: [14724], 711: [14725], 8378: [14738], 719: [14739], 7515: [14740], 713: [14741, 14884, 15226, 15227, 15229, 15234, 15344, 15346, 15397, 15406, 15421, 15495, 15691, 15720, 15764, 15911], 16012: [14747], 9265: [14753, 14791], 9207: [14759], 9089: [14762], 9552: [14768], 56: [14776], 6213: [14777], 9161: [14778, 14972, 14976], 7506: [14782, 14785], 12310: [14783], 9238: [14790], 820: [14793], 17891: [14797], 16407: [14800], 10674: [14801], 10384: [14803], 16728: [14804], 10781: [14805], 10666: [14806, 15435, 16422, 20165, 22186, 22628, 23669, 24239, 25949, 26011, 26018, 26058, 26436, 26438, 26494, 27015, 27017, 27031, 27071, 27211, 27224, 27230, 27235, 27263, 27626, 27679, 27683, 27690, 27692, 27707, 27754, 27757, 27759, 27767, 27772, 27813, 27868, 27884, 27901, 27971, 28280], 5646: [14807], 9622: [14808], 10067: [14809], 11523: [14811], 12316: [14815], 11983: [14816, 17993], 12690: [14817, 17996], 12832: [14818], 5800: [14819], 18366: [14820], 12623: [14821, 18951], 7284: [14822, 15148], 12524: [14823], 15901: [14824], 7174: [14825], 7130: [14826], 10848: [14827], 16570: [14828], 11051: [14829], 9571: [14831], 10590: [14832], 7038: [14833], 7158: [14834], 5477: [14835], 5548: [14836], 7164: [14837], 17675: [14845], 14991: [14846], 15144: [14847], 3550: [14848], 4455: [14851, 15020], 4471: [14853, 15022, 15340], 4609: [14854, 15480], 15458: [14862, 15882], 15106: [14864], 15104: [14867], 7013: [14868], 1562: [14870], 4976: [14871], 19297: [14874], 19273: [14876], 37: [14878, 22475, 23030], 3518: [14879], 1332: [14880], 1244: [14881], 1078: [14883, 15530], 15468: [14885], 14458: [14886], 1604: [14887, 15526], 10086: [14888], 19084: [14890], 10947: [14894, 15039], 1233: [14895], 15437: [14897], 449: [14898, 15113], 1571: [14899, 15074, 15330, 15334, 15349, 15379, 15381, 15382, 15491, 15503], 17732: [14901], 3736: [14902], 19278: [14903, 15588], 5310: [14904, 19161, 29223, 29942, 30162, 30603, 30607, 30608, 30609, 30612, 30615, 30619, 30620, 30621, 30625, 30626, 30628, 30629, 30631, 30632, 30633, 30635, 30646, 30664, 30669, 30671, 30678, 30683, 30702, 30707, 30709, 30725, 30726, 30728, 30736, 30740, 30752, 30754, 30755, 30772, 30777, 30784, 30800, 30801, 30802, 30805, 30806, 30810, 30813, 30817, 30821, 30827, 30837, 30841, 30848, 30850, 30853, 30854, 30860, 30868, 30872, 30876, 30878, 30882, 30884, 30885, 30887, 30891, 30896, 30902, 30903, 30904, 30913, 30916, 30918, 30920, 30924, 30926, 30929, 30933, 30948, 30950, 30951, 30952, 30959, 30971, 30973, 30998, 31382, 31617], 10297: [14905], 1064: [14907], 19625: [14908], 12312: [14909], 931: [14910], 444: [14911], 565: [14912], 556: [14913], 7974: [14920], 42: [14923], 8506: [14926], 453: [14932], 708: [14937, 15394, 15498, 15548, 15669, 15675, 15676, 15685, 15695, 15700, 15713, 15718, 15722, 15723, 15726, 15727, 15732, 15733, 15756, 15761, 15762, 15845, 15848, 15906, 16027, 16055, 16065, 16210, 16345], 703: [14948], 9029: [14955], 9345: [14959], 8808: [14960], 10318: [14965, 18847, 19351, 20412, 20414, 20430, 20437, 20440, 20445, 20460, 20493, 20502, 20520, 20521, 20718, 20754, 21027], 6580: [14967], 46: [14969], 10392: [14970], 10872: [14971], 7459: [14974], 6543: [14977], 8335: [14979], 10317: [14981, 15110, 16369, 16744, 18131, 18175, 18865, 19121, 19357, 20450, 20711, 20727], 9352: [14983, 15109, 15269, 15274, 15417, 15418, 15426, 15434, 15550, 15554, 15562, 15575, 15579, 15728, 15730, 15731, 15738, 15742, 15743, 15744, 15745, 15746, 15747, 15748, 15751, 15753, 15755, 15760, 15765, 15774, 15781, 15792, 15793, 15799, 15804, 15806, 15815, 15920, 15924, 15926, 15964, 16131], 10727: [14984], 10381: [14986], 8442: [14988, 15135], 6526: [14989], 7531: [14990], 10952: [14991, 15149], 10831: [14992], 9239: [14994], 12548: [14998, 15638, 16458], 10768: [14999, 23712, 23790, 24037, 24854, 24906, 25136, 25816, 25842, 25878, 25887, 25899, 25911, 25934, 26075, 26918], 12707: [15001], 11113: [15002], 7023: [15003], 7055: [15004], 5801: [15005], 5815: [15006], 5831: [15007, 16315, 17150, 17153, 17154, 17407, 17411, 17420], 5767: [15009], 7109: [15011], 17676: [15012], 3251: [15014, 15321], 4477: [15016], 15146: [15019, 15030, 15488], 4458: [15023], 3504: [15024], 14818: [15025], 15162: [15026, 15333], 3437: [15027], 15081: [15029, 15335], 15051: [15031], 14344: [15032], 4617: [15033], 3384: [15036], 15518: [15038], 4464: [15040], 14448: [15044], 3206: [15046], 693: [15048], 2668: [15049], 5122: [15051], 15609: [15053, 15878, 15879], 14372: [15054], 14710: [15055], 6375: [15056], 14599: [15059], 16896: [15060], 6094: [15061], 6216: [15062, 15854, 15892], 9572: [15063], 534: [15065], 15501: [15066], 15618: [15067], 15441: [15068], 19373: [15070], 18170: [15071], 19241: [15072], 1572: [15075, 15216], 19245: [15076], 17345: [15077, 15360], 1082: [15078], 16997: [15079], 17344: [15080, 15535], 17109: [15084], 15890: [15085], 10928: [15086], 642: [15087], 16827: [15088], 6505: [15089], 17918: [15092], 19372: [15093], 500: [15094], 10452: [15096], 16605: [15097], 622: [15099, 15264], 17715: [15102], 15997: [15103], 261: [15106], 16063: [15107], 5075: [15111], 9290: [15114, 15242, 15404], 16493: [15115], 7837: [15116], 10424: [15117], 9330: [15118, 15589, 16075, 16081, 16248], 8968: [15122], 7095: [15123], 12302: [15124], 7975: [15125], 16015: [15126], 6573: [15127], 16470: [15128], 16788: [15129], 9579: [15130], 16222: [15132], 8073: [15136], 18671: [15137], 11533: [15139], 9450: [15140], 11487: [15141], 9453: [15142], 12262: [15143], 15669: [15144], 8909: [15145], 10846: [15146], 12589: [15147, 15814, 15818, 16127, 16870], 11496: [15150], 11309: [15151], 11514: [15152, 16288], 12687: [15154, 18238], 5739: [15155], 5820: [15156], 5536: [15157, 15159], 7332: [15158], 5768: [15160, 15472], 5765: [15161], 5771: [15162], 10394: [15163], 5865: [15164], 14974: [15165], 3581: [15166], 19243: [15167], 15116: [15168, 15181, 17838, 18064], 3480: [15169, 15482, 15647, 15649, 16000], 3534: [15170], 15148: [15171], 3483: [15172], 15145: [15173, 15320], 15157: [15174, 15182], 3474: [15175], 14798: [15178], 3455: [15179], 14803: [15180], 4449: [15183, 15490], 3378: [15184], 623: [15185], 3511: [15187], 6166: [15188, 15509], 4629: [15189], 6527: [15190], 14594: [15192], 3246: [15194], 4599: [15196, 15345], 15454: [15197], 18815: [15199], 16961: [15200], 547: [15202], 18155: [15203], 3845: [15205], 5276: [15206], 19741: [15209], 5019: [15210], 16992: [15213], 15611: [15214, 15362], 18574: [15215], 19298: [15217, 15390, 15514, 16360], 13896: [15219], 18072: [15221], 5221: [15222], 19267: [15223, 15710], 19624: [15225], 19573: [15230], 5307: [15233, 28803, 29246, 30890, 31313, 32331], 9006: [15235, 15304], 9356: [15236], 9338: [15237], 9391: [15239], 315: [15240], 8601: [15241], 10981: [15243], 5036: [15244], 9163: [15245], 8337: [15246], 9288: [15247], 549: [15251], 15909: [15252], 393: [15253], 9164: [15254], 530: [15255], 555: [15257], 17157: [15258], 17826: [15259], 699: [15261], 67: [15262], 854: [15265], 257: [15266], 9380: [15267], 10938: [15268, 15273, 15776, 15932], 8048: [15270], 17101: [15272], 8259: [15276], 9240: [15277], 11087: [15278], 7551: [15281, 21856, 22143, 22157, 22284, 22326, 22347, 22590, 22817], 5165: [15282, 26860, 26917, 26964, 26987], 7145: [15283], 12317: [15284], 10074: [15285, 19129, 19416], 6123: [15287], 9342: [15288], 15284: [15289], 10399: [15290, 16133], 6475: [15292], 15747: [15293], 6837: [15295], 8809: [15296], 8635: [15297], 10582: [15299], 11517: [15300, 15621, 15976, 16103], 7391: [15301], 16769: [15302, 22732, 23114, 23434, 23573, 23630, 24092, 24259, 24282, 24849, 24871, 24882], 11745: [15303], 17234: [15305], 12597: [15306], 11791: [15307], 12676: [15308], 9279: [15309, 15423], 7881: [15310], 5840: [15312], 6993: [15313], 5486: [15315], 5438: [15316], 6013: [15318], 12650: [15319, 17794], 7788: [15323], 15117: [15324], 3567: [15325], 3492: [15326], 3495: [15327], 15074: [15328, 15497], 1188: [15329], 15147: [15331, 15338, 15492], 15149: [15332], 14977: [15336], 15154: [15337, 15642, 15841], 4447: [15339], 701: [15341, 15413, 15539], 4610: [15342], 3365: [15343], 15595: [15347], 1553: [15348], 1718: [15350], 6467: [15351], 18569: [15353], 19605: [15354, 17485], 16934: [15355], 1573: [15356, 15375], 280: [15359], 16806: [15364], 15603: [15365], 19739: [15366], 15605: [15367], 2791: [15368], 10841: [15370], 1301: [15371], 5028: [15372, 15858, 19585, 19613, 19650, 20327, 20330, 20332, 20375, 20433, 20507, 20662, 20719], 16924: [15374], 512: [15377], 1560: [15378, 15483], 1234: [15380], 8334: [15383, 16063, 16073], 1881: [15386], 316: [15387], 19637: [15388], 691: [15389], 715: [15391, 16044, 16333, 16562, 16577], 13996: [15392], 10335: [15393], 16990: [15395], 9294: [15398], 6435: [15399], 19174: [15401], 712: [15402, 16022], 9034: [15403, 15601], 239: [15405], 8405: [15407], 10950: [15408], 9165: [15409], 878: [15410], 10334: [15412], 9119: [15414, 15564, 16420], 9199: [15420], 12277: [15425], 17790: [15427], 6215: [15428, 16419], 9401: [15430], 8294: [15431], 16371: [15432], 8134: [15433, 15438], 769: [15436], 17140: [15437], 9698: [15439], 10867: [15442], 11312: [15443], 10853: [15444, 15449], 5287: [15445], 12270: [15446], 9346: [15447, 15907], 16530: [15450], 12502: [15451], 16000: [15452], 7461: [15453], 11495: [15454], 11490: [15455, 15965], 11747: [15456], 11073: [15457], 6852: [15458], 7545: [15459], 11519: [15460], 9658: [15461], 7468: [15463], 7532: [15464], 11481: [15465], 12780: [15466], 12699: [15467], 12592: [15468, 16461, 17588], 5764: [15469, 15635, 15824], 7091: [15470, 15473], 5769: [15471], 5640: [15474], 5505: [15476], 15143: [15477, 15494, 15641, 15832], 3580: [15478], 3547: [15479], 3457: [15481], 3541: [15484], 3590: [15485], 4442: [15486, 15487, 15499, 16018], 15118: [15489], 14982: [15493], 15467: [15496], 13822: [15500], 1084: [15501], 4540: [15502], 2631: [15504], 14592: [15505], 19658: [15506], 1933: [15507], 14697: [15510, 15657, 15673, 15678, 15679, 15680, 15687, 15859, 15862], 2793: [15511], 14601: [15512, 15860], 14431: [15513], 14450: [15515], 14722: [15516], 14643: [15517], 6211: [15518], 17092: [15519], 671: [15520, 15594, 16066], 3767: [15521], 16910: [15522], 9336: [15523], 15435: [15524], 1161: [15525], 17378: [15527], 1195: [15528], 14570: [15529], 1079: [15532, 15706], 1201: [15533], 1955: [15534], 16902: [15536], 19593: [15538], 10337: [15540], 16798: [15541], 19594: [15542], 19622: [15543], 882: [15544], 1835: [15545, 15757], 16904: [15546], 6141: [15547], 7891: [15553], 2626: [15555], 19300: [15557], 8511: [15558], 17881: [15561], 4981: [15567], 792: [15568], 717: [15569], 9112: [15571], 9208: [15574], 10407: [15577, 16093], 679: [15578, 15919], 9341: [15580], 670: [15584], 9232: [15592], 10830: [15595], 6540: [15596], 11709: [15597, 17558, 19740, 20113, 20257, 20275, 20876], 7640: [15599, 16607], 17149: [15600], 5023: [15602], 7637: [15603], 6167: [15607], 6547: [15608], 9891: [15609], 10418: [15610], 9394: [15611], 10942: [15612], 10481: [15613], 10687: [15614], 11417: [15615], 12255: [15617], 11089: [15618], 11526: [15619], 11518: [15620], 15285: [15622], 12675: [15623], 16574: [15624], 8911: [15625], 12136: [15626, 19797], 5746: [15627, 16311], 8928: [15628], 11511: [15629], 5838: [15632], 5482: [15633], 5846: [15634], 5537: [15636], 12664: [15637, 16137, 16445, 16702, 16878], 5487: [15639], 5506: [15640], 14978: [15643], 4456: [15645, 15648, 15652], 3454: [15646], 19301: [15650], 15075: [15653, 15842, 16167], 1063: [15654], 3463: [15655], 18148: [15656], 1558: [15658], 15217: [15659], 15105: [15661], 3605: [15662], 15150: [15663, 15666, 15835], 1159: [15664], 14802: [15665, 15840], 14219: [15667], 3271: [15668], 3358: [15670], 638: [15671, 17208], 15519: [15672], 13893: [15674], 14528: [15677], 14705: [15681], 15564: [15682], 19632: [15683], 4980: [15684], 16933: [15686], 13952: [15688], 14359: [15689], 1953: [15690], 16966: [15693, 15885, 15894], 446: [15694], 1140: [15696], 1243: [15697], 1342: [15699], 19595: [15701], 19231: [15702], 8927: [15703], 1273: [15704], 4822: [15705], 19285: [15707], 18396: [15708], 19020: [15709], 704: [15711], 6222: [15712, 15786], 6217: [15714], 19644: [15715], 4979: [15716], 6539: [15717], 10313: [15719], 695: [15721], 1893: [15724, 15929], 17809: [15725], 10254: [15729], 8785: [15734], 9019: [15735], 9289: [15736], 19275: [15737], 9200: [15740], 8180: [15741, 21386, 21734, 22550, 23495, 23955, 23962, 24214, 24789, 24847], 535: [15749], 9153: [15750], 6113: [15759], 10953: [15763], 8599: [15766], 9404: [15767], 16471: [15770], 16032: [15771], 9726: [15772], 1854: [15773, 15946], 10881: [15778], 6659: [15779], 10688: [15780], 10675: [15783], 6156: [15784], 9160: [15785], 6802: [15787], 19152: [15788], 10333: [15789], 4834: [15790], 19041: [15791], 11123: [15794, 15967], 10458: [15795], 15727: [15796], 8432: [15797], 12311: [15798], 5766: [15800], 10660: [15801], 11492: [15802], 9538: [15803], 11406: [15805], 10939: [15807, 15813, 15930, 16112, 16279], 10425: [15808], 7477: [15809], 9176: [15811, 16241], 11715: [15812], 11491: [15816], 7056: [15817], 7108: [15819], 7033: [15820], 5532: [15822], 5728: [15823], 7770: [15825], 7092: [15826], 5762: [15827], 5761: [15828], 12659: [15829, 15979], 5472: [15830], 3262: [15834], 15484: [15836], 15103: [15837, 16326], 15371: [15844], 3382: [15846], 3374: [15847], 1363: [15849], 19539: [15850, 16041, 16052], 3360: [15851, 18536], 1249: [15852], 14725: [15853], 16962: [15855], 14466: [15856], 16914: [15857], 1194: [15861], 14598: [15863], 14595: [15864], 1080: [15865, 16221, 16497, 16509], 14354: [15866], 13953: [15867], 1248: [15868], 3776: [15869], 15382: [15870], 173: [15871], 1556: [15872], 17810: [15873], 18531: [15874], 15651: [15876], 1198: [15877, 17680, 17874], 15442: [15881], 17857: [15884], 1083: [15886], 1294: [15887], 17429: [15888], 974: [15889], 1062: [15891], 19224: [15893], 19620: [15895], 19269: [15896, 15903, 15933, 16219, 16220], 860: [15897], 19621: [15898], 10002: [15900], 879: [15902], 17766: [15904], 1972: [15905], 16546: [15908], 9180: [15909], 263: [15912], 9351: [15913, 16088, 16264], 10954: [15914], 572: [15915], 454: [15916], 626: [15917, 16249], 16064: [15918], 681: [15921], 689: [15922, 16382], 9329: [15923, 16237], 9108: [15925, 16393, 16400, 16416], 1825: [15927], 9339: [15928], 322: [15931], 16408: [15934], 16016: [15935], 10385: [15936], 12591: [15937, 16060, 16155, 17125, 17377], 16353: [15938], 16472: [15939], 6087: [15940], 11197: [15941], 8995: [15942], 6801: [15943], 15870: [15944], 10410: [15945], 7502: [15947], 985: [15948, 25534], 11482: [15949], 9171: [15950], 1826: [15951], 11488: [15952, 16136, 16650], 6803: [15953], 1000: [15954], 6102: [15955], 6516: [15956], 8350: [15957, 17069], 7498: [15959], 7093: [15960], 4959: [15961], 10396: [15962], 8938: [15963], 10833: [15966], 12682: [15968], 12673: [15969, 16654, 17112], 19085: [15970], 9377: [15971], 11509: [15972], 9090: [15973], 10926: [15974], 9325: [15975], 11792: [15977], 12588: [15978, 17123], 12841: [15980], 7514: [15981], 5473: [15983], 17214: [15985], 12131: [15986], 5854: [15987, 17624], 7050: [15989], 17200: [15990], 5810: [15991], 12587: [15992, 16300, 16694], 12663: [15993, 16308, 17579, 17995], 3538: [15998, 17426, 17632, 17634, 17635, 17636, 17834, 17841, 17842, 17843, 18052, 18061], 3458: [15999, 16160], 3540: [16001], 3493: [16003], 14723: [16006], 15402: [16011], 4444: [16016], 14975: [16017], 14872: [16023], 4600: [16024], 1059: [16025], 3850: [16026], 14377: [16028], 5012: [16029], 637: [16030, 16398], 13867: [16031], 6548: [16032], 14717: [16033], 3774: [16034], 19010: [16035], 15496: [16036], 15566: [16037], 17049: [16038], 6199: [16039], 14604: [16040], 15440: [16042], 18977: [16043], 19317: [16045], 3772: [16046], 5148: [16047], 14730: [16048, 16356], 18933: [16049], 317: [16050], 18117: [16051], 19008: [16053], 17831: [16054], 19277: [16056], 10736: [16058], 8987: [16059, 16128, 16269, 16286], 16785: [16061], 19057: [16062], 1978: [16064], 10226: [16067], 9291: [16068], 17694: [16069], 9159: [16071, 16246], 9331: [16072], 8486: [16074], 6836: [16076], 9010: [16077], 550: [16078], 8029: [16079], 9050: [16080], 1919: [16082, 17249], 17863: [16083], 634: [16084], 6574: [16085], 8826: [16086], 11718: [16087], 6070: [16089], 10571: [16090], 9181: [16091], 11515: [16092], 9395: [16094], 11748: [16095], 8340: [16096], 7516: [16098], 8042: [16099], 7363: [16100], 16330: [16101], 11608: [16102], 9088: [16104, 16236, 16789], 19173: [16105], 6524: [16106], 10084: [16107], 826: [16108], 5060: [16109], 9343: [16110], 10406: [16111], 10416: [16113, 18966], 15745: [16114], 9914: [16115], 11513: [16116, 16119], 7010: [16117], 7978: [16118], 8568: [16120], 17759: [16121], 11516: [16122, 16123, 16861], 9451: [16124], 10984: [16125], 16979: [16129], 5921: [16130], 11708: [16132, 19444], 12149: [16134], 10568: [16138], 12556: [16139, 17382], 12695: [16142, 17100, 18193], 5535: [16144], 10387: [16145], 5529: [16146], 5682: [16150], 12661: [16151, 16291, 17629], 14778: [16154], 15910: [16156], 14986: [16161], 3600: [16162], 4443: [16164, 16498, 16728], 1163: [16168], 15156: [16170], 3418: [16178], 15121: [16182], 3464: [16190], 3265: [16191], 3366: [16193], 14638: [16194], 3367: [16195], 3204: [16196, 16721, 16924, 16928], 1388: [16197], 3331: [16198], 10680: [16199], 707: [16200, 16206], 14464: [16201], 3461: [16202], 6511: [16203], 6072: [16204], 5254: [16205], 684: [16207], 1160: [16209, 16215, 16355], 702: [16211], 16813: [16212], 14688: [16213], 19313: [16214, 17630, 17683, 17832, 17840, 17848, 17851, 17860, 17862, 17884, 17901, 18075], 1565: [16216], 16893: [16217], 19319: [16218], 16598: [16222], 19284: [16223], 6104: [16224, 16527], 6131: [16225], 551: [16226], 19325: [16227], 16592: [16228], 1808: [16229], 6470: [16230], 674: [16231, 16372, 16573, 16740, 16963], 614: [16233], 682: [16234], 9333: [16235, 17254], 9236: [16238], 9318: [16239], 15926: [16240], 617: [16242], 9048: [16243], 18540: [16244], 677: [16245, 16552], 18548: [16247], 16308: [16250], 9320: [16252, 16433], 9280: [16253], 7766: [16255], 6119: [16256], 12678: [16257, 16852, 16907, 17389], 7754: [16259, 16446], 6205: [16260], 11751: [16261], 7633: [16263, 16467, 16592, 16809], 5199: [16265], 10935: [16266], 15768: [16267, 22150, 22562, 22639, 23100, 23546, 23579, 23583, 23589, 23591, 23598, 23894, 23900, 23904, 23909, 23915, 23926, 23927, 23948, 23958, 23972, 23974, 23975, 23991, 24011, 24014, 24017, 24031, 24044, 24053, 24057, 24059, 24088, 24098, 24102, 24120, 24130, 24131, 24158, 24160, 24163, 24164, 24173, 24190, 24198, 24206, 24233, 24235, 24249, 24256, 24267, 24270, 24300, 24308, 24310, 24480, 24595, 24732, 24844, 25843], 9044: [16268], 773: [16270, 16399], 11122: [16271, 16272], 9448: [16273], 11483: [16274], 18679: [16275], 15889: [16276], 11228: [16277], 7547: [16278], 10395: [16280], 16114: [16281], 9067: [16282], 10667: [16283], 18903: [16285], 9120: [16287], 7769: [16289], 12625: [16290], 9321: [16292], 7709: [16293], 12273: [16294], 6967: [16295], 10864: [16297, 16474], 17776: [16298], 9357: [16299], 18381: [16301], 12668: [16302, 16591, 16646, 17578, 17998], 12696: [16303, 17098, 17146, 17572, 17595, 17607, 18217], 7014: [16305], 5858: [16306, 17143], 11050: [16309], 5869: [16310], 7235: [16312], 11402: [16313], 12557: [16314], 17221: [16317], 15929: [16319, 16644, 16651], 3537: [16320, 17165], 3598: [16321], 15115: [16322, 16501], 15025: [16323], 15592: [16324], 14777: [16325, 16912], 14733: [16327], 15562: [16328], 3373: [16329], 15589: [16330], 3380: [16331, 16925], 625: [16332, 16390], 3487: [16334], 4448: [16335], 1146: [16336], 1143: [16337, 16749], 4977: [16338, 16614, 16766, 16824], 14648: [16339], 15521: [16340], 6197: [16341], 1574: [16342], 19618: [16343], 714: [16344], 19740: [16346], 14647: [16347, 16348], 3860: [16351], 15466: [16352], 1720: [16353], 5220: [16354], 1300: [16357], 5123: [16358], 19731: [16359], 1259: [16361], 7464: [16363], 19268: [16364], 19617: [16365], 19607: [16366, 17909, 18119, 18263, 18347, 18562, 18565, 18596, 18603, 18607, 18773, 18829, 18993, 19060, 19074], 753: [16367], 14727: [16368], 62: [16371, 21306], 8606: [16373], 273: [16375], 8171: [16376], 9096: [16377, 16395, 16817, 16868], 673: [16378, 16719, 16986], 10973: [16379], 11115: [16380], 7924: [16381], 9347: [16383, 16391, 17114], 10329: [16384], 9237: [16385], 8589: [16386, 16387, 16578], 10845: [16388], 96: [16389], 18687: [16392], 9349: [16394], 10447: [16396], 8986: [16397], 9195: [16402, 16442], 602: [16403], 16239: [16404], 8948: [16405, 16608, 16854], 16030: [16408], 8507: [16411], 7838: [16412], 10784: [16413], 7357: [16414, 17570, 18169, 18494, 18677, 18961, 19123, 19170, 19402, 19404, 19419], 9229: [16417], 4835: [16418], 4810: [16421], 8988: [16423], 12303: [16425], 6544: [16426], 7016: [16427], 16122: [16428], 10118: [16429], 19093: [16430], 18942: [16432], 17310: [16434], 11060: [16435], 11693: [16436], 12300: [16437], 12368: [16438], 11310: [16439], 12842: [16440], 1802: [16441], 18021: [16443], 6908: [16444], 9091: [16447], 12660: [16450, 16472, 16490, 16850, 17103, 17386, 17422, 18460], 11507: [16451], 11120: [16453], 12793: [16454], 12158: [16455], 18983: [16456], 12722: [16460], 8815: [16462], 6978: [16463], 11508: [16464], 12611: [16465, 16840, 17772], 12827: [16466, 19799], 6019: [16468], 6994: [16469], 18941: [16470], 7529: [16471], 5862: [16473, 16479], 5832: [16478, 16482, 16669, 16845, 16888, 16889, 16891, 16896, 16902], 6888: [16480], 9373: [16483], 12369: [16486], 12733: [16489], 11478: [16491], 12208: [16492], 12576: [16493], 3589: [16496], 4453: [16499], 18854: [16500], 14878: [16502], 15483: [16504, 16541], 15140: [16505], 1559: [16506], 3356: [16508, 17172], 15491: [16510], 3284: [16511], 15372: [16512], 598: [16513], 3485: [16515], 6118: [16516, 16946], 6120: [16517, 16525, 16561, 17056, 17301, 17678], 5319: [16518, 29345, 29557, 29624, 29633, 29925, 29929, 29930, 29936, 29937, 29938, 29940, 29941, 29945, 29946, 29948, 29950, 29956, 29973, 29974, 29980, 29989, 29998, 30004, 30020, 30031, 30042, 30043, 30046, 30047, 30050, 30053, 30055, 30058, 30078, 30081, 30082, 30109, 30111, 30112, 30114, 30122, 30137, 30149, 30165, 30168, 30202, 30231, 30232, 30239, 30244, 30250, 30252, 30268, 30269, 30277, 30279, 30292, 30307, 30308, 30668], 19619: [16519], 9596: [16520], 3359: [16521], 14646: [16522], 554: [16524], 14707: [16526], 14593: [16528], 14401: [16529], 17716: [16530], 13956: [16532], 15520: [16533], 19519: [16534], 15498: [16535], 19584: [16536], 15459: [16537], 10828: [16538], 15455: [16539], 15541: [16540], 15375: [16542], 15606: [16543], 6157: [16544], 6194: [16545], 17740: [16546], 6442: [16547], 17464: [16548], 18198: [16549], 1150: [16550, 17191, 17657], 3699: [16553], 3704: [16554], 19266: [16555], 11420: [16556], 19272: [16557], 1841: [16558], 17107: [16559], 17669: [16560], 16952: [16563], 276: [16565], 640: [16566, 16784, 17022, 17445], 8622: [16567], 639: [16568], 9117: [16569], 8965: [16570, 16588, 16800], 5009: [16571], 10475: [16572, 17317, 17333], 7982: [16574], 7643: [16576], 9281: [16579], 17379: [16581], 16807: [16582], 19: [16583], 9098: [16585, 16802, 17228, 17236, 17247, 17248, 17259, 17268, 17277, 17305, 17516, 17599], 10332: [16586], 12701: [16587, 16859, 16874, 17359], 10388: [16589], 8338: [16593, 17293, 17392, 17949], 9227: [16594], 6224: [16595], 447: [16596], 13894: [16597], 5778: [16598], 7875: [16599, 21826, 24329, 24503, 25239, 25769, 25938, 25947, 25971, 25985, 26017, 26033, 26042, 26054, 26081, 26109, 26358], 17940: [16600], 806: [16601], 6463: [16605], 8604: [16609], 9074: [16610], 15295: [16611], 6165: [16613], 5281: [16615], 6509: [16616], 10326: [16617], 6521: [16618], 9452: [16619], 4998: [16620], 6552: [16621], 6826: [16622], 11649: [16623], 9069: [16626], 10740: [16627, 27716, 27764], 903: [16628], 16783: [16629], 7528: [16631, 17818], 9078: [16632, 17367], 12704: [16633, 17769], 7513: [16634, 16679], 9183: [16635, 16812, 17094, 17298], 15725: [16636], 11489: [16637], 6979: [16639], 11535: [16640], 11769: [16641], 9184: [16642], 12758: [16643], 12624: [16649, 17369], 15829: [16653], 12566: [16656, 16687, 17360], 6937: [16657], 11510: [16658], 12536: [16660, 16779], 6233: [16663], 9684: [16664], 5758: [16682], 7880: [16696], 6925: [16701], 12648: [16705], 12430: [16708], 12407: [16709], 15119: [16710], 19304: [16712], 14976: [16713], 1189: [16714], 608: [16715], 14795: [16716], 570: [16717, 17530], 1214: [16718, 17895], 3527: [16720], 3357: [16722], 14691: [16723, 16734], 3254: [16724], 15497: [16725], 680: [16726], 594: [16729], 6073: [16730], 1199: [16731], 6060: [16732, 19837], 3552: [16733], 14559: [16735], 6225: [16736], 6122: [16737], 13950: [16742], 3469: [16743], 705: [16745], 14408: [16746], 18566: [16747], 14699: [16748], 14764: [16750], 914: [16751, 16756, 16940, 16941, 17187], 5041: [16752], 4839: [16753], 18896: [16754], 19323: [16755], 57: [16757], 15728: [16758], 521: [16759], 19194: [16760], 669: [16761, 16793], 567: [16762], 15891: [16763], 19610: [16764, 18114, 18350, 18591], 16939: [16765], 18563: [16767], 8990: [16768], 548: [16769], 8963: [16771], 9014: [16772], 8221: [16773], 9941: [16774], 7542: [16775, 17580], 566: [16777], 17006: [16778], 9179: [16780, 16971, 17039], 313: [16781], 597: [16782, 16786], 10409: [16783, 16791, 17085, 17319], 721: [16785], 9337: [16792], 687: [16794], 19378: [16797, 28245, 28270, 28812], 18364: [16798], 15757: [16799], 15737: [16801], 18401: [16804], 16444: [16805], 7499: [16806], 9095: [16807, 17564], 7510: [16808], 9458: [16811, 18453], 6212: [16813], 18937: [16814], 7150: [16815], 8937: [16816], 9319: [16818], 6471: [16819], 16028: [16820], 9594: [16821], 9335: [16822], 6202: [16823], 9111: [16825], 10432: [16826], 9537: [16827], 1812: [16828], 1003: [16829], 16438: [16830, 17335, 17568, 17596, 18445, 18711], 16395: [16831, 17327, 17336], 8936: [16832, 17757, 17971, 17977], 8387: [16833, 33368], 11300: [16835, 23246, 23682, 24456], 12558: [16836, 17776], 7786: [16837], 15286: [16838], 16698: [16841, 24417], 11594: [16842], 19079: [16843], 8614: [16844], 16721: [16846], 12677: [16847, 17378], 11524: [16848], 12629: [16849], 19144: [16855], 7149: [16856, 17144, 17542], 12193: [16857], 12534: [16860], 12662: [16862, 17400], 15940: [16863], 7544: [16864], 12694: [16865, 17095, 17820], 12593: [16866], 12263: [16867], 11503: [16869], 9733: [16871], 7205: [16872, 17131, 17134], 17209: [16873], 11075: [16875], 10936: [16876], 10627: [16877], 10100: [16881], 12599: [16882], 5759: [16884], 5385: [16886], 12595: [16908], 12703: [16909, 17410], 12024: [16910], 14776: [16913, 18050], 3498: [16914, 16916], 14984: [16915], 15367: [16917], 15139: [16918, 17642], 15005: [16919], 15098: [16920], 3449: [16921], 2682: [16922], 2680: [16923], 15607: [16926], 3351: [16927], 3285: [16929], 1822: [16930], 207: [16931, 26145, 26284, 26771, 26783, 28063], 17713: [16932], 14639: [16933], 19310: [16934, 17675, 17679, 17681, 17700, 17830, 17911, 17914, 18108], 15444: [16935], 14706: [16936], 14684: [16937, 16938, 17188], 14645: [16939], 14449: [16942], 1145: [16943, 17457], 16835: [16944], 912: [16945], 19715: [16947], 17094: [16948], 19002: [16949], 19733: [16950], 15341: [16951], 1230: [16952], 15635: [16953], 1272: [16954], 17418: [16955, 16957], 19608: [16956], 1104: [16958], 1186: [16959], 6195: [16960], 559: [16961], 632: [16962, 17265], 16497: [16964], 19615: [16965], 7787: [16966], 19614: [16967], 19311: [16968], 763: [16969], 683: [16970], 955: [16972], 18122: [16973], 5063: [16974, 20175, 21091, 21684], 266: [16981], 9762: [16988], 9274: [16989], 9130: [16990], 12585: [16994], 7634: [16997], 9197: [17002], 15999: [17016], 9049: [17017], 11979: [17024], 578: [17026, 17040], 9104: [17027, 17567, 17705, 17725], 8464: [17031], 18069: [17033], 1823: [17034], 650: [17037], 9647: [17041, 17344], 9009: [17044], 5803: [17049], 6534: [17050], 7817: [17051], 10417: [17053], 9327: [17054], 8360: [17057], 10479: [17058], 7980: [17061], 1807: [17063], 12306: [17064], 7360: [17067], 776: [17071], 10960: [17072], 10737: [17075], 9358: [17076], 6110: [17078], 6441: [17079], 10397: [17080], 6577: [17081], 11714: [17083, 21802], 9701: [17084], 15739: [17086], 11502: [17087, 17780], 8666: [17089], 11405: [17090], 12635: [17091], 9662: [17093], 11520: [17097], 12571: [17099], 11805: [17101], 12641: [17102, 17398], 7622: [17104], 12614: [17106], 7220: [17107], 12608: [17108, 17119, 17338], 7162: [17109], 15833: [17110], 12653: [17111], 12685: [17113], 11485: [17115], 12563: [17116, 17351], 5678: [17120, 17414], 11059: [17121], 11521: [17122], 5826: [17126, 17152, 17612], 15902: [17128], 15782: [17129], 5804: [17130, 17404, 17620, 18020], 5791: [17132], 15935: [17135], 12618: [17136], 12679: [17137, 17804], 9798: [17138], 12617: [17141, 17151, 17416], 9575: [17142], 12126: [17147], 12683: [17148, 17774], 5915: [17155], 12565: [17158, 18029], 5834: [17161], 5843: [17162], 12261: [17163], 15000: [17164], 3436: [17166], 14979: [17167], 3614: [17168, 27321, 27323, 27327, 27342, 28003, 28602], 3539: [17169], 19312: [17170, 17429], 115: [17171], 5160: [17173], 5073: [17174], 16953: [17175], 4982: [17177], 5005: [17178, 17215, 17651], 16907: [17179, 17647], 5110: [17180], 14636: [17181, 17871], 1081: [17182], 1147: [17184], 19626: [17185], 14346: [17186], 18995: [17189], 15465: [17190], 14386: [17192], 2684: [17193], 19328: [17194, 18296], 6208: [17195], 1187: [17196, 17677, 17684, 18097], 19389: [17197], 1245: [17198, 17428], 389: [17199], 15596: [17200], 17858: [17201], 1193: [17202], 169: [17203], 16905: [17204], 12161: [17205], 3775: [17206], 891: [17207], 7742: [17209, 27650, 28426], 797: [17210], 3723: [17212], 17698: [17213], 5201: [17214], 5663: [17216, 18033, 18042, 18210, 18233, 18420], 171: [17217], 16915: [17218], 628: [17219], 16830: [17220], 17871: [17221], 9105: [17224], 10272: [17226, 23489, 23505, 23556, 23600, 24816], 10933: [17227], 10225: [17232], 611: [17234], 8021: [17237, 17513, 17933, 18359], 9266: [17238], 7925: [17239], 667: [17241], 16235: [17243, 17505], 17869: [17244], 10311: [17246, 17696], 688: [17250], 15930: [17262], 36: [17264], 16416: [17266], 8804: [17276], 668: [17282], 17380: [17283], 1856: [17284], 9626: [17285], 17951: [17286], 68: [17287], 7144: [17289, 18402], 8173: [17290], 16382: [17291], 6980: [17292], 6155: [17296], 16504: [17299], 15936: [17303], 11484: [17304], 9132: [17306], 18669: [17307], 7543: [17309], 16365: [17310], 9543: [17314], 9790: [17315], 1965: [17318], 19044: [17320], 8981: [17321, 17789], 8646: [17323], 10569: [17324], 6512: [17326], 833: [17328], 862: [17329, 17987], 6473: [17330], 8522: [17331], 6207: [17332], 9541: [17334], 4838: [17337], 6838: [17339, 17566, 18116], 10404: [17340], 15965: [17341], 11418: [17343], 7789: [17345], 16236: [17347], 10469: [17348], 7755: [17349], 8819: [17354], 9099: [17356, 17518, 17708], 12621: [17357, 18467], 11500: [17358], 12590: [17361], 12529: [17363], 12626: [17364, 17646], 12539: [17365, 18489], 18384: [17368], 12141: [17373], 12706: [17374, 17401, 17803], 8471: [17375], 8769: [17376], 11043: [17379], 7362: [17380], 11512: [17384, 17797], 12619: [17385, 18463, 18476, 18509], 9172: [17387], 7546: [17388], 12693: [17393, 17421, 17481, 18040], 12681: [17394, 17576], 12154: [17397, 19388], 19136: [17399], 11419: [17402], 12638: [17403, 17575], 5848: [17405], 5659: [17406], 16093: [17408], 5554: [17409], 7799: [17413], 12090: [17415], 15925: [17417], 12414: [17423], 14987: [17424], 3460: [17425], 3542: [17427], 3470: [17430, 18063], 14994: [17431, 19003], 3549: [17432], 14794: [17433], 552: [17434], 2683: [17436], 1065: [17437], 1176: [17438], 599: [17439, 18355], 18853: [17440, 17656, 18553], 19638: [17441], 14711: [17442], 12723: [17443], 15565: [17444], 1149: [17446], 1175: [17447], 14662: [17448], 3421: [17449], 14683: [17450], 19265: [17451, 17686, 17688, 17905], 1920: [17452, 18141], 17847: [17453], 3846: [17454], 1208: [17455], 6114: [17456], 15533: [17459, 22030, 22451, 22925, 22927, 23340, 23341, 23342, 23346, 23347, 23351, 23353, 23356, 23361, 23372, 23374, 23378, 23379, 23385, 23391, 23396, 23397, 23398, 23399, 23400, 23401, 23403, 23404, 23406, 23412, 23413, 23417, 23418, 23422, 23424, 23846], 14728: [17460], 641: [17461, 17653], 19172: [17462, 17728], 15438: [17463], 19019: [17464], 1209: [17465], 17935: [17466], 1356: [17467], 17845: [17468], 1229: [17469], 1246: [17470], 19291: [17472, 18579], 17884: [17473, 17538, 18400, 18640, 18896], 1267: [17474], 6490: [17475], 793: [17476], 19014: [17477], 3705: [17478], 19666: [17479], 3673: [17480, 28040, 28041, 28061, 28068, 28082, 28144, 28147, 28613, 28692], 19609: [17482], 5013: [17483], 4823: [17484], 18919: [17486], 540: [17487, 18621], 3859: [17488], 8516: [17489], 601: [17490], 580: [17491], 10941: [17492], 43: [17493], 9042: [17494], 12666: [17495], 9004: [17496, 19082, 19136, 19159, 19167, 19672], 9040: [17497, 19381, 19382], 8816: [17498], 9097: [17500], 12622: [17501], 8613: [17502], 7976: [17504], 138: [17506], 8032: [17507], 10080: [17508], 8966: [17509], 591: [17510], 474: [17511], 635: [17512], 15904: [17514], 675: [17515], 12627: [17517], 5120: [17521], 546: [17524], 8964: [17526], 19385: [17527], 9075: [17528], 8929: [17529], 6229: [17531], 16791: [17532], 8923: [17533], 18003: [17534], 8992: [17535, 17721, 17932, 18132, 18138, 18349, 18369], 17393: [17536], 8341: [17537], 11435: [17539], 4978: [17540], 9065: [17541], 4812: [17543], 8993: [17544], 9174: [17545], 8935: [17546, 18176, 18669, 18680, 18682], 6200: [17547], 887: [17548], 15746: [17550], 6582: [17551], 6117: [17552, 17747], 16596: [17553], 6477: [17554], 6592: [17555], 16017: [17557, 17937], 9084: [17559], 4955: [17560], 4917: [17561], 7760: [17562], 7500: [17563], 10642: [17565], 16190: [17569], 10931: [17571], 12754: [17573], 11713: [17574], 12759: [17577], 10927: [17581], 7991: [17582], 11596: [17583], 11991: [17584], 12475: [17585], 12644: [17586], 1809: [17587], 8867: [17589], 11422: [17590], 11411: [17591], 11757: [17593], 12535: [17594, 17994], 12610: [17598, 18475], 1806: [17601, 18008], 9043: [17602], 9328: [17603], 12550: [17604], 15967: [17605], 16088: [17606], 12764: [17608], 12609: [17609], 5938: [17610, 22331, 22572, 22740, 23280, 23762, 23780, 23795, 23799, 23801, 24357], 5814: [17611, 17813], 15647: [17615], 12412: [17616], 12633: [17618], 12606: [17621, 17775], 18279: [17622], 5550: [17625], 7233: [17626], 12830: [17627], 12602: [17628, 18204], 14774: [17631], 12581: [17633], 3593: [17637], 3465: [17638], 14838: [17639], 14992: [17640, 17845], 15493: [17641], 3343: [17643], 15374: [17644], 3323: [17645], 3381: [17649], 4433: [17650], 18872: [17652], 1932: [17654], 1216: [17655, 17864], 1152: [17658], 1962: [17659], 18855: [17660], 19708: [17661], 616: [17662], 14712: [17663], 18996: [17664, 17673, 17865], 5068: [17666], 15630: [17667], 1956: [17668], 15434: [17669], 17346: [17671], 2625: [17672], 17051: [17674], 1148: [17676], 75: [17685], 59: [17687, 17695], 19612: [17689, 18338], 1942: [17690], 19611: [17691, 17692, 17853, 17882, 18094, 18105, 18112, 18259, 18260, 18261, 18264, 18265, 18278, 18288, 18313, 18319, 18333, 18334, 18337, 18339, 18340, 18341, 18344, 18345, 18348, 18351], 3727: [17693], 16881: [17694, 28723, 28726], 10327: [17697], 10290: [17701], 9454: [17704], 19253: [17706], 9359: [17709], 12598: [17710, 17814], 10971: [17711], 1021: [17712], 9046: [17713, 18653], 943: [17714], 9332: [17715], 18293: [17718], 18433: [17719], 7273: [17722], 19089: [17726], 12295: [17727], 16192: [17729], 9070: [17730], 15836: [17731], 16527: [17733], 10940: [17734], 16349: [17735], 18058: [17737], 8596: [17739], 19178: [17740], 6106: [17741], 15791: [17742], 5317: [17743], 8358: [17744], 10082: [17745, 18398, 18659], 5038: [17746], 10473: [17748], 7730: [17749], 5026: [17750], 8453: [17751, 20485], 11501: [17752], 7983: [17753], 5072: [17754, 19144], 6555: [17755], 15995: [17758], 6545: [17759], 8985: [17760, 18183], 16300: [17761], 11475: [17762, 17802, 18191, 18209, 18213], 12573: [17764, 17991], 16761: [17765], 10408: [17766, 20748], 12684: [17767], 16567: [17768], 8991: [17771], 11530: [17773], 8513: [17777], 5454: [17778], 15663: [17779], 11486: [17781], 9127: [17782, 20862], 10389: [17783], 11522: [17784], 11477: [17785], 10044: [17786], 12564: [17787], 12151: [17788, 18157, 18222, 18753, 19748], 16972: [17790], 12738: [17791], 9771: [17792, 17808], 11537: [17793], 12603: [17796, 18208], 12768: [17798], 12700: [17799], 7478: [17800], 5825: [17805], 5809: [17806, 17821], 5849: [17807], 5439: [17809], 9447: [17810], 5847: [17811], 7255: [17812], 7106: [17815], 12705: [17816, 18249], 9113: [17817], 12492: [17819], 10721: [17822], 12620: [17823], 12605: [17824], 5808: [17825], 12423: [17826], 12005: [17827, 28572, 29863, 30556, 30577, 30582, 30584], 12812: [17828], 14985: [17829], 3565: [17831], 3456: [17833], 3501: [17835, 19249], 15002: [17844, 19825, 20644], 19513: [17846], 3473: [17847], 3610: [17849], 4445: [17850], 1351: [17854], 3329: [17855], 3324: [17857, 18284, 18783], 5086: [17858], 6203: [17859], 14663: [17861], 4602: [17863], 4451: [17866], 6108: [17867], 15538: [17868], 1207: [17869], 14596: [17870], 3422: [17872], 15426: [17873, 20660, 26210, 26713, 26724, 26741, 26804, 26807, 27318, 27320, 27329, 27331, 27333, 27344, 27345, 27347, 27348, 27357, 27360, 27362, 27376, 27377, 27382, 27384, 27387, 27398, 27400, 27403, 27408, 27417, 27421, 27423, 27426, 27430, 27432, 27436, 27442, 27443, 27444, 27450, 27451, 27452, 27453, 27455, 27456, 27459, 27460, 27461, 27464, 27465, 27466, 27469, 27470, 27471, 27472, 27473, 27474, 27476, 27477, 27478, 27479, 27480, 27481, 27482, 27483, 27486, 27487, 28004, 28011, 28064], 8960: [17876], 19187: [17877], 14360: [17878], 16812: [17879], 874: [17880, 17913], 18891: [17881], 19111: [17883], 1153: [17885], 15373: [17886], 14460: [17887], 9383: [17888], 18530: [17889, 18335, 18839], 1228: [17890], 913: [17891], 6541: [17892], 6196: [17893], 1288: [17894], 19257: [17896], 17432: [17897], 18411: [17900], 7512: [17902], 5043: [17904], 19709: [17906], 610: [17907], 15288: [17908], 7511: [17910], 7743: [17912, 18660, 18707, 21421, 21476, 24105, 25323, 25755, 25798, 25889, 26336, 26350, 26355, 26575, 26608, 26621, 26831, 26871, 26896, 26900, 26912, 26915, 26919, 26920, 26921, 26923, 26926, 26928, 26929, 26930, 26938, 26939, 26941, 26957, 26958, 26959, 26960, 26965, 26966, 26969, 26984, 26996, 27020, 27024, 27025, 27030, 27038, 27047, 27058, 27063, 27069, 27079, 27082, 27083, 27094, 27102, 27118, 27119, 27123, 27139, 27151, 27160, 27162, 27164, 27167, 27181, 27191, 27192, 27195, 27199, 27216, 27219, 27228, 27234, 27239, 27242, 27246, 27247, 27251, 27257, 27261, 27264, 27266, 27267, 27269, 27270, 27271, 27280, 27283, 27285, 27293, 27297, 27299, 27306, 27630, 27909], 9026: [17915], 10087: [17916], 19054: [17917], 8354: [17918], 7936: [17920], 1964: [17922], 18558: [17923], 889: [17924], 15931: [17925], 18544: [17926], 8146: [17928], 8135: [17929], 485: [17930], 685: [17934], 9109: [17936], 8078: [17939, 18373], 9273: [17940], 8461: [17941], 7988: [17942], 6537: [17943], 6501: [17944], 6506: [17945], 17960: [17946], 10516: [17947], 4816: [17948], 6111: [17950], 5002: [17951], 6530: [17952], 16475: [17953], 6502: [17954], 16096: [17955], 6538: [17956], 5010: [17957], 7904: [17958], 5007: [17959, 17968], 8934: [17960, 18168, 18179, 18409], 7625: [17961], 5191: [17962, 23020], 18970: [17963], 7457: [17965], 5338: [17966, 29370, 30265, 30267], 6077: [17967], 4983: [17969], 10710: [17970], 8999: [17972], 6973: [17973], 16415: [17974], 4997: [17975], 16552: [17976], 16424: [17978], 16033: [17979], 15676: [17980], 12424: [17982], 12147: [17983, 18456], 12596: [17984], 12570: [17985, 18253], 16217: [17986], 18375: [17988], 17250: [17989], 8651: [17990], 12604: [17992, 19217], 12541: [17997], 12531: [17999], 18386: [18000], 12532: [18001], 10782: [18002], 5816: [18003], 5511: [18004], 11539: [18005], 18254: [18006], 10847: [18007], 11730: [18009, 18712, 19200, 19205, 19211, 19424, 19448, 19463, 19465, 19472, 19484, 19486, 19736, 19751], 9654: [18010], 12773: [18011], 11528: [18012], 11538: [18013], 12525: [18014], 12691: [18016], 16437: [18017, 23636], 9024: [18018], 16034: [18019], 7303: [18021], 7323: [18022], 5478: [18023], 5744: [18025], 15708: [18026], 12584: [18027, 18221], 5546: [18028], 7178: [18030], 12649: [18031], 5817: [18032], 5811: [18034], 5835: [18035], 10020: [18036, 19201], 7613: [18037, 31030], 5592: [18038], 5850: [18039], 5833: [18041], 12582: [18043], 5683: [18044], 12560: [18045, 18049], 12632: [18046, 18655], 5822: [18047], 12538: [18048], 3588: [18051], 4454: [18054], 3551: [18058], 14981: [18065], 15012: [18066], 14879: [18067], 14815: [18068], 14980: [18069], 3387: [18070], 14833: [18071], 14839: [18073], 15014: [18074], 3364: [18076, 18540, 19020, 19263], 4974: [18078], 3660: [18080], 3205: [18081], 14637: [18082], 19353: [18083], 13943: [18084, 18303, 18557, 18797], 14462: [18086], 15522: [18087, 18312], 13946: [18089], 16897: [18090], 4975: [18091], 17864: [18093], 14718: [18095], 1178: [18096], 1383: [18098], 19527: [18100], 17048: [18101], 1290: [18102], 1255: [18103], 5268: [18106, 25542], 956: [18107, 29387, 33904], 1892: [18110], 14459: [18113], 999: [18115], 19683: [18117], 16132: [18118], 19286: [18120], 16168: [18121], 15780: [18122], 6510: [18123], 17334: [18126], 12299: [18130], 277: [18133, 19081], 8920: [18134, 21108], 132: [18135], 7984: [18139], 18340: [18140], 98: [18142], 1882: [18143, 23066], 8996: [18144], 9316: [18145], 8468: [18146], 278: [18148], 10298: [18150], 9152: [18151], 7839: [18153], 18683: [18154], 9013: [18155], 7549: [18156], 8955: [18158], 7854: [18160], 15684: [18161], 10644: [18162], 7722: [18163], 12567: [18164, 18375], 10204: [18165], 16375: [18166], 10145: [18167], 7641: [18171], 1810: [18172, 18418, 19440], 4999: [18173], 10744: [18177, 20128, 20186], 19082: [18178], 16369: [18180], 16023: [18181, 20902, 20915], 15670: [18182], 7572: [18184, 18725], 5812: [18185], 9322: [18186], 8600: [18187], 10937: [18188], 12686: [18189], 12476: [18192], 12568: [18194], 7979: [18195], 10758: [18196], 8969: [18197], 12824: [18198, 20481, 20619], 12143: [18199, 19501], 12559: [18200], 7460: [18201], 11223: [18202], 11739: [18203, 18955, 19176, 19195, 19196, 19429, 19442, 19452, 19453, 19479, 19750, 19752, 19756, 20227], 12537: [18205], 17121: [18206], 12578: [18207], 12646: [18211, 18224, 18250], 12645: [18212], 8473: [18215], 12615: [18216], 11183: [18218], 10832: [18219], 12628: [18220], 10664: [18223, 28240, 29037], 12186: [18225], 11793: [18226], 12561: [18227], 12630: [18228], 16495: [18229], 18387: [18230], 7288: [18232], 19076: [18235], 6899: [18236], 7125: [18237], 5516: [18239, 18443, 18751], 5916: [18240], 5636: [18241], 7355: [18242, 20535], 12792: [18243], 11079: [18244, 18427], 12569: [18245], 7358: [18246], 5830: [18247], 5795: [18248, 18504], 5763: [18251], 11088: [18252], 15694: [18254], 5483: [18255], 12420: [18256], 12580: [18257], 3591: [18266, 18757], 3597: [18267], 3592: [18268, 18989, 19247], 3582: [18269], 1340: [18270], 18918: [18271, 18609], 15003: [18273], 3553: [18274], 14871: [18275], 15013: [18276], 14998: [18277], 3568: [18279], 3345: [18280, 18281], 15368: [18282], 3325: [18283, 18286, 19276], 16908: [18285], 3502: [18287], 19631: [18289, 18297], 1057: [18290], 4: [18292], 18688: [18293], 1192: [18294, 18782, 18811, 18814], 6063: [18295], 3486: [18298], 19713: [18299], 14660: [18300], 15539: [18301], 15594: [18302], 19264: [18304, 18799], 14634: [18305, 18554, 18556, 18558, 18767, 18796, 19029, 19032], 16845: [18306], 18800: [18307], 5184: [18308], 19541: [18309], 12783: [18310], 15349: [18311], 15351: [18314], 15462: [18315], 6109: [18316], 15542: [18317], 15650: [18318, 19043], 52: [18320, 19095, 19301, 19339, 19379, 19564, 20017, 20126], 9061: [18321, 18873, 19090], 16917: [18322], 1292: [18323], 19528: [18324], 19307: [18326, 18804, 18810], 1220: [18327, 19047], 17428: [18328], 1256: [18329], 17430: [18331], 13873: [18332], 4127: [18336], 3725: [18343], 16912: [18352], 615: [18353], 6531: [18354], 7977: [18356], 569: [18361], 9052: [18362], 134: [18363], 17897: [18364], 3: [18365, 18606], 9103: [18366], 725: [18367], 8182: [18368], 12634: [18370], 438: [18371], 746: [18372], 47: [18374, 18785], 4996: [18376], 15924: [18377, 18379], 17084: [18378], 12636: [18381], 620: [18383], 4967: [18386], 8958: [18387, 18633], 18231: [18388], 19344: [18389], 10208: [18391], 8962: [18392], 8947: [18393, 18683], 18026: [18395], 8148: [18396], 5006: [18397], 19068: [18399], 8025: [18401], 9304: [18403], 5296: [18404], 17118: [18405], 10477: [18406], 8088: [18407, 34026, 36668, 36817], 5978: [18408], 8348: [18410], 19358: [18411], 17760: [18413], 6150: [18414, 18842], 7972: [18415], 6115: [18416], 8094: [18417], 10934: [18419, 18459], 7675: [18421], 18019: [18422], 15998: [18423], 19785: [18424], 9587: [18425], 9031: [18426], 16607: [18428], 5016: [18429], 16498: [18431], 982: [18432], 11749: [18433], 11404: [18434, 19207], 8172: [18435], 12689: [18436], 7895: [18438], 11221: [18439], 19138: [18440], 16046: [18441], 11804: [18442, 22741], 1811: [18446, 20802], 12594: [18447], 12551: [18448], 11837: [18449], 19026: [18450], 11607: [18451], 7094: [18452], 9648: [18454], 12750: [18455], 8979: [18457], 11759: [18458], 11845: [18461], 7520: [18462], 16118: [18464], 18250: [18465], 10849: [18466], 12834: [18468], 11722: [18469, 18962], 16514: [18471], 12577: [18472], 10932: [18473], 11061: [18477], 9384: [18478], 17324: [18479], 8706: [18481], 18981: [18482], 6014: [18483], 10957: [18484], 5818: [18485], 7191: [18486, 18738], 7237: [18487], 7726: [18488], 7247: [18490], 5517: [18491], 5917: [18492, 19225], 7170: [18493], 8873: [18496], 5813: [18497], 12155: [18498, 19210], 6995: [18499], 12540: [18500], 7177: [18502], 17224: [18503], 12144: [18505, 19766], 5855: [18506], 12601: [18507], 12080: [18508], 5624: [18510], 5794: [18511], 12697: [18512], 12651: [18513], 12586: [18514], 1205: [18515, 18754, 18755], 3535: [18516, 18518, 18525, 18768], 15011: [18517], 6022: [18519], 12575: [18520], 3503: [18521], 1088: [18527], 3442: [18528], 3445: [18530, 18763, 18764, 18995], 14990: [18531], 3472: [18532, 18777, 20971, 21970, 22398], 14799: [18533, 19827], 14996: [18534], 3361: [18535, 18775], 1902: [18537], 3259: [18538], 66: [18539], 271: [18541], 3379: [18542], 15377: [18543], 6198: [18544], 1203: [18545, 18559, 18568, 18761, 18774, 18805, 18988, 19030, 19268, 19273, 19318], 14681: [18546], 15369: [18547], 5022: [18548], 1215: [18549], 15563: [18550], 5175: [18552], 15674: [18555], 13954: [18561], 1226: [18563], 1089: [18564], 5032: [18566, 19059], 15436: [18567], 17765: [18569, 19109], 17367: [18572], 15679: [18573], 15464: [18574, 18996], 15781: [18575], 60: [18576], 19198: [18578], 7824: [18580], 1151: [18582], 1353: [18583, 22477], 19597: [18584], 1385: [18585], 19546: [18586], 1204: [18587], 19613: [18588, 18599, 18604, 18760, 18769, 18834, 18835], 17468: [18589], 1227: [18590], 17870: [18592], 53: [18593], 726: [18594], 19732: [18595], 17193: [18597], 1891: [18598, 19626, 19644, 20443, 20690], 19529: [18600], 19603: [18601], 17828: [18602], 5057: [18605], 19329: [18608], 19384: [18611], 16873: [18612], 16059: [18613], 19361: [18614], 10985: [18615], 7973: [18616], 10291: [18617], 9072: [18618, 18866, 19471], 636: [18619], 16048: [18620], 6799: [18622], 19246: [18623], 10325: [18624], 8028: [18625], 15918: [18626], 612: [18627, 19368], 10505: [18628, 19067], 9063: [18629], 560: [18630], 595: [18631], 9323: [18632], 19346: [18634], 618: [18635], 17883: [18636, 18651, 18793, 18843, 18885], 592: [18637], 8954: [18638, 19363], 9066: [18639], 9317: [18641], 9032: [18642], 798: [18643], 8183: [18644], 5088: [18645, 24935], 7729: [18646, 18749], 11732: [18647], 7495: [18648, 19189, 19449], 17971: [18649], 19512: [18650], 9177: [18652, 18695], 16491: [18654], 8444: [18657, 18663, 18911], 8849: [18658], 5039: [18661], 18110: [18662], 7088: [18664], 15796: [18665], 16392: [18666], 18965: [18667], 16409: [18668], 16306: [18670], 8493: [18671], 11053: [18672], 6101: [18673], 9539: [18674], 4817: [18675], 10783: [18676], 16345: [18678], 8640: [18679, 20908], 11719: [18681], 9082: [18684, 18905, 18906], 18318: [18685], 18104: [18686, 21626, 21693], 15741: [18687], 10717: [18688], 11795: [18689], 17225: [18690], 10992: [18692], 10976: [18693], 9128: [18694], 11076: [18697], 17183: [18698], 12156: [18699], 12129: [18700], 12522: [18701], 6981: [18702], 15738: [18703], 11928: [18704], 18307: [18705], 12572: [18708], 11244: [18710, 19739, 27028, 28411], 16241: [18713], 11727: [18714, 18936, 18944, 18946, 18949, 18953, 19454, 19464, 19746, 20568], 16129: [18715], 12692: [18716], 9847: [18717], 11794: [18718], 12153: [18719], 15919: [18720], 12132: [18721], 10761: [18722, 22173, 25087, 25875], 11504: [18723], 9057: [18724], 11559: [18726], 11428: [18727], 12546: [18728], 12150: [18729, 20603], 7497: [18730], 12745: [18731], 11820: [18732], 12221: [18733], 5796: [18734], 7181: [18735], 8899: [18736], 5845: [18737], 10714: [18739, 29774, 30975, 30979, 31003], 5841: [18740], 5793: [18741], 7356: [18742, 18973], 7676: [18743], 15906: [18744], 6992: [18745], 7555: [18746, 20149], 5872: [18747], 12213: [18748], 5837: [18750], 12647: [18752], 3219: [18756], 3536: [18758], 3587: [18759], 3459: [18762, 19547], 15593: [18765, 19536], 15486: [18766], 3435: [18770], 14793: [18771, 19258], 15452: [18772], 19302: [18776], 19315: [18778, 18830], 15523: [18779], 18142: [18780], 1906: [18781], 3371: [18784, 19006], 3659: [18786], 15488: [18787], 1097: [18788, 23856, 24694, 24700, 24728, 24735, 25515], 3412: [18789], 6097: [18790], 994: [18791, 24066, 28353], 15433: [18792], 15561: [18794], 18161: [18795, 18803], 14355: [18798], 14640: [18800], 18153: [18801], 15490: [18802], 54: [18806], 15597: [18807], 4811: [18808], 1325: [18809], 18234: [18812], 5314: [18813, 28052, 28829, 29205, 29221, 29252, 29261, 29277, 29287, 29314, 29324, 29330, 29346, 29356, 29364, 29376, 29386, 29390, 29395, 29431, 29438, 29482, 29592], 1002: [18815], 1364: [18816], 6525: [18818], 48: [18819, 18853], 3826: [18820], 19116: [18821], 18413: [18822], 15667: [18823], 6116: [18824], 2624: [18825], 6517: [18826], 92: [18828], 16951: [18831], 5: [18832], 17730: [18833], 16799: [18836], 16986: [18838], 6132: [18840], 16965: [18841], 7992: [18845], 93: [18848], 7981: [18849], 593: [18850], 8961: [18851], 16154: [18852], 571: [18854], 17002: [18855], 181: [18856], 9272: [18857], 8632: [18858], 581: [18859], 7965: [18860], 10111: [18861], 8030: [18862], 15923: [18863], 8003: [18864], 390: [18867], 17394: [18868], 8994: [18869], 8023: [18870], 7986: [18871], 377: [18872], 5286: [18874], 590: [18875, 19114], 4829: [18876], 9093: [18877], 7869: [18878], 7123: [18879], 8952: [18880], 7812: [18881], 5305: [18882], 16724: [18883], 16784: [18884], 7767: [18886, 18895], 16038: [18888], 9406: [18889], 7763: [18890], 16613: [18891], 17961: [18892], 5129: [18893], 15743: [18894], 958: [18897], 12130: [18898], 16103: [18899, 18977], 6204: [18900], 7870: [18901], 17786: [18902, 20121], 8805: [18903], 7810: [18904, 21730, 21838, 22118, 22136, 22144, 22236, 22745, 22807], 5187: [18907], 7434: [18908], 6086: [18909], 7765: [18910], 6209: [18912], 16351: [18913], 6064: [18914], 5024: [18915], 10461: [18916, 18921, 21079, 22629], 9154: [18917], 9374: [18918, 21158], 16737: [18920], 10508: [18922], 18402: [18923], 15798: [18924, 20807, 21101], 6532: [18925], 11933: [18926], 15726: [18927], 9001: [18928, 19699], 8593: [18929], 9045: [18930], 10834: [18931], 12631: [18932], 17151: [18933], 11813: [18934], 17226: [18935], 15955: [18937], 12600: [18938], 11892: [18939], 8652: [18941], 12574: [18943], 10929: [18945], 9987: [18947], 11424: [18950], 12688: [18952], 12349: [18954], 10670: [18956], 8609: [18958], 16547: [18959], 12520: [18963], 11431: [18964], 12826: [18965, 19213, 19497, 19767], 12747: [18967], 12637: [18968], 12616: [18970], 5856: [18971], 7752: [18972], 6893: [18974], 12373: [18975], 5919: [18976], 7324: [18978], 5760: [18979], 5637: [18980], 12370: [18981], 7194: [18982], 5860: [18983], 12121: [18984, 20620], 12485: [18985], 5806: [18986], 1206: [18987, 19241, 19243, 19251, 19254, 19271, 19275, 19294, 19302, 19305, 19308, 19322], 15794: [18990], 3595: [18991, 19245, 19250, 19800, 19801, 19803, 19804, 19805, 19806, 19808, 19809, 19810, 19811, 19813, 19814, 19815, 19816, 19817, 19818, 19821, 19824, 20305, 20311, 20317, 20319, 20632], 3596: [18992], 3448: [18994], 19598: [18997], 19659: [18998], 15548: [18999], 3434: [19000, 21967, 22397], 14824: [19002], 15560: [19004], 603: [19005], 3363: [19007, 19266], 3352: [19008], 17014: [19009], 3370: [19010], 17814: [19011, 19840], 3346: [19012], 14695: [19013], 3475: [19014], 17919: [19016], 14682: [19017], 4995: [19018], 15598: [19019], 6096: [19021], 4446: [19022], 17865: [19026], 1222: [19027, 19259, 19283, 19285, 19287, 19289, 19298], 14693: [19028, 20965], 14635: [19031], 16819: [19033], 17697: [19035, 19329], 14434: [19036], 3812: [19037, 31347, 32209], 5275: [19038, 19068], 18151: [19039], 541: [19041], 15540: [19042], 1218: [19044], 1093: [19045], 16954: [19046], 1303: [19048], 1171: [19049], 18186: [19051], 16909: [19052], 1859: [19054], 1269: [19056, 19307, 19319, 19321], 1302: [19057], 3728: [19058], 16359: [19061], 630: [19062], 2627: [19063], 6130: [19064], 1374: [19065], 19604: [19066], 17651: [19069], 19652: [19070], 15058: [19071], 755: [19072], 965: [19073], 4818: [19075], 600: [19076], 6085: [19077], 18039: [19078], 16891: [19079], 606: [19083], 58: [19084, 19110, 19635], 544: [19085], 16490: [19086], 17653: [19087], 238: [19088], 8997: [19089, 19638, 19713], 8215: [19091], 7635: [19092], 631: [19093], 8956: [19094], 77: [19096], 15977: [19097], 15742: [19098], 16043: [19099], 8930: [19100], 8520: [19101], 10402: [19102], 167: [19104], 5976: [19105], 16969: [19106], 7905: [19107], 9023: [19108], 9020: [19111, 20250], 17: [19113], 15907: [19115], 279: [19116], 17168: [19117], 10148: [19118], 16219: [19119], 629: [19120], 16492: [19122], 19369: [19124], 6112: [19125], 10079: [19126, 19436], 10166: [19127, 28889, 30062, 30783, 30818, 30857, 30949, 30963, 31002], 11044: [19128], 16050: [19130], 16037: [19131], 10752: [19132], 15779: [19133], 9000: [19134], 19107: [19135], 975: [19137], 16499: [19138], 17767: [19139], 9129: [19140], 8216: [19142], 16496: [19143], 7706: [19145, 19686, 20095, 26313, 26365, 27081, 27634, 27654, 27844], 10645: [19148], 4969: [19149], 10083: [19150], 19155: [19151], 15825: [19153], 8663: [19154], 10988: [19155], 5171: [19156], 17761: [19157], 10711: [19158], 9600: [19160, 19445], 8922: [19162], 7728: [19163], 7452: [19164, 29058, 29704], 7807: [19166], 7831: [19168], 8643: [19169], 17158: [19171], 9008: [19172], 8982: [19173], 8967: [19174], 11735: [19177, 20223, 20255, 20555], 5851: [19178], 11190: [19179], 8498: [19180], 11429: [19181], 9085: [19182], 19090: [19183], 7619: [19184], 16186: [19185], 11436: [19186], 7700: [19187], 17122: [19188], 18895: [19190], 11741: [19191, 19759, 20166, 20597, 20874, 21162], 11096: [19192], 19158: [19193], 12371: [19194], 11536: [19197], 12521: [19198], 8720: [19199], 12822: [19202], 11222: [19203], 11771: [19204], 16439: [19206], 12813: [19208], 12746: [19209], 18403: [19212], 18944: [19214], 5707: [19215], 12818: [19216, 19714], 7361: [19218], 7364: [19219, 22772, 23270], 7189: [19220], 6024: [19221], 7193: [19222], 17123: [19223], 5475: [19224], 7496: [19226], 5920: [19227], 12562: [19228], 5544: [19229], 5638: [19230, 21219], 5805: [19231], 5626: [19232], 7270: [19233], 5699: [19234], 5615: [19236], 12790: [19237], 5870: [19238], 12077: [19239], 12825: [19240, 19795, 20571], 14989: [19242, 19256], 15007: [19244], 3499: [19246], 3217: [19248], 14993: [19252], 14821: [19255], 1223: [19257, 19604], 1903: [19260], 3369: [19261, 19534], 3322: [19262], 3260: [19264], 3336: [19265], 3328: [19269], 14732: [19270], 15460: [19272], 15527: [19274], 15499: [19278], 14562: [19281], 14597: [19282], 14685: [19284], 1907: [19286], 6126: [19288], 19710: [19290], 14393: [19291], 15412: [19292], 15450: [19293], 5256: [19296], 3840: [19297], 64: [19300], 15546: [19303], 19221: [19306, 19606], 3852: [19310], 15733: [19313], 880: [19314], 19287: [19317], 1212: [19320, 19561], 15922: [19323, 19649], 1266: [19324], 17012: [19326], 18328: [19327], 17827: [19328], 19684: [19330], 19661: [19331], 4837: [19332], 3426: [19333], 17769: [19334], 19602: [19335, 19610], 588: [19336], 16814: [19337], 5004: [19338], 6134: [19340], 18435: [19341, 19618], 5873: [19342, 20249], 25: [19343], 609: [19344], 7989: [19345], 9275: [19346], 15744: [19347], 9086: [19348], 8136: [19349, 19400], 9073: [19350], 9094: [19352], 9110: [19353], 10030: [19354, 25250], 8959: [19355, 19374, 19632], 1894: [19356], 15962: [19358], 8272: [19359], 18358: [19360], 886: [19361], 16269: [19362], 9047: [19364], 9002: [19365, 19731], 15827: [19366], 7844: [19367], 17882: [19369], 568: [19370], 15972: [19372, 23957, 24785, 24899, 25367, 25707, 25722, 25760, 25773, 25791, 25806, 26052, 26085, 26363, 26393, 26555, 26564, 26573, 27060], 8022: [19373, 20082, 20470], 1888: [19375], 19293: [19376], 189: [19377], 8422: [19378], 16601: [19380], 799: [19383], 19069: [19384], 16542: [19385], 15933: [19386, 21044], 11760: [19387], 7775: [19389, 22589, 27194, 27200], 11725: [19391, 19711, 19723, 19725, 19764, 20236, 20241], 8465: [19392], 8983: [19393], 6151: [19394], 7422: [19396], 8277: [19397], 12642: [19398], 7548: [19399, 19413], 8045: [19401, 21048], 9230: [19403], 10400: [19406], 10251: [19407], 8361: [19408], 10720: [19409], 7968: [19410], 16390: [19411], 831: [19412], 8644: [19415], 10751: [19417], 19080: [19418], 18367: [19420], 15840: [19421], 5330: [19422], 19062: [19423], 6515: [19425, 20822], 19169: [19426, 20522, 20835], 7448: [19427], 16307: [19428, 19683], 10705: [19430], 12140: [19431], 4922: [19432], 12315: [19433], 18390: [19434], 5650: [19435], 10415: [19437, 19761], 9035: [19438], 10659: [19439, 22813, 27217, 27771, 28369, 28473, 28923], 15873: [19441], 11531: [19443], 15652: [19446, 19490], 10778: [19447], 9727: [19450], 7832: [19451], 8645: [19455], 7896: [19456], 11437: [19457], 8009: [19458], 7723: [19459], 12788: [19460], 11529: [19461], 11736: [19462], 18902: [19466], 12820: [19467], 8649: [19468, 19624], 8790: [19469], 8697: [19470], 15682: [19473], 8514: [19474], 11822: [19475], 11621: [19476], 17008: [19477], 10757: [19478], 12789: [19480], 11724: [19481, 19742], 11758: [19482], 6905: [19483, 23557, 23561, 23723, 23766, 24006, 24099, 24168, 24177, 24255, 24305, 24423, 24490, 24528, 24544, 24563, 24575, 24592], 11800: [19485, 21453], 12138: [19487], 12470: [19488], 12836: [19491], 12808: [19492], 12490: [19493], 11690: [19494], 7664: [19495], 12652: [19496, 20265], 5885: [19498], 5807: [19499], 17949: [19500], 7084: [19502], 7492: [19503], 5871: [19504], 12742: [19505], 5779: [19506, 20304], 6989: [19507], 5632: [19508, 19771], 15001: [19511], 3594: [19513, 19517, 19802, 19812], 3584: [19514, 20315], 3586: [19515, 19807], 14997: [19516], 3212: [19518], 3500: [19520, 19529, 20640], 3623: [19521], 3556: [19523], 3446: [19524], 3413: [19526], 3606: [19528], 19656: [19530], 14649: [19531], 3202: [19532], 664: [19533], 3302: [19535, 32093, 32098, 32102, 32128], 3327: [19537, 19836], 16808: [19538], 3362: [19539], 15449: [19543, 19586], 4902: [19545], 4994: [19546, 19565, 19615, 19853, 19856, 20203], 19305: [19549], 14376: [19557], 1368: [19568], 14650: [19571], 16940: [19572, 19576], 15342: [19574], 14429: [19575], 17797: [19578, 20958], 17717: [19579], 14352: [19580], 1954: [19581], 15463: [19582], 17704: [19584], 15838: [19588], 916: [19601], 17654: [19602], 19308: [19609], 1343: [19611], 14001: [19612], 7621: [19614], 19586: [19616], 4986: [19617], 1842: [19620], 16352: [19621], 8035: [19628, 20815], 10324: [19633], 5018: [19634], 15908: [19636], 18559: [19637], 91: [19639], 7993: [19640], 9027: [19641], 7800: [19642, 19657, 19661, 19664, 19673, 19760, 20083], 17889: [19643], 8924: [19645], 18913: [19647], 18244: [19651], 7902: [19652], 6103: [19653], 9530: [19654], 5059: [19655], 11625: [19656], 7568: [19658], 9017: [19660], 542: [19662], 15795: [19663], 7843: [19665], 17990: [19666], 821: [19667, 19848, 19962, 20052], 15969: [19668], 827: [19669], 18680: [19670], 9149: [19671], 7935: [19674], 11680: [19676, 21454], 5112: [19677, 30041, 30266, 30966], 10555: [19678, 30486, 30843, 31051, 31632, 31860], 6519: [19679, 19681], 8439: [19680], 6061: [19682], 15289: [19684], 5166: [19687], 8950: [19688], 9022: [19689, 19738], 11303: [19690], 9033: [19692], 11184: [19693], 11396: [19694], 8386: [19695], 8024: [19696], 17062: [19697], 10643: [19698], 10765: [19700], 16474: [19702], 17781: [19704, 19894], 18048: [19705], 8615: [19707], 10302: [19709, 21591, 21641, 22112, 22531, 22602], 8970: [19710], 11506: [19712], 9823: [19715], 1798: [19716, 30385, 31056, 31107], 11740: [19717, 20244, 20263, 20274, 20553], 11968: [19718], 11729: [19719, 19734, 20239, 20468], 12514: [19720], 11731: [19721, 20270, 20558], 12823: [19722, 20878], 18838: [19724], 11540: [19727], 12579: [19728], 11711: [19729, 20598], 7015: [19730], 11728: [19732, 20215, 20228, 20240], 11934: [19733], 12348: [19735], 11674: [19737], 11710: [19743, 19762, 20216, 20217, 20233, 20575], 9030: [19744], 11733: [19745, 21153], 8973: [19747], 11887: [19749], 7352: [19753], 6965: [19754], 10837: [19755], 12810: [19757], 9649: [19758], 17317: [19763], 11703: [19765], 10835: [19768], 7803: [19770], 12804: [19772], 5705: [19773], 5798: [19774], 6942: [19775], 6938: [19776], 5551: [19777], 7569: [19778], 5780: [19779], 5853: [19780], 5797: [19781], 5942: [19782], 5441: [19783], 5512: [19785], 12816: [19786], 5745: [19787], 9767: [19788], 5687: [19789], 11039: [19790], 6038: [19791, 21480], 5476: [19792], 12744: [19793], 6894: [19794], 12418: [19798], 3622: [19819], 14734: [19820], 3447: [19822], 15554: [19823], 15004: [19826], 3406: [19828], 19318: [19829], 49: [19830], 3476: [19831], 3341: [19832], 3216: [19833, 20310, 20328], 14590: [19834], 5216: [19835], 15559: [19839], 3300: [19841], 19616: [19842], 14659: [19843], 15410: [19844, 19865], 15633: [19845], 2632: [19846], 5000: [19847], 5033: [19849], 5035: [19850], 14669: [19851], 14379: [19854], 3771: [19855, 22487, 23868], 17799: [19857, 20371], 17356: [19858], 51: [19859, 20446], 15487: [19860], 15553: [19861], 17056: [19862], 15610: [19863], 18997: [19864], 1095: [19866], 1341: [19867], 19190: [19868], 19306: [19869], 17936: [19870], 10524: [19871], 18156: [19872], 13874: [19877], 3700: [19888], 649: [19892, 20323, 20336, 20349, 20453], 17818: [19893], 17088: [19895], 4830: [19897], 759: [19898], 19585: [19904, 20377, 20379, 20385, 20388, 20717, 20721, 20724, 20726], 5282: [19905], 13866: [19907], 19309: [19912], 16936: [19916], 8825: [19927], 9106: [19977], 8607: [19980], 9036: [19983], 323: [19984], 8033: [19987], 9012: [19989, 20572], 8295: [19996], 9053: [19997], 19294: [19998], 733: [20005], 9271: [20011], 113: [20012], 574: [20015, 20416], 8592: [20029], 589: [20030, 20745], 15966: [20032], 15308: [20040], 17419: [20044], 613: [20049], 11: [20055], 545: [20056], 17934: [20060], 18338: [20061], 9151: [20062], 8926: [20071], 8027: [20078, 20100, 20219], 55: [20080], 374: [20081], 9267: [20089], 9390: [20090, 20566], 4860: [20093], 10150: [20097], 894: [20101], 11686: [20104], 888: [20106], 8436: [20107], 16465: [20108, 21037], 8044: [20115, 25713], 10563: [20116], 16739: [20118], 8220: [20120], 16738: [20122], 7816: [20123], 16745: [20125], 7735: [20130, 29460], 5080: [20133], 10485: [20141, 30213, 30445, 30969], 9051: [20147, 20819], 19363: [20151], 4814: [20157], 5789: [20158], 16445: [20159], 10403: [20168], 10759: [20169], 8976: [20171], 5339: [20176, 28612, 28689, 28773, 28915, 29240, 29328, 29565], 7348: [20178], 18095: [20179], 5202: [20191], 18414: [20193], 5709: [20196], 15911: [20198], 10151: [20205], 19303: [20206], 7146: [20209], 9385: [20213], 6571: [20214, 20395, 20500], 9039: [20218, 20747], 10457: [20220, 20276], 9041: [20221], 16709: [20222], 10025: [20224], 11742: [20225], 11966: [20226], 11505: [20229], 8691: [20231], 12125: [20232], 6583: [20234], 1813: [20235], 9890: [20237], 10930: [20238], 7567: [20242], 17162: [20243], 9586: [20245], 11541: [20246], 11752: [20247], 10991: [20248], 11761: [20251], 11871: [20252], 11895: [20253], 9794: [20254], 10036: [20256], 11663: [20258, 20489, 21809], 7565: [20259], 11697: [20260], 12344: [20261], 11844: [20262, 29063, 29470], 7480: [20264], 15653: [20266], 18428: [20267], 12814: [20268], 9142: [20269], 7275: [20271], 12152: [20272], 12828: [20273], 12137: [20277, 20593], 16710: [20278], 11657: [20279, 20600], 7354: [20280, 20294], 7855: [20281, 21492, 22570, 23518, 23574, 23706, 23750], 9723: [20282], 6234: [20283], 12340: [20284], 5390: [20285], 7257: [20286], 7330: [20287], 6783: [20288], 9739: [20289], 17269: [20290], 5635: [20291], 12134: [20292], 7115: [20293], 5547: [20295], 5911: [20296], 12123: [20297], 5391: [20298], 9768: [20299], 5927: [20300], 12769: [20301], 5949: [20302], 7878: [20303], 3566: [20306], 15006: [20307, 20320, 20634, 20635, 20642, 20643, 20649], 3583: [20308, 21234], 15010: [20309], 3570: [20312, 20637], 3585: [20313, 20633, 20636], 1217: [20314, 20322, 20364, 20693, 20976], 14463: [20316], 15370: [20318], 3203: [20321], 3466: [20324], 18437: [20325, 21245], 1087: [20326, 20667, 20998, 21255, 21282], 1945: [20329], 14589: [20331, 24693], 5058: [20333, 20384, 20979], 1958: [20334, 20376], 5176: [20335], 885: [20337, 20359, 20673, 20678, 20683, 20691, 20694, 20739, 20756, 20975, 20987, 21018, 21019, 21060, 21281, 21361], 1221: [20338, 21012], 1210: [20339, 20969, 21246], 2629: [20340], 14651: [20341], 1219: [20342, 20966], 19676: [20343], 14430: [20344, 20350], 14694: [20345], 14657: [20346], 7830: [20347, 20599, 20844, 21200], 1128: [20348, 21543], 3807: [20351], 3828: [20352], 16809: [20353], 17668: [20354], 15526: [20355, 21007], 17365: [20356], 15378: [20357], 14461: [20358], 1552: [20360], 1270: [20361], 17819: [20362], 17705: [20363], 1338: [20365], 17438: [20366], 4815: [20367], 16958: [20368], 17370: [20369], 1271: [20370], 41: [20372, 22088, 22529, 22548, 23034, 23354, 23366, 23388, 23393, 23432], 17872: [20373], 6500: [20378], 19734: [20380], 19678: [20381], 1917: [20382], 686: [20383], 76: [20386], 16866: [20387], 18457: [20389], 17652: [20390], 10322: [20392, 20456, 20458, 20463, 20483, 20498, 20501, 20519, 20766], 10319: [20393, 20431, 20434, 20477, 20510, 20531, 21053], 16938: [20396, 20729], 16949: [20399, 20732], 8363: [20401], 5074: [20403], 16950: [20404, 20795, 21032, 21085], 747: [20406], 9062: [20407], 63: [20408, 20954, 20957, 20999, 21030, 21063, 21315, 21330], 17335: [20409], 7901: [20411, 20420, 21311], 8616: [20413], 8211: [20415], 8427: [20421], 385: [20422], 16107: [20423], 192: [20424], 8971: [20425], 5185: [20428], 8212: [20429, 20441, 20454], 9269: [20432], 6549: [20435], 9007: [20436, 21127], 8425: [20439], 9038: [20442], 8420: [20444, 25701], 69: [20449], 9887: [20451], 15964: [20452], 16174: [20455], 10525: [20457], 734: [20461], 16790: [20462, 20792], 7402: [20464, 20848, 23092, 31028, 31699, 31701, 31877, 32617, 32618, 32628, 32629, 32654, 32657, 32693, 32699, 32703, 32713, 32776, 32780, 32819, 33287, 33330, 33396, 33441, 33455, 33572, 33581, 33604, 33621, 33648, 33675, 33681, 33682, 33686, 33688, 33707, 33708, 33717, 33729, 34483, 34703], 5270: [20465], 6129: [20466, 20656, 21096], 18885: [20467], 6227: [20472, 21083], 4809: [20473], 16350: [20474], 4963: [20475, 20962], 9175: [20478], 3722: [20482], 4813: [20484, 21369], 16506: [20486], 5251: [20488], 5003: [20490], 16402: [20491], 10143: [20492], 18033: [20495], 5153: [20496], 10735: [20497], 15749: [20499], 5105: [20506], 5017: [20508], 16451: [20509], 15806: [20512], 8484: [20514], 10686: [20515], 10530: [20516], 11452: [20517], 8642: [20518], 872: [20523], 9155: [20524], 16051: [20526], 8939: [20527], 9580: [20528], 16291: [20529], 839: [20530], 10762: [20532, 20938, 21397, 23276, 23472, 23554, 24034, 24231, 24947, 25069, 25297, 25823, 25879, 25916, 26099, 26495], 15809: [20533], 5677: [20534], 10356: [20536], 6231: [20537, 20820, 20919, 21499], 1827: [20538], 16115: [20539], 9003: [20540, 21429], 8202: [20541], 7210: [20542], 10993: [20543], 11701: [20544, 20564, 20591, 20892], 12493: [20546], 12817: [20547, 21365], 12815: [20548], 8925: [20549], 11738: [20550], 11578: [20551], 12774: [20552], 7378: [20554], 7814: [20556, 21197, 21394], 11691: [20557, 21152, 21472], 12474: [20559, 22224], 8181: [20560], 12127: [20561], 7783: [20562], 12767: [20565], 9943: [20567], 12791: [20569], 5667: [20570], 11238: [20573, 26543, 27809], 9892: [20574], 7768: [20576], 10839: [20577], 9005: [20578], 15830: [20579], 7879: [20580], 10974: [20581], 7353: [20582], 18296: [20583], 11055: [20584], 15946: [20585], 18988: [20586], 12135: [20587], 8474: [20588], 12719: [20589], 11704: [20590], 18255: [20592], 11818: [20595, 20869, 21830], 11415: [20596], 12157: [20601], 12229: [20604], 9354: [20605], 12749: [20606], 19077: [20607], 7179: [20608], 6958: [20609, 28487, 29083], 5647: [20610], 5639: [20611], 7151: [20612], 7841: [20613], 12739: [20614], 5633: [20615], 16578: [20616], 12421: [20618], 5556: [20621], 5875: [20622], 10766: [20623], 12734: [20624], 12643: [20625], 12756: [20626], 7753: [20627], 9901: [20628], 12251: [20629], 9737: [20630], 3218: [20631], 3641: [20638], 14816: [20639], 3439: [20641, 20949], 3433: [20645], 14995: [20646], 3388: [20647], 14840: [20648], 15008: [20650, 20943], 1173: [20651, 22035], 1314: [20652], 17034: [20653], 3335: [20654, 20665], 3372: [20655], 3471: [20657, 20676, 20989], 16906: [20658, 20733], 6128: [20659], 1094: [20661], 1179: [20663], 6089: [20664], 1225: [20666], 19531: [20668, 21054, 21582], 17366: [20669], 14658: [20670], 14654: [20671], 3514: [20672], 14368: [20674], 6062: [20675, 21021], 14406: [20679], 19645: [20680, 20968, 20984, 21558], 3748: [20682], 6071: [20684], 5527: [20685], 103: [20686, 21249, 21337, 21600], 3750: [20687], 1963: [20688], 16167: [20689], 15544: [20692], 15543: [20695, 21278], 15627: [20696], 19181: [20697], 17647: [20699, 21243, 21608, 21610, 21645, 22051, 22053, 22059, 22069, 22075], 1174: [20700], 18397: [20701], 166: [20702], 17648: [20703, 21011, 21289], 19227: [20704, 22022, 22043, 22056, 22471], 16911: [20705], 19322: [20706], 1384: [20707], 19339: [20708, 20730, 20806], 825: [20709], 50: [20710, 20712], 1824: [20713], 10320: [20714], 800: [20715], 19600: [20716], 15892: [20720], 19668: [20722], 19599: [20723], 33: [20731, 21035, 21296, 21307, 21313, 21321, 21346, 21548], 8357: [20734], 5001: [20735], 87: [20736, 25658], 6100: [20737], 7964: [20738], 9016: [20741, 21090, 21327], 19258: [20742], 8097: [20743, 20744], 577: [20746], 10321: [20749, 20750, 21303], 1912: [20751, 21571], 185: [20752], 17457: [20753], 9270: [20755], 19042: [20757], 7962: [20758, 23103], 10159: [20759], 19784: [20760, 21118, 21144], 8977: [20761], 16240: [20762], 10284: [20763], 8623: [20764], 663: [20765], 19163: [20767], 5146: [20768], 34: [20769], 17921: [20770], 97: [20771, 21040], 8041: [20772, 21328], 15927: [20773], 739: [20775], 8789: [20776], 8957: [20778], 8110: [20779, 22147], 4971: [20780], 7840: [20781], 10780: [20782], 17787: [20783], 9021: [20784, 20899], 16423: [20785], 16503: [20786, 21123], 16725: [20787], 7866: [20788], 16763: [20789], 7553: [20790, 23508, 23517], 16202: [20791], 8108: [20794], 8998: [20796], 15810: [20797], 16203: [20798], 18455: [20799], 5492: [20800], 9064: [20803], 15952: [20804, 26529, 26968, 27027, 27240, 27638, 27696, 27724], 16446: [20805], 10531: [20808], 15664: [20809], 16361: [20811], 6057: [20812], 16779: [20813], 16399: [20814, 21707], 7165: [20816], 5134: [20817], 18078: [20818], 16394: [20821, 20845, 21131], 10526: [20823], 8283: [20824], 16378: [20825, 20846], 5200: [20826], 9923: [20827], 10756: [20828], 7764: [20829], 8036: [20830, 20841], 1009: [20831], 11227: [20832], 10709: [20833], 12177: [20836], 11706: [20837], 10754: [20838], 8791: [20839], 10043: [20840], 12345: [20842], 11754: [20843], 8483: [20847], 9326: [20849], 11716: [20850], 11557: [20851], 8060: [20852], 18887: [20853], 19703: [20854], 16690: [20855], 10790: [20856], 12471: [20857], 11439: [20858], 7524: [20859], 1801: [20860, 22558, 23638], 16522: [20861], 8829: [20863], 10001: [20864], 16042: [20865], 18258: [20866], 7906: [20867], 12372: [20868], 7101: [20870, 21097], 10966: [20871], 11407: [20872], 11614: [20873], 16758: [20875], 10398: [20877], 11114: [20879], 12743: [20880], 11879: [20881, 22289, 24087, 24619], 11811: [20882], 8433: [20883], 11450: [20884, 23174, 23663], 8441: [20885, 21100], 11283: [20886], 11416: [20887], 15773: [20888], 8641: [20889], 12838: [20890], 5560: [20893], 11659: [20894], 11595: [20895], 9948: [20896], 5785: [20897], 11799: [20898], 12188: [20900, 21864], 7304: [20901], 12489: [20903], 12247: [20904], 12142: [20905], 12128: [20906], 16537: [20907], 12133: [20910], 7312: [20911], 10977: [20912], 11987: [20913, 31032, 35745], 12821: [20914], 11242: [20916], 7188: [20917], 7276: [20918], 7815: [20920], 7852: [20921, 21908], 5538: [20922], 15800: [20923, 21686, 21689], 5679: [20925], 12729: [20926], 6056: [20927], 17251: [20928], 5405: [20929], 7110: [20930], 5918: [20931], 5597: [20932, 34722], 5842: [20933], 5876: [20934], 5670: [20935], 12226: [20936], 12831: [20937], 5937: [20939, 26067], 5701: [20940], 7331: [20941, 21194], 12078: [20942], 3569: [20944, 21228, 21230, 21231, 21232, 21237], 3576: [20945], 18147: [20946, 21257], 3645: [20947], 3441: [20948], 15552: [20950], 15009: [20951, 21225, 21226, 21233, 21238, 21240, 21964], 14820: [20952], 14801: [20953], 15413: [20955], 15529: [20960, 21008], 3515: [20961], 5329: [20964], 6491: [20967], 5135: [20970], 19331: [20972], 14708: [20973], 14652: [20974, 20980, 20985, 21258, 21535, 21554], 14369: [20977], 5159: [20978], 1268: [20981, 20982], 101: [20983], 3691: [20990], 3795: [20991], 6575: [20992], 17115: [20993], 5044: [20994, 21264], 3853: [20995], 3851: [20996], 15536: [20997], 15612: [21000], 15590: [21001], 15439: [21002], 15515: [21003], 4899: [21004, 33881], 17035: [21005], 17963: [21009], 15887: [21010], 17431: [21013], 18202: [21014], 19735: [21015], 17117: [21016], 5376: [21017], 170: [21020], 585: [21022], 19694: [21023], 4962: [21024], 5029: [21025], 1973: [21026], 11571: [21028], 5183: [21029], 187: [21031], 11619: [21033, 22129, 22269, 22666, 22715, 23173, 23185, 23187, 23646], 8782: [21034, 21051, 21102], 607: [21036], 18441: [21038], 19347: [21039, 21116], 9059: [21041], 5198: [21042, 23119], 8612: [21045], 619: [21046], 15841: [21047], 15893: [21049], 8428: [21052], 573: [21055], 732: [21056, 22123, 22446, 22457, 22492, 22526, 22532, 22533, 22547, 22549, 22552], 10191: [21057, 34247, 34487, 34526, 34531], 17892: [21059, 21370], 10255: [21061], 10315: [21062, 21119], 16018: [21065], 4833: [21067], 17898: [21068], 9268: [21069], 9964: [21070], 7494: [21071], 7858: [21072, 22776, 24216, 24422], 18049: [21073], 8448: [21074], 19167: [21075], 10362: [21076], 7943: [21077], 4992: [21078, 21251], 17893: [21080], 7797: [21081], 7350: [21082, 21691], 17885: [21084], 16781: [21086], 16031: [21087], 7985: [21088], 7903: [21089], 12296: [21092], 18370: [21093], 10969: [21095], 4920: [21098], 5567: [21099], 5056: [21103], 15996: [21104], 17658: [21105], 5277: [21106], 5052: [21107], 5011: [21109], 18032: [21110], 7809: [21111, 21372, 21898], 9060: [21112], 16431: [21113], 10497: [21114, 24107], 4991: [21115], 7642: [21117], 7359: [21120], 10615: [21122], 10998: [21124], 7563: [21126, 21201, 21488], 16347: [21128], 15774: [21129], 760: [21130], 18034: [21132], 5048: [21133, 22571], 9915: [21134], 19699: [21135], 5066: [21136], 8147: [21137], 7483: [21138], 8636: [21139, 21750], 9056: [21140], 6135: [21141], 16652: [21142], 9125: [21143, 21714], 5545: [21145], 12374: [21146], 17297: [21147], 12145: [21148], 11692: [21149], 16764: [21150], 16662: [21151], 7829: [21154, 21166], 9934: [21155], 11712: [21156], 11191: [21157], 7801: [21159], 17184: [21160], 10996: [21161], 8787: [21163], 11734: [21164], 10763: [21165], 9842: [21167], 9807: [21168], 18431: [21169], 19139: [21170], 11648: [21172], 11815: [21173, 21810], 9150: [21174], 12741: [21175], 12784: [21176], 11245: [21177], 17133: [21178], 17152: [21179], 9573: [21180], 9140: [21181], 7345: [21182], 12389: [21183], 17298: [21184], 11986: [21185, 27797], 12737: [21186], 11564: [21187], 11304: [21188], 11661: [21189, 22617], 10817: [21190, 22673], 6900: [21192], 7212: [21193], 5790: [21195], 5782: [21196, 21869, 22761], 5625: [21198], 12341: [21199], 5627: [21202], 5948: [21203], 6891: [21205], 7493: [21206], 12460: [21207], 5450: [21208], 9945: [21209], 6782: [21210], 7522: [21211], 12809: [21212], 5621: [21213], 5888: [21214], 12366: [21215], 5642: [21216, 22359], 5555: [21217], 10413: [21218], 12070: [21220, 21943], 12071: [21221, 22822, 23807], 12440: [21222], 5479: [21223], 12425: [21224], 3573: [21227, 21235, 21945, 21948, 21949, 21958], 1026: [21229], 14814: [21236], 183: [21239], 14836: [21241], 3273: [21242], 3368: [21244], 18149: [21247], 3249: [21248, 21527], 3701: [21254], 5204: [21256], 17015: [21259], 14370: [21260], 14729: [21261], 576: [21262], 5065: [21263], 18162: [21265], 18152: [21266], 16231: [21268], 45: [21269, 21570], 1133: [21270], 2789: [21271], 15431: [21272], 1172: [21273, 21547], 15532: [21274, 21960], 980: [21275, 28714, 28727, 29253], 18144: [21276], 15489: [21277], 15591: [21279], 15614: [21280], 17372: [21283], 18188: [21284], 17415: [21285], 6010: [21286], 3788: [21287], 1119: [21288], 17111: [21290], 582: [21291], 14738: [21292], 104: [21293, 21537, 22091, 22107, 22126, 22462, 22514], 5334: [21294, 29514], 16892: [21295], 19601: [21297], 17867: [21298], 1916: [21299], 5188: [21300], 3735: [21301], 538: [21302], 945: [21305], 1979: [21308], 107: [21309, 23073], 18545: [21310], 5130: [21312], 18016: [21314, 21351, 21593], 9054: [21316], 228: [21317, 32299], 16999: [21318], 6529: [21319], 18074: [21320], 17134: [21322], 8569: [21323], 40: [21324, 23933, 23982], 16035: [21325, 21343], 17659: [21326], 16009: [21329], 18922: [21331], 5360: [21332], 8415: [21333, 22138, 22294], 7994: [21334, 21338, 21619, 21650, 21704, 22120], 7966: [21335], 2628: [21336], 1889: [21340], 8093: [21341], 8974: [21342], 182: [21344], 8494: [21345], 16101: [21347], 8006: [21348], 17702: [21349], 8281: [21350, 34498], 6098: [21352], 4908: [21353, 21567, 24150, 28341, 29515, 30012, 31567, 33785, 33930, 34875, 34991, 35192, 35218, 35256, 35295, 35309, 35353, 35433, 35454, 35856, 35886, 35887, 35888, 35891, 35893, 35894, 35896, 35902, 35903, 35904, 35906, 35907, 35908, 35910, 35911, 35913, 35916, 35917, 35919, 35920, 35924, 35925, 35926, 35927, 35928, 35929, 35932, 35934, 35937, 35938, 35940, 35941, 35942, 35946, 35947, 35949, 35951, 35953, 35955, 35956, 35957, 35959, 35960, 35961, 35964, 35966, 35967, 35970, 35971, 35972, 35975, 35976, 35977, 35978, 35979, 35980, 35981, 35982, 35983, 35984, 35985, 35986, 35988, 35990, 35991, 35993, 35994, 35995, 35996, 35997, 36000, 36001, 36007, 36010, 36011, 36014, 36016, 36017, 36020, 36023, 36029, 36031, 36035, 36041, 36042, 36044, 36049, 36050, 36055, 36056, 36057, 36061, 36063, 36065, 36066, 36067, 36068, 36070, 36072, 36076, 36077, 36078, 36079, 36080, 36081, 36082, 36083, 36084, 36085, 36086, 36088, 36090, 36091, 36093, 36095, 36097, 36098, 36099, 36101, 36102, 36103, 36104, 36105, 36106, 36107, 36108, 36110, 36112, 36114, 36117, 36119, 36122, 36124, 36125, 36127, 36128, 36129, 36130, 36132, 36133, 36134, 36136, 36139, 36140, 36141, 36142, 36144, 36145, 36148, 36150, 36151, 36153, 36154, 36155, 36156, 36158, 36159, 36162, 36164, 36165, 36166, 36167, 36168, 36169, 36170, 36171, 36177, 36181, 36209, 36212, 36213, 36220, 36227, 36228, 36248, 36252, 36259, 36264, 36280, 36283, 36294, 36297, 36298, 36301, 36309, 36316, 36319, 36327, 36331, 36332, 36333, 36338, 36342, 36352, 36356, 36357, 36360, 36362, 36363, 36365, 36368, 36369, 36370, 36371, 36372, 36373, 36379, 36385, 36388, 36390, 36391, 36392, 36393, 36394, 36397, 36399, 36401, 36402, 36403, 36404, 36407, 36409, 36410, 36411, 36412, 36413, 36414, 36415, 36417, 36418, 36420, 36422, 36424, 36429, 36430, 36431, 36432, 36433, 36434, 36435, 36436, 36439, 36442, 36443, 36447, 36449, 36450, 36453, 36454, 36457, 36460, 36462, 36463, 36465, 36466, 36469, 36470, 36471, 36472, 36475, 36479, 36480, 36481, 36482, 36484, 36485, 36486, 36487, 36489, 36490, 36491, 36494, 36496, 36497, 36498, 36499, 36500, 36501, 36502, 36505, 36508, 36509, 36511, 36512, 36513, 36514, 36515, 36518, 36519, 36520, 36521, 36524, 36525, 36526, 36528, 36531, 36532, 36539, 36541, 36545, 36546, 36547, 36549, 36550, 36552, 36555, 36556, 36557, 36560, 36561, 36562, 36567, 36569, 36570, 36571, 36572, 36573, 36574, 36575, 36577, 36579, 36585, 36587, 36588, 36590, 36591, 36594, 36595, 36598, 36599, 36600, 36602, 36603, 36604, 36605, 36608, 36610, 36612, 36614, 36615, 36617, 36620, 36621, 36624, 36625, 36627, 36631, 36632, 36633, 36635, 36636, 36637, 36638, 36642, 36646, 36648, 36649, 36651, 36654, 36656, 36657, 36659, 36660, 36664, 36667, 36670, 36671, 36675, 36677, 36680, 36681, 36685, 36690, 36696, 36697, 36699, 36703, 36706, 36707, 36708, 36712, 36714, 36715, 36716, 36717, 36718, 36719, 36720, 36727, 36728, 36731, 36732, 36734, 36737, 36738, 36748, 36753, 36758], 855: [21354], 7842: [21355, 21470], 5131: [21356], 7808: [21358], 7863: [21359], 10250: [21360], 16304: [21362], 19161: [21363], 17390: [21364], 1001: [21366], 16473: [21367, 21379], 17788: [21368], 16759: [21373], 10750: [21374], 18904: [21375], 16755: [21376], 4961: [21377], 17125: [21378], 1817: [21380], 6099: [21381], 18009: [21383, 22431, 24205, 25170, 25869], 10285: [21384, 22680, 23482, 23937], 7521: [21385], 6493: [21388], 10603: [21389], 5327: [21390], 939: [21391], 5666: [21392, 21469, 21918, 22786], 5118: [21393], 16732: [21395], 15772: [21398], 8577: [21399], 18064: [21400], 16105: [21401], 9598: [21403], 16767: [21404], 15752: [21405], 1966: [21406], 8004: [21407], 8783: [21408], 11129: [21409, 21765, 22278], 9962: [21411], 11814: [21412], 10414: [21414, 21486], 11797: [21415], 9028: [21416], 10753: [21418], 1040: [21419], 9055: [21420], 16119: [21422], 11681: [21423], 11737: [21424], 6235: [21425], 7846: [21426, 22329, 24771, 24831, 24834, 24841, 24842, 24846, 24851, 24863, 24868, 24877, 24901, 24966, 24974, 25014, 25025, 25071, 25086, 25111, 25166, 25179, 25189, 25218, 25219, 25254, 25281, 25291, 25324, 25329, 25340, 25351, 25354, 25360, 25382, 25388, 25398, 25403, 25984], 8650: [21427], 11810: [21428, 21450, 21812], 11633: [21430], 11705: [21433], 7487: [21434], 18054: [21435], 12162: [21436], 17245: [21437], 12269: [21438], 8912: [21439], 10616: [21440], 11750: [21441], 7724: [21444], 11049: [21445, 21493, 21504], 11294: [21446, 25223, 25302, 25305, 25935, 26007, 26019, 26105, 27207], 11938: [21447], 11549: [21448], 18398: [21451], 12775: [21452], 8670: [21455], 10023: [21456], 12189: [21458], 12187: [21459], 19359: [21460], 11819: [21461, 21841], 11678: [21462], 12118: [21463], 11597: [21464], 15942: [21465], 7307: [21466], 9133: [21467], 12359: [21468], 12713: [21471], 11290: [21473, 26492, 28428], 12357: [21474], 16692: [21475], 12511: [21477], 15648: [21478], 18943: [21481], 5542: [21482], 5641: [21483], 6012: [21484], 11838: [21485, 23175], 10641: [21487], 7525: [21489], 9764: [21490], 5912: [21491], 5874: [21494], 7333: [21495], 12496: [21496], 5990: [21498], 10104: [21500], 5471: [21501, 21509], 12837: [21503], 7550: [21505, 22649, 22775, 22785, 23525, 23776], 16111: [21506], 16637: [21507, 26679], 5634: [21510], 12346: [21511], 18235: [21512], 12073: [21513], 12079: [21514], 12415: [21515], 12120: [21516], 3636: [21518], 14677: [21519], 3625: [21520], 19589: [21521, 22064], 3405: [21522], 14811: [21523], 14808: [21524], 3611: [21525], 14870: [21526], 3290: [21528], 3250: [21529], 3350: [21530], 3450: [21531], 3330: [21532], 3235: [21533], 15430: [21534], 13944: [21536], 1549: [21538], 11543: [21539], 19350: [21540], 19324: [21541], 16889: [21544], 16810: [21545], 5177: [21546, 22574, 23616], 3410: [21549], 5186: [21550], 14356: [21551], 14689: [21555], 795: [21556], 16815: [21557], 19714: [21559], 17093: [21560, 21562, 21579, 22032], 188: [21561], 15429: [21563], 15535: [21564], 17417: [21565], 19778: [21566], 4957: [21568], 18: [21569], 18993: [21572], 15555: [21573, 22033], 19220: [21574], 18191: [21575], 17454: [21576], 17856: [21577], 2633: [21580], 16853: [21581], 17833: [21583], 17420: [21584], 6083: [21585], 18409: [21586], 17798: [21587], 3796: [21588], 16987: [21589], 14553: [21590], 3789: [21592], 5363: [21594], 102: [21595], 1915: [21596], 5053: [21597], 18849: [21598], 17357: [21599], 17830: [21601, 23022], 16372: [21602], 19570: [21603], 5312: [21604], 19247: [21605], 10183: [21606, 33910, 34131, 34167, 34254, 34289, 34367, 34397], 5182: [21607, 22498, 22663], 4918: [21609], 822: [21611, 22188], 16565: [21612], 10283: [21613, 21768, 23135], 796: [21614], 121: [21615], 813: [21616], 15801: [21617, 22192, 23038], 10982: [21618], 112: [21621], 10434: [21622], 4965: [21623], 6498: [21624], 9037: [21625, 21642, 21836], 15804: [21629, 22169, 22599, 22725], 8213: [21631], 17815: [21632], 100: [21633], 5218: [21634], 8069: [21635], 4987: [21636], 15920: [21637], 126: [21638], 10429: [21639], 18230: [21640], 8007: [21646], 7942: [21647, 23041], 8975: [21651], 15943: [21652], 15957: [21653, 22565, 23078, 23169, 23217], 18053: [21655], 6909: [21660], 7940: [21662], 16311: [21664], 1828: [21669], 17899: [21671], 10190: [21678, 30394, 33912, 34039, 34056, 34135, 34467, 34497, 34613, 34955], 803: [21679], 18905: [21680], 11558: [21681], 16844: [21682], 13951: [21683], 18557: [21687], 4970: [21688], 16127: [21695], 8684: [21698], 15675: [21705], 4916: [21710], 10718: [21711], 7347: [21713], 4819: [21720], 6127: [21721], 6084: [21725], 5197: [21727], 8379: [21728], 11412: [21732], 10791: [21733], 7889: [21739, 21788], 10305: [21740], 16151: [21741], 15823: [21742], 5081: [21744], 9939: [21745], 10120: [21746], 5064: [21748], 17240: [21749], 16337: [21751], 10114: [21755], 18107: [21756], 16463: [21758], 7776: [21760], 7953: [21767], 10553: [21769], 16380: [21771], 16090: [21772], 10146: [21774], 8074: [21776], 7941: [21778], 10029: [21780], 11163: [21781, 34555], 18382: [21784], 17150: [21785], 12086: [21786], 19150: [21787], 8362: [21789], 18892: [21790], 11433: [21792], 15835: [21793], 6907: [21794, 23159, 23302, 23560, 24566, 24887, 24888, 24971, 25165, 25270, 25287, 25293, 25306, 25308, 25366, 25379, 26661], 16768: [21797, 28247], 9966: [21798], 11687: [21800], 10512: [21803, 22242, 28316, 30352, 35291, 36542], 12819: [21804], 11868: [21805, 24475, 25307], 10021: [21807, 25204], 8667: [21811], 12811: [21815], 11664: [21816], 10975: [21819], 18986: [21820], 16508: [21821], 11699: [21823], 19113: [21825], 7090: [21828], 8222: [21829], 11720: [21833], 11965: [21835], 12500: [21839], 17135: [21840], 10017: [21842], 18701: [21843], 5573: [21844], 12785: [21845], 15692: [21847], 8567: [21848], 15660: [21849], 17173: [21850], 8715: [21851], 15662: [21855], 12361: [21857], 16097: [21861], 12654: [21862], 16707: [21865], 9770: [21867], 6232: [21870], 5409: [21871], 5643: [21872], 5654: [21873], 10776: [21875], 10045: [21877], 5939: [21878, 22353, 23080, 23096, 23287, 23316, 23782], 5866: [21887, 22313], 16052: [21888], 7562: [21890, 22137, 22149, 22153, 22171, 22212, 22272, 22282, 22283, 22321, 22322, 22327, 22341, 22343], 5406: [21893], 16204: [21894, 22189], 8717: [21895], 7216: [21904], 12771: [21906], 7281: [21909], 10704: [21912], 5559: [21913], 11942: [21914], 6027: [21916], 7559: [21917, 22135, 22213, 22222, 22247, 22298, 22324, 22355, 22584, 22685, 22809], 7834: [21920], 7811: [21926], 12433: [21928], 12227: [21930], 12375: [21931], 5952: [21932], 5604: [21933], 12833: [21936], 9814: [21937], 5943: [21938], 12442: [21939], 11401: [21940], 12092: [21941], 5417: [21942], 12001: [21944], 3575: [21946, 21950, 22369, 22370, 22371, 22372, 22373, 22374, 22375, 22376, 22378, 22379, 22380, 22381, 22827, 23329], 3571: [21947, 21951], 3574: [21952, 22377, 22826], 3280: [21954, 35898], 3279: [21955, 22368, 30610, 33794, 34844, 34846, 34849, 34851, 35879, 35950], 3432: [21956], 3619: [21957, 23333, 23809, 23829, 24641, 24642, 24643, 24646, 24647, 24664, 25434, 25435], 3612: [21962, 22859], 3440: [21963], 3616: [21965, 22916, 23336, 23811, 23812, 23814, 23815, 23816, 23817, 23819, 23820, 23822], 15556: [21966, 22013, 22386], 14819: [21968, 21971, 22399], 14800: [21969], 3277: [21974], 3338: [21975], 3275: [21976], 13: [21979], 14744: [21980], 17832: [21982, 21995, 22456, 23008], 17816: [21983], 14357: [21985, 22937], 15557: [21987, 22387, 22412, 22426], 15545: [21992], 5061: [21996], 3690: [21998, 25494, 25502], 18871: [21999], 14347: [22004], 17709: [22007], 14656: [22008], 1265: [22009, 22481], 5144: [22015], 14380: [22017], 14432: [22018, 22942, 23384, 24710], 7458: [22019], 5257: [22023], 15418: [22024], 3765: [22026], 38: [22027], 456: [22028], 3838: [22031], 5132: [22034, 22991], 18167: [22036], 15409: [22037], 19295: [22038], 15348: [22039, 22428, 22459], 19756: [22040], 18163: [22041], 15620: [22042], 17057: [22044], 19289: [22045], 19349: [22046], 19226: [22047, 22065, 22074, 22424, 22476, 22478, 22480, 22482], 19250: [22048], 9743: [22049], 1285: [22050], 3757: [22052], 19218: [22054, 22828], 10312: [22055, 22193], 17778: [22057], 4846: [22058, 32311, 33806, 33877, 34091, 34290, 34396, 35076, 35262], 17643: [22060], 3424: [22061], 6520: [22062], 19590: [22063], 17684: [22066], 17660: [22067, 22085, 22485], 15803: [22068, 22461, 23111, 23263], 19591: [22070], 17041: [22071], 19292: [22072], 10978: [22073], 16956: [22076, 22078, 22503], 17886: [22077], 5313: [22079], 941: [22080], 10259: [22081], 575: [22082, 22093, 22443, 22453, 22527, 22541, 22556, 23031], 89: [22083], 208: [22084], 621: [22086], 10592: [22087], 8722: [22089], 1975: [22090], 8177: [22092], 1883: [22094], 6: [22095, 26274, 26841], 8179: [22096, 22128], 16210: [22097], 16553: [22098], 15970: [22099], 5014: [22100], 15805: [22101], 8352: [22102, 22140], 8712: [22103, 22113], 133: [22105], 18954: [22106], 19653: [22108], 11976: [22109, 31106], 586: [22110], 10276: [22111], 120: [22114], 18282: [22115], 8214: [22116], 8932: [22117], 15976: [22119], 15291: [22121], 1918: [22122], 10282: [22124, 22152], 8344: [22125, 23053], 15916: [22127], 883: [22130], 1852: [22131], 18410: [22132], 8501: [22139], 16600: [22141], 17907: [22145], 1033: [22146, 34446, 36019], 19754: [22148, 22511], 832: [22151], 5133: [22154], 10258: [22155, 23035, 23490, 23916, 23939], 7342: [22156, 23657], 15888: [22158], 17975: [22159], 8419: [22160], 16452: [22161, 23075, 27826], 16425: [22163], 6840: [22164], 1014: [22165, 22174], 4827: [22166], 11782: [22167], 10232: [22168], 16608: [22170], 5322: [22172], 7556: [22175, 22176, 22203, 22238, 22302, 22307, 22319, 22337, 22346, 22350, 22561], 519: [22179], 11629: [22180], 7554: [22181, 22205, 22252, 22567, 22739, 22758], 9601: [22182], 4889: [22183, 33921, 35209, 35368], 7343: [22184, 22720, 23309], 9409: [22187], 4993: [22190, 23084], 922: [22191, 26180, 28398, 29506, 33677], 8449: [22195], 10719: [22196], 8431: [22197, 26454], 4824: [22198], 15802: [22199, 23132], 17726: [22201], 18971: [22202], 18418: [22207], 5332: [22209], 10091: [22210], 16430: [22211], 18964: [22215], 1803: [22216], 18923: [22217], 16214: [22219], 19217: [22221], 11821: [22223], 8364: [22225], 19343: [22227], 19772: [22228], 11449: [22229, 23206], 7245: [22230], 8913: [22231], 7877: [22232], 17137: [22233], 10767: [22234, 23581, 23604, 24439, 26072, 26501], 11604: [22235], 15797: [22237], 11298: [22239], 12195: [22240, 22250, 22270, 23705], 10541: [22241], 10026: [22243], 16486: [22244], 11307: [22246, 22300], 12494: [22248], 11802: [22249], 10963: [22253], 11721: [22255], 8910: [22256], 12203: [22257, 22280, 22296, 22706], 11809: [22258, 22708, 22722, 23171], 12214: [22259], 11655: [22260], 12835: [22261], 18432: [22263], 11816: [22264], 16267: [22265], 18900: [22266], 7474: [22267, 22608, 22660, 22694, 22712], 11453: [22268], 11414: [22271], 9378: [22273], 12164: [22274], 12715: [22277], 7861: [22279], 9781: [22281, 22704], 10405: [22285], 11471: [22286], 17227: [22287], 10772: [22288, 24577, 24984, 25845, 25851, 25936, 26100], 11231: [22290], 5704: [22291, 22311, 22344], 11408: [22292], 10770: [22293, 23233, 23618, 23734, 24444, 24558, 24915, 24979, 25022, 25032, 25059, 25101, 25138, 25148, 25855, 25928, 25930], 8421: [22295], 12194: [22297], 8437: [22299], 12358: [22301], 11311: [22303], 7740: [22304, 24082], 7234: [22305], 10626: [22306], 7132: [22308], 5447: [22309], 10096: [22312], 6892: [22314], 11695: [22315], 12173: [22316], 5905: [22317, 26114, 26687], 15654: [22320], 7197: [22323], 7137: [22328], 12482: [22330], 7888: [22333], 16223: [22334], 7818: [22335], 7791: [22336, 27932, 29503, 29716, 29724, 29740, 29811, 29838, 30242], 6029: [22338], 5886: [22339], 7089: [22340], 17126: [22342], 6046: [22345], 12730: [22348], 11130: [22351], 10542: [22352], 5613: [22354, 22782], 5857: [22356], 5645: [22357], 12367: [22358], 5395: [22360], 12337: [22361], 12065: [22362], 5620: [22363], 12709: [22364], 12400: [22365], 11997: [22366], 14810: [22367, 22394], 14999: [22382], 3629: [22383], 3634: [22384], 3430: [22391], 14832: [22400], 3632: [22402, 22832, 22838, 23813, 23823, 24633, 24635, 24636, 24639, 24650, 24651, 24653, 24656, 24667, 24668], 3347: [22403], 3348: [22406], 3291: [22407, 26144], 5164: [22416, 27009], 3342: [22417], 6528: [22420], 5284: [22430, 23879], 4960: [22432, 22489], 1946: [22439], 4832: [22440], 14428: [22441], 18572: [22442], 5265: [22444], 3747: [22450], 19223: [22454], 14371: [22455], 15416: [22460], 5124: [22464], 17964: [22465], 17800: [22466, 23866], 5145: [22467], 1283: [22468], 4956: [22469], 1090: [22470], 3770: [22472, 22939, 23433], 4841: [22473], 17400: [22474, 23427], 5098: [22479], 794: [22483], 15886: [22484], 9886: [22486], 17662: [22488, 22518], 5079: [22490], 17664: [22491, 23613], 19639: [22494, 22962], 119: [22495], 5252: [22496], 5143: [22497, 23001], 835: [22500], 17663: [22501, 22504, 22507, 23459], 17060: [22502], 1959: [22505], 5362: [22506], 17027: [22508], 1060: [22509], 16875: [22510], 16960: [22512], 5101: [22513], 10286: [22515, 22634, 26310, 26339, 26488], 1131: [22516], 17656: [22517, 23474, 23920], 18537: [22519], 16106: [22520], 7945: [22521], 19219: [22522, 23987], 18560: [22523], 186: [22524], 8408: [22525], 7937: [22528], 5266: [22530], 8406: [22534], 16140: [22536], 18002: [22537], 6058: [22538], 1884: [22539, 25716, 25719, 27564], 475: [22540], 8726: [22542], 7190: [22543], 11344: [22544, 22557], 583: [22545], 7938: [22546], 5152: [22551, 23368], 17876: [22553], 6080: [22554], 7995: [22555], 1890: [22559], 17969: [22560], 10314: [22563], 7748: [22564], 1061: [22566], 9813: [22568], 17988: [22569], 8005: [22573, 22603, 23036, 23107], 11545: [22575], 5062: [22576], 9936: [22577], 16772: [22578], 6968: [22580], 16610: [22581], 893: [22582], 9581: [22585], 7708: [22587], 8460: [22588], 6581: [22591], 10602: [22592], 10234: [22593, 35001, 35110, 35302, 35329, 35370], 8140: [22594, 24169], 10217: [22595, 29393], 16295: [22596], 8894: [22597], 19003: [22598], 11798: [22600], 6078: [22601], 16744: [22604], 4831: [22607, 26269], 5237: [22609], 16360: [22610, 26982], 988: [22614, 29971, 30259], 8400: [22616], 19103: [22618], 897: [22620], 18105: [22622], 8305: [22623], 10152: [22625], 7552: [22626, 22687, 22727, 22771, 23087, 23094, 23285, 23748], 5181: [22627, 23590], 6780: [22630], 16481: [22631], 10078: [22633], 5168: [22636, 26207, 26272, 26459, 26747, 26772, 26839, 26898, 26949, 27021], 10836: [22637], 16765: [22641], 5020: [22642], 11345: [22644], 18921: [22646], 5126: [22647, 23126, 23425, 23455, 24705, 24864, 25885, 26156, 26158, 26163, 26167, 26168, 26170, 26178, 26187, 26189, 26197, 26201, 26223, 26258, 26260, 26265, 26359, 26385, 26387, 26388, 26392, 26401, 26403, 26408, 26415, 26428, 26431, 26434, 26443, 26449, 26450, 26456, 26462, 26465, 26479, 26482, 26498, 26847, 27631], 17144: [22648], 7862: [22650], 16373: [22651], 16379: [22652], 5179: [22653], 18232: [22654], 10755: [22656], 18106: [22657], 8095: [22658], 16435: [22661], 16242: [22662], 10611: [22664, 29533, 29632, 30261], 8893: [22665, 22773, 23707], 11444: [22667], 17294: [22668], 12204: [22669], 8353: [22670], 12265: [22671], 8330: [22672], 7566: [22674], 12342: [22675], 12266: [22676], 16243: [22677], 11670: [22678], 11696: [22679], 16188: [22682], 10210: [22683], 11447: [22684], 12503: [22686], 18980: [22688], 11842: [22689], 10779: [22690], 16230: [22691], 12198: [22692, 23225], 15724: [22693], 15287: [22695], 16505: [22696], 18256: [22697], 10011: [22699, 24397, 24438], 8716: [22700], 7853: [22703, 23744], 19063: [22705], 8895: [22707], 11743: [22709], 11806: [22711], 11034: [22716], 16113: [22717], 11682: [22718], 11542: [22719], 11386: [22721], 8978: [22723], 17259: [22726], 19170: [22730], 11823: [22731], 15958: [22734, 22735, 23052, 23236, 23266], 9909: [22738], 12159: [22742], 12205: [22743], 17325: [22744], 12217: [22746], 10535: [22747], 8654: [22748], 11817: [22750], 6931: [22751, 25224, 28489, 30519], 7790: [22752], 15961: [22753], 10630: [22755], 6976: [22756], 11658: [22759], 8732: [22760], 5540: [22762], 7804: [22763], 7365: [22764], 5630: [22765], 5710: [22767, 23260], 12197: [22769], 12191: [22770], 11662: [22774, 23596], 11665: [22777], 18841: [22779], 7160: [22780], 6921: [22781], 7860: [22787], 5859: [22788, 22811], 15974: [22789, 26283, 26525, 26531, 26545, 26649, 26676, 26895, 27096, 27209, 27238, 27719], 12735: [22790], 5628: [22793], 16193: [22796], 12498: [22797], 12240: [22798], 7211: [22799], 18399: [22800], 5616: [22801, 23800], 8786: [22802], 5698: [22803], 6890: [22805], 5523: [22806], 12146: [22808], 10510: [22810], 7258: [22812], 7105: [22815], 5421: [22816, 34815, 35657, 35682, 35684, 35690, 35714, 35751, 35756, 35786, 36892], 12076: [22818], 11840: [22819], 12072: [22820], 5644: [22821], 12444: [22823], 12068: [22824, 23324, 24632], 3572: [22825, 22855, 23334], 3617: [22829, 22833, 23331, 23335, 23338], 3637: [22830, 23330, 23332], 14812: [22831], 1105: [22834, 23884], 3620: [22835], 3643: [22836], 14680: [22837], 14834: [22840], 15549: [22844, 22982, 23371, 23410, 23880, 24716], 3429: [22850, 23337, 23348], 15507: [22852, 23394, 23395, 23847], 3633: [22865], 1905: [22879], 1182: [22883], 3337: [22884, 23837], 14767: [22892], 1231: [22894], 105: [22903], 5055: [22908], 19587: [22911], 3635: [22915], 1132: [22922], 1184: [22924], 14666: [22926, 22945], 1211: [22930], 5149: [22932], 18434: [22935], 17699: [22938], 14373: [22941], 805: [22949], 118: [22950, 23039, 23838, 23919, 23924, 23973, 24830], 18873: [22955], 5222: [22957], 15432: [22958], 7: [22960], 5328: [22964], 19675: [22967], 8919: [22969], 16945: [22970], 10: [22976], 19669: [22979], 735: [22981], 18460: [22986], 18171: [22987], 17433: [22990], 1337: [22992, 23405], 19182: [22993], 17945: [22994], 1274: [22995], 18408: [22997], 18994: [22998], 16913: [22999], 17375: [23000], 1370: [23002], 1354: [23003], 17665: [23004, 24748, 24756], 19340: [23005], 1295: [23006], 1304: [23007], 5278: [23009], 6499: [23010], 17211: [23011], 19515: [23012], 1930: [23013], 19665: [23014], 18097: [23015], 881: [23016, 23026], 17649: [23017, 24757], 17016: [23018], 17657: [23019, 23402, 23934], 5267: [23021], 17661: [23024], 16829: [23025], 10206: [23027], 16946: [23028], 5364: [23029], 8039: [23032], 7963: [23033], 12376: [23037], 1976: [23040], 15: [23042], 17874: [23043], 8175: [23044], 8111: [23045], 8193: [23046], 5071: [23047], 18326: [23049], 3785: [23050], 8178: [23051, 24812], 6492: [23055], 8530: [23056], 18565: [23057], 19222: [23058], 18672: [23059], 8243: [23060], 16170: [23061], 7806: [23062, 24007], 10310: [23063, 23533], 8160: [23065], 7970: [23067], 206: [23068, 26185], 18339: [23069], 17000: [23070], 10972: [23071], 8038: [23072, 23121], 1861: [23074], 15959: [23076, 23298, 24096], 236: [23077], 1855: [23083], 5170: [23085], 15799: [23086], 7865: [23088], 16774: [23089], 16368: [23090], 15683: [23091], 7944: [23093], 16780: [23095, 23537], 868: [23097], 16717: [23098], 8104: [23099], 5147: [23101], 16782: [23102, 27565, 27637], 8355: [23104], 17718: [23105], 6904: [23106], 5299: [23109, 29215, 29347, 29549, 29617, 30322], 5283: [23110], 10731: [23112], 7711: [23113, 29576, 29850, 30220, 30303, 30391, 30397, 30479, 31207], 10316: [23115], 18108: [23116], 6984: [23117], 10211: [23118], 10748: [23120, 25997, 26467, 26666, 26988, 27005, 27068, 27300], 10506: [23122], 8655: [23123], 18040: [23125], 6495: [23127], 10561: [23128], 18901: [23129], 8921: [23131], 10125: [23133], 6513: [23136], 19186: [23137], 5295: [23138, 24097, 30205, 30905, 31297, 31362, 31404, 31406, 31416, 31468, 31529, 31559, 31562, 31638, 31654, 31656, 31676, 31689], 8788: [23139], 5205: [23141], 10769: [23144], 17737: [23145], 1866: [23146], 18909: [23147], 18051: [23148], 18015: [23149], 10777: [23150], 7731: [23151], 8689: [23152], 10460: [23154, 23622], 19112: [23155], 4990: [23156], 8072: [23158], 10741: [23161, 24175], 18012: [23162], 16120: [23164], 10961: [23165], 8414: [23167], 17147: [23168], 11125: [23172], 11880: [23176, 26630, 26658, 27802], 7561: [23177, 23736], 11824: [23178], 11305: [23179], 11013: [23181], 9816: [23182], 11978: [23183], 11689: [23184, 23191], 15905: [23186], 11206: [23188], 18987: [23189], 19137: [23190], 12772: [23192], 11282: [23195], 12480: [23198], 10979: [23199], 11807: [23200], 11683: [23201], 11534: [23202], 11550: [23203], 16021: [23204], 12201: [23205, 23314, 23318, 24379], 9937: [23208], 11675: [23210], 11707: [23211], 12228: [23212], 11801: [23213, 23702], 8653: [23214], 7182: [23216], 7873: [23218], 11173: [23219], 12160: [23223], 17204: [23224], 10651: [23226, 25819, 27116], 10980: [23227], 7712: [23230], 11833: [23232, 23568], 19192: [23234], 16529: [23235], 11456: [23237], 11839: [23238], 7121: [23239], 8659: [23242], 18274: [23243], 7688: [23245], 12381: [23247], 8727: [23248], 8587: [23249], 10653: [23250, 23594, 25190, 26447, 26993, 27052, 27737], 6844: [23251], 17246: [23252], 8718: [23258], 6025: [23259], 5631: [23261], 8844: [23262], 9999: [23264, 26044], 15850: [23265], 5651: [23268], 5706: [23271], 9795: [23272], 6986: [23273], 19037: [23274], 5594: [23275], 7249: [23277], 5864: [23279, 25376], 5629: [23281], 7540: [23283], 11652: [23284], 15732: [23288], 5584: [23289], 17312: [23291], 18233: [23292], 5708: [23294], 17272: [23295], 12343: [23299], 5518: [23300], 12736: [23301], 5684: [23303], 6906: [23304, 25328, 26045, 26057], 6932: [23305, 30408, 31748, 31834, 31891, 31967], 7154: [23306, 23721], 12170: [23310], 5941: [23313, 23768, 23784, 24090, 24596, 24597, 24620, 25413], 11343: [23315], 12025: [23317], 9735: [23319], 7872: [23320, 23563, 24265, 24606, 24883, 25128, 25214, 25259, 25284, 25317, 25378, 25384, 25402, 25411], 8495: [23322], 11464: [23323], 12416: [23325], 12069: [23326], 12417: [23327], 12419: [23328], 3640: [23339], 14813: [23344], 3431: [23345], 14809: [23349], 14837: [23350], 15513: [23352], 3451: [23355], 3234: [23357], 5054: [23358], 3283: [23359], 5161: [23362, 26999, 27411, 28302], 5096: [23363, 27698], 5045: [23364], 1092: [23367], 14751: [23369], 19552: [23370], 1375: [23373], 6090: [23375], 1847: [23376], 16846: [23377], 14367: [23380], 1275: [23381], 14661: [23382], 1134: [23383], 14409: [23386], 14374: [23387], 15506: [23389, 23392, 23414, 23423, 23834, 23863, 23869, 23881], 14641: [23390], 17188: [23407], 3724: [23408], 17413: [23409], 17439: [23411], 6928: [23415], 15417: [23416], 3824: [23419], 17710: [23420], 19210: [23421], 1091: [23426], 1099: [23428], 3793: [23429], 812: [23430], 17844: [23431], 3707: [23435], 3674: [23436], 16839: [23437], 85: [23438, 23477, 23968, 24796, 25690], 3684: [23440], 17024: [23441], 16849: [23443], 19571: [23444], 5219: [23445], 16385: [23446], 17834: [23447], 5034: [23448], 1908: [23449], 175: [23450], 17382: [23451, 23959], 19342: [23452, 23745, 23914, 24999, 25077], 65: [23453], 16816: [23454], 18070: [23456], 5358: [23457], 16973: [23460], 110: [23461, 23860], 16890: [23462], 216: [23463], 7997: [23464, 25746], 16502: [23465], 1039: [23466], 8416: [23467], 8418: [23468], 177: [23469], 8410: [23470], 18554: [23471], 5224: [23473], 9583: [23475, 24828], 10240: [23476, 35259, 35396], 190: [23478], 7998: [23479], 16247: [23480], 1913: [23481], 8870: [23483], 3743: [23484], 18575: [23485], 12726: [23486], 17460: [23487], 227: [23488], 15968: [23491], 8980: [23492], 7141: [23493], 17434: [23494], 211: [23498], 16171: [23499], 10983: [23500], 18576: [23501], 16220: [23502], 16165: [23503], 16200: [23506], 8260: [23507, 25779, 25840], 5211: [23509], 10650: [23510, 26484], 16319: [23511], 5049: [23512], 18125: [23514], 18083: [23516], 8656: [23519], 16376: [23520], 15960: [23521], 8156: [23522], 17001: [23523, 25771], 15767: [23524, 23542, 24073], 952: [23526], 5107: [23527], 5050: [23530], 17028: [23531], 17768: [23532], 6874: [23534, 34728, 35668], 18126: [23535], 5189: [23539], 8564: [23541], 6228: [23543], 7560: [23545], 18085: [23547], 16263: [23548], 11825: [23550], 5089: [23552], 17069: [23553], 5069: [23555], 16417: [23559], 11656: [23562], 4984: [23565], 16743: [23566, 27662], 8941: [23567], 8399: [23570], 8376: [23571], 8266: [23572], 7836: [23575], 8744: [23576], 16742: [23580], 5195: [23585], 7782: [23586], 9974: [23587], 6482: [23592], 18011: [23602, 24383, 24739, 24832], 16544: [23603], 5180: [23605], 10663: [23606, 26083], 7893: [23607], 5240: [23608], 10967: [23610], 5128: [23611], 19341: [23615], 18391: [23617], 19774: [23619], 8037: [23621], 17794: [23623], 6930: [23627, 27970], 11677: [23628], 8291: [23629], 11592: [23631], 11673: [23632], 12501: [23633], 15975: [23634], 8373: [23637], 12760: [23639], 11562: [23640, 24447], 8679: [23641], 11826: [23642], 11434: [23643], 11863: [23644], 19193: [23645], 12215: [23647], 11445: [23648], 12168: [23649], 11313: [23650, 23786], 10032: [23651, 24430], 18336: [23653], 15765: [23654, 24924, 24939, 25969], 7433: [23655], 10648: [23656, 27245, 27533, 27684, 27685, 27710, 27740, 27770, 27776], 11867: [23659, 27145], 10253: [23660], 9976: [23662], 7926: [23664], 15824: [23666], 11609: [23667], 12806: [23668], 12209: [23671], 8454: [23672], 18440: [23673], 18333: [23674], 10595: [23675, 25862], 8794: [23676], 9919: [23677], 11154: [23678], 15839: [23679], 11563: [23680], 7167: [23684], 11342: [23685], 11618: [23686, 24324, 25249], 12352: [23688, 25240], 8267: [23689], 12481: [23690], 10628: [23692], 7738: [23695, 24838, 25649], 17242: [23696], 10511: [23698], 12202: [23699], 10073: [23700], 9985: [23701], 8711: [23703], 8263: [23704], 12778: [23708], 12171: [23709], 17260: [23710], 16281: [23711], 12190: [23713], 5787: [23715], 15945: [23716, 24537, 25344], 18881: [23717], 9815: [23718], 7166: [23722], 6047: [23724], 7351: [23725], 7339: [23726], 6037: [23727], 7851: [23728, 24210, 24814, 24856, 24859, 24861, 24874, 24881, 25012, 25072, 25106, 25185, 25230, 25231, 25280, 25299, 25311, 25349, 25352, 25359, 25362, 25363, 25824, 26023, 26691], 11281: [23729], 11932: [23730], 18314: [23731], 16272: [23732], 5617: [23737, 23785, 25389], 11301: [23739, 24095, 24434, 24436, 24452, 24472, 24488, 25194, 25207, 25221, 25267, 25318, 25780, 26001, 26600], 7833: [23740, 28335], 6940: [23743, 24500, 24547], 18309: [23749], 5878: [23751], 6943: [23753], 11860: [23754, 27022], 5781: [23755], 7119: [23756], 5783: [23758], 5700: [23760], 12116: [23764], 5541: [23767], 5880: [23769], 11929: [23770], 9893: [23772], 12434: [23773], 5665: [23774, 26111], 12192: [23775], 11425: [23777, 24083], 6886: [23778], 6988: [23779], 7315: [23781, 24616, 31123, 31171, 31188, 31939, 33701], 10546: [23787, 31621, 31622, 31642, 31678, 31682, 31683, 33171, 33329, 34419], 11853: [23788, 25296], 5913: [23789], 11970: [23791], 6021: [23792], 6011: [23794, 25232], 12166: [23796], 11054: [23797], 5936: [23798, 24615, 24621], 12426: [23802], 12438: [23803], 12059: [23804], 5452: [23805], 12066: [23806], 5861: [23808], 3639: [23810, 24637, 24644, 24645, 25438], 3618: [23818, 24652, 25443], 3642: [23821, 24648, 24649, 24678, 25433, 25436, 25437, 25442], 3286: [23824, 24672], 3628: [23825, 24654, 24655], 3599: [23826], 3409: [23827], 3408: [23828], 14823: [23830], 14831: [23831], 15510: [23832, 23842, 24718, 24719, 24731, 25567], 14822: [23833, 24669, 25447, 25448, 25454], 3339: [23835], 3340: [23836], 15352: [23839], 5095: [23840, 28289], 5247: [23841, 29500, 29920, 29943, 29951, 30003, 30008, 30067, 30164, 30282, 30340], 15551: [23843], 4923: [23844, 23870], 5117: [23845], 18013: [23849, 24956, 25763, 26399, 26997], 14655: [23850], 6081: [23851], 1109: [23852], 14674: [23854, 23857, 24638], 195: [23858], 14417: [23859], 5140: [23861, 24703, 25557, 25573, 25612, 25624, 25706, 25815, 26152, 26155, 26160, 26161, 26165, 26169, 26171, 26173, 26181, 26184, 26186, 26188, 26193, 26198, 26206, 26213, 26241, 26257, 26259, 26266, 26270, 26325, 26326, 26344, 26347, 26367, 26371, 26377, 26384, 26391, 26395, 26397, 26419, 26422, 26425, 26468, 26489], 15428: [23862], 19640: [23864], 19259: [23865], 17095: [23867], 15427: [23872], 5208: [23873], 1117: [23875], 15383: [23876], 15392: [23877], 744: [23878], 16847: [23882], 1886: [23883], 17801: [23886, 26252], 1284: [23887], 19252: [23888], 17368: [23889], 1169: [23890], 17440: [23892], 3773: [23896], 3711: [23897], 17414: [23898], 19213: [23899, 23912, 25681], 15309: [23901], 18911: [23902], 19168: [23907], 18907: [23908], 19689: [23910], 17733: [23911], 18010: [23913], 16983: [23917, 25661], 18098: [23918], 5192: [23921, 24763], 17650: [23923], 998: [23925], 8375: [23928], 15917: [23930], 8116: [23935, 30151, 31042, 31418, 31422, 31429, 31432, 31433, 31437, 31438, 31439, 31440, 31444, 31449, 31451, 31455, 31456, 31457, 31459, 31460, 31461, 31462, 31465, 31466, 31467, 31472, 31473, 31474, 31480, 31485, 31497, 31500, 31501, 31503, 31510, 31512, 31519, 31528, 31531, 31532, 31543, 31544, 31546, 31549, 31574, 31592, 31618, 31652, 31655, 31658, 31664, 31685, 31729, 31740, 31743, 31760, 31765, 31786, 31795], 16270: [23936], 587: [23938], 16959: [23940], 7967: [23941], 8398: [23943], 8034: [23944], 7923: [23945], 10484: [23947, 27144], 19058: [23949], 8806: [23950], 8015: [23952], 8157: [23953], 17764: [23954], 8314: [23956], 269: [23961], 584: [23963], 18573: [23964], 8972: [23966, 23989], 8246: [23967, 24335, 24363], 39: [23969], 18533: [23970, 24768], 7969: [23971], 817: [23977], 8227: [23978], 9126: [23979], 8273: [23980], 19038: [23981], 117: [23984, 24784], 8105: [23985], 8417: [23988], 10401: [23990], 15303: [23995], 17738: [23997], 647: [24002], 10970: [24005], 16027: [24022], 17970: [24026], 8764: [24032], 9375: [24036], 6483: [24039], 17984: [24055], 5664: [24056, 24963], 5090: [24061, 28163], 8237: [24070], 10303: [24072], 16421: [24084], 4985: [24089], 19030: [24103], 18017: [24109], 8692: [24111], 5238: [24113], 789: [24122], 8765: [24125], 991: [24126, 24275, 27007, 27062, 27446, 27494, 27551, 27703, 28094, 28351], 8109: [24127], 18448: [24132], 1983: [24136], 8158: [24137], 5217: [24147], 10729: [24152, 25811, 26065, 26534, 26622, 26981, 27010, 27693, 27773], 10749: [24162, 24219, 24513, 25809, 25826, 25836, 25838, 25867, 25900, 26000, 26094, 26117, 26424], 4964: [24167], 4807: [24170], 11698: [24171], 15885: [24172], 10556: [24174], 8713: [24179], 16328: [24188], 4952: [24191], 16331: [24192], 16977: [24193], 8749: [24196], 16225: [24212], 8455: [24215], 6068: [24217], 8708: [24223], 10554: [24224, 28373, 29516], 15777: [24230], 7996: [24236, 24362, 25030], 8325: [24237], 11694: [24238], 18836: [24240], 5116: [24242], 8144: [24244], 9071: [24247], 5070: [24251], 9588: [24252], 10202: [24257], 8750: [24269], 18935: [24274], 10470: [24276], 5156: [24284, 26230, 26239, 26240, 26246, 26256, 26781], 10636: [24285], 7897: [24287, 25016], 16429: [24288], 10697: [24293], 10624: [24296, 31101, 31648], 10538: [24297], 16357: [24303], 7486: [24314, 24426], 8020: [24315], 10634: [24318], 10657: [24320], 7107: [24321], 15807: [24322], 11280: [24326, 24458], 8176: [24327], 16229: [24328], 8784: [24330], 7225: [24331], 5889: [24334], 11438: [24340], 18031: [24345], 16575: [24346], 11855: [24354], 12781: [24358], 6788: [24359], 15764: [24360], 7915: [24361], 7309: [24367], 15292: [24368], 12731: [24372], 12183: [24373], 12238: [24374], 18292: [24376], 12231: [24380], 16221: [24382], 5712: [24384], 7898: [24396], 8395: [24399], 15826: [24402], 11246: [24403], 12499: [24404], 9785: [24405], 5711: [24407], 11479: [24409], 17231: [24411], 10207: [24414], 11828: [24416], 8823: [24418], 8152: [24424], 17943: [24428, 26655], 8951: [24429], 11628: [24431], 18430: [24433], 11626: [24437], 18368: [24443], 11259: [24449], 18385: [24454], 11297: [24457, 25952, 25991, 26008, 26118, 26604, 26644], 7680: [24471], 11851: [24478, 26653, 26690], 16252: [24482], 11660: [24483], 11031: [24484, 25180], 16086: [24485], 5877: [24493], 7381: [24496], 9946: [24499], 7720: [24510], 17287: [24515], 10654: [24527], 5448: [24530], 16130: [24532], 16535: [24538], 7157: [24541, 28537], 7739: [24545], 6850: [24549], 12239: [24550], 16094: [24551], 7195: [24553], 5396: [24557], 12751: [24560], 9134: [24564], 18334: [24572], 9898: [24573], 11077: [24574], 11291: [24582], 10620: [24583], 5879: [24587], 8747: [24599], 5451: [24604], 12087: [24605], 5694: [24611], 5614: [24612], 12428: [24623], 18239: [24624], 12257: [24626], 5467: [24628], 12732: [24629], 5867: [24630], 12017: [24631], 3630: [24634, 24640, 25440, 25455, 25456, 26138, 26149, 26150], 3621: [24657], 14847: [24659], 3626: [24660], 3403: [24661], 15411: [24662, 24730, 25444, 25445, 25458, 25493, 25509, 25518, 26204, 26218], 3428: [24663, 24665, 25450], 3477: [24670], 1904: [24671, 26132], 3267: [24673], 3320: [24674], 14825: [24676], 14869: [24677], 3295: [24679], 15512: [24680, 24717, 25561, 25577, 26146, 26148, 26177, 26194, 26195, 26212, 26220, 26791, 26796], 3321: [24681], 1326: [24683], 3407: [24684, 26179, 26753, 27418, 27467], 15769: [24685, 25946, 26995], 3670: [24686], 5127: [24688], 5047: [24689], 3577: [24690], 1550: [24695], 15530: [24696], 15511: [24698, 25466, 25503], 5343: [24699, 28846, 29486], 4919: [24701], 19229: [24704, 25627], 19051: [24706], 5178: [24707, 25812], 1111: [24708], 934: [24712, 25768, 28916], 19524: [24713], 16985: [24714], 3769: [24715, 25677], 18461: [24722], 18189: [24723], 15632: [24724], 16947: [24725], 15399: [24726], 17848: [24727], 18173: [24729], 17408: [24733], 19184: [24734], 124: [24736, 24791, 25588, 26278], 18203: [24737], 3827: [24738], 17369: [24740], 4931: [24741], 5194: [24742], 8: [24743], 17190: [24744], 3777: [24745], 17007: [24746], 16152: [24747], 17113: [24749], 18327: [24750], 5167: [24751], 5226: [24752], 17063: [24753], 3698: [24754], 17192: [24755, 25621, 26251], 14750: [24758], 19569: [24759, 25640, 25645], 18866: [24760, 26242, 26264], 5190: [24762], 19530: [24764], 5788: [24765], 14: [24766], 5092: [24767], 17023: [24769, 26250], 16825: [24770], 19786: [24772], 17667: [24775], 5264: [24776, 26842], 17905: [24777], 17068: [24778], 5245: [24779], 14407: [24780], 237: [24781], 8001: [24782], 8118: [24783], 7946: [24786], 15944: [24787], 17098: [24788], 108: [24790, 24799, 24802, 25628], 184: [24794], 8598: [24795], 150: [24801], 17210: [24803], 8013: [24804, 24815, 24823, 25704, 25720, 25725, 25794, 26025, 26277, 26295], 8008: [24805], 8479: [24807], 16: [24808], 9058: [24809], 179: [24810, 26292], 16501: [24813], 5231: [24817, 25761], 651: [24819], 8470: [24820], 8051: [24822, 30197, 32827, 36180, 36185, 36208, 36211, 36215, 36226, 36236, 36238, 36244, 36257, 36266, 36269, 36270, 36274, 36275, 36278, 36284, 36292, 36303, 36310, 36315, 36320, 36330, 36345, 36350, 36361, 36387, 36405, 36458, 36504, 36536, 36596, 36611, 36672, 36730, 36741, 36805], 3751: [24824], 15766: [24825, 25915, 25918], 948: [24826], 18273: [24827], 7849: [24833, 24852, 24876, 24962, 25109, 25139, 25313, 25325, 25326, 25327, 25339, 25348, 25372, 25387, 25394, 25410, 25415, 25417, 25421], 15775: [24835], 5323: [24837, 25860, 27051], 11446: [24839], 7847: [24840, 25220, 25253, 25322, 25803, 25943, 25965, 26032, 26055, 26124, 26586], 7407: [24845, 24891], 15857: [24848], 16556: [24857], 15770: [24860, 24923, 25158, 25866], 8429: [24862, 24866], 7911: [24867], 17902: [24869], 15813: [24872, 25960], 5046: [24873, 27510], 9410: [24875], 8475: [24878], 11248: [24880, 25882, 25953, 26464, 26507, 26540, 26601, 26970, 27090, 27183, 27892], 8014: [24890], 10144: [24892], 993: [24896], 7661: [24897], 5067: [24898], 16363: [24904], 16315: [24908], 5354: [24910, 26757, 26774, 26840, 26852, 27385, 27454, 27484, 27517, 27584, 27598, 27608, 27678, 27687, 27694, 27722, 28205, 28303, 28319], 10273: [24917], 8064: [24918], 8194: [24920], 5374: [24933], 7446: [24944], 907: [24945], 5239: [24952], 7322: [24960], 779: [24961], 1816: [24981], 10818: [24986], 5986: [24990], 8862: [24995], 17720: [25002], 16377: [25003], 968: [25004], 10646: [25007, 30548, 33291], 18417: [25018, 25790], 10168: [25029], 10529: [25031], 16462: [25037], 10496: [25038, 27755], 16019: [25044], 5253: [25049], 5015: [25052], 15735: [25054], 15672: [25055, 34366, 35495], 10658: [25060], 18280: [25064], 10605: [25066, 27760, 28919], 8871: [25074], 8446: [25079, 25154], 10540: [25094], 5100: [25107], 5232: [25116], 7536: [25119, 26662], 16233: [25121], 18454: [25131], 10668: [25132], 9921: [25134], 16571: [25135], 11835: [25141], 807: [25159], 15990: [25160], 9720: [25182], 16047: [25183], 11229: [25187], 16162: [25188], 11951: [25191], 10052: [25193], 9993: [25195], 11207: [25196], 19768: [25197], 11685: [25198, 25252], 1800: [25199, 25970], 11772: [25200], 8578: [25202], 7778: [25203, 27918], 7310: [25205], 11776: [25206], 18380: [25208], 18974: [25209], 953: [25211], 10041: [25212], 16684: [25213], 19145: [25215], 8235: [25216], 10771: [25217, 25261, 25390, 26041, 26650, 27054], 12018: [25222], 11894: [25226], 11780: [25228], 11532: [25229], 11212: [25233], 11266: [25234, 26605], 19348: [25235], 11777: [25236], 11812: [25237], 12163: [25241], 12807: [25242], 8426: [25243], 11684: [25244], 10968: [25246], 12360: [25247], 16645: [25255], 8017: [25256], 11650: [25257, 26472], 16531: [25260], 12386: [25262], 7744: [25263], 8777: [25265], 11774: [25266], 11803: [25272], 8288: [25273], 11189: [25274], 11666: [25275], 9783: [25277, 26579], 11947: [25278], 7692: [25279], 12347: [25282], 12185: [25285], 11299: [25286, 25310, 25870], 7335: [25288], 16092: [25289], 17308: [25292], 7153: [25294], 19031: [25295], 10604: [25298], 16226: [25300], 12249: [25301, 27823], 12181: [25309], 11295: [25314, 26002, 26010, 27189], 12504: [25315], 11903: [25320, 28391], 10813: [25321], 5980: [25330], 7349: [25334], 9776: [25336], 16453: [25337], 12196: [25341], 7673: [25342], 5944: [25343], 8748: [25345], 16218: [25346], 16478: [25350], 12717: [25353], 12388: [25355, 25940], 17268: [25356], 5906: [25358], 7228: [25361], 5932: [25364, 26078], 7606: [25368, 34747, 34757, 34803], 7745: [25369], 5419: [25370], 10743: [25371], 5413: [25375], 10085: [25377], 5928: [25380], 16450: [25381], 7584: [25383], 18449: [25385], 11469: [25386], 7229: [25391], 7004: [25392], 7152: [25393], 7311: [25396], 7346: [25397], 12353: [25401], 5690: [25404], 5685: [25405], 7242: [25407], 12362: [25412], 12379: [25414], 5784: [25416], 5923: [25418, 26123], 5424: [25419], 9660: [25420], 12399: [25422], 12067: [25423], 7746: [25424], 12410: [25425], 12082: [25426], 12060: [25427], 11998: [25428], 12445: [25429], 12061: [25430], 5622: [25431], 12081: [25432], 1098: [25439], 3638: [25441], 14835: [25446], 14845: [25449], 14867: [25451], 14868: [25452], 3317: [25453], 3270: [25457], 15509: [25459, 25465, 25486, 25538, 25565, 25578, 25580, 25583, 26153], 3261: [25460], 3349: [25461, 26140, 26141], 109: [25462], 15419: [25463, 25532, 26131, 26203, 26775], 3272: [25464], 16840: [25467], 3452: [25468], 6074: [25484], 5272: [25487], 15420: [25496, 25530, 25576, 26726, 26735, 26744, 26745, 26752, 26777, 26786, 26795, 26798, 26800, 26801, 26803, 26805, 26809, 27401], 205: [25501], 5340: [25506], 3658: [25508], 14771: [25511], 3693: [25517], 15534: [25519], 19525: [25522], 3694: [25535, 26174], 1977: [25539], 3214: [25543, 27379, 28026, 28036, 28046, 28608, 28626, 29196], 14363: [25548], 986: [25549], 14419: [25551], 6518: [25553], 15405: [25554, 28007, 28589], 14375: [25556], 14670: [25558], 16831: [25559], 14405: [25560], 3818: [25563, 30649, 31326, 31327, 31330, 31368, 32169], 15531: [25572], 15414: [25579, 25585, 25590, 25596], 18174: [25581], 15415: [25582, 26176, 26211, 26708, 26792, 26802, 26808], 3829: [25584], 17686: [25587, 26648], 15634: [25589], 1860: [25593], 16980: [25597], 17835: [25600], 3808: [25610], 1315: [25614], 123: [25616, 25721, 26147, 26191, 26208, 26273, 26276, 26280, 26300, 26301, 26308, 26722], 217: [25618], 17078: [25620], 78: [25622, 26502], 3815: [25629], 15778: [25635], 1386: [25638], 4927: [25639], 5279: [25641], 17822: [25644], 4951: [25646], 932: [25650], 1909: [25654], 17655: [25660, 25670], 1124: [25673], 10257: [25674, 26410, 26485], 1960: [25675], 6076: [25676], 17700: [25679], 16943: [25685], 727: [25686], 5193: [25688, 26285], 16271: [25689], 7929: [25691], 16117: [25692], 19091: [25693], 18538: [25694], 8602: [25695], 539: [25696], 16146: [25699], 8763: [25700, 26348, 26405, 26444, 26560, 26571, 26597, 26598], 1896: [25703], 17019: [25708], 15973: [25709, 27847], 214: [25710], 1121: [25711], 1845: [25712], 8040: [25714], 996: [25715], 10154: [25717], 8046: [25726], 8000: [25727, 25772, 25785, 26321], 4925: [25728], 111: [25729], 7894: [25730], 8603: [25731], 5352: [25732], 224: [25734], 1887: [25736], 8343: [25738, 26338], 18542: [25742], 10464: [25743], 8114: [25744], 17701: [25745], 8821: [25748, 25759], 5125: [25749, 26263, 26402, 26404, 26759, 26913, 26922, 26967, 27042, 27046, 27049], 35: [25750], 16279: [25752], 7871: [25753, 25895, 26060, 26077, 26086, 26090, 26091, 26103], 10170: [25756], 7850: [25758, 25800, 25914, 26048, 26107, 26561, 26583, 26629], 12199: [25762, 25945], 12355: [25767], 8830: [25777], 8230: [25778], 7587: [25784], 1022: [25786], 7856: [25787, 26574], 16488: [25793], 8231: [25802], 5082: [25807], 5085: [25808, 27389], 16383: [25810], 15783: [25817], 10527: [25820], 10773: [25822, 25831, 25888, 26005], 15808: [25827], 10745: [25828], 18924: [25829], 10774: [25832, 25856, 26490], 16305: [25833], 983: [25834], 5349: [25835], 7732: [25839], 5203: [25844], 5263: [25846], 5341: [25847], 6082: [25848], 16084: [25849], 5083: [25850], 10608: [25853], 5102: [25858], 11249: [25861, 26508, 27799], 439: [25863], 17722: [25864], 9381: [25865], 8674: [25871], 17901: [25874, 25883], 926: [25876], 7647: [25884], 969: [25886], 8555: [25890], 6075: [25891], 7795: [25893], 16007: [25898], 8499: [25902], 10155: [25904], 19765: [25905], 10989: [25907], 8824: [25909], 4954: [25910], 7538: [25912], 15971: [25913, 26616, 27169], 17685: [25919], 7928: [25920], 6786: [25921], 16374: [25923], 1969: [25924], 10156: [25926, 26418], 19782: [25929], 18378: [25932], 19004: [25937], 8374: [25939], 8122: [25941], 8546: [25942], 8250: [25944], 12200: [25948], 9138: [25950], 8845: [25951, 27259], 10027: [25954], 17258: [25955, 27798], 7658: [25956], 7813: [25957], 11861: [25958], 16187: [25959, 26320, 26496, 26592, 27085], 8031: [25961], 16566: [25962], 7183: [25963], 8018: [25964], 12206: [25966, 26593], 8714: [25967], 11016: [25968], 10028: [25972, 27107], 15895: [25973], 11451: [25974], 15722: [25975], 5569: [25976], 11546: [25977], 11341: [25978], 6023: [25979], 7581: [25980], 11630: [25981], 11643: [25982], 11560: [25983], 17195: [25986], 11857: [25987, 26536], 6901: [25988, 26471, 26620, 26674, 27236], 12207: [25989], 8043: [25990], 8200: [25992, 25993], 16666: [25994], 11247: [25995, 26039, 26511], 11957: [25996], 11024: [25998], 7120: [25999], 16483: [26003], 11775: [26004], 12390: [26006], 11869: [26009], 18218: [26012], 8730: [26013, 27221], 11547: [26014], 12233: [26015], 12184: [26016], 11302: [26020, 26570, 26603, 27735], 8863: [26021], 11045: [26022], 19070: [26024], 7570: [26026], 12491: [26027], 8693: [26028], 11873: [26029, 27265], 11270: [26030, 27792, 28242, 28441, 28467], 12182: [26031], 11554: [26034], 5662: [26035, 26632], 10095: [26036, 26106], 11669: [26037], 7874: [26040, 26093, 26351, 26500, 26563, 26657, 26665, 26698, 26699, 26701], 12720: [26043], 12508: [26046], 7313: [26047], 9599: [26049], 5455: [26050], 5926: [26051, 27961], 7488: [26053], 8878: [26056], 11859: [26059], 12463: [26061], 18242: [26062], 7344: [26063], 11296: [26064, 26615, 26642, 27186, 27302], 5401: [26066], 7601: [26068], 10101: [26069], 16988: [26070], 5381: [26073], 5974: [26074, 28524], 16509: [26076], 6004: [26079], 5692: [26080, 27203, 27947], 5649: [26082], 10815: [26084], 12180: [26087], 7426: [26089], 5502: [26092], 5524: [26095], 5480: [26096], 5590: [26097], 7294: [26098], 7246: [26101], 6969: [26102], 7239: [26108, 35809], 11846: [26110, 26659], 8884: [26112, 26547], 9766: [26113], 12728: [26115], 12264: [26116], 5435: [26119], 5514: [26120], 12462: [26121, 27281], 5648: [26122, 26694], 12063: [26125], 11041: [26126], 12016: [26127], 15166: [26128], 3427: [26129, 27394], 3667: [26130, 26709, 27330, 28088], 14857: [26133, 28016, 28017, 28019, 28022], 14848: [26134, 28013], 14828: [26135, 26714, 26721, 27341, 28025], 14830: [26136], 3578: [26137], 3266: [26139, 26727, 26750], 19553: [26142], 3319: [26143], 4882: [26151], 3334: [26154], 5051: [26157], 3332: [26159], 992: [26162], 19345: [26164], 18906: [26166, 26238], 5154: [26172, 26175, 26951], 1183: [26182], 18118: [26183], 16872: [26190], 1928: [26192], 3830: [26196, 27518, 28087, 28120, 28655], 3742: [26199], 1023: [26200], 15424: [26202, 26219, 26730], 3758: [26205], 16836: [26209], 18187: [26214], 17017: [26215], 15423: [26216, 26785, 27475, 28005], 5326: [26217, 26742], 1345: [26221], 5113: [26222, 28060, 29216, 29543], 1106: [26224], 17455: [26225], 892: [26226, 26288, 27741, 28073], 1357: [26227], 19251: [26228], 1382: [26229], 1307: [26231], 17377: [26232], 1286: [26233], 17962: [26234, 26815, 26818, 26820], 18137: [26235], 17467: [26236], 5331: [26237], 130: [26243, 26287], 116: [26244, 26322], 17640: [26245], 17782: [26247], 1951: [26248], 3833: [26249], 4885: [26253], 3425: [26254], 106: [26255], 17852: [26261], 15763: [26267, 26361, 26486], 4988: [26268, 26886], 16963: [26271], 9: [26275], 19009: [26279], 19096: [26281], 193: [26282], 5298: [26286], 16208: [26289], 8217: [26290, 26521], 10357: [26291], 270: [26293], 18215: [26294], 174: [26296, 26816, 27577], 745: [26297], 17364: [26299], 7912: [26302, 26976], 16205: [26303], 122: [26304, 26330], 5269: [26305], 1126: [26306], 18541: [26307, 26875, 27578, 27597], 19379: [26309], 16108: [26311], 17875: [26312], 15819: [26314], 18543: [26315], 1895: [26316, 28748, 28766], 19015: [26317], 8377: [26318], 10222: [26319, 27039, 27605, 34022, 35120, 35134, 35138, 35332, 35400], 86: [26323], 10231: [26324], 17025: [26327], 212: [26329], 23: [26331, 26866], 17391: [26332], 19027: [26333], 17888: [26334], 7845: [26335, 28243], 8210: [26337], 3712: [26340], 9796: [26341], 7701: [26342, 26524], 17906: [26345], 15731: [26346], 16419: [26349], 16344: [26352], 16729: [26353], 8864: [26354], 17994: [26356], 7539: [26360], 5361: [26362], 16852: [26364], 18124: [26366, 26956], 17013: [26368], 7392: [26369], 9811: [26370], 17392: [26372], 7586: [26373, 27290, 27663, 28340, 28526], 19755: [26374, 26375], 8456: [26376], 19700: [26378, 28208], 791: [26380], 8365: [26381], 8476: [26382], 4968: [26383], 8561: [26386], 16384: [26389], 11778: [26396], 15880: [26398], 10614: [26400, 27284, 27761, 28294, 28413, 28856, 28882, 28906, 28936, 28941, 29134, 29520, 29529, 29536, 29558, 29568, 29604, 29631, 29636, 29661, 29683, 30444], 7857: [26406], 17207: [26407], 15734: [26409], 16422: [26411], 8424: [26412], 4828: [26413], 9754: [26414], 5078: [26416], 4921: [26417], 5353: [26420], 9379: [26421, 26426, 26440, 26473], 7409: [26423, 30831], 17735: [26427], 10558: [26429, 28347], 17719: [26432], 906: [26433], 6842: [26435], 5151: [26437], 9804: [26441], 8931: [26442], 18057: [26446], 5963: [26448], 7952: [26451], 15785: [26453, 26894, 27059, 27086, 27093, 28282], 15993: [26455], 16089: [26457], 11316: [26458, 26537], 6987: [26460], 6876: [26461, 28839, 30450, 30824, 30935, 30961, 31023, 31138, 31211, 31524, 31537, 31569, 31583, 31653, 31681, 31688, 31707, 31721, 31747, 31872, 31893, 31902, 31913, 31928, 31951, 33624], 15956: [26463], 8308: [26466], 4808: [26469], 16420: [26470], 6079: [26474], 7672: [26476], 16770: [26477], 16309: [26478], 5443: [26480], 10532: [26481], 11409: [26483], 7163: [26487], 8682: [26491], 7670: [26493], 10031: [26497], 17218: [26499], 19770: [26503], 1850: [26504], 11963: [26505], 10049: [26506], 19783: [26509], 16182: [26510], 10800: [26512], 8435: [26513], 16766: [26514], 18394: [26515], 11671: [26516], 12354: [26517], 16685: [26518], 10160: [26519], 11593: [26520], 11234: [26522], 17255: [26523], 11864: [26526], 12350: [26527], 15915: [26528, 26566], 11267: [26530, 26541, 26556], 17213: [26532], 12174: [26533], 8434: [26535], 9942: [26538], 8394: [26539], 15655: [26542], 9805: [26544], 10171: [26546], 8678: [26548], 11003: [26549], 18266: [26550], 7462: [26551], 11275: [26552], 16665: [26553], 9752: [26554, 34556], 12253: [26557], 16697: [26558], 16705: [26559], 9958: [26562], 9782: [26565], 11388: [26567, 26613, 27132], 7328: [26568], 6144: [26569], 10994: [26572], 15771: [26576, 27109], 11553: [26577], 15837: [26578], 18360: [26580], 10617: [26581, 29014, 30889, 30925], 12245: [26582], 10814: [26584], 12178: [26585], 8430: [26587], 16001: [26588], 10066: [26589], 15912: [26590], 8359: [26591], 8536: [26594], 11293: [26595, 26612], 10722: [26596, 27718, 28333], 11841: [26602], 8299: [26606], 12179: [26607], 7696: [26609, 29114, 29473, 29823, 30526], 18346: [26610], 9984: [26611], 9689: [26614], 12796: [26617], 5674: [26618], 6957: [26619, 29784, 31130, 31134, 31139, 31146, 31149, 31157, 31915], 16579: [26623], 5383: [26624], 10692: [26625], 5883: [26626, 26952, 27212], 16644: [26627], 10013: [26628], 7226: [26631, 26678], 9758: [26633], 5934: [26635], 15661: [26636], 7086: [26637], 5962: [26638], 6017: [26639], 18301: [26640], 7406: [26641], 7334: [26643, 26645], 12363: [26646], 5672: [26647, 27978, 27980], 5598: [26651], 15698: [26652, 27253], 12172: [26654], 5539: [26656], 7271: [26660], 5882: [26664, 27187, 27920], 5945: [26667], 7386: [26668], 7338: [26669, 29795], 16642: [26670], 10594: [26671], 7707: [26672], 11128: [26673], 11995: [26675], 5593: [26677], 12794: [26680], 17131: [26681], 5940: [26682, 26689], 5891: [26683, 33601], 11465: [26684], 5581: [26686], 7772: [26688, 27653, 27660, 27986], 12218: [26692], 18839: [26693], 15658: [26695], 5924: [26696, 27256], 12014: [26697, 26702, 27304, 27993, 28570, 29149, 29858, 29874, 30553, 30554, 30563, 30566, 30567, 30571, 30576, 30580, 31061, 31240, 31241], 12439: [26700], 12454: [26703], 3393: [26704], 14827: [26705, 26720, 27343], 3666: [26706, 26707, 26711, 26734, 26738, 26794, 27392, 27399, 27503], 14826: [26710, 26717], 14844: [26712], 3644: [26715], 14854: [26716, 26718, 27340], 3392: [26719], 3631: [26723], 3293: [26725, 28603], 1180: [26728], 226: [26729], 3264: [26731, 27352, 28027], 3292: [26732], 15355: [26733], 3288: [26736], 3211: [26737], 3233: [26739], 4929: [26740], 1114: [26743, 26756, 26760], 15404: [26746, 29192], 1115: [26748, 27359, 28699], 4854: [26749, 26834], 5207: [26751], 3395: [26754], 981: [26755], 16818: [26758], 3579: [26761], 3669: [26762, 26767, 27317, 27319, 27324, 27325, 27326, 27328, 27332, 27346, 27350, 27355, 27358, 27363, 27365, 27366, 27368, 27369, 27370, 27371, 27373, 27380, 27383, 27386, 27393, 27395, 27402, 27404, 27406, 27410, 27414, 27415, 27416, 27420, 27425, 27428, 27429, 27431, 27439, 27440, 27445, 27492, 27495, 27506, 27507, 27509, 27512, 27520, 27521, 27522, 27525, 27527, 27531, 27535, 27539, 27544, 27547, 28051, 28071, 28093, 28134, 28136, 28149], 14675: [26763, 26766, 28006], 3479: [26764], 19706: [26765, 27044, 27530], 1170: [26768], 3416: [26769], 5274: [26770, 26891, 26983, 26992, 27438, 27627, 28181], 14382: [26773], 14378: [26776], 14361: [26778], 15353: [26779], 18246: [26780], 15356: [26782], 73: [26784, 26836], 3820: [26787], 18183: [26788], 5139: [26789, 27029, 27390], 18160: [26790], 15638: [26793], 1123: [26797], 1949: [26799], 19633: [26806, 26843], 17373: [26811], 18204: [26812], 3835: [26813], 3738: [26814], 19188: [26817], 4953: [26819, 27437, 27618], 1347: [26821], 1366: [26822], 16833: [26823], 1320: [26824, 28048], 9745: [26825], 3799: [26826], 15508: [26827], 3790: [26828], 5359: [26829], 17114: [26830], 14749: [26832], 176: [26833], 14591: [26835], 14739: [26837], 5375: [26838], 5342: [26844, 30246], 3783: [26845], 19643: [26846], 5346: [26848, 27061], 19634: [26849], 14762: [26850], 16942: [26851, 26859], 153: [26853], 17829: [26854], 5930: [26855, 27286], 5316: [26856], 3781: [26857], 5209: [26858], 7958: [26861], 9784: [26862], 8268: [26863], 18075: [26864], 8162: [26865], 8529: [26867], 11287: [26868], 3764: [26869], 5163: [26870, 27546, 27603], 18179: [26873], 8103: [26874, 27104], 740: [26876], 17938: [26877], 10304: [26878], 17383: [26880, 26899], 17389: [26881], 8184: [26882, 26910, 26942, 26975], 5321: [26883], 1122: [26884], 17894: [26885], 5325: [26887], 7607: [26888, 31933], 8401: [26889], 8186: [26890], 235: [26892], 16004: [26893], 180: [26897], 8411: [26902], 1936: [26903], 15894: [26904], 8068: [26905, 26906, 27804], 7914: [26908], 1129: [26909], 17083: [26911], 17026: [26914], 7290: [26916], 16760: [26924], 10997: [26925], 7999: [26927], 9585: [26931], 8617: [26932], 15282: [26933], 8257: [26934, 28406], 18416: [26935], 1924: [26936], 16273: [26937, 27016], 16793: [26940, 29593, 30342, 30947, 31596], 8798: [26943], 15847: [26944, 27067], 16246: [26945, 27176, 27889], 8328: [26946, 26961], 8916: [26947], 7588: [26948], 7825: [26950], 1922: [26953], 17887: [26955, 27620], 6841: [26962], 7159: [26963, 27202], 8332: [26971], 11366: [26972, 27946], 5345: [26973], 10268: [26974, 26986], 9786: [26977], 8270: [26978], 7777: [26979, 27088, 27896], 17707: [26980], 11237: [26985], 10597: [26989, 29532], 10260: [26990], 16317: [26991], 884: [26994], 11622: [26998, 27110, 27149], 935: [27000], 15845: [27001], 10739: [27002, 27668, 27743], 8861: [27003, 29054], 5297: [27006], 10088: [27008, 27669, 27748, 28291], 8219: [27011], 5091: [27012], 9748: [27013], 10760: [27014, 27103], 10742: [27018, 27778, 27885, 28852], 16433: [27019, 27800], 938: [27023, 27555, 28311, 28886, 30140], 4842: [27026, 27681], 11225: [27032], 8846: [27033, 27795], 8102: [27034], 8198: [27035], 17071: [27036], 15846: [27037, 27700], 10128: [27040], 10649: [27041, 27674, 27727, 27765, 27840, 27910], 1832: [27045], 10488: [27048], 8552: [27050], 10962: [27053], 16750: [27055, 29634], 8628: [27056], 8760: [27057, 30097], 17189: [27064], 8141: [27065], 10747: [27066, 28451], 7955: [27070], 8139: [27072], 10598: [27073], 12473: [27074], 7301: [27075], 12176: [27076], 12782: [27077], 19522: [27078], 11876: [27080], 17252: [27084, 34587, 34643], 11829: [27087], 11667: [27089], 9751: [27091, 28407], 12011: [27092], 11612: [27095], 12333: [27097], 11870: [27098], 11271: [27099, 28479], 10816: [27100], 8083: [27101, 32494], 5520: [27105], 11627: [27106], 8244: [27108], 10501: [27111, 27851, 27863, 29578, 29615, 29616, 29731], 12167: [27113], 17124: [27114], 10995: [27115], 869: [27117], 16215: [27120], 16005: [27121], 9744: [27122, 28135], 10618: [27124, 33488], 7927: [27125], 11858: [27126], 11413: [27127], 18451: [27128], 16773: [27129], 11632: [27130], 17136: [27131], 8496: [27133], 10024: [27134], 11865: [27135], 11153: [27136], 18018: [27137], 11370: [27138], 19142: [27140], 11285: [27141], 11620: [27142], 12397: [27143], 15704: [27146, 27172], 8154: [27147], 17708: [27148], 9843: [27150], 7671: [27152, 27214, 27223, 27872], 12486: [27153], 11052: [27154], 10493: [27155], 11241: [27156], 1013: [27157], 8701: [27158], 12169: [27159], 8276: [27161], 10665: [27163, 28315], 12383: [27165], 8883: [27166], 12382: [27168], 11843: [27170], 11856: [27171], 12267: [27173], 11862: [27174], 16562: [27175], 15283: [27177], 12356: [27179], 11884: [27180], 10661: [27182, 27671, 27717, 28275, 28331, 28535], 7537: [27184], 11426: [27185], 10987: [27188], 11171: [27190], 15954: [27193], 15814: [27196, 27658, 27836], 17128: [27197], 11830: [27198], 15701: [27201], 5519: [27204], 9740: [27205], 7611: [27206], 5933: [27208], 7366: [27210], 10000: [27213], 8877: [27215, 28193], 7659: [27218], 11036: [27220], 5887: [27222], 17315: [27225], 7369: [27226], 6977: [27227], 16643: [27229], 6902: [27231], 7774: [27232], 5392: [27233, 27275], 7248: [27237], 19176: [27241], 16536: [27243], 10807: [27244, 27262, 27965], 9791: [27248], 6853: [27249, 28339], 5453: [27250], 10819: [27252], 5618: [27255], 12232: [27258], 11373: [27260], 12513: [27268], 12326: [27272], 7122: [27273], 9902: [27274], 5668: [27276, 28556], 7268: [27277], 12216: [27278], 5595: [27279], 16539: [27282], 5397: [27287], 12004: [27288], 16268: [27289], 16224: [27291], 10033: [27292], 8875: [27294], 7097: [27295], 7453: [27296], 7698: [27298], 11466: [27301], 7278: [27303], 12015: [27305, 29865], 12328: [27307], 10823: [27308], 12084: [27309], 12413: [27310], 5400: [27311], 12110: [27312], 5414: [27313], 12441: [27314], 5515: [27315], 5623: [27316], 14843: [27322], 14849: [27334, 27337], 14858: [27335, 27339], 14865: [27336], 14853: [27338], 3263: [27349, 27361, 27378, 28029], 1929: [27351, 27364, 27524], 15528: [27353, 27463], 3314: [27354, 29185], 3318: [27356], 14348: [27367], 1306: [27374, 27407], 3662: [27375, 28074, 28132], 3276: [27381], 17837: [27388], 1313: [27391], 3333: [27396], 3394: [27397], 3695: [27405], 3294: [27409], 18870: [27412], 5348: [27413, 28110, 28180, 28185, 28195, 28284, 28287, 28646, 29212], 14672: [27419], 920: [27422, 33927, 35634], 15398: [27424], 1101: [27427, 28050], 16870: [27433], 3844: [27434, 27449], 234: [27435], 14416: [27441], 3245: [27447], 3832: [27448], 19290: [27457], 16811: [27458], 3811: [27462], 15639: [27468, 28102], 1277: [27485], 15504: [27488], 5142: [27489], 17403: [27490], 5262: [27491, 28250], 17427: [27493], 14753: [27496], 16957: [27497], 17406: [27498], 1346: [27499], 16832: [27500], 5212: [27501], 3697: [27502, 27540], 3816: [27504], 5356: [27505, 28083, 28165, 28248, 28251, 28268, 28272, 28274, 28863], 19650: [27508], 19550: [27511], 3680: [27513], 17191: [27514], 17358: [27515], 1339: [27516], 14760: [27519], 74: [27523], 5037: [27526], 17029: [27528], 90: [27529], 17711: [27532], 19551: [27534], 16874: [27536], 203: [27537, 28124, 28745], 16871: [27538], 5300: [27541], 17288: [27542], 16823: [27543], 16854: [27545], 17666: [27548], 5271: [27549, 28668], 204: [27550, 27573, 28107, 28155, 28635, 28693, 28737, 28742, 28774, 29380], 16848: [27552], 17996: [27553], 8256: [27554], 202: [27556, 27569, 27586, 27595, 28097, 28142], 16850: [27557], 16886: [27558], 17384: [27559], 16489: [27560], 17398: [27561], 17205: [27562], 156: [27563, 28749], 8755: [27566], 8249: [27567, 27640], 8391: [27570], 8413: [27571], 2794: [27572], 140: [27574, 36196], 8579: [27575], 8087: [27576], 737: [27579], 3744: [27580], 8356: [27581], 987: [27582, 28273, 28708], 10209: [27583], 139: [27585], 8236: [27587], 17448: [27588], 8850: [27589], 1937: [27590], 8187: [27591], 8229: [27592, 28744], 8914: [27593, 28767], 201: [27594], 17058: [27596], 7916: [27600], 8002: [27601], 7961: [27602], 144: [27604], 8201: [27606], 7703: [27607, 27624, 27645, 27656, 27689, 27691, 27812, 27832, 27837, 27900, 27903, 27952, 28246], 7702: [27609, 28252, 28322, 28375], 7451: [27610, 28338, 29046], 10274: [27612], 17703: [27613], 543: [27614], 8138: [27615, 27728], 8066: [27616], 16714: [27617], 7848: [27621], 16484: [27622], 10990: [27623], 18001: [27629], 1027: [27632], 17351: [27633], 5273: [27635, 28286], 16746: [27636], 18119: [27639], 9532: [27641], 8113: [27642], 18004: [27643], 898: [27644], 383: [27646], 17895: [27647], 18059: [27648], 899: [27649], 4851: [27651], 7747: [27652], 15897: [27655, 28324], 16487: [27657], 8538: [27659], 17959: [27661, 29400], 10153: [27664, 27666], 8745: [27665, 28435, 28830, 29067], 5285: [27667], 16196: [27670], 18835: [27672, 28299, 28350, 28354, 28359], 8381: [27675], 5227: [27676], 10528: [27677], 5094: [27680, 28313], 10515: [27688, 33596, 36452], 5157: [27695], 8548: [27697], 8576: [27699], 10288: [27702], 10270: [27704], 961: [27705], 12298: [27706], 10638: [27708, 28453, 29009], 729: [27709], 10652: [27711, 28905], 15730: [27712], 7892: [27713], 8680: [27714], 5234: [27715], 16274: [27720, 27845, 37002], 10607: [27721], 9755: [27723], 8371: [27725], 17064: [27726], 1794: [27730, 28271], 10560: [27731, 27926, 28511, 28960, 29757, 29777, 30309, 30383, 30413, 30980], 4805: [27732], 11262: [27733, 29607], 8736: [27734, 30223], 10583: [27742], 18910: [27744], 5210: [27745], 15874: [27746], 17194: [27747, 28469], 18109: [27749], 19215: [27750], 16327: [27751], 18376: [27752], 8155: [27753], 8323: [27762], 10655: [27763], 18035: [27766], 18006: [27768], 901: [27769], 7733: [27774], 924: [27777], 9139: [27779], 11258: [27780, 29727], 16194: [27781], 18046: [27782], 8143: [27783], 8758: [27784], 10669: [27785], 6897: [27786, 27919, 28317], 17201: [27787, 28440], 11989: [27788], 11272: [27790], 8945: [27791], 9769: [27793], 17142: [27794], 7884: [27796, 27842], 12802: [27801], 19779: [27803, 28158, 28401, 28690, 28701, 28736, 28964, 30207], 11462: [27805], 11544: [27806], 9131: [27807], 8669: [27808], 10039: [27810], 8261: [27811], 6898: [27814], 6026: [27815, 27939], 11836: [27816], 10610: [27817, 28495, 30301, 30957], 11046: [27818, 27843, 28396], 12766: [27820], 11602: [27821], 18023: [27822], 7913: [27824, 28222, 28225, 28257, 28310, 28741, 28977], 10135: [27825], 8657: [27827], 11881: [27828], 8658: [27829], 18014: [27830], 11668: [27831], 12787: [27833], 11252: [27834, 29050, 29748], 19701: [27835], 5973: [27839], 18103: [27841], 7909: [27846], 5106: [27849, 27880], 11423: [27850], 16702: [27852], 7864: [27853], 11008: [27854], 11548: [27855], 12244: [27857], 18283: [27858], 8253: [27859], 5899: [27860], 18372: [27861], 11365: [27862, 31785], 10504: [27864], 11779: [27865], 11893: [27866], 11253: [27867], 11384: [27869], 11847: [27870, 28389], 11924: [27871], 18982: [27873], 16244: [27874], 6966: [27875], 8130: [27876], 18220: [27877, 34745], 19143: [27878], 11292: [27879], 5585: [27881], 16663: [27882], 11278: [27883], 17166: [27886], 7425: [27887], 12725: [27888], 7489: [27890], 12727: [27891], 8944: [27893], 16125: [27894], 8770: [27895, 28525], 8874: [27897], 7876: [27898], 16701: [27899], 7012: [27902], 5922: [27904], 7250: [27906, 27933], 7127: [27908], 12259: [27912], 10097: [27913], 12798: [27914], 15776: [27915], 7296: [27916], 7691: [27917], 16280: [27921], 5579: [27922], 7617: [27923], 11967: [27924], 8705: [27927], 8857: [27928], 10821: [27929], 9996: [27930], 7599: [27931], 15820: [27934], 10811: [27935, 28513], 7008: [27936], 12012: [27938], 5957: [27940], 8019: [27941], 7232: [27942], 7314: [27944], 12714: [27945], 10629: [27948, 29603], 17129: [27949], 11391: [27950], 5458: [27951], 12258: [27953], 7582: [27954], 5907: [27955], 5418: [27956], 5992: [27957], 7383: [27958], 5576: [27960], 11254: [27962], 7156: [27963], 5468: [27964], 5931: [27967], 5946: [27968], 15723: [27969], 7780: [27972], 7098: [27973], 6008: [27974], 10487: [27975], 10732: [27976], 12103: [27977], 5680: [27979], 5935: [27982], 16454: [27983], 5382: [27985], 10010: [27987], 5602: [27988], 11878: [27989], 12096: [27991], 5619: [27992], 12041: [27994], 5503: [27995], 12093: [27996], 11996: [27997], 12047: [27998], 12083: [27999], 12064: [28000], 3627: [28001], 14842: [28002, 28008, 28010, 28018, 28586, 29156, 29159], 15425: [28009, 28682], 3671: [28012, 28047, 28654], 3668: [28014, 28035, 28043, 28058, 28075, 28084, 28123, 28148, 28150, 28160, 28709], 3389: [28015, 29165], 14859: [28020, 29164, 29170, 29171, 29172, 29182], 14852: [28021], 14863: [28023], 14829: [28024], 3287: [28028, 28604], 15350: [28030, 28105], 3664: [28031, 28128, 28607], 1952: [28032], 3402: [28033], 1311: [28034], 15406: [28037, 28104, 28587], 3232: [28038], 5141: [28039, 28183], 19228: [28042], 14678: [28044], 3213: [28045], 3210: [28049, 28615], 1344: [28053, 28108], 1329: [28055], 1323: [28056], 4989: [28057], 3478: [28059], 5158: [28062], 1934: [28065], 16948: [28066], 14390: [28067], 18869: [28069, 28619, 28632], 14402: [28070], 14433: [28072], 88: [28076], 14350: [28077], 14398: [28078, 29249, 29976], 16817: [28079], 18177: [28080, 28090], 14667: [28081], 18879: [28085], 3663: [28086, 28593, 28617], 3856: [28089], 1102: [28091], 1108: [28092], 15625: [28095], 15407: [28096, 29994], 17040: [28098], 919: [28099], 900: [28100], 995: [28101], 15421: [28103], 1107: [28106], 1352: [28109], 15389: [28111], 17817: [28112], 4915: [28113], 15631: [28114], 15623: [28115], 15636: [28116], 19214: [28117], 18205: [28118], 14736: [28119], 1365: [28121], 4937: [28122], 16877: [28125], 1309: [28126], 19230: [28127], 3715: [28129], 3689: [28130], 18080: [28131], 220: [28133, 28137], 3836: [28138], 196: [28139, 28179, 28190, 28209, 28213, 28221, 28227, 28229, 28232, 28756], 17853: [28140], 19554: [28141], 9746: [28143], 3809: [28145, 30011], 5337: [28146, 28628, 28731, 28946], 17371: [28151], 15703: [28152, 28254, 28491, 28542, 29026], 19667: [28153], 19635: [28154], 2630: [28156], 16804: [28157], 10165: [28159], 16298: [28161], 3734: [28162, 31298], 19237: [28164, 29437, 30644], 748: [28166], 17639: [28167, 28695], 17904: [28168, 28199], 16944: [28169], 16964: [28171, 29296], 19336: [28172], 16800: [28173], 14740: [28174], 20: [28175], 17779: [28176], 225: [28177], 18353: [28178, 28219], 127: [28182, 28191, 28198], 8402: [28184], 18359: [28186], 10216: [28187, 28230, 28231, 28332], 19104: [28188], 9888: [28189], 209: [28192, 28707], 8409: [28194], 17326: [28196, 29389, 29405], 125: [28197], 8185: [28201, 29409], 129: [28202, 28223], 8685: [28203], 19021: [28204], 221: [28206, 29406, 29419, 29436, 29447, 29997, 30038, 30084, 30085, 30087, 30090, 30091, 30102, 30103, 30117, 30129, 30132, 30135, 30136, 30144, 30145, 30157], 16516: [28207], 17807: [28210], 19787: [28211], 8282: [28212], 1839: [28214], 222: [28215], 16841: [28216, 28704, 28724], 1885: [28217], 16232: [28218], 194: [28220], 10287: [28224], 18908: [28226], 18038: [28228], 8933: [28233], 15855: [28234], 10724: [28235], 741: [28236], 19127: [28237], 15758: [28238], 8366: [28239], 16719: [28241], 8752: [28244, 29038], 16722: [28249], 476: [28253], 1797: [28255], 16797: [28256], 15761: [28258], 17976: [28259], 18043: [28260], 7781: [28262], 16775: [28263], 7794: [28264], 16555: [28265, 30188], 7939: [28266], 10738: [28267, 29055], 17003: [28269], 908: [28276], 8370: [28277], 5206: [28278, 28716], 5344: [28279], 16730: [28281], 6781: [28283], 18052: [28285], 10557: [28288], 18946: [28290], 6069: [28292], 16733: [28293], 8447: [28295], 11389: [28296], 5904: [28297, 28548], 9977: [28298], 11194: [28300], 17727: [28301], 7087: [28304], 11351: [28305], 730: [28306], 16189: [28307], 6067: [28308, 28857, 29280, 29480], 8753: [28312], 7933: [28314], 8637: [28318], 8145: [28320], 10730: [28321], 5318: [28323], 11219: [28325], 8234: [28326], 15854: [28328, 28431, 29434, 29462, 29540, 29581, 29623, 29648], 6522: [28329], 10552: [28330, 28890, 29019, 29538, 29669, 29762, 30333, 30354, 31687, 33013], 16321: [28334], 10463: [28336], 7450: [28337, 28794, 28956, 28966, 29039, 29070, 29103, 29111, 29125, 29726, 29787, 29791], 8562: [28342], 11269: [28343], 1818: [28344], 6494: [28345], 19702: [28346], 5261: [28348], 8638: [28349], 7139: [28352], 1024: [28355], 8333: [28356], 15842: [28357, 28529, 29638], 15649: [28358], 5162: [28360, 28725], 16329: [28361], 8315: [28362], 6999: [28363], 15786: [28365], 16362: [28366], 10113: [28367, 28909], 1970: [28368], 11877: [28370], 17319: [28371], 11613: [28372], 7793: [28374, 28813, 28815, 28820, 28875, 28979, 28990, 29006, 29048, 29060, 29088, 29109, 29146], 18099: [28376], 11172: [28377], 16747: [28378], 18955: [28379], 11243: [28380], 11623: [28381], 16169: [28382], 16500: [28383], 7442: [28384], 11340: [28385, 28421], 11990: [28386], 17771: [28387], 8888: [28388], 11616: [28390], 7798: [28392], 11672: [28393], 11289: [28394, 29135], 15686: [28395, 29743], 17139: [28397], 12762: [28399], 16131: [28400], 18221: [28402], 11573: [28403], 11375: [28404], 7741: [28405, 28789], 11925: [28408], 18290: [28409], 17968: [28410], 8438: [28412], 11848: [28414], 11909: [28415], 10060: [28416], 10459: [28417], 8795: [28418], 11598: [28419], 8694: [28420], 19071: [28422], 11834: [28423], 18975: [28424], 19233: [28425], 18938: [28427], 19780: [28429], 12248: [28430], 7382: [28432], 8554: [28433], 11421: [28434], 7749: [28436, 28797], 16123: [28437], 6914: [28438, 33018], 8675: [28439], 19777: [28442], 10786: [28443], 18275: [28444], 9576: [28445], 17318: [28446], 16699: [28447], 15863: [28448], 12364: [28449], 11923: [28450, 31063], 11467: [28452], 7737: [28454], 16227: [28455], 6935: [28456], 10619: [28457], 12322: [28458], 11256: [28459], 15816: [28460], 11265: [28461], 10637: [28462], 15713: [28463], 18347: [28464], 16686: [28465], 11872: [28466], 11913: [28468, 30368], 12509: [28470], 11268: [28471], 18978: [28472], 11240: [28474], 11235: [28475], 11638: [28476], 6784: [28477], 17167: [28478], 16251: [28480, 29700], 6152: [28481], 9824: [28482], 5497: [28483], 7376: [28484], 11131: [28485], 12385: [28486, 29856], 7259: [28488], 18960: [28490], 5449: [28492], 10695: [28493], 17301: [28494], 18912: [28496], 12260: [28497], 7609: [28498], 16512: [28499], 7379: [28501], 5446: [28502], 10826: [28503], 10810: [28504], 19216: [28505], 16264: [28506], 17293: [28507], 7320: [28508], 10799: [28509], 8882: [28510], 5407: [28512], 7596: [28514], 8676: [28515], 7243: [28516], 11037: [28517], 9724: [28518], 7111: [28519], 5608: [28520], 11062: [28521], 7695: [28522, 31730], 7280: [28523, 28551], 5688: [28527], 12323: [28528], 11126: [28530], 11910: [28531], 7377: [28532], 19100: [28533], 5384: [28534, 31176, 31208, 31886], 6044: [28536], 6015: [28539, 29124], 6020: [28540], 5697: [28541, 28559], 17285: [28543], 5669: [28544], 5444: [28545], 12091: [28546], 9825: [28547], 6851: [28549], 6007: [28550, 30523], 7221: [28552], 5612: [28553], 12222: [28554], 15706: [28555], 15687: [28557], 11403: [28558], 5713: [28560], 11472: [28561], 5412: [28562], 12212: [28563], 5689: [28564], 7291: [28565], 5499: [28566], 12013: [28567], 5656: [28568], 5402: [28569], 5445: [28571], 12114: [28573], 12404: [28574], 12472: [28575], 12335: [28576, 31236], 12431: [28577], 5657: [28578], 12038: [28579], 12443: [28580], 5574: [28581], 12008: [28582, 29143, 32838], 12327: [28583], 5236: [28584, 29237, 29323, 29461], 3613: [28585, 29911], 14850: [28588, 28590, 28594, 28597], 3650: [28591], 3396: [28592, 29151, 29152, 29155, 29158, 29160, 29173], 14860: [28595, 29166], 14851: [28596, 28599, 28600, 29150, 29153, 29154, 29157, 29167, 29175, 29178, 29184], 14864: [28598], 3400: [28601], 1100: [28605], 128: [28606, 28623], 5248: [28610, 28885, 29471], 5246: [28618, 29199], 3692: [28620], 15354: [28622, 28657], 3269: [28624], 3240: [28630], 19588: [28631], 15422: [28633], 5357: [28634], 947: [28638], 3665: [28641, 29248, 30048, 30052], 15503: [28642, 28652, 29988], 3761: [28644], 5308: [28645, 28869], 5260: [28648, 29239, 29306, 29344, 29539], 5303: [28650], 15357: [28651], 19162: [28656], 1322: [28658, 28659, 29274], 15397: [28660], 15617: [28661], 17465: [28662], 15524: [28663], 5196: [28664], 17404: [28665, 28669, 28675, 29308, 29315, 29420], 3801: [28666, 33826, 33846], 17447: [28667], 14737: [28670], 1308: [28673], 5138: [28674], 1846: [28677], 18136: [28679], 1387: [28680], 17412: [28681], 1029: [28683], 215: [28686], 3423: [28688, 30033], 5169: [28691], 3837: [28694], 18129: [28696], 3834: [28697, 29242, 29331], 19682: [28698, 28706, 30708], 18086: [28700], 19532: [28702], 17422: [28703], 19775: [28710], 19690: [28711], 17352: [28712], 15680: [28715], 213: [28717, 28775, 29327, 29452], 971: [28720], 16134: [28721], 16984: [28722], 15537: [28728], 4898: [28733], 16869: [28734], 17396: [28738], 8117: [28739], 736: [28743], 6523: [28746], 3745: [28747], 17327: [28750], 1120: [28751, 29197], 8100: [28752], 8054: [28753], 18423: [28754, 30073], 19238: [28755], 8466: [28757], 10140: [28759], 8199: [28760], 1865: [28761, 31410], 8189: [28762], 8324: [28763], 1025: [28764], 18564: [28765, 29410], 16245: [28768], 17967: [28769], 8120: [28771], 8396: [28772, 28781], 16256: [28776], 5259: [28777], 21: [28778], 17399: [28779], 8301: [28780], 17741: [28782], 16476: [28783], 16970: [28784], 9975: [28785], 5077: [28786], 7773: [28787], 7826: [28788], 1843: [28790], 18436: [28791], 933: [28792], 7411: [28793, 36348, 36375, 36398, 36444, 36507, 36736, 36787, 36840, 36844, 36879, 36899, 36926, 36927, 36970, 36992, 37000, 37007, 37036, 37054], 8346: [28795], 17748: [28796], 923: [28798, 28811, 29402, 29551, 31376], 16485: [28799], 6866: [28800, 30210, 30992, 31009, 31178, 31948, 32778, 32805, 32812, 32866, 32957, 32962, 33065, 33083, 33200, 33220, 33294, 33333, 33355, 33520, 33522, 33566, 33586, 33598, 33602, 33614, 33622, 33630, 33638, 33657, 33663, 33668, 33680, 34144, 34623], 16602: [28801], 10723: [28802, 29512], 5099: [28804], 1815: [28805, 28904], 8218: [28806], 16322: [28807, 29475], 16756: [28808], 3759: [28809], 4852: [28810], 16776: [28814], 16164: [28816], 15983: [28817, 30672], 7704: [28818, 29104], 8112: [28819, 28893], 7632: [28821, 29507], 10733: [28822], 8557: [28823, 31076], 16201: [28824], 17004: [28825], 18833: [28826], 8161: [28827, 29658, 29685], 19533: [28828], 8188: [28831], 4840: [28832], 8404: [28833, 28877], 10764: [28834], 5347: [28835, 29440, 29467], 10612: [28836], 18056: [28837, 30238], 6878: [28838], 10462: [28840], 16507: [28842], 7922: [28843], 946: [28845], 5304: [28848], 11364: [28849, 31055], 15812: [28850], 17944: [28851], 8061: [28853, 30216], 7605: [28854], 7690: [28858], 786: [28859, 29518, 29519], 15815: [28860, 30462], 10656: [28861], 16386: [28862, 29589], 15822: [28864], 7689: [28866], 8865: [28867], 963: [28868], 15843: [28870], 10698: [28872], 8096: [28874], 5214: [28876], 15948: [28878, 29034], 10539: [28880], 8751: [28881], 10266: [28883], 870: [28887], 10559: [28888, 28967, 29713, 31675], 8639: [28891], 16008: [28892], 8778: [28894], 5355: [28896, 29361, 29579], 19147: [28897], 16293: [28898], 5280: [28899], 16348: [28903], 10599: [28907], 16316: [28908], 10223: [28910, 29446, 30104, 31623, 32584, 33026, 33205, 33272, 33304, 33367, 34041, 34112, 34250, 35008, 35045, 35119, 35365, 36175, 36184, 36186, 36195, 36197, 36198, 36199, 36200, 36202, 36206, 36210, 36214, 36219, 36221, 36222, 36223, 36239, 36240, 36241, 36242, 36245, 36246, 36249, 36250, 36251, 36253, 36255, 36256, 36258, 36261, 36263, 36268, 36271, 36272, 36273, 36279, 36287, 36289, 36290, 36291, 36293, 36295, 36299, 36300, 36305, 36307, 36308, 36317, 36322, 36324, 36329, 36337, 36389, 36416, 36456, 36464, 36467, 36468, 36473, 36474, 36493, 36516, 36522, 36530, 36540, 36544, 36548, 36551, 36554, 36564, 36565, 36566, 36568, 36576, 36582, 36584, 36589, 36593, 36606, 36607, 36609, 36639, 36641, 36644, 36652, 36653, 36655, 36662, 36663, 36666, 36669, 36684, 36691, 36692, 36693, 36695, 36698, 36701, 36709, 36710, 36713, 36724, 36725, 36726, 36739, 36742, 36746, 36749, 36750, 36754, 36760, 36761, 36763, 36774], 17172: [28911], 6913: [28912, 30965], 8016: [28913], 10728: [28914], 8768: [28918], 808: [28920], 16754: [28922], 921: [28924], 5336: [28925, 29371], 16568: [28926], 18096: [28927], 15307: [28928], 966: [28929], 8010: [28930], 10212: [28931], 1030: [28932], 18007: [28933], 11236: [28934], 16318: [28935], 17180: [28937], 18028: [28938], 6915: [28940], 16323: [28942], 15762: [28943], 19191: [28944, 30527], 15787: [28945], 10613: [28947, 29522], 17985: [28948], 19360: [28949], 8412: [28950, 29397], 8125: [28951], 18268: [28952], 11854: [28953], 18248: [28954], 8943: [28957], 7618: [28958], 5881: [28959, 29115], 6489: [28961], 8766: [28962, 29808], 18237: [28963], 11586: [28965], 11273: [28968], 17169: [28969], 11320: [28970], 11610: [28971], 8571: [28972, 31072], 16703: [28973], 18929: [28974, 31105, 31351], 8383: [28975, 29699], 18270: [28976], 6933: [28978], 16669: [28980], 8242: [28981], 11458: [28982], 8668: [28983], 11220: [28984, 30433], 11926: [28985], 11427: [28986], 8773: [28987], 8767: [28988], 8545: [28989], 11209: [28991, 29690], 11875: [28992], 12477: [28993], 16258: [28994], 7697: [28995], 11468: [28996], 16039: [28997], 12394: [28998], 12505: [28999], 11443: [29000], 11371: [29001], 15677: [29002, 29812], 8269: [29003], 10040: [29004], 11944: [29005], 12752: [29007], 7867: [29008], 16711: [29010], 12523: [29011], 16259: [29012], 11332: [29013], 11939: [29015], 12839: [29016], 8539: [29017], 18458: [29018], 7427: [29020, 29553], 7408: [29021, 30545], 11338: [29022], 8142: [29023, 29663], 8661: [29024], 11274: [29025], 11284: [29027, 30355], 11962: [29028, 33511], 7297: [29029], 11276: [29030], 16664: [29031], 11679: [29032], 18886: [29033], 18976: [29035], 11377: [29036], 12721: [29040], 11905: [29041], 12387: [29042], 12770: [29043], 11961: [29044], 11277: [29045], 11279: [29047], 16212: [29049], 11850: [29051], 11644: [29052], 18299: [29053], 15665: [29056], 936: [29057], 5429: [29059], 18956: [29061], 6951: [29062], 8681: [29064], 18228: [29065], 6002: [29066], 7196: [29068], 11392: [29069, 29586], 5521: [29071], 19179: [29072], 6041: [29073], 15696: [29074], 7719: [29075], 6869: [29076], 10808: [29077, 29853, 31177], 15862: [29078], 16087: [29079], 5652: [29080], 6881: [29081], 7214: [29082], 6005: [29084], 6879: [29085], 7418: [29086], 17215: [29087], 9792: [29089], 7456: [29090], 7272: [29091], 16695: [29092], 7236: [29093], 16191: [29094], 8771: [29095], 7397: [29096], 7699: [29097], 5695: [29098], 15702: [29099], 16524: [29100], 17274: [29101], 18957: [29102], 7124: [29105], 7616: [29106, 31990], 8731: [29107], 8841: [29108], 5900: [29110], 9738: [29112, 29138], 11866: [29113], 6051: [29116], 5543: [29117], 7710: [29118, 30845, 30938, 31100, 31110, 31119, 31167, 31192, 31238, 31246], 7445: [29119, 31194, 31548, 31867], 5568: [29120], 10014: [29121], 5386: [29122], 6045: [29123], 17306: [29126], 7222: [29127], 8754: [29128], 6016: [29129], 7454: [29130], 16511: [29131, 29797, 29821], 5393: [29132, 29824], 5470: [29133], 17303: [29136], 9778: [29137], 11288: [29139], 12429: [29140], 12085: [29141], 19105: [29142], 12058: [29144], 12006: [29145, 31247, 31250, 31256, 31261, 31930, 32003], 12027: [29147, 30575, 33639, 33732], 5580: [29148], 3397: [29161], 14862: [29162, 29163, 29174, 29176, 29181, 29877, 29879, 29880, 29881, 29882, 29884, 29885, 29886, 29888, 29889, 29890, 29891, 29892, 29893, 29894, 29896, 29897, 29898, 29899, 29900, 29901, 29902, 29903, 29904, 29905], 3390: [29168, 29180, 29878, 29887, 29906, 29924, 29927, 29928, 29955, 29958, 29960, 29961], 14861: [29169, 29177, 29179, 29183], 1910: [29186], 3313: [29187, 31271], 1177: [29188], 3289: [29189], 14676: [29190], 3303: [29191], 3297: [29193, 29220, 29913, 29914, 29915], 3414: [29194], 1130: [29195], 3221: [29198, 29931], 3282: [29202], 5320: [29206, 31312, 31647], 5242: [29207], 3220: [29208, 29219], 5367: [29210], 3244: [29213], 19520: [29214], 3657: [29217], 5233: [29225, 29229, 29374, 29548, 29584, 29587, 30106], 1181: [29226], 1350: [29228, 29944, 29947, 29949, 29952, 30001, 30006, 30623], 1116: [29230], 14421: [29231], 14673: [29232], 14769: [29233], 14745: [29234], 14387: [29238, 29244, 29967], 14394: [29241], 4943: [29245], 19758: [29250], 22: [29251], 14411: [29254], 198: [29255], 4806: [29256], 14671: [29257], 165: [29258], 3215: [29259], 979: [29260, 30332], 3784: [29262], 3766: [29263], 14362: [29264], 3782: [29265], 15362: [29268], 3819: [29269, 30700, 31381], 3733: [29272, 29991], 15626: [29279], 1257: [29282], 18185: [29283], 19662: [29284], 17018: [29285, 29289, 29291, 29575, 30173, 30746, 30835, 30895], 3672: [29290, 29360], 3858: [29293], 1324: [29294], 1938: [29298], 18210: [29299], 17466: [29300], 18194: [29301, 29312], 1293: [29302], 1369: [29303], 18062: [29304], 6496: [29305], 1335: [29307], 18182: [29309], 3831: [29310, 29325], 16868: [29311], 1328: [29317], 17998: [29318], 3683: [29319], 17641: [29320], 1927: [29321, 29350, 29372, 29916, 30009, 30022, 30025, 30051, 30110, 30180], 19547: [29322], 200: [29332, 29429, 30030, 30130], 16636: [29333], 17061: [29335], 19548: [29337], 19232: [29339, 30732], 17103: [29343], 19685: [29348], 17065: [29351], 19641: [29353, 30712, 31386, 31387, 31394, 32273], 19664: [29354], 19636: [29355], 4912: [29358], 6146: [29362], 1948: [29363], 18928: [29368], 168: [29369], 18546: [29373], 19517: [29375], 3755: [29377], 9788: [29379], 10169: [29382], 16828: [29383, 30227], 1038: [29385], 9960: [29388], 7948: [29391, 29492], 7931: [29394, 29463, 29464], 8203: [29396, 29401, 29411], 8079: [29398], 10271: [29399], 178: [29403], 8423: [29404, 29450], 17461: [29407], 16261: [29408], 15729: [29412, 30893], 3677: [29413, 34984], 10247: [29414, 35132, 35419], 5087: [29415], 1897: [29416], 19016: [29417], 8195: [29418], 8480: [29422], 8582: [29423], 8585: [29424], 743: [29427], 7907: [29428, 30107], 8279: [29430], 4939: [29432], 16611: [29433], 17387: [29435], 10176: [29439, 33869, 33875, 33913, 34233, 34301, 34503], 16843: [29441], 8076: [29442, 33189], 8232: [29443], 8106: [29445], 8233: [29449, 30214], 8746: [29451], 17328: [29453], 17079: [29455], 8759: [29456], 8065: [29458], 6990: [29466], 5292: [29468, 30174], 15760: [29469], 9806: [29472], 19651: [29476], 16313: [29477], 17085: [29478], 4924: [29479], 11201: [29481], 7387: [29483], 8372: [29484], 8322: [29485], 6860: [29488, 34557], 5243: [29489, 29610, 29932, 29933, 29939, 29963, 29965, 29970, 29975, 30054, 30191, 30249, 30251, 30263, 30264, 30283, 30296, 30318, 30323, 30327], 18415: [29490, 31791], 16577: [29491], 8843: [29496], 11882: [29497], 8574: [29499], 18071: [29501], 16716: [29505], 11210: [29513], 5324: [29521], 8091: [29524], 1971: [29525], 10172: [29526, 33893, 33903, 33907, 33931, 33936, 33938, 34007, 34069, 34095, 34143, 34154, 34163, 34185, 34191, 34193, 34217, 34220, 34265, 34282, 34292, 34328, 34381, 34392, 34403, 34456, 34461, 34493, 34565, 34621, 34630, 34631, 34636], 1830: [29527], 9944: [29528], 18984: [29535], 7533: [29537, 30506], 18934: [29541, 30377], 8245: [29542, 29555, 29667], 997: [29544], 19757: [29546], 7796: [29547], 10205: [29550], 17780: [29552], 1028: [29554, 32596], 10517: [29556], 19029: [29559], 4926: [29561], 10639: [29562], 1796: [29563], 8385: [29567], 10289: [29569], 18123: [29570], 16751: [29572], 18966: [29580], 17179: [29582], 5302: [29583, 29922, 29926, 29935, 29962, 29978, 30005, 30028, 30039, 30049, 30056, 30071, 30076, 30080, 30146, 30150, 30163, 30183, 30187, 30204, 30224, 30237, 30258, 30270, 30273, 30320, 30331], 16325: [29585], 11264: [29590, 30400], 18920: [29594], 16588: [29595], 18362: [29597], 4866: [29598, 32310, 33929, 33933, 34015, 34317], 10158: [29599], 18044: [29600], 5309: [29601, 30281], 15709: [29602, 29650, 29664, 29701, 29710, 29763, 29854, 30294, 30374, 30389], 17161: [29605], 1017: [29606, 30057], 10194: [29611, 31053], 10725: [29613], 18088: [29614], 8756: [29618, 31012, 31014, 31108], 11257: [29619], 16006: [29620], 10157: [29621], 11263: [29622], 16354: [29627], 902: [29628], 10239: [29629, 36314], 12318: [29630], 10631: [29635], 8621: [29637], 6584: [29639], 19364: [29640], 17154: [29641], 11992: [29642], 11784: [29643], 8080: [29644], 18271: [29645], 11971: [29646], 865: [29647], 8133: [29649], 7899: [29651], 8647: [29652, 30452], 11911: [29653], 11195: [29654], 11883: [29655], 9928: [29656], 10699: [29657], 18897: [29659], 8907: [29660], 10149: [29662], 16109: [29665], 967: [29666], 18303: [29668], 10050: [29670], 11367: [29671], 11200: [29672], 7734: [29673], 7956: [29674], 11047: [29675], 12351: [29676], 8807: [29677], 11260: [29678], 8570: [29680, 29703], 16482: [29681], 11849: [29682], 7006: [29684], 9808: [29686], 11783: [29687, 31026], 11239: [29688], 18985: [29689], 11250: [29691], 8898: [29692], 8500: [29693], 11921: [29694], 8126: [29695], 8703: [29696], 11180: [29697], 16002: [29698], 7269: [29702], 11226: [29705], 7784: [29706], 12250: [29707], 9900: [29708], 12235: [29709], 8527: [29711], 16040: [29712], 15875: [29714], 18024: [29715], 12464: [29717], 11035: [29718], 11577: [29719], 12801: [29720], 11169: [29721], 11317: [29722], 8049: [29723], 12765: [29725], 11579: [29728], 11339: [29729, 29736, 30372], 16183: [29730, 30359], 18555: [29732], 10696: [29733], 18379: [29734, 31013], 8942: [29735], 7299: [29737], 16135: [29738], 6975: [29739], 11561: [29741], 17253: [29742], 17262: [29744], 17243: [29745], 15980: [29746], 16519: [29747], 12478: [29749], 8723: [29750], 15858: [29751], 927: [29752], 6929: [29753], 7298: [29754], 11441: [29755], 11463: [29756], 12246: [29758], 11981: [29759, 31852, 31901, 33548, 34538, 34635, 34705, 35512, 35578, 35616], 11019: [29760], 17235: [29761], 15716: [29764], 16589: [29765], 15695: [29766], 12459: [29767], 6877: [29768], 7000: [29769], 6911: [29770], 16521: [29771], 5908: [29772, 29825], 9741: [29773], 7771: [29775, 29827], 10548: [29776, 31083, 34356], 5408: [29778], 16091: [29779], 7126: [29780], 6001: [29781], 7662: [29782], 11954: [29783], 5965: [29785], 5925: [29786], 12495: [29788], 15991: [29789], 6920: [29790], 9983: [29792], 10662: [29793], 16538: [29794], 7449: [29796], 19006: [29798], 16638: [29799], 18216: [29800], 16691: [29801, 31956], 5558: [29802, 29803, 29807], 7293: [29804], 11346: [29805], 17270: [29806], 10824: [29809, 29810, 31974], 8707: [29813], 10792: [29814, 31039, 31141, 31180, 31889], 5377: [29815], 7657: [29816], 12003: [29817], 15953: [29818], 7785: [29819], 10543: [29820, 31035], 5611: [29822], 8796: [29826, 29828], 5498: [29829], 15951: [29830], 5607: [29831], 12035: [29832], 19040: [29833], 7595: [29834], 5469: [29835], 5378: [29836], 11852: [29837], 7541: [29839], 12512: [29840], 8698: [29841], 5571: [29842], 6926: [29843], 11397: [29844], 11393: [29845], 10804: [29846], 7317: [29847], 18383: [29848], 11874: [29849], 5394: [29851], 10502: [29852], 7227: [29855], 6970: [29857], 11021: [29859], 12062: [29860], 12422: [29861], 12010: [29862], 12002: [29864, 30568, 32009, 32017, 32028], 12007: [29866], 5459: [29867], 12053: [29868], 12451: [29869], 12056: [29870, 31253, 32018, 32021, 32023], 5953: [29871], 5575: [29872], 12037: [29873, 29875], 12044: [29876], 3315: [29883, 29908, 29909, 30600, 30606, 31279, 31285, 31286, 31295, 31299, 31304, 31315, 32033, 32034, 32035, 32036, 32037, 32038, 32039, 32040, 32041, 32042, 32044, 32045, 32046, 32048, 32049, 32050, 32051, 32052, 32053, 32054, 32055, 32056, 32057, 32059, 32060, 32061, 32062, 32063, 32064, 32065, 32066, 32068, 32069, 32070, 32071, 32072, 32073, 32074, 32075, 32076, 32077, 32078, 32080, 32081, 32082, 32083, 32084, 32085, 32086, 32087, 32088, 32089, 32091, 32092, 32094, 32095, 32096, 32097, 32099, 32100, 32101, 32103, 32105, 32106, 32107, 32108, 32109, 32110, 32111, 32112, 32113, 32116, 32117, 32121, 32122, 32129, 32132, 32133, 32134, 32135, 32140, 32141, 32292], 3401: [29895], 3563: [29907, 29910, 30593, 30598], 17860: [29912], 15396: [29917, 34867], 3230: [29918], 219: [29919, 31319, 31366, 31481], 3298: [29921], 18868: [29923, 30023], 3239: [29934], 1127: [29953], 5289: [29954], 19670: [29957], 4942: [29959, 30822], 14412: [29964], 14413: [29966], 978: [29968, 30119], 14400: [29969, 30638, 31310], 18178: [29972], 3822: [29977, 29982, 29984, 29985], 15363: [29979], 3737: [29981], 3810: [29983, 30634], 17436: [29986], 15642: [29987], 15624: [29990], 15640: [29992], 15619: [29993], 5136: [29995], 18211: [29996], 17099: [29999], 1280: [30000], 937: [30002], 14759: [30007], 1380: [30010], 18181: [30013, 30014], 18141: [30015], 18200: [30016], 1103: [30017], 1310: [30018, 30687], 17424: [30019], 3825: [30021], 3823: [30024, 30026, 30032, 30037], 14765: [30027], 3754: [30029], 3710: [30034], 15312: [30035], 163: [30036, 30153], 18422: [30040, 30061, 30113, 30386, 30460, 31135], 233: [30044], 210: [30045], 11063: [30059], 19781: [30060], 143: [30063], 18552: [30064], 4855: [30065], 17395: [30066, 30128], 17645: [30068], 15705: [30069], 218: [30070, 30083, 30086, 30601, 30602, 30654, 30704, 30775, 30788, 30794, 30796], 787: [30072, 30177, 30236], 5114: [30074, 30185, 30245, 30744], 17840: [30075], 10203: [30077], 1008: [30079, 30248], 18341: [30088], 8859: [30089], 197: [30092, 30719], 16250: [30093], 18357: [30094], 16207: [30095], 8842: [30096, 30384], 16195: [30098], 18948: [30099], 7138: [30100], 7908: [30101, 30852], 16128: [30105], 17850: [30108], 8208: [30115, 30133], 19262: [30116, 32444], 8251: [30118, 31452], 17965: [30120], 232: [30121, 32155, 32465, 33765, 34002], 17879: [30123], 230: [30124, 30750], 17385: [30125], 8077: [30126], 131: [30127], 1931: [30131], 7920: [30138], 17086: [30139], 17877: [30141], 18577: [30142], 10220: [30143], 18843: [30147], 6479: [30148], 17388: [30152], 1015: [30154], 8196: [30155], 18429: [30156], 17423: [30158], 145: [30159], 7396: [30160], 8058: [30161, 35090], 6848: [30166], 7827: [30167, 31541], 17896: [30169], 16320: [30170, 30991], 10249: [30171], 6006: [30172, 31124, 31227], 7705: [30175], 8618: [30176], 8292: [30178], 19098: [30179], 8287: [30181, 35569], 973: [30182], 15851: [30184, 30816, 31535], 8327: [30186, 30235, 30448], 4938: [30189], 16477: [30190], 17977: [30192], 8583: [30193], 6849: [30194], 7828: [30195], 15514: [30196], 977: [30198, 30313, 30714], 10246: [30199, 35220, 35413, 35462], 16569: [30200], 8517: [30201], 19022: [30203], 19128: [30206], 8285: [30208], 7750: [30209], 8802: [30211], 8915: [30212], 16554: [30215], 8290: [30217, 30781], 5398: [30218], 13897: [30219], 19362: [30221], 16172: [30222], 4891: [30225], 7594: [30226, 30271, 31181, 31985], 10606: [30228, 30330, 30943], 16343: [30229], 9584: [30230, 30921, 31508, 31517], 4804: [30233, 30299], 15784: [30234], 15853: [30240, 30324, 30820], 10520: [30241], 18361: [30243], 5335: [30253, 31659], 12401: [30254], 814: [30255], 7395: [30256, 31025, 31534, 31695, 31727, 31843, 31869, 31884, 31966, 31978, 32001, 32024, 33374], 16292: [30257], 5291: [30260, 30289, 30874, 30881, 30931, 30968], 10198: [30262, 32719, 33895, 33958], 16346: [30272], 4850: [30274], 4928: [30275, 32869, 33795, 33797, 33812, 33817, 33839, 33900, 33919, 34058, 34061, 34063, 34092, 34145, 34196, 34229, 34257, 34313, 34340, 34349, 35376], 8452: [30276], 6912: [30278], 16792: [30280, 30291, 30830, 31593, 31607], 16726: [30284], 10533: [30285, 34420], 16358: [30286], 18834: [30287, 30907, 30923, 31788, 31837], 19059: [30288], 8258: [30290], 1829: [30293], 10495: [30295], 1862: [30297, 31686], 17112: [30298], 4892: [30300], 7410: [30302], 17059: [30304, 31502, 31539], 17772: [30305], 16312: [30306, 30936], 7652: [30310], 4844: [30311], 10278: [30312], 8159: [30314], 1851: [30315], 5097: [30316], 10591: [30317], 10726: [30321], 11358: [30325, 33521], 10693: [30326], 8633: [30328, 30441], 15699: [30329], 8629: [30334, 30864], 1848: [30335], 7610: [30336], 18060: [30337], 8209: [30338], 7648: [30339], 6480: [30341], 19354: [30343], 8553: [30344], 8891: [30345, 31784], 8504: [30346], 10108: [30347], 16515: [30348], 10046: [30349, 31841], 11032: [30350], 11767: [30351], 9844: [30353], 9799: [30356], 7485: [30357], 8905: [30358], 18316: [30360], 11015: [30361, 30369], 16228: [30362], 18305: [30363], 12384: [30364], 11587: [30365], 11455: [30366, 30398], 16824: [30367], 11387: [30370, 30418, 31024], 8384: [30371, 31426], 11349: [30373], 8505: [30375], 8634: [30376], 11442: [30378, 30412], 7917: [30379], 17736: [30380], 11974: [30381], 11376: [30382], 11603: [30387], 19773: [30388], 8502: [30390], 15656: [30392], 19101: [30393], 10047: [30395], 11899: [30396], 11975: [30399], 8889: [30401], 10037: [30402], 11922: [30403], 7886: [30404], 18298: [30405], 11580: [30406], 10518: [30407], 11575: [30409], 12497: [30410], 11334: [30411], 12391: [30414], 18260: [30415], 18345: [30416], 17263: [30417], 18082: [30419], 11010: [30420], 11831: [30421], 7128: [30422], 1006: [30423], 15864: [30424], 8462: [30425], 11972: [30426], 18276: [30427], 11348: [30428], 11185: [30429], 17320: [30430], 12301: [30431], 10964: [30432], 8879: [30434], 10048: [30435], 18882: [30436], 11948: [30437], 10486: [30438], 11336: [30439, 30490], 7203: [30440, 30510], 15714: [30442], 11786: [30443], 11605: [30446], 9797: [30447], 11576: [30449], 11308: [30451], 11009: [30453], 16564: [30454], 8908: [30455], 6895: [30456], 11901: [30457], 15659: [30458], 11977: [30459], 9774: [30461], 12237: [30463], 7003: [30464], 11914: [30465], 11007: [30466], 17731: [30467], 8917: [30468, 31131], 7615: [30469, 31952], 6875: [30470, 31604, 33582], 18958: [30471], 10490: [30472], 17276: [30473], 8761: [30474], 10601: [30475], 5553: [30476, 31195], 8902: [30477], 16436: [30478], 16197: [30480], 7263: [30481], 1010: [30482], 16584: [30483], 6039: [30484], 5890: [30485], 7535: [30487], 10544: [30488, 31677], 18243: [30489], 6944: [30491, 31125, 31183], 7112: [30492], 7674: [30493], 10812: [30494], 8660: [30495], 15697: [30496], 10802: [30497], 6945: [30498], 6955: [30499], 8741: [30500, 31706], 17947: [30501], 18945: [30502], 16447: [30503], 7340: [30504], 7287: [30505], 7326: [30507], 5494: [30508, 31942, 31997], 6147: [30509], 17278: [30511], 17304: [30512], 18332: [30513], 9578: [30514], 18963: [30515], 16262: [30516], 6998: [30517], 17275: [30518], 11935: [30520], 7209: [30521, 34735], 5951: [30522], 7199: [30524], 12456: [30525], 9407: [30528], 7603: [30529], 10797: [30530], 5967: [30531], 9731: [30532], 18952: [30533], 9935: [30534], 19121: [30535], 7261: [30536], 18304: [30537], 11203: [30538], 11027: [30539], 11949: [30540], 17198: [30541], 7375: [30542], 11040: [30543], 12026: [30544], 11900: [30546], 10489: [30547, 35472], 7238: [30549], 18252: [30550], 8725: [30551], 11931: [30552], 12406: [30555], 12449: [30557, 30572], 12009: [30558], 12452: [30559], 12054: [30560], 12465: [30561], 12365: [30562], 12408: [30564], 12048: [30565], 12111: [30569], 12088: [30570], 11999: [30573, 33724, 33745], 5586: [30574], 12112: [30578], 12023: [30579], 12030: [30581], 12435: [30583], 5399: [30585], 12402: [30586], 12051: [30587, 31235], 7835: [30588], 3647: [30589, 30591, 30592, 31267, 31273, 32120], 3398: [30590], 16976: [30594], 3316: [30595], 3306: [30596], 15017: [30597], 3296: [30599, 31276], 19050: [30604], 3299: [30605], 14742: [30611], 15365: [30613, 30624, 32163], 14746: [30614], 4867: [30616], 17806: [30617], 1319: [30618], 18880: [30622], 3399: [30627], 14403: [30630], 3800: [30636, 30653, 30657, 31363], 15403: [30637, 31294, 31339, 31340], 18131: [30639], 14351: [30640], 17983: [30641], 4857: [30642], 17045: [30643, 30673, 30721, 31352], 14364: [30645], 18212: [30647, 32167], 5241: [30648, 30718, 30789, 30863, 30892, 30932, 30983, 30985], 14768: [30650], 957: [30651], 15408: [30652], 17802: [30655], 17066: [30656], 4864: [30658], 3752: [30659], 10142: [30660], 17401: [30661, 30665, 30677, 30682, 30685, 30690, 30743], 17353: [30662], 17039: [30663], 1291: [30666, 30688], 18159: [30667, 30670, 30696], 1258: [30674], 17846: [30675], 1321: [30676], 17441: [30679], 17449: [30680], 18041: [30681, 30695], 3756: [30684], 17435: [30686], 18192: [30689], 17405: [30691], 5368: [30692, 31579], 19254: [30693], 16882: [30694, 30730], 1943: [30697], 3794: [30698], 18878: [30699], 3821: [30701, 31343], 17104: [30703], 231: [30705], 6497: [30706, 31540, 32664], 3687: [30710], 984: [30711], 4904: [30713], 17783: [30715], 16876: [30716], 83: [30717], 162: [30720], 5306: [30722, 30808, 30879], 1118: [30723], 5137: [30724], 3726: [30727], 16842: [30729, 30738, 32480], 17646: [30731], 15298: [30733, 35436], 19707: [30734], 16867: [30735], 1837: [30737], 944: [30739], 8389: [30741], 199: [30742, 30745, 30785], 8450: [30747], 19036: [30748], 137: [30749], 8820: [30751, 30928, 31152], 18348: [30756], 8627: [30757], 18094: [30758], 5964: [30759], 7910: [30760, 30846], 18342: [30761], 9989: [30762, 30941, 30942, 30946], 18114: [30763], 158: [30764, 32171], 8886: [30765], 10430: [30766], 15759: [30768], 16155: [30769], 18121: [30770], 17386: [30771], 10229: [30773], 17374: [30774], 7921: [30778], 16606: [30779], 6028: [30780], 9382: [30782], 9845: [30786], 19017: [30787], 16837: [30790], 8262: [30791], 18578: [30792], 8580: [30793], 8284: [30795], 8204: [30797, 33439], 742: [30798], 7389: [30799], 16941: [30803], 4941: [30804], 16301: [30807], 3857: [30809], 1901: [30811], 7934: [30812], 5288: [30814, 31637], 8584: [30815], 7751: [30819], 15852: [30823, 33043], 17997: [30825], 16387: [30826], 15978: [30828], 16020: [30829], 18837: [30832], 8630: [30834], 7649: [30838], 5250: [30839], 17941: [30840], 14633: [30842], 8869: [30844, 31044, 31198], 6230: [30847], 15986: [30849], 989: [30851], 15947: [30855], 11261: [30856], 7475: [30858], 1305: [30859], 10522: [30861], 4859: [30862], 8880: [30865], 8319: [30866], 8531: [30867], 7439: [30869], 4911: [30870], 10196: [30871], 4849: [30873], 6478: [30875], 6872: [30877, 31161, 31633, 31808, 33662, 34651, 34658, 34675, 34682, 34693, 34719], 18092: [30880], 4865: [30883], 17185: [30886], 9750: [30888], 9965: [30894], 16355: [30897], 10635: [30899], 15710: [30900], 5301: [30901, 30917, 31576], 15949: [30906], 5093: [30908, 32865], 8588: [30909], 7651: [30910], 7947: [30911, 31112, 31691], 15882: [30912, 34338, 34959, 35184, 35213, 35228, 35287, 35330, 35461, 35502, 35622, 35638, 35715, 36207, 37008], 7713: [30914, 32622, 32678], 7385: [30915], 5244: [30919, 31568], 1820: [30922], 5372: [30927], 11773: [30930], 19764: [30934], 15989: [30937], 809: [30939], 19106: [30940], 8119: [30944, 31006], 10534: [30945], 5369: [30953, 31679, 32152, 32162, 32164, 32246, 32676, 33045, 34336], 1831: [30954], 10746: [30955], 10702: [30956], 16615: [30958], 15856: [30960], 7423: [30962], 16333: [30964], 4883: [30967], 15941: [30970], 8128: [30972], 16388: [30974], 4896: [30976], 18089: [30977], 11322: [30978], 10499: [30981], 15788: [30982], 11584: [30984], 18967: [30986], 1035: [30987], 19338: [30988], 7932: [30989], 16517: [30990], 9747: [30993], 15671: [30994, 31586, 31588, 31741, 31855], 15678: [30995, 31169, 31954], 17130: [30996], 16393: [30997], 18427: [30999], 18111: [31000], 871: [31004], 731: [31005], 8885: [31007], 12797: [31008], 17186: [31010], 18264: [31011], 18227: [31015], 10068: [31016], 19153: [31017], 8086: [31018, 31557, 31778], 6867: [31019], 17248: [31020], 11381: [31021], 15673: [31022], 10354: [31027], 11885: [31029], 11973: [31031], 7900: [31033], 12483: [31034], 12234: [31036], 11770: [31037], 15871: [31038], 11958: [31040], 16583: [31041], 16794: [31043], 18883: [31045], 11765: [31046], 15817: [31047], 11984: [31048], 17174: [31049], 8345: [31050], 11927: [31052], 8881: [31054, 33616], 11182: [31057], 11599: [31058, 33502], 18446: [31059], 18247: [31060], 17146: [31062], 11789: [31064], 11572: [31065, 31724], 11624: [31066], 12799: [31067], 10012: [31068], 10230: [31069], 11188: [31070], 11470: [31071], 11181: [31073, 31086], 16700: [31074, 31870], 11005: [31075], 10139: [31077], 7534: [31078], 11600: [31079, 31168], 11917: [31080], 7660: [31081, 31193], 16659: [31082], 11369: [31084], 11950: [31085], 17280: [31087], 16646: [31088], 16639: [31089], 8101: [31090], 11601: [31091], 8688: [31092], 11368: [31093], 16682: [31094], 11255: [31095], 1011: [31096], 11676: [31097], 16655: [31098], 15666: [31099], 17721: [31102], 18238: [31103], 8463: [31104], 8124: [31109], 12230: [31111], 16582: [31113], 11335: [31114], 8662: [31115], 11567: [31116], 15921: [31117], 16656: [31118], 16648: [31120], 5914: [31121], 5108: [31122], 5981: [31126], 6961: [31127], 10003: [31128], 5969: [31129, 33660, 34660], 7367: [31132], 10386: [31133], 5433: [31136], 8799: [31137], 5599: [31140], 7264: [31142], 10795: [31143, 33465], 7325: [31144], 6916: [31145], 16540: [31147], 18245: [31148], 7282: [31150], 5987: [31151], 5609: [31153], 5570: [31154], 16586: [31155], 7336: [31156], 930: [31158], 10703: [31159], 17728: [31160], 5389: [31162], 15707: [31163], 16513: [31164], 12089: [31165], 18267: [31166], 7223: [31170], 18241: [31172], 5929: [31173], 5415: [31174, 31932, 33359, 34834], 7131: [31175], 7687: [31179], 6887: [31182], 10806: [31184, 31218, 31888], 5508: [31185], 7230: [31186], 10588: [31187], 18261: [31189], 7589: [31190], 9777: [31191], 11969: [31196], 7254: [31197], 7337: [31199], 7218: [31200], 17284: [31201], 16184: [31202], 12805: [31203], 6034: [31204], 8695: [31205], 17277: [31206], 11906: [31209], 11980: [31210], 5582: [31212], 5410: [31213], 12210: [31214], 9817: [31215], 11959: [31216], 5681: [31217], 5380: [31219], 8900: [31220], 5696: [31221, 31766], 12219: [31222], 7213: [31223], 15657: [31224], 7398: [31225], 11028: [31226], 16518: [31228], 9907: [31229], 9894: [31230], 7279: [31231], 11565: [31232], 12795: [31233], 12045: [31234], 12403: [31237], 7390: [31239], 5461: [31242], 12097: [31243], 12107: [31244], 6985: [31245], 12000: [31248], 7252: [31249], 12052: [31251], 7099: [31252], 12411: [31254], 5495: [31255, 35846], 5411: [31257], 7100: [31258], 12436: [31259], 7262: [31260], 11023: [31262], 12057: [31263, 33746], 12469: [31264], 12437: [31265], 12466: [31266], 3557: [31268], 14855: [31269, 33760], 3608: [31270, 31272, 31288, 32047, 32058], 15388: [31274, 31309], 19260: [31275], 3301: [31277, 31280, 31284, 31287], 3312: [31278, 31281, 31290, 32104], 18138: [31282], 3311: [31283, 32090, 32130], 15361: [31289], 3305: [31291, 33771], 3229: [31292], 15364: [31293], 17808: [31296], 3654: [31300], 18139: [31301, 33859], 14763: [31302], 3656: [31303], 18874: [31305], 1349: [31306], 14743: [31307], 3304: [31308], 3248: [31311], 14425: [31314], 16884: [31316], 18877: [31317], 19760: [31318, 31611], 17451: [31320], 14427: [31321], 14383: [31322], 1034: [31323], 14399: [31324], 161: [31325, 33791], 17805: [31328, 32161, 33776, 33779, 33801, 33815], 16865: [31329], 18067: [31331], 17453: [31332], 1950: [31333], 146: [31334, 31425], 15391: [31335], 15393: [31336], 15310: [31337], 15386: [31338], 15621: [31341], 18190: [31342], 18130: [31344], 3242: [31345], 3813: [31346, 31356], 17462: [31348], 1381: [31349], 17456: [31350], 3780: [31353, 31414, 34933], 1371: [31354, 33854], 3760: [31355], 5350: [31357], 3768: [31358], 19261: [31359], 16878: [31360], 18196: [31361], 3713: [31364], 3817: [31367, 32187, 33816, 33824], 3720: [31369], 4930: [31371], 15736: [31372], 3797: [31373, 31375], 3730: [31374, 32274], 18027: [31377, 34237], 17841: [31378], 16859: [31379], 3702: [31380], 19663: [31383, 32260, 33885], 16803: [31384, 31392, 31395, 32236, 32237, 32245, 32252, 32256, 32265, 32269], 17868: [31385], 5213: [31388, 31556, 32143], 19691: [31389], 3675: [31390], 17687: [31391], 19671: [31393], 18551: [31396], 3805: [31398], 18867: [31400], 16855: [31401], 18036: [31402], 3731: [31405, 33862, 34957], 19211: [31408], 16887: [31409, 33836], 10134: [31411, 31469], 4932: [31412, 32204], 81: [31415], 1925: [31419], 3561: [31420], 751: [31421], 19788: [31423], 17331: [31424, 32533], 18102: [31427], 17073: [31430, 34019], 8440: [31431], 15987: [31435], 972: [31441], 749: [31442], 19521: [31443], 8205: [31445], 750: [31446], 8535: [31447], 1899: [31448], 19165: [31450], 1018: [31453], 15849: [31458], 1911: [31463], 19239: [31470], 8521: [31471], 16255: [31475], 990: [31476], 19011: [31477], 10173: [31478, 33909, 35099], 17866: [31479], 17043: [31482], 157: [31484], 18442: [31486], 18832: [31487, 32587, 34326, 34649], 1898: [31488, 31498], 4900: [31489, 35389, 36674], 19023: [31490], 17105: [31491], 8481: [31492], 8055: [31493], 16145: [31495, 31734], 10224: [31496], 8115: [31499, 32437, 32469, 32504], 8558: [31507], 10275: [31509], 18344: [31513], 4858: [31514, 34400], 15296: [31515], 17021: [31516], 19761: [31518], 8367: [31521, 33366], 18992: [31523], 815: [31525], 7429: [31526, 34763], 7590: [31527], 11832: [31530], 114: [31533], 6484: [31536], 10075: [31538], 18450: [31545], 7575: [31551, 31936, 31957], 11150: [31553], 16335: [31554], 7792: [31555], 1036: [31558], 15950: [31561], 8532: [31563], 15720: [31564], 4803: [31565, 31581, 31601], 942: [31566], 16678: [31570], 18008: [31571], 1819: [31572], 19043: [31573], 6066: [31575, 35379], 8081: [31577], 11121: [31578, 31755, 31806], 5294: [31587, 32728], 7653: [31590], 16213: [31597], 18045: [31598], 4950: [31599], 5115: [31600], 8056: [31605], 19166: [31606], 16336: [31608], 8084: [31610], 8317: [31612], 16757: [31614], 19776: [31615], 15898: [31616], 10279: [31619], 4847: [31620], 10124: [31626], 18042: [31627], 18047: [31629], 6873: [31630, 33637, 34687], 10514: [31631], 16434: [31634], 8316: [31635, 31666, 31672, 31880, 32975], 8457: [31636, 32777, 32816, 33300, 34486, 34637], 8586: [31639], 10503: [31640], 1004: [31641], 10632: [31643], 4897: [31645, 34204], 10492: [31646, 34335], 4880: [31649, 32474], 18093: [31651], 5103: [31657], 16734: [31660], 18077: [31661], 8575: [31662], 16332: [31663], 16276: [31665], 8458: [31667], 4903: [31668], 11333: [31670], 19180: [31671], 16479: [31673], 6847: [31674, 33126], 19766: [31684, 31693], 10121: [31690], 18369: [31692], 10623: [31694, 33296], 16296: [31696], 5370: [31697, 32639], 15848: [31698], 15884: [31700], 7148: [31702], 10509: [31705], 16389: [31709], 8482: [31712], 863: [31713, 32724], 9780: [31714], 11230: [31715], 15297: [31716], 11946: [31717], 17119: [31718], 7959: [31719], 6939: [31720], 12506: [31722], 15979: [31723], 7428: [31725, 31794, 34309], 10715: [31726, 32985, 33154], 8892: [31728], 15793: [31731], 18297: [31732], 8331: [31733], 19097: [31735], 16676: [31736, 33466, 34547, 34612, 34617, 34634, 34639, 35630], 10789: [31737, 31898], 9986: [31738], 16133: [31739, 32598, 32662], 929: [31742, 35615], 11186: [31744], 11350: [31745], 10587: [31746], 16449: [31749], 8278: [31750], 10042: [31751], 7372: [31752], 11286: [31753], 9981: [31756], 17153: [31757], 11017: [31758], 16683: [31759], 12175: [31761], 8946: [31762], 11202: [31763], 16543: [31764], 17159: [31767], 11378: [31768], 11904: [31769], 16144: [31770], 18452: [31771], 8702: [31772], 12254: [31773], 11178: [31774], 7117: [31775], 9800: [31776], 864: [31777], 16708: [31779], 10007: [31780], 8050: [31781], 9918: [31782], 8832: [31783], 8774: [31787], 11590: [31789], 18253: [31790], 11918: [31792], 8797: [31793], 18932: [31796], 11912: [31797], 17261: [31798, 34627], 9772: [31799], 11326: [31800, 31825], 5111: [31801], 9988: [31802], 7930: [31803], 16649: [31804], 12334: [31805], 18257: [31807], 11233: [31809], 8833: [31810], 9920: [31811], 19094: [31812], 10536: [31813], 12507: [31814], 9802: [31815], 11048: [31816], 7608: [31817, 35546, 35671], 11330: [31818, 33485], 12763: [31819], 6040: [31820], 16653: [31822, 34551], 5513: [31823, 35702], 19234: [31824], 11006: [31826], 6865: [31827, 34784, 35254], 5463: [31828], 10070: [31829], 9926: [31830], 19114: [31831], 11354: [31832], 11583: [31833, 35598], 7447: [31835], 8822: [31836], 18979: [31838, 35545], 16124: [31839], 8547: [31840], 1863: [31842], 11688: [31844], 16173: [31845], 11372: [31846], 10545: [31847, 31911, 33058, 33570], 16675: [31848, 33454, 33503, 33519, 33561, 34510], 11952: [31849], 18317: [31850], 11379: [31851], 19148: [31853], 16024: [31854, 34670], 18388: [31856], 12800: [31857], 17143: [31858], 8890: [31859], 12252: [31861], 7371: [31862], 11331: [31863], 18936: [31864], 17127: [31865], 11001: [31866], 11176: [31868, 33535], 11359: [31871], 11213: [31873], 12803: [31874], 7388: [31875], 11919: [31876], 12761: [31878], 11360: [31879, 35709], 18224: [31881], 11611: [31882], 17181: [31883], 15715: [31885], 6889: [31887], 16175: [31890], 8686: [31892], 5427: [31894, 31977, 33615, 33633, 33654, 33671, 33698, 33705, 33716, 33722, 33740, 33741, 33742, 33749, 33752, 34657, 34665, 34673, 34691, 34699, 34717, 34730, 34736, 34741, 34744, 34746, 34753, 34756, 34765, 34766, 34768, 34770, 34775, 34780, 34789, 34796, 34801, 34805, 34817, 34819, 34830, 34837, 34839], 6952: [31895, 34652, 34729], 16136: [31896], 15688: [31897], 9897: [31899], 10537: [31900], 18272: [31903], 12377: [31904], 11907: [31905], 19356: [31906], 9929: [31907], 17305: [31908], 12488: [31909], 7186: [31910, 31949], 10009: [31912], 7424: [31914], 6882: [31916], 10004: [31917], 5972: [31918], 16282: [31919], 10500: [31920], 8776: [31921], 16580: [31922], 8779: [31923], 18313: [31924, 31964], 5901: [31925], 19032: [31926], 6870: [31927], 18236: [31929], 5496: [31931], 7198: [31934], 5422: [31935, 32013, 34662, 34726, 34777, 34825, 35662, 35672, 35708, 35718, 35734, 35746, 35757, 35759, 35776, 35795, 35813, 35851, 37027], 18953: [31937], 7201: [31938], 5999: [31940], 5605: [31941], 7155: [31943], 15985: [31944], 7321: [31945], 7136: [31946], 11192: [31947], 5456: [31950, 33727, 34751], 15711: [31953], 7007: [31955], 16532: [31958], 7260: [31959], 925: [31960, 31983, 33528], 11460: [31961], 9903: [31962], 10521: [31963], 16694: [31965], 18225: [31968], 8858: [31969], 7414: [31970], 7251: [31971], 7612: [31972], 11897: [31973], 10621: [31975], 9736: [31976], 5606: [31979], 6859: [31980], 8835: [31981], 5673: [31982], 7591: [31984], 11170: [31986], 10609: [31987, 34792], 5893: [31988], 19072: [31989], 5958: [31991], 5507: [31992], 12395: [31993], 15712: [31994], 16640: [31995], 5510: [31996], 10677: [31998], 5457: [31999], 17216: [32000], 5675: [32002], 11457: [32004], 5596: [32005], 10586: [32006], 12031: [32007, 34816, 34820], 12029: [32008, 32015], 5561: [32010], 12405: [32011], 5600: [32012], 12108: [32014], 12455: [32016], 12320: [32019], 12046: [32020, 33725], 12034: [32022, 33730, 37053], 12036: [32025, 34836], 11400: [32026, 33723, 34833], 9980: [32027], 12446: [32029], 12113: [32030], 12461: [32031], 3391: [32032], 3607: [32043, 33778], 3679: [32067, 32079, 32259, 33782, 33799, 33802, 33810, 33845, 33856, 33890, 33917, 34898], 3648: [32114], 17861: [32115], 3281: [32118], 19390: [32119], 4933: [32123, 33128, 33825, 33932, 34062], 15387: [32125], 5365: [32126, 32148, 32160, 32467, 32524], 4944: [32127, 32146], 3241: [32131, 34873], 15637: [32136], 3222: [32137, 34868], 19332: [32138], 4861: [32139, 34331], 15390: [32142], 14391: [32144], 14365: [32145], 1330: [32147], 16834: [32149], 19256: [32150], 14404: [32151], 14424: [32153], 14414: [32154], 4936: [32156, 34350], 1287: [32157], 18165: [32159], 3802: [32165, 33818], 4948: [32166], 18549: [32168, 35020], 3545: [32170], 15622: [32172], 18459: [32173, 32181], 1355: [32174], 5076: [32175, 33986, 35244], 3763: [32176], 19255: [32177], 4940: [32178, 34337], 16303: [32179], 15359: [32180], 3814: [32182], 15525: [32183], 15641: [32184], 17402: [32185], 18135: [32186], 18213: [32188], 18180: [32189, 32195, 32196, 32205], 18166: [32190, 32203], 16851: [32191, 34999], 17416: [32192], 1367: [32193], 1358: [32194], 17823: [32197], 17362: [32198], 1318: [32199], 17855: [32200], 17407: [32201], 17729: [32202, 36147], 1278: [32206], 5977: [32207], 18193: [32208, 33819], 4845: [32211, 32442, 33112, 33804, 34262], 3716: [32212], 3685: [32223, 34946, 34974], 3696: [32224], 17047: [32228], 15304: [32233], 3709: [32234], 147: [32241], 17036: [32244, 33872], 136: [32250, 32566], 802: [32253, 32518], 950: [32261], 18444: [32262], 159: [32267, 33955], 19674: [32271], 17055: [32279, 32476, 33925], 4843: [32323, 33099, 34369], 17644: [32344, 33922], 5371: [32348, 34227, 34380, 34395], 7393: [32357, 35694], 19759: [32372], 3661: [32380, 33887], 1838: [32389], 17842: [32392], 18037: [32398], 4949: [32401], 79: [32408], 16805: [32413], 4863: [32417], 18570: [32420], 1974: [32435, 32543], 8121: [32439], 1900: [32441], 18354: [32453], 8197: [32454], 8191: [32457], 8625: [32461], 8624: [32466, 35005, 35591], 15878: [32468, 32574, 32730, 32765, 32775, 32792, 32882, 33260, 33290, 34361], 5290: [32492], 15844: [32495], 16448: [32501], 8206: [32506], 895: [32511], 18550: [32514], 8312: [32515, 33967], 16287: [32522], 8762: [32528], 223: [32531], 8581: [32534], 17332: [32536], 10218: [32541], 8397: [32542], 976: [32546, 32635, 32974], 17081: [32547], 19263: [32549], 17074: [32550], 16277: [32553], 17333: [32568], 19235: [32575], 6488: [32576, 33578], 8699: [32588, 33436], 8099: [32589], 18352: [32595], 18556: [32597], 16022: [32601], 154: [32604, 34035], 16085: [32608], 16209: [32609], 16275: [32610], 17903: [32616, 35193], 8393: [32632], 18128: [32634], 8459: [32649], 19381: [32653], 648: [32661], 18425: [32665, 35025, 36441], 17743: [32668], 19380: [32669], 16778: [32671], 5997: [32681], 16248: [32685], 15700: [32688], 7421: [32689], 16338: [32690], 8240: [32691], 11945: [32697], 866: [32704], 8572: [32714], 10193: [32732, 33914, 33916, 34130, 34153, 34465, 34485, 34502, 34533, 34548, 34604], 4820: [32734], 16342: [32752], 8228: [32755], 5968: [32784], 16206: [32788, 35528], 11167: [32791, 35580], 7455: [32796], 16749: [32810], 7413: [32818], 1007: [32820], 8537: [32824, 34225], 17323: [32842], 10127: [32873], 15881: [32883, 32953, 33092], 15305: [32884], 10494: [32891], 16356: [32895, 33186], 7682: [32919], 11461: [32928], 18914: [32931], 4910: [32935], 19762: [32937], 7431: [32942], 15717: [32945, 33393], 4945: [32950, 33975, 35973, 36419, 36425, 36495, 36503, 36616, 36618, 36640, 36650, 36678], 12304: [32965], 19248: [32986], 10589: [32991], 17290: [32995], 970: [32999], 6514: [33003], 4901: [33007], 16299: [33008], 4907: [33031, 34310], 8677: [33036], 4877: [33037, 36060, 36146, 36377, 36533, 36543, 36553, 36581, 36629], 10507: [33042], 1849: [33052], 5373: [33053], 16199: [33056, 34184], 10562: [33061], 16712: [33063], 16713: [33067, 33508], 904: [33076], 10264: [33078, 34029], 6864: [33081, 33608, 33613], 8860: [33105], 19195: [33109, 34415], 15879: [33135], 16752: [33136], 7432: [33139], 17206: [33143], 16370: [33148], 15721: [33152], 4853: [33157], 11347: [33165, 33489, 35619], 8297: [33180], 18029: [33182], 6858: [33192], 18073: [33199], 8503: [33210], 16576: [33214, 34333], 10126: [33226], 7579: [33237, 35808, 36478], 4947: [33242, 33898, 34341, 34363, 34404, 34855, 34857, 34859, 34876, 34877, 34881, 34884, 34885, 34902, 34908, 34910, 34914, 34924, 34934, 34949, 34960, 34961, 34971, 34973, 34989, 34993, 34998, 35018, 35092, 35171, 35195, 35203, 35235, 35242, 35274, 35277, 35293, 35301, 35321, 35335, 35338, 35346, 35354, 35358, 35380, 35382, 35411, 35416, 35437, 35467, 36121, 36157], 8896: [33257], 15691: [33268], 8123: [33278, 33444, 34324], 19067: [33295], 8275: [33303, 34242, 34329], 810: [33305], 1968: [33306], 10261: [33318], 8839: [33323], 8070: [33369], 10701: [33372], 10038: [33379], 7416: [33383], 17296: [33384], 18259: [33385], 16654: [33386], 11321: [33389, 34626], 16777: [33390], 18421: [33397], 11700: [33398], 7436: [33399], 16670: [33400], 16112: [33401], 17236: [33402], 11790: [33403], 11174: [33405], 11581: [33406], 8836: [33407], 17145: [33408], 11634: [33409], 7693: [33410], 17244: [33411], 16289: [33413], 11640: [33417], 17257: [33418], 11011: [33421], 11329: [33422, 33514, 34469], 10034: [33424], 19146: [33427], 7887: [33430], 18389: [33433], 11323: [33434], 8239: [33435, 34017, 34088], 11636: [33437], 11982: [33438], 8309: [33442], 19099: [33447], 11208: [33448], 7597: [33449], 18310: [33450], 8254: [33451], 12392: [33452], 5897: [33453], 18968: [33456], 17254: [33457, 34524], 17249: [33458], 8313: [33460], 16673: [33461], 16257: [33462], 11953: [33463], 16520: [33468], 17321: [33470], 15859: [33471], 18373: [33472], 11018: [33474], 11943: [33475], 10600: [33476], 11552: [33478, 33564, 34578], 11908: [33481], 8549: [33482], 11936: [33483], 12487: [33486], 6065: [33487], 11890: [33490], 11915: [33492], 8906: [33493], 12393: [33494], 18426: [33496, 34173, 34482, 34932], 16647: [33497, 35561], 11930: [33499], 11314: [33500], 10355: [33501], 11985: [33504, 33524, 33563, 34564, 34609, 34715], 12718: [33505], 12225: [33506], 11617: [33507], 7374: [33510], 18950: [33512], 17785: [33513], 8903: [33515], 11187: [33516], 7400: [33517, 34607, 34676], 16661: [33518], 11588: [33525], 16290: [33527], 16147: [33530, 33695], 10640: [33532], 11020: [33533], 8792: [33536], 11175: [33537, 33539], 11956: [33538], 17176: [33540], 8742: [33541], 11327: [33543], 11639: [33544], 11151: [33545], 8247: [33547], 15982: [33550], 18079: [33551], 8127: [33552], 16160: [33553], 7954: [33554], 11382: [33555], 17295: [33556], 8150: [33557, 35527], 11888: [33558], 11448: [33559], 10054: [33560], 10136: [33562], 18947: [33565], 8472: [33568], 12224: [33569], 11324: [33571], 1864: [33573], 18961: [33574], 16179: [33575], 11251: [33576], 7578: [33577], 11214: [33579, 35656], 19073: [33580], 7204: [33583], 6000: [33584], 7329: [33585, 33706], 6941: [33587], 5660: [33588], 15293: [33589], 8687: [33590, 34592], 16688: [33591], 5601: [33592], 11004: [33593], 16137: [33594, 35199], 6953: [33595], 16587: [33597], 9906: [33599], 7113: [33600, 33689], 11022: [33603], 18240: [33605], 7231: [33606, 33700], 6949: [33607], 19095: [33609], 18229: [33610], 7318: [33611], 6948: [33612, 33625], 8887: [33617], 10055: [33618, 34795], 5671: [33619], 16585: [33620], 7479: [33623], 7286: [33626, 33641], 12484: [33627], 5909: [33628], 9931: [33629], 5966: [33631], 10796: [33632], 10734: [33634], 9756: [33635], 12236: [33636], 5658: [33640], 6880: [33642], 7161: [33643], 15860: [33644, 35691], 17264: [33645, 33696], 17271: [33646], 7306: [33647], 5526: [33649], 6032: [33650, 35724], 7394: [33651, 34591], 5557: [33652, 34824], 7224: [33653], 5898: [33655], 6996: [33656], 7200: [33658], 18335: [33659], 15865: [33661], 7437: [33664], 7202: [33665], 5910: [33666], 5587: [33667], 9994: [33669], 7341: [33670], 8757: [33672], 5995: [33673, 34678], 11038: [33674], 16718: [33676], 7576: [33678], 7714: [33679, 34293, 34646], 10798: [33683], 5950: [33684, 35738], 10005: [33685], 7244: [33687], 7265: [33690], 7085: [33691], 8876: [33692], 10700: [33693], 15872: [33694], 7404: [33697], 9905: [33699, 35799], 10106: [33702], 8772: [33703], 7114: [33704], 7585: [33709], 7001: [33710], 8897: [33711], 11198: [33712], 5892: [33713], 17222: [33714], 5464: [33715], 8838: [33718, 34210, 34554], 5894: [33719], 12331: [33720], 11653: [33721], 11993: [33726], 12049: [33728], 12324: [33731], 12106: [33733], 12457: [33734], 5960: [33735], 5583: [33736], 12033: [33737, 33753], 12458: [33738], 12074: [33739], 12409: [33743], 12447: [33744], 12032: [33747, 34843, 35836], 5591: [33748], 12427: [33750], 12095: [33751], 3308: [33754, 33756, 33759, 33761, 33768, 33773, 33874], 3411: [33755], 14866: [33757], 3278: [33758, 33763, 33764, 33769], 3564: [33762], 16863: [33766], 16860: [33767, 33934], 3806: [33770], 3415: [33772], 15384: [33774], 5366: [33775, 33787, 33811, 33886, 33894, 33902, 33988, 34330, 34359, 34982], 3231: [33777], 17839: [33780], 14770: [33781], 3655: [33783], 1373: [33784], 15616: [33786, 33788, 33789, 33790], 3729: [33792, 33860], 14349: [33793], 4856: [33796, 33805, 33899], 19516: [33798], 14388: [33800], 14758: [33803], 14679: [33807], 14415: [33808], 14410: [33809], 18201: [33813], 3681: [33814, 34901], 18132: [33820], 16302: [33821], 19518: [33822], 3732: [33823], 14761: [33827], 18164: [33828, 34929], 17425: [33829], 3559: [33830], 5223: [33831, 33835, 34377, 36204], 15358: [33832, 34848, 34854, 34866, 34870, 34872, 34879, 34893, 34905, 34906, 34915, 35933], 18991: [33833, 36092], 1312: [33834], 1939: [33837], 19185: [33838], 1279: [33840], 1378: [33841, 36008], 1376: [33842], 1379: [33843], 18134: [33844, 33857, 34922, 36038], 18567: [33847], 17854: [33848, 33853, 34947], 17046: [33849, 34907], 17410: [33850, 34923, 34937, 34941], 17452: [33851], 1377: [33852], 1333: [33855], 18157: [33858], 10195: [33861, 33935, 34139, 34159], 3717: [33863], 19763: [33864, 36395], 3562: [33865], 18329: [33866], 4935: [33867, 34082, 35073, 35326, 35404], 3740: [33868, 33878], 10200: [33870, 34249, 34519], 3708: [33871], 3718: [33873], 3307: [33876], 19159: [33879, 33940, 34454, 35395], 19672: [33880], 18120: [33882], 17980: [33883], 17011: [33884], 528: [33888], 3803: [33889], 10179: [33891, 33897, 33928, 33939, 34072, 34146, 34170, 34178, 34219, 34226, 34394, 34479, 34480, 34490, 34495, 34501, 34504, 34506, 34513, 34517, 34529, 34549, 34558, 34582, 34595, 34600, 35246], 19555: [33892], 17030: [33896], 17363: [33901, 34079], 17981: [33905], 16864: [33906], 1031: [33908, 34243, 34887, 34972, 36002], 16856: [33911], 10181: [33915, 34128, 34364], 10180: [33918, 35386, 36174], 16294: [33920], 15311: [33924], 10186: [33926, 34168, 34186, 34263, 34272, 34305, 34353, 34378, 34391, 34393, 34421, 34435, 34445], 3762: [33937], 9991: [33949], 9789: [33951, 34030, 34141, 34492, 34614], 8321: [33954, 34031, 34188, 34358], 18539: [33957], 11574: [33965], 16696: [33968, 34537], 7949: [33972, 35499], 16003: [33976], 16510: [33977], 8238: [33978, 33993, 34010, 34102, 34594], 16253: [33997, 34291, 34464], 18355: [34000], 8803: [34012], 7918: [34014], 4894: [34016, 34856, 34886, 34900, 34952, 34981, 34996, 35217, 35307, 35362, 36366, 36537], 16802: [34021, 34985], 151: [34028], 12: [34034], 8264: [34042], 19212: [34043], 18343: [34048], 4946: [34053], 17330: [34060], 8052: [34065], 10197: [34066, 34070, 34114, 34172, 34176, 34256, 35207], 17742: [34067], 18553: [34068], 18534: [34077], 7950: [34081], 8523: [34083], 10199: [34084, 34258, 34285, 34316], 19024: [34089], 17880: [34098], 8310: [34100], 10353: [34107, 34575], 16143: [34121], 16159: [34122], 16741: [34123], 15753: [34124], 18112: [34125], 17999: [34126], 16153: [34127], 4872: [34129, 35319, 36630], 6857: [34132, 35663, 35719, 35790, 36872], 8255: [34133, 34235, 34274, 34436], 8271: [34134], 11440: [34137, 34647], 8626: [34138], 1923: [34142], 11012: [34148], 873: [34150], 16720: [34152], 8403: [34155], 10513: [34156, 34723, 35252, 35369, 35484, 35692], 10177: [34157, 35275, 35341, 36765], 4876: [34158, 34162, 34362, 35285], 16156: [34165], 71: [34169], 19351: [34171], 8388: [34174], 8551: [34175], 9773: [34177], 16286: [34179, 35037, 35064, 35457], 5994: [34180], 8098: [34181, 34370], 10122: [34182], 16142: [34187], 16442: [34190, 35529, 35758], 1853: [34192], 8318: [34195], 1032: [34197], 15984: [34198], 17022: [34199], 1016: [34200, 34428, 35011], 8059: [34203], 18337: [34205], 4906: [34206, 35392], 19357: [34207], 16297: [34208], 16029: [34209], 6003: [34211], 11165: [34212], 5084: [34215], 15301: [34221], 4868: [34222], 4874: [34230], 4848: [34244], 4881: [34245, 35281, 35315], 16545: [34252], 4875: [34260, 35249, 35407], 7412: [34261], 10269: [34269], 7650: [34270], 7686: [34276], 16366: [34277], 19160: [34280], 1833: [34283], 18100: [34284], 10633: [34288], 8089: [34294], 17199: [34296], 4895: [34298], 11204: [34302], 10115: [34303], 5215: [34304], 6843: [34307], 16339: [34308], 10523: [34312], 5293: [34315, 34424], 8847: [34318, 34511], 8631: [34321], 4893: [34325], 19117: [34347], 15876: [34351, 36358], 15868: [34354], 10498: [34360, 34411], 8289: [34375], 6918: [34376], 19047: [34385], 15755: [34387], 15754: [34389], 11768: [34405], 10213: [34407], 18127: [34410], 896: [34412], 19789: [34413], 10820: [34414], 16364: [34417], 7420: [34425, 35372], 16795: [34426], 16731: [34430], 6856: [34431, 34733], 17706: [34434, 34979, 36623], 11168: [34442, 34793, 35604, 36558, 36643], 7717: [34444], 7614: [34448], 10188: [34450, 35273], 19355: [34453], 8852: [34458, 36815], 16735: [34460], 18217: [34462, 34599], 7694: [34463], 19151: [34466], 12268: [34468], 10062: [34470, 34576, 34602, 35550], 18288: [34471], 8326: [34472], 19060: [34473], 11157: [34474], 16572: [34475], 18845: [34476], 16658: [34477, 35587, 36868], 11916: [34478], 1795: [34481, 36791], 16464: [34484, 34534], 16249: [34488], 11029: [34489], 17196: [34491], 17247: [34494], 15896: [34496], 18302: [34499], 19177: [34500], 18022: [34505], 12223: [34507], 15834: [34508], 11637: [34509], 16667: [34512], 18269: [34514], 9809: [34515], 8131: [34516], 11030: [34518], 16283: [34520], 16753: [34521], 8848: [34522], 8107: [34523, 36461], 11161: [34525], 11319: [34527, 35575], 9927: [34528], 11941: [34530], 16166: [34532], 19025: [34535], 11964: [34536], 8392: [34539, 34571], 18285: [34540], 16650: [34541], 11555: [34542], 3531: [34543], 7885: [34544], 7957: [34545], 8801: [34546], 8225: [34550], 8368: [34552], 11156: [34553], 11355: [34559], 8544: [34560], 18308: [34561], 8560: [34562], 11781: [34563], 8369: [34566], 11955: [34567], 11569: [34568], 11177: [34569], 18300: [34570], 11591: [34572], 12119: [34573], 11179: [34574], 6854: [34577], 7440: [34579], 8306: [34580], 9137: [34581], 8534: [34583], 7598: [34584], 11193: [34585], 17208: [34586], 18990: [34588], 8573: [34589, 36745], 10999: [34590, 35563, 35610], 11787: [34593], 11337: [34596], 18424: [34597], 8451: [34598], 10358: [34601], 11898: [34603], 18287: [34605, 35593, 36856], 16494: [34606], 11211: [34608, 34633], 17171: [34610, 34711], 7295: [34611], 9997: [34615], 11473: [34616], 11459: [34618], 11556: [34619], 16680: [34620], 19064: [34622], 11385: [34624], 7655: [34625], 18445: [34628], 11356: [34629], 11988: [34632], 17202: [34638], 18315: [34640], 9940: [34641], 16704: [34642], 8542: [34644], 18277: [34645], 11315: [34648], 6884: [34650], 18311: [34653], 5975: [34654], 16641: [34655], 17273: [34656], 6956: [34659], 18226: [34661], 17299: [34663], 16177: [34664], 5416: [34666], 17223: [34667], 18222: [34668], 16693: [34669, 34688, 34695, 34773, 34787, 35803], 17302: [34671], 8293: [34672], 8683: [34674], 18940: [34677], 7277: [34679, 35693, 35705], 5691: [34680], 6862: [34681], 11937: [34683], 9933: [34684], 18959: [34685], 17182: [34686], 16278: [34689], 7668: [34690], 6896: [34692], 11224: [34694], 15869: [34696], 9899: [34697], 6959: [34698], 5434: [34700], 6960: [34701, 35664, 35791, 36962], 8854: [34702], 8827: [34704], 16265: [34706], 7187: [34707], 7482: [34708], 17292: [34709], 10015: [34710], 5985: [34712], 11891: [34713], 15821: [34714], 9990: [34716], 6030: [34718], 15831: [34720], 17232: [34721], 17177: [34724], 15981: [34725], 7217: [34727], 940: [34731], 18846: [34732], 7219: [34734], 10584: [34737], 15685: [34738], 6946: [34739], 9930: [34740], 8740: [34742], 18848: [34743], 5428: [34748], 17289: [34749], 9577: [34750], 7685: [34752], 7403: [34754, 35673], 16104: [34755], 6923: [34758], 9765: [34759], 1012: [34760], 17300: [34761], 5988: [34762], 12241: [34764], 5676: [34767], 8856: [34769], 6055: [34771], 7142: [34772], 5895: [34774], 11654: [34776], 12380: [34778], 5442: [34779], 17291: [34781, 35633], 7316: [34782], 5996: [34783], 11390: [34785, 35725], 12325: [34786], 17217: [34788], 5387: [34790], 6009: [34791], 7481: [34794], 6050: [34797], 6043: [34798], 9685: [34799], 10107: [34800], 11395: [34802], 7283: [34804], 17266: [34806], 7266: [34807], 5903: [34808], 12220: [34809], 12099: [34810], 9829: [34811], 11394: [34812], 5954: [34813], 5961: [34814], 5436: [34818], 12022: [34821], 9810: [34822], 5799: [34823], 11025: [34826], 12321: [34827], 11474: [34828], 12336: [34829], 12028: [34831], 11886: [34832], 12101: [34835], 12104: [34838], 15681: [34840], 12332: [34841, 35854], 12105: [34842], 3310: [34845, 34847], 3309: [34850, 35922], 16862: [34852, 34953, 34977, 35212, 35915, 35921, 35923, 35948, 35969, 36012, 36021, 36030, 36033, 36054, 36062, 36074, 36094, 36111, 36123, 36135, 36149, 36161, 36334, 36339, 36364, 36386], 3227: [34853, 34860, 34869, 35857, 35860, 35861, 35862, 35863, 35866, 35867, 35870, 35872, 35873, 35874, 35877, 35878, 35880, 35882, 35883, 35884, 35890, 35892, 35897, 35901], 229: [34858], 1316: [34861], 19673: [34862], 3653: [34863, 35918], 3243: [34864], 3226: [34865], 15385: [34871], 14420: [34874], 14757: [34878], 15643: [34880], 3237: [34882], 3404: [34883], 3646: [34888], 19642: [34889], 14422: [34890], 14418: [34891], 14668: [34892], 14423: [34894], 18876: [34895], 3678: [34896, 34986], 3609: [34897], 15360: [34899], 4890: [34903, 36006], 18145: [34904], 15366: [34909], 18133: [34911, 34925, 34930, 34939, 34944], 19130: [34912], 3804: [34913], 17688: [34916], 15615: [34917], 15400: [34918], 3798: [34919], 18208: [34920], 16879: [34921], 1336: [34926], 17445: [34927], 1317: [34928], 17450: [34931], 17038: [34935], 17442: [34936], 18568: [34938], 18146: [34940], 18197: [34942], 17409: [34943], 80: [34945], 160: [34948, 35056, 35098, 35100, 35136, 35865], 10178: [34950, 36772], 1940: [34951], 18453: [34954], 17116: [34956], 3703: [34958], 3714: [34962], 14754: [34963], 4913: [34964], 18351: [34965, 35107], 17849: [34966], 3615: [34967], 19688: [34968], 17097: [34969, 36113, 36137, 36173], 19686: [34970], 3688: [34975], 70: [34976, 35198], 4870: [34978], 19692: [34980], 16883: [34983], 3676: [34987], 4888: [34988, 35002, 36613], 16857: [34990], 954: [34992, 35180], 11642: [34994], 142: [34995], 15314: [34997], 16838: [35000], 3741: [35009], 164: [35014], 19526: [35015], 10245: [35021, 36190], 10235: [35022, 35343, 35514, 35519, 35539, 36506, 36771, 36822], 15299: [35023], 7683: [35027, 35675, 37028], 148: [35028], 155: [35029], 16288: [35034], 10242: [35035, 35144, 35261, 35374, 36262], 10243: [35040, 35336, 36311], 10215: [35041], 17337: [35043], 149: [35044], 1941: [35052], 19012: [35054], 6042: [35055], 10182: [35057, 35167, 36634], 17459: [35060], 15300: [35062], 17458: [35063, 36051, 36282], 8619: [35071], 8011: [35077], 8053: [35084], 8207: [35108], 8286: [35109], 8524: [35114], 19045: [35131], 17054: [35139, 36321], 8518: [35141], 8543: [35151], 7667: [35152, 35523], 17937: [35160], 8594: [35162], 8610: [35164], 8082: [35170], 8837: [35172, 36768], 761: [35174], 10241: [35175, 35283, 36517, 36586], 17973: [35176], 16861: [35177, 35232], 16110: [35178], 15290: [35179], 18115: [35181], 811: [35182, 35453], 16796: [35183], 17100: [35185, 36052, 36100], 8611: [35186], 1037: [35187], 16314: [35188], 19514: [35189], 10227: [35190, 35357, 35381, 36347, 36380, 36477], 7405: [35197], 7654: [35202], 16326: [35204], 4862: [35206, 35328, 36756], 9759: [35210], 16740: [35211], 18395: [35214], 18005: [35215], 4871: [35216], 8252: [35221], 10265: [35222], 4905: [35223], 16216: [35224], 1020: [35225], 7484: [35226, 35609], 4914: [35227], 7666: [35229], 8743: [35230], 11166: [35231], 7417: [35233], 8062: [35237, 35631], 5228: [35238], 18438: [35239], 8729: [35240, 35260, 35698, 36233, 36943], 7718: [35241], 18030: [35245], 10471: [35253], 18084: [35264], 959: [35266], 17784: [35268, 35540, 36823], 16185: [35271], 8012: [35278], 16533: [35279], 11362: [35286], 19767: [35290, 35446, 36764], 19771: [35296], 10694: [35300], 8090: [35303], 16340: [35304], 818: [35306], 17178: [35320], 7384: [35333], 10187: [35347, 35498], 10622: [35348], 16341: [35350], 10549: [35361, 35442], 17777: [35366], 16885: [35375], 12396: [35378], 11325: [35383], 18884: [35385], 6863: [35399], 10141: [35401], 788: [35403], 19164: [35405], 10550: [35414], 10267: [35415], 7415: [35421], 10214: [35428], 4934: [35434, 36455, 36476], 6922: [35447], 10244: [35449, 36751], 8307: [35456], 5311: [35458], 10519: [35459, 35479, 35560], 18925: [35463], 17690: [35464], 10237: [35465, 35470, 36488], 9978: [35476], 5230: [35477], 9910: [35478], 8265: [35480], 8151: [35482], 8153: [35483], 15789: [35486], 7600: [35487], 10221: [35490], 18377: [35491], 17689: [35497], 8280: [35503], 11352: [35504], 10061: [35505], 8904: [35506], 16671: [35507, 35544], 8311: [35508], 8274: [35509, 36782, 36851, 36990], 11570: [35510], 8085: [35511], 8129: [35513], 11318: [35515], 11363: [35516], 11582: [35517], 10016: [35518], 928: [35520], 18286: [35521], 10057: [35522], 10051: [35524], 11164: [35525], 17203: [35526], 867: [35530], 9801: [35531], 16266: [35532], 10018: [35533], 816: [35534], 11147: [35535], 5991: [35536], 11002: [35537], 11196: [35538], 19337: [35541, 35611, 36438], 11766: [35542], 11155: [35543], 11353: [35547], 17155: [35548], 12098: [35549], 9967: [35551], 8226: [35552], 8800: [35553, 35576, 35788], 5564: [35554], 17974: [35555, 35737], 8224: [35556, 36384], 11383: [35557], 7592: [35558, 36784, 36831], 11205: [35559], 10625: [35562], 12448: [35564], 16581: [35565], 11615: [35566], 11159: [35567, 35606], 7951: [35568], 6883: [35570], 9721: [35571, 35741], 16254: [35573], 10058: [35574], 16284: [35577, 36887], 9827: [35579], 15861: [35581], 11380: [35582], 18219: [35583], 18289: [35584], 18291: [35585], 10098: [35586, 35655, 35754], 17212: [35588], 18939: [35589], 9968: [35590], 18447: [35592], 10138: [35594], 5989: [35595], 7684: [35596], 10069: [35597], 7602: [35599, 35628], 8303: [35601], 5104: [35602, 35644], 10056: [35603, 36824], 18284: [35605], 9729: [35607], 17138: [35608], 11585: [35612], 7644: [35613], 18294: [35614], 16150: [35617], 7883: [35618, 35642], 17197: [35620], 10137: [35621], 17256: [35623, 36838], 10053: [35624], 16432: [35625], 11149: [35626, 36850], 6481: [35627], 11454: [35629], 6485: [35632], 11606: [35635], 7133: [35636], 11896: [35637], 11158: [35639], 16672: [35640, 36776, 36820], 16681: [35641], 16176: [35643], 16651: [35645], 18306: [35646, 35650], 11940: [35647], 8728: [35648], 15877: [35649, 36845], 8780: [35651], 10822: [35652], 7580: [35653], 16679: [35654], 18962: [35658, 35711], 5984: [35659], 10105: [35660, 35707, 35716], 16528: [35661, 35744], 5971: [35665, 36952, 37017], 18844: [35666, 37034], 8834: [35667], 16260: [35669], 5603: [35670], 6871: [35674, 36941], 16181: [35676], 6964: [35677], 5577: [35678], 15988: [35679], 5403: [35680], 17265: [35681], 7679: [35683], 16148: [35685], 19046: [35686], 6950: [35687], 5982: [35688, 35765, 36981], 6031: [35689], 5423: [35695, 35773, 35835, 36914], 10801: [35696, 36883], 18223: [35697], 18330: [35699], 12510: [35700], 11232: [35701], 6868: [35703], 5970: [35704], 9812: [35706], 5702: [35710], 5655: [35712], 11568: [35713], 5491: [35717, 35720], 8671: [35721], 5566: [35722], 16706: [35723], 7368: [35726], 18840: [35727, 35781], 7593: [35728], 15689: [35729], 6919: [35730], 5902: [35731], 10099: [35732], 6035: [35733], 9732: [35735], 16161: [35736], 7476: [35739], 10691: [35740], 12242: [35742], 17279: [35743], 7005: [35747], 6885: [35748], 17313: [35749], 5465: [35750], 15690: [35752], 11374: [35753], 7289: [35755], 11132: [35760], 5388: [35761], 17267: [35762], 5522: [35763], 19333: [35764], 5466: [35766], 19005: [35767], 9822: [35768, 35807, 35839], 5979: [35769], 6927: [35770], 10596: [35771], 10825: [35772], 18281: [35774], 16138: [35775], 5420: [35777, 36986, 37012, 37019], 16687: [35778, 36977], 9908: [35779], 18404: [35780], 11199: [35782], 5501: [35783], 10093: [35784], 10793: [35785], 17948: [35787], 5610: [35789], 7241: [35792], 5431: [35793], 5404: [35794], 9725: [35796], 5493: [35797], 5525: [35798], 7319: [35800], 8696: [35801], 5983: [35802], 17282: [35804], 5955: [35805], 17238: [35806], 5430: [35810, 35833, 35837, 36886, 36888, 36938, 36939, 36972, 36994, 37026, 37029, 37035, 37040, 37044, 37045, 37049, 37055, 37057], 10092: [35811], 9742: [35812], 6048: [35814], 5578: [35815], 5661: [35816], 19052: [35817], 5460: [35818], 12378: [35819], 5572: [35820], 7256: [35821], 5786: [35822], 12115: [35823], 12453: [35824], 17773: [35825], 12450: [35826], 5379: [35827], 12102: [35828], 6997: [35829], 11399: [35830], 12050: [35831], 12055: [35832, 35841], 7240: [35834], 8298: [35838], 12019: [35840], 12109: [35842], 12100: [35843], 12468: [35844], 12042: [35845], 11994: [35847], 12040: [35848], 5959: [35849, 36997, 37048], 12329: [35850], 15866: [35852], 12021: [35853], 12467: [35855], 17843: [35858], 3558: [35859], 14856: [35864], 14389: [35868, 35871, 35889], 14366: [35869], 3649: [35875], 14817: [35876], 1331: [35881], 3223: [35885], 3224: [35895], 14752: [35899], 3225: [35900], 17820: [35905], 3228: [35909], 960: [35912, 35987], 3560: [35914], 4879: [35930], 3236: [35931, 35965], 18875: [35935], 18214: [35936], 1348: [35939], 3651: [35943], 1327: [35944, 36037, 36043], 19534: [35945], 141: [35952, 36193], 17804: [35954, 36003], 14755: [35958], 18547: [35962], 14756: [35963], 15395: [35968], 14426: [35974], 17642: [35989], 3749: [35992], 18184: [35998], 18140: [35999], 18175: [36004], 4878: [36005], 15394: [36009], 15645: [36013], 15644: [36015], 1019: [36018, 36400], 18195: [36022], 15313: [36024], 1281: [36025], 1334: [36026], 17426: [36027], 18206: [36028], 1112: [36032], 3753: [36036], 14766: [36039], 1282: [36040], 18207: [36045], 3238: [36046], 18199: [36047], 17443: [36048], 18209: [36053], 3719: [36058], 3686: [36059], 19335: [36064], 16858: [36069, 36163], 1110: [36071], 3721: [36073], 17031: [36075], 19693: [36087], 19687: [36089], 18063: [36096], 14741: [36109], 10164: [36115], 5351: [36116], 16888: [36118], 876: [36120], 8690: [36126], 10175: [36131], 15302: [36138], 82: [36143], 3778: [36152], 10184: [36160], 10174: [36172, 36276, 36281], 10233: [36176, 36201, 36296], 17397: [36178], 19013: [36179], 17329: [36183, 36203, 36225], 16560: [36187], 10262: [36188, 36235, 36326], 19236: [36189], 8302: [36191], 17444: [36192], 16198: [36194, 36796], 10185: [36205], 17838: [36216], 18356: [36217], 3779: [36218], 19352: [36224], 19769: [36229], 4909: [36230], 7285: [36232, 36302], 7665: [36234], 17037: [36237], 11116: [36247], 16978: [36254], 17878: [36260], 17446: [36265], 17692: [36267], 8620: [36277], 8595: [36285], 8525: [36288], 16178: [36304], 18081: [36312], 3682: [36313], 8559: [36318], 8241: [36323], 152: [36325], 10263: [36328], 1926: [36335], 8390: [36336], 8541: [36340], 10236: [36341, 36351, 36578], 1005: [36344], 72: [36346], 17995: [36349], 11357: [36353], 8550: [36354], 7919: [36355], 17411: [36359], 7438: [36367], 18101: [36374], 16139: [36376], 17939: [36378], 16801: [36381], 17338: [36382], 861: [36383], 18000: [36396], 17774: [36406], 6145: [36408], 8248: [36421], 17009: [36423], 16715: [36426], 17108: [36427], 3706: [36428], 6787: [36437], 17067: [36440], 15306: [36445], 16157: [36446], 951: [36448], 4886: [36451], 17966: [36459], 11160: [36483], 8540: [36492], 4887: [36510], 18456: [36523], 8775: [36527], 8738: [36529], 10161: [36534], 8057: [36535], 8700: [36538], 10219: [36559], 18371: [36563], 18319: [36580], 16534: [36583], 16324: [36592], 18090: [36597], 15790: [36601], 18076: [36619], 10123: [36622], 10163: [36626, 36676], 16660: [36628], 16211: [36645, 36722, 36902, 36980, 37001], 19108: [36647], 905: [36658], 15818: [36661], 15516: [36665], 8329: [36673], 18087: [36679], 84: [36682], 7604: [36683], 19115: [36686], 9749: [36687], 18926: [36689], 5229: [36694], 16736: [36700], 10647: [36702], 16748: [36711], 8840: [36721], 8526: [36723], 18949: [36729], 7577: [36735, 36925, 37005], 8519: [36740], 16334: [36743], 8673: [36744], 9895: [36747], 4884: [36752], 10593: [36755], 10827: [36757], 10189: [36759], 18061: [36762], 8853: [36766, 37003], 18091: [36767], 7443: [36769], 11589: [36770], 11641: [36773], 18262: [36775], 16677: [36777], 8300: [36778], 17309: [36779], 18930: [36780], 10064: [36781], 7129: [36783], 11148: [36785], 11014: [36786], 15719: [36788], 16025: [36789], 11328: [36790], 12165: [36792], 18931: [36793], 10192: [36794], 10071: [36795], 10109: [36797], 18263: [36798], 10065: [36799], 7715: [36800], 19141: [36801], 10162: [36802], 16657: [36803, 36827, 36848], 8132: [36804], 17175: [36806, 36821], 11788: [36807], 11785: [36808], 18898: [36809], 17311: [36810], 10063: [36811], 10059: [36812], 11920: [36813], 9753: [36814], 17141: [36816], 7435: [36818, 36826, 36932, 36979], 11889: [36819], 19334: [36825], 7401: [36828], 19065: [36829], 19066: [36830], 11000: [36832], 11635: [36833], 6486: [36834], 6487: [36835], 16158: [36836], 12479: [36837], 16674: [36839], 6917: [36841, 36937], 10551: [36842], 8063: [36843], 17770: [36846], 17946: [36847], 6936: [36849], 17239: [36852], 8831: [36853, 36854, 36961], 11361: [36855], 18847: [36857], 11645: [36859], 8067: [36860], 11152: [36861], 6845: [36862], 9779: [36863], 16026: [36864], 19061: [36865], 11902: [36866], 12256: [36867], 19110: [36869], 7444: [36870], 18312: [36871], 8851: [36873], 11566: [36874], 7380: [36875], 1799: [36876], 7960: [36877], 19102: [36878], 16149: [36880], 9969: [36881], 9904: [36882], 16126: [36884], 9938: [36885], 5425: [36889], 8793: [36890], 5998: [36891], 10673: [36893], 16053: [36894], 16668: [36895], 7441: [36896], 16141: [36897, 36960], 9734: [36898], 9995: [36900], 7663: [36901], 6962: [36903], 17283: [36904], 7677: [36905], 16180: [36906], 6963: [36907], 11398: [36908], 9932: [36909], 10805: [36910], 16163: [36911], 6934: [36912], 8648: [36913], 7656: [36915], 17286: [36916], 5509: [36917], 17187: [36918], 8704: [36919], 10094: [36920], 18331: [36921], 5589: [36922], 6910: [36923], 10006: [36924], 7370: [36928], 11651: [36929], 7215: [36930], 7302: [36931], 8781: [36933], 7399: [36934, 37033], 15718: [36935], 8739: [36936], 5432: [36940], 6971: [36942], 5947: [36944], 10803: [36945], 6054: [36946], 8672: [36947], 5562: [36948], 5993: [36949], 8855: [36950], 6947: [36951], 7430: [36953, 36954], 7678: [36955], 5565: [36956], 7583: [36957], 18443: [36958], 9730: [36959], 18265: [36963], 8304: [36964], 5462: [36965], 5563: [36966, 36975, 37011, 37032], 6861: [36967], 7292: [36968], 16523: [36969], 8733: [36971], 7140: [36973], 9998: [36974], 6036: [36976], 6855: [36978], 6785: [36982], 9757: [36983, 36985], 5426: [36984], 9979: [36987], 19156: [36988], 15883: [36989], 8556: [36991], 10794: [36993], 8828: [36995], 17307: [36996], 18951: [36998], 6033: [36999], 6049: [37004], 7267: [37006], 7327: [37009], 17322: [37010], 10008: [37013], 17132: [37014], 11217: [37015, 37020], 10585: [37016], 11162: [37018], 17281: [37021], 9982: [37022], 9775: [37023], 10547: [37024], 5653: [37025], 9728: [37030], 5896: [37031], 8724: [37037], 5500: [37038], 9722: [37039], 15867: [37041], 5504: [37042], 12338: [37043], 5956: [37046], 5588: [37047], 10022: [37050], 12043: [37051], 12039: [37052], 11026: [37056], 12020: [37058], 7253: [37059], 0: []}\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(gene_cluster_presence_absence, taxa, test_frac):\n",
    "    #split gene_cluster_presence_absence into training and test set based on test_size\n",
    "    #test_size is the proportion of the dataset that is allocated to the test set\n",
    "    #the training set is the complement of the test set\n",
    "    #gene_cluster_presence_absence is a dataframe with genomes as rows and gene clusters as columns\n",
    "    #taxa is a dataframe with genomes as rows and taxonomy as columns\n",
    "    #returns taxa of the test set and training set\n",
    "    #returns gene_cluster_presence_absence of the test set and training set\n",
    "\n",
    "    test_size = int(len(gene_cluster_presence_absence.index)*test_frac)\n",
    "    test_set = random.sample(list(gene_cluster_presence_absence.index), test_size)\n",
    "    training_set = [x for x in gene_cluster_presence_absence.index if x not in test_set]\n",
    "    \n",
    "    test_taxa = taxa.loc[test_set]\n",
    "    test_taxa = [1 if x == 'Sphingomonadaceae' else 0 for x in test_taxa.loc[:, 1]]\n",
    "    training_taxa = taxa.loc[training_set]\n",
    "    training_taxa = [1 if x == 'Sphingomonadaceae' else 0 for x in training_taxa.loc[:, 1]]\n",
    "    test_gene_cluster_presence_absence = gene_cluster_presence_absence.loc[test_set, :]\n",
    "    training_gene_cluster_presence_absence = gene_cluster_presence_absence.loc[training_set, :]\n",
    "\n",
    "    return training_gene_cluster_presence_absence, training_taxa, test_gene_cluster_presence_absence, test_taxa  \n",
    "\n",
    "#print (cluster_id_to_feature_ids)\n",
    "#print (dict(cluster_id_to_feature_ids))\n",
    "\n",
    "import pickle\n",
    "if not os.path.isfile('{}cluster_id_to_feature_ids.pkl'.format(output_dir)):\n",
    "    with open('{}cluster_id_to_feature_ids.pkl'.format(output_dir), 'wb') as f:\n",
    "        pickle.dump(dict(cluster_id_to_feature_ids), f)\n",
    "\n",
    "else:\n",
    "    cluster_id_to_feature_ids2 = pickle.load(open('{}cluster_id_to_feature_ids.pkl'.format(output_dir), 'rb'))\n",
    "\n",
    "print (cluster_id_to_feature_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996031746031746\n",
      "item\n",
      "GC_00001622    1.0\n",
      "GC_00000001    0.0\n",
      "GC_00024837    0.0\n",
      "GC_00024831    0.0\n",
      "GC_00024832    0.0\n",
      "              ... \n",
      "GC_00024739    0.0\n",
      "GC_00024740    0.0\n",
      "GC_00024741    0.0\n",
      "GC_00024742    0.0\n",
      "GC_00024743    0.0\n",
      "Length: 100, dtype: float64\n",
      "0.0\n",
      "18531.0\n",
      "1.0\n",
      "item\n",
      "GC_00001929    0.003090\n",
      "GC_00002064    0.003081\n",
      "GC_00001685    0.003031\n",
      "GC_00001935    0.002995\n",
      "GC_00001577    0.002984\n",
      "                 ...   \n",
      "GC_00001474    0.002839\n",
      "GC_00001542    0.002835\n",
      "GC_00001443    0.002831\n",
      "GC_00002020    0.002820\n",
      "GC_00001150    0.002811\n",
      "Length: 100, dtype: float64\n",
      "0.002911119974156058\n",
      "45.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "item\n",
      "GC_00001479    0.018769\n",
      "GC_00001574    0.018769\n",
      "GC_00001554    0.018769\n",
      "GC_00001622    0.018769\n",
      "GC_00001513    0.018769\n",
      "                 ...   \n",
      "GC_00001505    0.018618\n",
      "GC_00001580    0.018567\n",
      "GC_00001329    0.018540\n",
      "GC_00001929    0.018526\n",
      "GC_00001767    0.018494\n",
      "Length: 100, dtype: float64\n",
      "0.01876860902407546\n",
      "37.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#decision tree with taxa labels binary and gc_matrix\n",
    "taxa_labels = [1 if x == 'Sphingomonadaceae' else 0 for x in taxa_df.loc[gene_cluster_presence_absence.index, 1]]\n",
    "gc_matrix = gene_cluster_presence_absence.values\n",
    "\n",
    "#taxa_labels = ['Sphingomonadaceae' if x == 'Sphingomonadaceae' else 'Other' for x in taxa_df.loc[:, 1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(gc_matrix, taxa_labels, test_size=0.2)\n",
    "\n",
    "#train the model\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print (accuracy_score(y_test, y_pred))\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "#std = np.std([clf.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=gene_cluster_presence_absence.columns)\n",
    "forest_ranked = forest_importances.rank(ascending=False)\n",
    "print (forest_importances.sort_values(ascending=False)[:100])\n",
    "print (forest_importances.loc['GC_00001531'])\n",
    "print (forest_ranked.loc['GC_00001531'])\n",
    "\n",
    "\n",
    "#print (forest_importances.loc['GC_00001531'])\n",
    "'''\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n",
    "'''\n",
    "\n",
    "#create classifier using ridgeclassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = RidgeClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "importances = clf.coef_\n",
    "ridge_importances = pd.Series(importances[0], index=gene_cluster_presence_absence.columns)\n",
    "ridge_ranked = ridge_importances.rank(ascending=False)\n",
    "print (ridge_importances.sort_values(ascending=False)[:100])\n",
    "print (ridge_importances.loc['GC_00001531'])\n",
    "print (ridge_ranked.loc['GC_00001531'])\n",
    "\n",
    "sns.histplot(ridge_importances, bins=100)\n",
    "plt.show()\n",
    "\n",
    "#create classifier using logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "importances = clf.coef_\n",
    "logReg_importances = pd.Series(importances[0], index=gene_cluster_presence_absence.columns)\n",
    "logReg_ranked = logReg_importances.rank(ascending=False)\n",
    "print (logReg_importances.sort_values(ascending=False)[:100])\n",
    "print (logReg_importances.loc['GC_00001531'])\n",
    "print (logReg_ranked.loc['GC_00001531'])\n",
    "\n",
    "sns.histplot(logReg_importances, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#decision tree with taxa labels binary and dataframe\\n\\nX_train, y_train, x_test, y_test = train_test_split(gene_cluster_presence_absence, taxa_df, test_frac=0.2)\\n\\nforest = RandomForestClassifier()\\nforest.fit(X_train, y_train)\\n\\ny_pred = clf.predict(X_test)\\n\\n#evaluate the model\\nprint (accuracy_score(y_test, y_pred))\\n\\nimportances = forest.feature_importances_\\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\\n\\nprint (X_train)\\n\\nforest_importances = pd.Series(importances, index=X_train.columns)\\nprint (forest_importances.sort_values(ascending=False)[:100])\\nprint (forest_importances.loc['GC_00001531'])\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#decision tree with taxa labels binary and dataframe\n",
    "\n",
    "X_train, y_train, x_test, y_test = train_test_split(gene_cluster_presence_absence, taxa_df, test_frac=0.2)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#evaluate the model\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "\n",
    "print (X_train)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "print (forest_importances.sort_values(ascending=False)[:100])\n",
    "print (forest_importances.loc['GC_00001531'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = permutation_importance(forest, X_test, y_test, n_repeats=2, random_state=42)\n",
    "#forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "\n",
    "#One approach to handling multicollinearity is by performing hierarchical clustering on the features’ Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster.\n",
    "#here we run the correlation or load it from a file\n",
    "#if not os.path.isfile('{}correlation.tsv'.format(output_dir)):\n",
    "#    spearman_corr = spearmanr(gene_cluster_presence_absence).correlation\n",
    "#    spearman_corr.to_csv('{}spearman_corr.tsv'.format(output_dir), sep='\\t')\n",
    "#else:\n",
    "#    spearman_corr = pd.read_csv('{}spearman_corr.tsv'.format(output_dir), sep='\\t', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.03161103  0.03839606 ... -0.14244776 -0.14244776\n",
      "  -0.12966398]\n",
      " [ 0.03161103  1.         -0.02858853 ...  0.00357924  0.00357924\n",
      "   0.00357924]\n",
      " [ 0.03839606 -0.02858853  1.         ...  0.12882756 -0.12519862\n",
      "   0.12882756]\n",
      " ...\n",
      " [-0.14244776  0.00357924  0.12882756 ...  1.         -0.01612903\n",
      "   0.18709677]\n",
      " [-0.14244776  0.00357924 -0.12519862 ... -0.01612903  1.\n",
      "  -0.01612903]\n",
      " [-0.12966398  0.00357924  0.12882756 ...  0.18709677 -0.01612903\n",
      "   1.        ]]\n",
      "[[ 1.          0.03161103  0.03839606 ... -0.14244776 -0.14244776\n",
      "  -0.12966398]\n",
      " [ 0.03161103  1.         -0.02858853 ...  0.00357924  0.00357924\n",
      "   0.00357924]\n",
      " [ 0.03839606 -0.02858853  1.         ...  0.12882756 -0.12519862\n",
      "   0.12882756]\n",
      " ...\n",
      " [-0.14244776  0.00357924  0.12882756 ...  1.         -0.01612903\n",
      "   0.18709677]\n",
      " [-0.14244776  0.00357924 -0.12519862 ... -0.01612903  1.\n",
      "  -0.01612903]\n",
      " [-0.12966398  0.00357924  0.12882756 ...  0.18709677 -0.01612903\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('{}spearman_corr.pkl'.format(output_dir)):\n",
    "    spearman_corr = spearmanr(gene_cluster_presence_absence).correlation\n",
    "    with open('{}spearman_corr.pkl'.format(output_dir), 'wb') as f:\n",
    "        pickle.dump(spearman_corr, f)\n",
    "else:\n",
    "    spearman_corr = pickle.load(open('{}spearman_corr.pkl'.format(output_dir), 'rb'))\n",
    "\n",
    "#spearman_corr = pd.read_csv('{}spearman_corr.tsv'.format(output_dir), sep='\\t', index_col=0)\n",
    "\n",
    "print (spearman_corr)\n",
    "spearman_corr = np.array(spearman_corr)\n",
    "print (spearman_corr)\n",
    "\n",
    "corr = (spearman_corr + spearman_corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "dendro = hierarchy.dendrogram(dist_linkage, labels=gene_cluster_presence_absence.columns.tolist(), ax=ax1, leaf_rotation=90)\n",
    "dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "'''\n",
    "if not os.path.isfile('{}spearman_corr.tsv'.format(output_dir)):\n",
    "    np.savetxt('{}spearman_corr.tsv'.format(output_dir), spearman_corr, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18602 18510 17472 ...  5430 12020  7253]\n",
      "0.5340133300952535\n",
      "[597, 974]\n",
      "[974]\n",
      "[597]\n",
      "[18602 18510 17472 ...  5430 12020  7253]\n",
      "0.5342831700801425\n",
      "GC_00000001    18602\n",
      "GC_00000002    18510\n",
      "GC_00000003    17472\n",
      "GC_00000004    17547\n",
      "GC_00000005     7469\n",
      "               ...  \n",
      "GC_00038550     5430\n",
      "GC_00038551    11026\n",
      "GC_00038554     5430\n",
      "GC_00038559    12020\n",
      "GC_00038560     7253\n",
      "Length: 37060, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "cluster_ids = hierarchy.fcluster(dist_linkage, t=0.05, criterion=\"distance\")\n",
    "print (cluster_ids)\n",
    "print (len(set(cluster_ids))/len(dist_linkage))\n",
    "\n",
    "cluster_id_to_feature_ids = defaultdict(list)\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "\n",
    "selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "clusters_in_use = len(cluster_id_to_feature_ids.keys())\n",
    "features_to_cluster = pd.Series()\n",
    "\n",
    "for cluster in range(len(cluster_ids)):\n",
    "    features_to_cluster.loc[gene_cluster_presence_absence.columns[cluster]] = cluster_ids[cluster]\n",
    "\n",
    "#given the absolute \n",
    "for cluster in range(1, len(cluster_id_to_feature_ids)):\n",
    "    if len(cluster_id_to_feature_ids[cluster])>1:\n",
    "        clustercorr = spearmanr(gene_cluster_presence_absence.iloc[:, cluster_id_to_feature_ids[cluster]]).correlation\n",
    "        directionality = np.sign(clustercorr)\n",
    "        if isinstance(directionality, np.ndarray):\n",
    "            directionality = directionality[0]\n",
    "            if -1 in directionality:\n",
    "                old_cluster = [cluster_id_to_feature_ids[cluster][i] for i, x in enumerate(directionality) if x == 1]\n",
    "                new_cluster = [cluster_id_to_feature_ids[cluster][i] for i, x in enumerate(directionality) if x == -1]\n",
    "                cluster_id_to_feature_ids[cluster] = old_cluster\n",
    "                cluster_id_to_feature_ids[len(cluster_id_to_feature_ids.keys())+1] = new_cluster\n",
    "                clusters_in_use +=1\n",
    "\n",
    "        elif isinstance(directionality, np.float64):\n",
    "            if directionality < 0:\n",
    "                print (cluster_id_to_feature_ids[cluster])\n",
    "                clusters_in_use +=1\n",
    "                cluster_id_to_feature_ids[clusters_in_use] = [cluster_id_to_feature_ids[cluster][1]]\n",
    "                cluster_id_to_feature_ids[cluster] = [cluster_id_to_feature_ids[cluster][0]]\n",
    "                print (cluster_id_to_feature_ids[clusters_in_use])\n",
    "                print (cluster_id_to_feature_ids[cluster])\n",
    "\n",
    "print (cluster_ids)\n",
    "print (len(cluster_id_to_feature_ids)/len(dist_linkage))\n",
    "\n",
    "#X_train_sel = X_train[:, selected_features]\n",
    "#X_test_sel = X_test[:, selected_features]\n",
    "\n",
    "selected_features_columns = [gene_cluster_presence_absence.columns[v[0]] for v in cluster_id_to_feature_ids.values()]\n",
    "print (features_to_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13368 ['GC_00000402', 'GC_00001115', 'GC_00001185', 'GC_00001262', 'GC_00001289', 'GC_00001329', 'GC_00001352', 'GC_00001427', 'GC_00001438', 'GC_00001443', 'GC_00001447', 'GC_00001448', 'GC_00001456', 'GC_00001459', 'GC_00001460', 'GC_00001461', 'GC_00001469', 'GC_00001470', 'GC_00001474', 'GC_00001479', 'GC_00001480', 'GC_00001481', 'GC_00001482', 'GC_00001486', 'GC_00001488', 'GC_00001489', 'GC_00001490', 'GC_00001491', 'GC_00001492', 'GC_00001493', 'GC_00001495', 'GC_00001496', 'GC_00001497', 'GC_00001498', 'GC_00001499', 'GC_00001501', 'GC_00001502', 'GC_00001504', 'GC_00001505', 'GC_00001506', 'GC_00001507', 'GC_00001509', 'GC_00001510', 'GC_00001511', 'GC_00001512', 'GC_00001513', 'GC_00001514', 'GC_00001516', 'GC_00001517', 'GC_00001518', 'GC_00001519', 'GC_00001521', 'GC_00001522', 'GC_00001523', 'GC_00001529', 'GC_00001530', 'GC_00001531', 'GC_00001532', 'GC_00001533', 'GC_00001534', 'GC_00001535', 'GC_00001537', 'GC_00001538', 'GC_00001539', 'GC_00001540', 'GC_00001541', 'GC_00001542', 'GC_00001543', 'GC_00001545', 'GC_00001546', 'GC_00001548', 'GC_00001549', 'GC_00001550', 'GC_00001554', 'GC_00001556', 'GC_00001559', 'GC_00001563', 'GC_00001566', 'GC_00001568', 'GC_00001569', 'GC_00001570', 'GC_00001571', 'GC_00001573', 'GC_00001574', 'GC_00001575', 'GC_00001576', 'GC_00001577', 'GC_00001578', 'GC_00001579', 'GC_00001580', 'GC_00001581', 'GC_00001582', 'GC_00001583', 'GC_00001584', 'GC_00001586', 'GC_00001587', 'GC_00001589', 'GC_00001591', 'GC_00001592', 'GC_00001594', 'GC_00001596', 'GC_00001597', 'GC_00001601', 'GC_00001603', 'GC_00001605', 'GC_00001611', 'GC_00001613', 'GC_00001614', 'GC_00001615', 'GC_00001616', 'GC_00001619', 'GC_00001620', 'GC_00001621', 'GC_00001622', 'GC_00001623', 'GC_00001624', 'GC_00001625', 'GC_00001626', 'GC_00001628', 'GC_00001629', 'GC_00001632', 'GC_00001635', 'GC_00001637', 'GC_00001639', 'GC_00001640', 'GC_00001641', 'GC_00001643', 'GC_00001644', 'GC_00001645', 'GC_00001648', 'GC_00001650', 'GC_00001651', 'GC_00001653', 'GC_00001656', 'GC_00001657', 'GC_00001659', 'GC_00001660', 'GC_00001667', 'GC_00001668', 'GC_00001672', 'GC_00001674', 'GC_00001675', 'GC_00001676', 'GC_00001678', 'GC_00001681', 'GC_00001682', 'GC_00001685', 'GC_00001689', 'GC_00001690', 'GC_00001692', 'GC_00001695', 'GC_00001696', 'GC_00001699', 'GC_00001700', 'GC_00001702', 'GC_00001705', 'GC_00001706', 'GC_00001711', 'GC_00001720', 'GC_00001723', 'GC_00001725', 'GC_00001726', 'GC_00001727', 'GC_00001737', 'GC_00001739', 'GC_00001741', 'GC_00001745', 'GC_00001746', 'GC_00001747', 'GC_00001749', 'GC_00001752', 'GC_00001753', 'GC_00001754', 'GC_00001756', 'GC_00001759', 'GC_00001760', 'GC_00001762', 'GC_00001765', 'GC_00001767', 'GC_00001772', 'GC_00001778', 'GC_00001781', 'GC_00001783', 'GC_00001786', 'GC_00001791', 'GC_00001794', 'GC_00001799', 'GC_00001804', 'GC_00001805', 'GC_00001807', 'GC_00001813', 'GC_00001823', 'GC_00001828', 'GC_00001831', 'GC_00001837', 'GC_00001838', 'GC_00001846', 'GC_00001874', 'GC_00001885', 'GC_00001900', 'GC_00001916']\n",
      "(201, 201)\n",
      "(6, 6)\n",
      "(207, 207)\n",
      "[[1.         0.96741751 0.98628114 0.97926237 0.97931243 0.97576023\n",
      "  0.96116889 0.97119409 0.98797984 0.97096431 0.97608443 0.98628114\n",
      "  0.98447381 0.98289734 0.98101524 0.98452462 0.98093597 0.98628114\n",
      "  0.97953149 0.98628114 0.97937401 0.98276932 0.98458699 0.98452462\n",
      "  0.98628114 0.98628114 0.96732737 0.98628114 0.97415895 0.98452462\n",
      "  0.98276932 0.98628114 0.97944705 0.98628114 0.98628114 0.9810694\n",
      "  0.98628114 0.98628114 0.97944705 0.98628114 0.98622621 0.98276932\n",
      "  0.98628114 0.98628114 0.98628114 0.98452462 0.98628114 0.98101524\n",
      "  0.98622621 0.98452462 0.98628114 0.98452462 0.98276932 0.98797984\n",
      "  0.98628114 0.98628114 0.98628114 0.98628114 0.98452462 0.98628114\n",
      "  0.98628114 0.98452462 0.98628114 0.98628114 0.98452462 0.98452462\n",
      "  0.98452462 0.98628114 0.98628114 0.98452462 0.98628114 0.98628114\n",
      "  0.98628114 0.98628114 0.98452462 0.97922391 0.98628114 0.98452462\n",
      "  0.98628114 0.98452462 0.98276932 0.98452462 0.98452462 0.98628114\n",
      "  0.98452462 0.98622621 0.98452462 0.98628114 0.97937401 0.98276932\n",
      "  0.98628114 0.98628114 0.98622621 0.98452462 0.98628114 0.98628114\n",
      "  0.98452462 0.98452462 0.98628114 0.98628114 0.98628114 0.97926237\n",
      "  0.98276932 0.98628114 0.98628114 0.98276932 0.98797984 0.98101524\n",
      "  0.98452462 0.98101524 0.98628114 0.98628114 0.98276932 0.98452462\n",
      "  0.98452462 0.98276932 0.98452462 0.98628114 0.98276932 0.98101524\n",
      "  0.97751071 0.98101524 0.98452462 0.98447381 0.98101524 0.98628114\n",
      "  0.9861829  0.97926237 0.98276932 0.98447381 0.98101524 0.98452462\n",
      "  0.98097267 0.98452462 0.98452462 0.98276932 0.98452462 0.98101524\n",
      "  0.98447381 0.98276932 0.98452462 0.98797984 0.97926237 0.98101524\n",
      "  0.98452462 0.98622621 0.98622621 0.9740981  0.98276932 0.97751071\n",
      "  0.98101524 0.97926237 0.98276932 0.98276932 0.98447381 0.98447381\n",
      "  0.98276932 0.97926237 0.97576023 0.98101524 0.98447381 0.98447381\n",
      "  0.97926237 0.97926237 0.98443464 0.97401093 0.9722407  0.98272264\n",
      "  0.97926237 0.98268759 0.97926237 0.97926237 0.97226281 0.97576023\n",
      "  0.98443464 0.98097267 0.97576023 0.97751071 0.97576023 0.97226281\n",
      "  0.97751071 0.97572996 0.97751071 0.97751071 0.97576023 0.98094175\n",
      "  0.97747634 0.97922391 0.98440716 0.97576023 0.97051585 0.97398475\n",
      "  0.97051585 0.95658083 0.97919711 0.97398475 0.9722407  0.97571137\n",
      "  0.97397025 0.96701546 0.97049695 0.95658736 0.96026382 0.97397025\n",
      "  0.97223167 0.97396752 0.96360302]\n",
      " [0.96741751 1.         0.97768473 0.97081709 0.97080998 0.96739058\n",
      "  0.95233857 0.96242322 0.97596597 0.96230778 0.96400024 0.97768473\n",
      "  0.97253216 0.97426221 0.97253216 0.97596597 0.95549042 0.97768473\n",
      "  0.97085762 0.97768473 0.96737925 0.97424845 0.97597122 0.97596597\n",
      "  0.97768473 0.97768473 0.9588036  0.97768473 0.96565555 0.97596597\n",
      "  0.97768692 0.97768473 0.97083031 0.97768473 0.97768473 0.96565555\n",
      "  0.97768473 0.97768473 0.97083031 0.97768473 0.97424845 0.97424845\n",
      "  0.97768473 0.97768473 0.97768473 0.97596597 0.97768473 0.97253216\n",
      "  0.97424845 0.97596597 0.97768473 0.97596597 0.97424845 0.97940278\n",
      "  0.97768473 0.97768473 0.97768473 0.97768473 0.97596597 0.97768473\n",
      "  0.97768473 0.97596597 0.97768473 0.97768473 0.97596597 0.97596597\n",
      "  0.97596597 0.97768473 0.97768473 0.97596597 0.97768473 0.97768473\n",
      "  0.97768473 0.97768473 0.97596597 0.96739058 0.97768473 0.97596597\n",
      "  0.97768473 0.97596597 0.97424845 0.97596597 0.97596597 0.97768473\n",
      "  0.97596597 0.97424845 0.97596597 0.97768473 0.97081441 0.97424845\n",
      "  0.97768473 0.97768473 0.97768692 0.97596597 0.97768473 0.97768473\n",
      "  0.97596597 0.97596597 0.97768473 0.97768473 0.97768473 0.97081709\n",
      "  0.97424845 0.97768473 0.97768473 0.97424845 0.97596597 0.97253216\n",
      "  0.97596597 0.97253216 0.97768473 0.97768473 0.97768692 0.97596597\n",
      "  0.97596597 0.97424845 0.97596597 0.97768473 0.97424845 0.97253216\n",
      "  0.96910323 0.97253216 0.97596597 0.97253216 0.97253216 0.97768473\n",
      "  0.97081709 0.97081709 0.97424845 0.97253216 0.97253216 0.97596597\n",
      "  0.96910323 0.97596597 0.97596597 0.97424845 0.97596597 0.97253216\n",
      "  0.9759723  0.97424845 0.97596597 0.97596597 0.97081709 0.97253216\n",
      "  0.97596597 0.97424845 0.97424845 0.96565189 0.97424845 0.96910323\n",
      "  0.97253216 0.97081709 0.97424845 0.97424845 0.97253216 0.9759723\n",
      "  0.97424845 0.97081709 0.96739058 0.97253216 0.97253216 0.9759723\n",
      "  0.97081709 0.97081709 0.96910323 0.97257299 0.96400397 0.97425891\n",
      "  0.97081709 0.9708358  0.97081709 0.97081709 0.96396884 0.96739058\n",
      "  0.96910323 0.97254675 0.96739058 0.96910323 0.96739058 0.96396884\n",
      "  0.96910323 0.96396884 0.96910323 0.96910323 0.96739058 0.96567912\n",
      "  0.96567912 0.96739058 0.96912606 0.96739058 0.96225974 0.96225974\n",
      "  0.96225974 0.94862812 0.96396884 0.96571015 0.9605518  0.96400397\n",
      "  0.95884502 0.9588924  0.95202929 0.94851989 0.9484512  0.96229896\n",
      "  0.95719084 0.9588924  0.95225568]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97926237 0.97081709 0.99313035 1.         0.98620585 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.98453429 0.99313035 0.9810474  0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98272197 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98445359 0.98792054 0.99139248 0.99137224 0.98792054 0.99313035\n",
      "  0.98618644 0.98618644 0.9931059  0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99139248 0.98792054\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.98618644 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98101714 0.98965588 0.98445359\n",
      "  0.98792054 0.98618644 0.98965588 0.98965588 0.98792054 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.98792054 0.98792054\n",
      "  0.98618644 0.98618644 0.98445359 0.98099157 0.97580759 0.98618644\n",
      "  0.98618644 0.98272197 0.98618644 0.99309322 0.97926237 0.98272197\n",
      "  0.98445359 0.98445359 0.98617877 0.98445359 0.98272197 0.9861829\n",
      "  0.98445359 0.9861829  0.98445359 0.98445359 0.98272197 0.98099157\n",
      "  0.98099157 0.99309237 0.98099157 0.98272197 0.97753439 0.97753439\n",
      "  0.9809964  0.96375263 0.97926237 0.97753439 0.97580759 0.97580759\n",
      "  0.97408198 0.97410339 0.96719117 0.96022688 0.97066203 0.97408198\n",
      "  0.96891215 0.97063426 0.95688889]\n",
      " [0.97931243 0.97080998 0.99311923 0.98620585 1.         0.98275669\n",
      "  0.96781155 0.97788924 0.99138898 0.97774303 0.97943198 0.99311923\n",
      "  0.9879323  0.98626334 0.9879323  0.99138898 0.96729517 0.99311923\n",
      "  0.98630571 0.99311923 0.97934583 0.99655334 0.99140905 0.99138898\n",
      "  0.99311923 0.99311923 0.9742005  0.99311923 0.97760898 0.99138898\n",
      "  0.98966001 0.99311923 0.98282326 0.99311923 0.99311923 0.98105398\n",
      "  0.99311923 0.99311923 0.98626334 0.99311923 0.98966001 0.98966001\n",
      "  0.99311923 0.99311923 0.99311923 0.99138898 0.99311923 0.9879323\n",
      "  0.98966001 0.99138898 0.99311923 0.99138898 0.99310667 0.99138898\n",
      "  0.99311923 0.99311923 0.99311923 0.99311923 0.99138898 0.99311923\n",
      "  0.99311923 0.99138898 0.99311923 0.99311923 0.99138898 0.99138898\n",
      "  0.99138898 0.99311923 0.99311923 0.99138898 0.99311923 0.99311923\n",
      "  0.99311923 0.99311923 0.99138898 0.98275669 0.99311923 0.99138898\n",
      "  0.99311923 0.99138898 0.98966001 0.99138898 0.99138898 0.99311923\n",
      "  0.99138898 0.98966001 0.99138898 0.99311923 0.98623253 0.98966001\n",
      "  0.99311923 0.99311923 0.99310667 0.99138898 0.99311923 0.99311923\n",
      "  0.99138898 0.99138898 0.99311923 0.99311923 0.99311923 0.9931059\n",
      "  0.98966001 0.99311923 0.99311923 0.98966001 0.99138898 0.9879323\n",
      "  0.99138898 0.9879323  0.99311923 0.99311923 0.98966001 0.99138898\n",
      "  0.99138898 0.98966001 0.99138898 0.99311923 0.98966001 0.9879323\n",
      "  0.98448065 0.9879323  0.99138898 0.9879323  0.9879323  0.99311923\n",
      "  0.98620585 0.98620585 0.98966001 0.9879323  0.9879323  0.99138898\n",
      "  0.98448065 0.99138898 0.99138898 0.98966001 0.99483398 0.9879323\n",
      "  0.9879323  0.98966001 0.99138898 0.99138898 0.98620585 0.9879323\n",
      "  0.99138898 0.98966001 0.98966001 0.98103563 0.98966001 0.98448065\n",
      "  0.9879323  0.98620585 0.98966001 0.98966001 0.9879323  0.9879323\n",
      "  0.98966001 0.98620585 0.98275669 0.9879323  0.9879323  0.99138064\n",
      "  0.98620585 0.98965588 0.98448065 0.98103395 0.97587301 0.98965588\n",
      "  0.98965588 0.98275669 0.98620585 0.98965588 0.97931243 0.98275669\n",
      "  0.98448065 0.98448065 0.98275669 0.98793237 0.98275669 0.97931243\n",
      "  0.98448065 0.98276932 0.98448065 0.98448065 0.98275669 0.98103395\n",
      "  0.98103395 0.98275669 0.98103395 0.98275669 0.97759212 0.97759212\n",
      "  0.98105076 0.96387211 0.97931243 0.97759212 0.97587301 0.97933341\n",
      "  0.9741551  0.9707228  0.96729517 0.96379131 0.97069062 0.97761727\n",
      "  0.97594352 0.9776543  0.96400057]\n",
      " [0.97576023 0.96739058 0.98970322 0.98272197 0.98275669 1.\n",
      "  0.96451919 0.97456383 0.98795605 0.97436405 0.97604293 0.98970322\n",
      "  0.98446543 0.98286084 0.98446543 0.98795605 0.98447948 0.98970322\n",
      "  0.98293015 0.98970322 0.97590277 0.98621012 0.98800319 0.98795605\n",
      "  0.98970322 0.98970322 0.97076084 0.98970322 0.97414898 0.98795605\n",
      "  0.98621012 0.98970322 0.979414   0.98970322 0.98970322 0.97760075\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.98621012 0.98621012\n",
      "  0.98970322 0.98970322 0.98970322 0.98795605 0.98970322 0.98446543\n",
      "  0.98621012 0.98795605 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.98795605 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.98795605 0.98795605\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.9792387  0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98621012 0.98795605 0.98795605 0.98970322\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.982803   0.98621012\n",
      "  0.98970322 0.98970322 0.98621012 0.98795605 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98621012 0.98970322 0.98970322 0.98621012 0.98795605 0.98446543\n",
      "  0.98795605 0.98446543 0.98970322 0.98970322 0.98621012 0.98795605\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.98621012 0.98446543\n",
      "  0.98789673 0.98792054 0.98795605 0.98446543 0.98446543 0.98970322\n",
      "  0.98272197 0.98272197 0.98621012 0.98446543 0.98446543 0.98795605\n",
      "  0.98097973 0.98795605 0.98795605 0.98966355 0.98795605 0.98446543\n",
      "  0.98446543 0.98621012 0.98795605 0.98795605 0.98272197 0.98446543\n",
      "  0.98795605 0.98621012 0.98621012 0.97755521 0.98621012 0.98097973\n",
      "  0.98446543 0.98272197 0.98621012 0.98621012 0.98446543 0.98446543\n",
      "  0.98621012 0.98272197 0.9792387  0.98446543 0.98446543 0.98446543\n",
      "  0.98272197 0.98272197 0.98443823 0.97749887 0.97228649 0.98272197\n",
      "  0.98272197 0.9792387  0.98617877 0.98272197 0.97576023 0.9792387\n",
      "  0.98097973 0.98097973 0.9792387  0.98097973 0.9792387  0.98268759\n",
      "  0.98097973 0.97576023 0.98097973 0.98097973 0.9792387  0.97749887\n",
      "  0.97749887 0.9792387  0.97749887 0.98615913 0.97402277 0.97748821\n",
      "  0.97402277 0.96016455 0.97922391 0.97402277 0.97228649 0.97228649\n",
      "  0.97055137 0.96708458 0.96709852 0.95319436 0.96027965 0.97055137\n",
      "  0.96535289 0.96708458 0.95326207]\n",
      " [0.96116889 0.95233857 0.97459965 0.96787436 0.96781155 0.96451919\n",
      "  1.         0.96256368 0.97291644 0.95915363 0.96086609 0.97459965\n",
      "  0.9695538  0.97113709 0.9695538  0.97291644 0.94948028 0.97459965\n",
      "  0.9676925  0.97459965 0.96092105 0.97123449 0.97286611 0.97291644\n",
      "  0.97459965 0.97459965 0.95577601 0.97459965 0.95923129 0.97291644\n",
      "  0.97123449 0.97459965 0.96772069 0.97459965 0.97459965 0.96607386\n",
      "  0.97459965 0.97459965 0.96772069 0.97459965 0.97123449 0.97123449\n",
      "  0.97459965 0.97459965 0.97459965 0.97291644 0.97459965 0.9695538\n",
      "  0.97123449 0.97291644 0.97459965 0.97291644 0.97123449 0.97291644\n",
      "  0.97459965 0.97459965 0.97459965 0.97459965 0.97291644 0.97459965\n",
      "  0.97459965 0.97291644 0.97459965 0.97459965 0.97291644 0.97291644\n",
      "  0.97291644 0.97459965 0.97459965 0.97291644 0.97459965 0.97459965\n",
      "  0.97459965 0.97459965 0.97291644 0.96451919 0.97459965 0.97291644\n",
      "  0.97459965 0.97291644 0.97123449 0.97291644 0.97291644 0.97459965\n",
      "  0.97291644 0.97123449 0.97291644 0.97459965 0.96776035 0.97123449\n",
      "  0.97459965 0.97459965 0.97123449 0.97291644 0.97459965 0.97459965\n",
      "  0.97291644 0.97291644 0.97459965 0.97459965 0.97459965 0.96787436\n",
      "  0.97123449 0.97459965 0.97459965 0.97123449 0.97291644 0.9695538\n",
      "  0.97291644 0.9695538  0.97459965 0.97459965 0.97123449 0.97291644\n",
      "  0.97291644 0.97123449 0.97291644 0.97459965 0.97123449 0.9695538\n",
      "  0.96619616 0.9695538  0.97291644 0.9695538  0.9695538  0.97459965\n",
      "  0.96787436 0.96787436 0.97123449 0.9695538  0.9695538  0.97291644\n",
      "  0.96619616 0.97291644 0.97291644 0.97123449 0.97291644 0.9695538\n",
      "  0.9695538  0.97123449 0.97291644 0.97291644 0.96787436 0.9695538\n",
      "  0.97291644 0.97123449 0.97123449 0.9627046  0.97123449 0.96619616\n",
      "  0.9695538  0.96787436 0.97123449 0.97123449 0.9695538  0.9695538\n",
      "  0.97123449 0.96787436 0.96451919 0.9695538  0.9695538  0.9695538\n",
      "  0.96787436 0.96787436 0.96619616 0.96284343 0.95782341 0.96787436\n",
      "  0.96787436 0.96451919 0.96787436 0.96787436 0.96116889 0.96451919\n",
      "  0.96619616 0.96619616 0.96451919 0.96619616 0.96451919 0.96116889\n",
      "  0.96619616 0.96116889 0.96619616 0.96619616 0.96451919 0.96284343\n",
      "  0.96284343 0.96451919 0.96284343 0.96451919 0.95949555 0.95949555\n",
      "  0.95949555 0.94615108 0.96116889 0.95949555 0.95782341 0.95782341\n",
      "  0.95615245 0.95281405 0.94948028 0.93904648 0.94558159 0.95615245\n",
      "  0.95114659 0.95281405 0.93950607]\n",
      " [0.97119409 0.96242322 0.98470309 0.97793852 0.97788924 0.97456383\n",
      "  0.96256368 1.         0.98301003 0.96926426 0.97097281 0.98470309\n",
      "  0.97962775 0.97782571 0.97962775 0.98301003 0.95943809 0.98470309\n",
      "  0.97781133 0.98470309 0.97100023 0.98131825 0.98297336 0.98301003\n",
      "  0.98470309 0.98470309 0.96585294 0.98470309 0.96930059 0.98301003\n",
      "  0.98131825 0.98470309 0.97440325 0.98470309 0.98470309 0.97272795\n",
      "  0.98470309 0.98470309 0.97782571 0.98470309 0.98131825 0.98131825\n",
      "  0.98470309 0.98470309 0.98470309 0.98301003 0.98470309 0.97962775\n",
      "  0.98131825 0.98301003 0.98470309 0.98301003 0.98131825 0.98301003\n",
      "  0.98470309 0.98470309 0.98470309 0.98470309 0.98301003 0.98470309\n",
      "  0.98470309 0.98301003 0.98470309 0.98470309 0.98301003 0.98301003\n",
      "  0.98301003 0.98470309 0.98470309 0.98301003 0.98470309 0.98470309\n",
      "  0.98470309 0.98470309 0.98301003 0.97456383 0.98470309 0.98301003\n",
      "  0.98470309 0.98301003 0.98131825 0.98301003 0.98301003 0.98470309\n",
      "  0.98301003 0.98131825 0.98301003 0.98470309 0.97785166 0.98131825\n",
      "  0.98470309 0.98470309 0.98131825 0.98301003 0.98470309 0.98470309\n",
      "  0.98301003 0.98301003 0.98470309 0.98470309 0.98470309 0.97793852\n",
      "  0.98131825 0.98470309 0.98470309 0.98131825 0.98301003 0.97962775\n",
      "  0.98301003 0.97962775 0.98470309 0.98470309 0.98131825 0.98301003\n",
      "  0.98301003 0.98131825 0.98301003 0.98470309 0.98131825 0.97962775\n",
      "  0.97625055 0.97962775 0.98301003 0.97962775 0.97962775 0.98470309\n",
      "  0.97793852 0.97793852 0.98131825 0.97962775 0.97962775 0.98301003\n",
      "  0.97625055 0.98301003 0.98301003 0.98131825 0.98301003 0.97962775\n",
      "  0.97962775 0.98131825 0.98301003 0.98301003 0.97793852 0.97962775\n",
      "  0.98301003 0.98131825 0.98131825 0.9727664  0.98131825 0.97625055\n",
      "  0.97962775 0.97793852 0.98131825 0.98131825 0.97962775 0.97962775\n",
      "  0.98131825 0.97793852 0.97456383 0.97962775 0.97962775 0.97962775\n",
      "  0.97793852 0.97793852 0.97625055 0.97287834 0.96782925 0.97793852\n",
      "  0.97793852 0.97456383 0.97793852 0.97793852 0.97119409 0.97456383\n",
      "  0.97625055 0.97625055 0.97456383 0.97625055 0.97456383 0.97119409\n",
      "  0.97625055 0.97119409 0.97625055 0.97625055 0.97456383 0.97287834\n",
      "  0.97287834 0.97456383 0.97287834 0.97456383 0.96951107 0.96951107\n",
      "  0.96951107 0.95608981 0.97119409 0.96951107 0.96782925 0.96782925\n",
      "  0.96614865 0.96279101 0.95943809 0.94899901 0.955613   0.96614865\n",
      "  0.96111396 0.96279101 0.9494069 ]\n",
      " [0.98797984 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 1.         0.98288499 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 0.99655666 0.97602065 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99827898 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99827898 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 1.         0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99655927 0.99311259 0.99828064\n",
      "  0.99484084 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.99312369 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 1.         0.99139248 0.99311259\n",
      "  0.99655666 0.99827898 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98797984 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98797984 0.98281076 0.98455684 0.98109812\n",
      "  0.98284719 0.97596745 0.97255295 0.96211115 0.96898587 0.98284719\n",
      "  0.97772549 0.97943152 0.96581609]\n",
      " [0.97096431 0.96230778 0.98459296 0.97776869 0.97774303 0.97436405\n",
      "  0.95915363 0.96926426 0.98288499 1.         0.97431021 0.98459296\n",
      "  0.9829098  0.97772661 0.97947287 0.98631861 0.9625607  0.98459296\n",
      "  0.97773571 0.98459296 0.97429706 0.9811783  0.98287187 0.98631861\n",
      "  0.98459296 0.98459296 0.96915054 0.98459296 0.96915055 0.98288499\n",
      "  0.98461357 0.98459296 0.9742979  0.98459296 0.98459296 0.97258416\n",
      "  0.98459296 0.98459296 0.97772661 0.98459296 0.98461357 0.98461357\n",
      "  0.98459296 0.98459296 0.98459296 0.98631861 0.98459296 0.97947287\n",
      "  0.98461357 0.98631861 0.98459296 0.98288499 0.9811783  0.98288499\n",
      "  0.98459296 0.98459296 0.98459296 0.98459296 0.98631861 0.98459296\n",
      "  0.98459296 0.98288499 0.98459296 0.98459296 0.98631861 0.98631861\n",
      "  0.98288499 0.98459296 0.98459296 0.98288499 0.98459296 0.98459296\n",
      "  0.98459296 0.98459296 0.98288499 0.97780607 0.98459296 0.98288499\n",
      "  0.98459296 0.98288499 0.98461357 0.98288499 0.98631861 0.98459296\n",
      "  0.98288499 0.9811783  0.98288499 0.98459296 0.98116099 0.98461357\n",
      "  0.98459296 0.98459296 0.9811783  0.98631861 0.98459296 0.98459296\n",
      "  0.98288499 0.98288499 0.98459296 0.98459296 0.98459296 0.97776869\n",
      "  0.98461357 0.98459296 0.98459296 0.9811783  0.98288499 0.97947287\n",
      "  0.98631861 0.97947287 0.98459296 0.98459296 0.9811783  0.98631861\n",
      "  0.98631861 0.98461357 0.98631861 0.98459296 0.9811783  0.97947287\n",
      "  0.97606575 0.97947287 0.98288499 0.97947287 0.97947287 0.98459296\n",
      "  0.97776869 0.97776869 0.9811783  0.9829098  0.97947287 0.98288499\n",
      "  0.97606575 0.98631861 0.98631861 0.98461357 0.98288499 0.97947287\n",
      "  0.97947287 0.9811783  0.98631861 0.98288499 0.97776869 0.9829098\n",
      "  0.98288499 0.9811783  0.98461357 0.97259899 0.9811783  0.97950606\n",
      "  0.97947287 0.98120731 0.9811783  0.98461357 0.97947287 0.9829098\n",
      "  0.98461357 0.98120731 0.97436405 0.9829098  0.9829098  0.97947287\n",
      "  0.97776869 0.97776869 0.97950606 0.97610731 0.9675694  0.98120731\n",
      "  0.97776869 0.97780607 0.97776869 0.97776869 0.97096431 0.97780607\n",
      "  0.97606575 0.97606575 0.97780607 0.97606575 0.97436405 0.97096431\n",
      "  0.97606575 0.97096431 0.97606575 0.97606575 0.97436405 0.97266357\n",
      "  0.97266357 0.97780607 0.97610731 0.97436405 0.96926626 0.97271346\n",
      "  0.97271346 0.95572421 0.97096431 0.97616067 0.9675694  0.97101836\n",
      "  0.96587374 0.96248594 0.9625607  0.95212307 0.9554143  0.96587374\n",
      "  0.96424988 0.96248594 0.9489805 ]\n",
      " [0.97608443 0.96400024 0.98628935 0.97945339 0.97943198 0.97604293\n",
      "  0.96086609 0.97097281 0.98801366 0.97431021 1.         0.98628935\n",
      "  0.98803755 0.97942408 0.98116049 0.98801366 0.96421506 0.98628935\n",
      "  0.97943747 0.98628935 0.97598868 0.98286884 0.9845696  0.98801366\n",
      "  0.98628935 0.98628935 0.97084191 0.98628935 0.97083764 0.98457846\n",
      "  0.98630571 0.98628935 0.97599379 0.98628935 0.98628935 0.97427285\n",
      "  0.98628935 0.98628935 0.97942408 0.98628935 0.98974257 0.98630571\n",
      "  0.98628935 0.98628935 0.98628935 0.98801366 0.98628935 0.98116049\n",
      "  0.98974257 0.98801366 0.98628935 0.98457846 0.98286884 0.98457846\n",
      "  0.98628935 0.98628935 0.98628935 0.98628935 0.98801366 0.98628935\n",
      "  0.98628935 0.98457846 0.98628935 0.98628935 0.98801366 0.98801366\n",
      "  0.98457846 0.98628935 0.98628935 0.98457846 0.98628935 0.98628935\n",
      "  0.98628935 0.98628935 0.98457846 0.98293015 0.98628935 0.98457846\n",
      "  0.98628935 0.98457846 0.98630571 0.98457846 0.98801366 0.98628935\n",
      "  0.98457846 0.98630571 0.98457846 0.98628935 0.98285579 0.98630571\n",
      "  0.98628935 0.98628935 0.98286884 0.98801366 0.98628935 0.98628935\n",
      "  0.98457846 0.98457846 0.98628935 0.98628935 0.98628935 0.97945339\n",
      "  0.98630571 0.98628935 0.98628935 0.98286884 0.98801366 0.98116049\n",
      "  0.98801366 0.98116049 0.98628935 0.98628935 0.98286884 0.98801366\n",
      "  0.98801366 0.98630571 0.98801366 0.98628935 0.98286884 0.98116049\n",
      "  0.97774754 0.98116049 0.98457846 0.98459902 0.98116049 0.98628935\n",
      "  0.98289361 0.97945339 0.98286884 0.98803755 0.98116049 0.98457846\n",
      "  0.98118945 0.98801366 0.98801366 0.98630571 0.98457846 0.98116049\n",
      "  0.98116049 0.98286884 0.98801366 0.98801366 0.97945339 0.98459902\n",
      "  0.98457846 0.98630571 0.98630571 0.97428343 0.98286884 0.98118945\n",
      "  0.98116049 0.98289361 0.98286884 0.98630571 0.98116049 0.98459902\n",
      "  0.98286884 0.98289361 0.97604293 0.98459902 0.98803755 0.98116049\n",
      "  0.97945339 0.97945339 0.97774754 0.97778487 0.96923665 0.98289361\n",
      "  0.97945339 0.98293015 0.97945339 0.97945339 0.97263737 0.97948654\n",
      "  0.97774754 0.97774754 0.97604293 0.97774754 0.97604293 0.97263737\n",
      "  0.97774754 0.97608443 0.97774754 0.97774754 0.97604293 0.97433954\n",
      "  0.97433954 0.98293015 0.9812302  0.97604293 0.97093641 0.97438522\n",
      "  0.97438522 0.95737119 0.97608443 0.97438522 0.97268721 0.96923665\n",
      "  0.97099041 0.96414449 0.96421506 0.95032092 0.95709077 0.97099041\n",
      "  0.96936483 0.96760038 0.9540866 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98447381 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99655927 0.9829098  0.98803755 0.99484582\n",
      "  1.         0.98799088 0.98964996 0.99655927 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98451075 0.99138064 0.99313695 0.99655927\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.9793259  0.99311259\n",
      "  0.99482898 0.99484582 0.98454913 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99827732 0.99482898\n",
      "  0.99484582 0.99484582 0.99484582 0.99655927 0.99484582 0.98964996\n",
      "  0.99827732 0.99655927 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99655927 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99655927 0.99655927\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.99137565 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99482898 0.99311259 0.99655927 0.99484582\n",
      "  0.99311259 0.99482898 0.99311259 0.99484582 0.9914008  0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99655927 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99482898 0.99484582 0.99484582 0.99138064 0.99655927 0.98964996\n",
      "  0.99655927 0.99309997 0.99484582 0.99484582 0.99138064 0.99655927\n",
      "  0.99655927 0.99482898 0.99655927 0.99484582 0.99138064 0.99309997\n",
      "  0.98619236 0.98964996 0.99311259 0.99309997 0.99309997 0.99484582\n",
      "  0.99137224 0.98792054 0.99482898 1.         0.99309997 0.99311259\n",
      "  0.98964576 0.99655927 0.99655927 0.99482898 0.99311259 0.98964996\n",
      "  0.99309997 0.99482898 0.99655927 0.99655927 0.98792054 0.99309997\n",
      "  0.99311259 0.99482898 0.99482898 0.98274993 0.99138064 0.98964576\n",
      "  0.98964996 0.99137224 0.99138064 0.99482898 0.98964996 0.99309997\n",
      "  0.99138064 0.99137224 0.98446543 0.99309997 0.99654999 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98619656 0.97756991 0.99137224\n",
      "  0.98792054 0.99137565 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98793238 0.98964576 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.99137565 0.98965339 0.98446543 0.97929197 0.98275229\n",
      "  0.98275229 0.96554834 0.98447381 0.98275229 0.98103198 0.97756991\n",
      "  0.97931288 0.97587826 0.97591941 0.9585411  0.96549987 0.97931288\n",
      "  0.97763196 0.97934569 0.96218617]\n",
      " [0.98289734 0.97426221 0.99313236 0.98627961 0.98626334 0.98286084\n",
      "  0.97113709 0.97782571 0.99141724 0.97772661 0.97942408 0.99313236\n",
      "  0.98799088 1.         0.98799088 0.99141724 0.97099968 0.99313236\n",
      "  0.98628468 0.99313236 0.98282203 0.98970342 0.99141363 0.99141724\n",
      "  0.99313236 0.99313236 0.97423794 0.99313236 0.98110198 0.99141724\n",
      "  0.98970342 0.99313236 0.99656649 0.99313236 0.99313236 0.99141724\n",
      "  0.99313236 0.99313236 0.98626594 0.99313236 0.98970342 0.98970342\n",
      "  0.99313236 0.99313236 0.99313236 0.99141724 0.99313236 0.98799088\n",
      "  0.98970342 0.99141724 0.99313236 0.99141724 0.98970342 0.99485567\n",
      "  0.99313236 0.99313236 0.99313236 0.99313236 0.99141724 0.99313236\n",
      "  0.99313236 0.99141724 0.99313236 0.99313236 0.99141724 0.99141724\n",
      "  0.99141724 0.99313236 0.99313236 0.99141724 0.99313236 0.99313236\n",
      "  0.99313236 0.99313236 0.99141724 0.98286084 0.99313236 0.99141724\n",
      "  0.99313236 0.99141724 0.98970342 0.99141724 0.99141724 0.99313236\n",
      "  0.99141724 0.98970342 0.99141724 0.99313236 0.98625881 0.98970342\n",
      "  0.99313236 0.99313236 0.9931435  0.99141724 0.99313236 0.99313236\n",
      "  0.99141724 0.99141724 0.99313236 0.99313236 0.99313236 0.98627961\n",
      "  0.98970342 0.99313236 0.99313236 0.98970342 0.99141724 0.98799088\n",
      "  0.99141724 0.98799088 0.99313236 0.99313236 0.98970342 0.99141724\n",
      "  0.99141724 0.98970342 0.99141724 0.99313236 0.98970342 0.98799088\n",
      "  0.9845696  0.98799088 0.99141724 0.98799088 0.98799088 0.99313236\n",
      "  0.98627961 0.98627961 0.98970342 0.98799088 0.98799088 0.99141724\n",
      "  0.9845696  0.99141724 0.99141724 0.98970342 0.99141724 0.98799088\n",
      "  0.99143263 0.98970342 0.99141724 0.99141724 0.98627961 0.98799088\n",
      "  0.99141724 0.98970342 0.98970342 0.98110737 0.98970342 0.9845696\n",
      "  0.98799088 0.98627961 0.98970342 0.98970342 0.98799088 0.99143263\n",
      "  0.98970342 0.98627961 0.98286084 0.98799088 0.98799088 0.99143263\n",
      "  0.98627961 0.98627961 0.9845696  0.98115333 0.97949196 0.98972305\n",
      "  0.98627961 0.98286084 0.98627961 0.98627961 0.97944705 0.98286084\n",
      "  0.9845696  0.9845696  0.98286084 0.9845696  0.98286084 0.97944705\n",
      "  0.9845696  0.97944705 0.9845696  0.9845696  0.98286084 0.98115333\n",
      "  0.98115333 0.98286084 0.98460189 0.98286084 0.977742   0.977742\n",
      "  0.977742   0.96414463 0.97944705 0.98119404 0.97603817 0.97949196\n",
      "  0.97433554 0.974393   0.96753692 0.96055648 0.9638986  0.97433554\n",
      "  0.96923481 0.974393   0.96084761]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.98799088 1.         0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99482898 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.98792054 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.98792054 0.99138064 0.99482898 0.98964996 0.98964996\n",
      "  0.99138064 0.99137224 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.99137224 0.98792054 0.98619236 0.98965339 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98619236 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98101524 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98446543 0.98273973 0.98446543 0.98275229 0.97929197\n",
      "  0.97929197 0.96554834 0.98101524 0.97929197 0.97756991 0.97756991\n",
      "  0.97584903 0.97241083 0.96897729 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97241083 0.95870391]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98093597 0.95549042 0.97434252 0.96719117 0.96729517 0.98447948\n",
      "  0.94948028 0.95943809 0.97602065 0.9625607  0.96421506 0.97434252\n",
      "  0.97244835 0.97099968 0.96897729 0.97255295 1.         0.97434252\n",
      "  0.96767457 0.97434252 0.96394439 0.97076454 0.97266887 0.97255295\n",
      "  0.97434252 0.97434252 0.95534691 0.97434252 0.96214984 0.97255295\n",
      "  0.97076454 0.97434252 0.96753692 0.97434252 0.97434252 0.96908525\n",
      "  0.97434252 0.97434252 0.96753692 0.97434252 0.97423392 0.97076454\n",
      "  0.97434252 0.97434252 0.97434252 0.97255295 0.97434252 0.96897729\n",
      "  0.97423392 0.97255295 0.97434252 0.97255295 0.97076454 0.97602065\n",
      "  0.97434252 0.97434252 0.97434252 0.97434252 0.97255295 0.97434252\n",
      "  0.97434252 0.97255295 0.97434252 0.97434252 0.97255295 0.97255295\n",
      "  0.97255295 0.97434252 0.97434252 0.97255295 0.97434252 0.97434252\n",
      "  0.97434252 0.97434252 0.97255295 0.96709852 0.97434252 0.97255295\n",
      "  0.97434252 0.97255295 0.97076454 0.97255295 0.97255295 0.97434252\n",
      "  0.97255295 0.97423392 0.97255295 0.97434252 0.96741044 0.97076454\n",
      "  0.97434252 0.97434252 0.97423392 0.97255295 0.97434252 0.97434252\n",
      "  0.97255295 0.97255295 0.97434252 0.97434252 0.97434252 0.96719117\n",
      "  0.97076454 0.97434252 0.97434252 0.97076454 0.97602065 0.96897729\n",
      "  0.97255295 0.96897729 0.97434252 0.97434252 0.97076454 0.97255295\n",
      "  0.97255295 0.97076454 0.97255295 0.97434252 0.97076454 0.96897729\n",
      "  0.97235513 0.97244835 0.97255295 0.97244835 0.96897729 0.97434252\n",
      "  0.97413669 0.96719117 0.97076454 0.97244835 0.96897729 0.97255295\n",
      "  0.96888066 0.97255295 0.97255295 0.97423392 0.97255295 0.96897729\n",
      "  0.97244835 0.97076454 0.97255295 0.97602065 0.96719117 0.96897729\n",
      "  0.97255295 0.97423392 0.97076454 0.96203516 0.97076454 0.96540619\n",
      "  0.96897729 0.96719117 0.97076454 0.97076454 0.97244835 0.97244835\n",
      "  0.97423392 0.96719117 0.96362233 0.96897729 0.97244835 0.97244835\n",
      "  0.96719117 0.96719117 0.9758296  0.96183958 0.95998111 0.97066393\n",
      "  0.96719117 0.96709852 0.97066393 0.96719117 0.96005794 0.96362233\n",
      "  0.97235513 0.96540619 0.96709852 0.96540619 0.96362233 0.96701728\n",
      "  0.96540619 0.96353761 0.96540619 0.96540619 0.96362233 0.96879543\n",
      "  0.96531751 0.96709852 0.97227336 0.97057472 0.95827738 0.96524024\n",
      "  0.95827738 0.94407103 0.97049695 0.96524024 0.95998111 0.96694751\n",
      "  0.96168947 0.95465446 0.96158537 0.9441887  0.94467985 0.96168947\n",
      "  0.95288103 0.95814305 0.9475027 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97953149 0.97085762 0.99315646 0.98633382 0.98630571 0.98293015\n",
      "  0.9676925  0.97781133 0.99144887 0.97773571 0.97943747 0.99315646\n",
      "  0.98803755 0.98628468 0.98803755 0.99144887 0.96767457 0.99315646\n",
      "  1.         0.99315646 0.97942223 0.98974257 0.99143344 0.99144887\n",
      "  0.99315646 0.99315646 0.97427383 0.99315646 0.97770805 0.99144887\n",
      "  0.98974257 0.99315646 0.98285438 0.99315646 0.99315646 0.98114326\n",
      "  0.99315646 0.99315646 0.98628468 0.99315646 0.98974257 0.98974257\n",
      "  0.99315646 0.99315646 0.99315646 0.99144887 0.99315646 0.98803755\n",
      "  0.98974257 0.99144887 0.99315646 0.99144887 0.98974257 0.99144887\n",
      "  0.99315646 0.99315646 0.99315646 0.99315646 0.99144887 0.99315646\n",
      "  0.99315646 0.99144887 0.99315646 0.99315646 0.99144887 0.99144887\n",
      "  0.99144887 0.99315646 0.99315646 0.99144887 0.99315646 0.99315646\n",
      "  0.99315646 0.99315646 0.99144887 0.98293015 0.99315646 0.99144887\n",
      "  0.99315646 0.99144887 0.98974257 0.99144887 0.99144887 0.99315646\n",
      "  0.99144887 0.98974257 0.99144887 0.99315646 0.98628935 0.98974257\n",
      "  0.99315646 0.99315646 0.98974257 0.99144887 0.99315646 0.99315646\n",
      "  0.99144887 0.99144887 0.99315646 0.99315646 0.99315646 0.98633382\n",
      "  0.98974257 0.99315646 0.99315646 0.98974257 0.99144887 0.98803755\n",
      "  0.99144887 0.98803755 0.99315646 0.99315646 0.98974257 0.99144887\n",
      "  0.99144887 0.98974257 0.99144887 0.99315646 0.98974257 0.98803755\n",
      "  0.98463136 0.98803755 0.99144887 0.98803755 0.98803755 0.99315646\n",
      "  0.98633382 0.98633382 0.98974257 0.98803755 0.98803755 0.99144887\n",
      "  0.98463136 0.99144887 0.99144887 0.98974257 0.99144887 0.98803755\n",
      "  0.98803755 0.98974257 0.99144887 0.99144887 0.98633382 0.98803755\n",
      "  0.99144887 0.98974257 0.98974257 0.98116049 0.98974257 0.98463136\n",
      "  0.98803755 0.98633382 0.98974257 0.98974257 0.98803755 0.98803755\n",
      "  0.98974257 0.98633382 0.98293015 0.98803755 0.98803755 0.98803755\n",
      "  0.98633382 0.98633382 0.98463136 0.9812302  0.97613777 0.98633382\n",
      "  0.98633382 0.98293015 0.98633382 0.98633382 0.97953149 0.98293015\n",
      "  0.98463136 0.98463136 0.98293015 0.98463136 0.98293015 0.97953149\n",
      "  0.98463136 0.97953149 0.98463136 0.98463136 0.98293015 0.9812302\n",
      "  0.9812302  0.98293015 0.9812302  0.98293015 0.97783402 0.97783402\n",
      "  0.97783402 0.96429755 0.97953149 0.97783402 0.97613777 0.97613777\n",
      "  0.97444273 0.97105627 0.96767457 0.95723271 0.96396783 0.97444273\n",
      "  0.96936483 0.97105627 0.95755727]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97937401 0.96737925 0.98623985 0.97934352 0.97934583 0.97590277\n",
      "  0.96092105 0.97100023 0.98451389 0.97429706 0.97598868 0.98623985\n",
      "  0.98451075 0.98282203 0.98106573 0.98795557 0.96394439 0.98623985\n",
      "  0.97942223 0.98623985 1.         0.98278918 0.98452868 0.98795557\n",
      "  0.98623985 0.98623985 0.97077507 0.98623985 0.99139726 0.98795557\n",
      "  0.98623253 0.98623985 0.97938526 0.98623985 0.98623985 0.97418882\n",
      "  0.98623985 0.98623985 0.97938526 0.98623985 0.98623253 0.98967588\n",
      "  0.98623985 0.98623985 0.98623985 0.98795557 0.98623985 0.98106573\n",
      "  0.98623253 0.98795557 0.98623985 0.98451389 0.98278918 0.98795557\n",
      "  0.98623985 0.98623985 0.98623985 0.98623985 0.98795557 0.98623985\n",
      "  0.98623985 0.98451389 0.98623985 0.98623985 0.98795557 0.98795557\n",
      "  0.98451389 0.98623985 0.98623985 0.98795557 0.98623985 0.98623985\n",
      "  0.98623985 0.98623985 0.98451389 0.97935289 0.98623985 0.98451389\n",
      "  0.98623985 0.98451389 0.98623253 0.98451389 0.98795557 0.98623985\n",
      "  0.98451389 0.98278918 0.98451389 0.98623985 0.98279981 0.98623253\n",
      "  0.98623985 0.98623985 0.98623253 0.98795557 0.98623985 0.98623985\n",
      "  0.98451389 0.98451389 0.98623985 0.98623985 0.98623985 0.97934352\n",
      "  0.98623253 0.98623985 0.98623985 0.98278918 0.98451389 0.98106573\n",
      "  0.98795557 0.98106573 0.98623985 0.98623985 0.98278918 0.98795557\n",
      "  0.98795557 0.98967588 0.98795557 0.98623985 0.98278918 0.98106573\n",
      "  0.97762253 0.98106573 0.98451389 0.98106573 0.98106573 0.98623985\n",
      "  0.97934352 0.97934352 0.98278918 0.98451075 0.98106573 0.98451389\n",
      "  0.97762253 0.98795557 0.98795557 0.98623253 0.98451389 0.98106573\n",
      "  0.98451075 0.98278918 0.98795557 0.98451389 0.97934352 0.98451075\n",
      "  0.98451389 0.98278918 0.98623253 0.97417569 0.98278918 0.98107094\n",
      "  0.98106573 0.98279022 0.98623253 0.98623253 0.98106573 0.98795577\n",
      "  0.98278918 0.98279022 0.97590277 0.98451075 0.98451075 0.98451075\n",
      "  0.98279022 0.97934352 0.98107094 0.97763606 0.97249283 0.98623693\n",
      "  0.97934352 0.97935289 0.98279022 0.97934352 0.97246688 0.982803\n",
      "  0.97762253 0.98107094 0.97590277 0.97762253 0.97590277 0.97246688\n",
      "  0.98107094 0.97246688 0.98107094 0.97762253 0.97590277 0.97418422\n",
      "  0.97418422 0.97935289 0.98108789 0.97935289 0.97420604 0.97420604\n",
      "  0.97420604 0.95706336 0.97246688 0.97766135 0.96903576 0.97594989\n",
      "  0.96732196 0.96736028 0.96394439 0.96043545 0.9603956  0.96732196\n",
      "  0.96911598 0.97082269 0.96067828]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.99655334 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 1.         0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99655334 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99655334 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.99655593\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99827898 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99482898\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.9844891  0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.96734516 0.98276932 0.98105076 0.97933341 0.98279381\n",
      "  0.97761727 0.97418855 0.97076454 0.96725706 0.97413895 0.98107943\n",
      "  0.97941107 0.98112005 0.96748114]\n",
      " [0.98458699 0.97597122 0.99828228 0.99142442 0.99140905 0.98800319\n",
      "  0.97286611 0.98297336 0.99656587 0.98287187 0.9845696  0.99828228\n",
      "  0.99313695 0.99141363 0.99313695 0.99656587 0.97266887 0.99828228\n",
      "  0.99143344 0.99828228 0.98452868 0.99485076 1.         0.99656587\n",
      "  0.99828228 0.99828228 0.97937942 0.99828228 0.98280567 0.99656587\n",
      "  0.99485076 0.99828228 0.98797849 0.99828228 0.99828228 0.98624572\n",
      "  0.99828228 0.99828228 0.99141363 0.99828228 0.99485076 0.99485076\n",
      "  0.99828228 0.99828228 0.99828228 0.99656587 0.99828228 0.99313695\n",
      "  0.99485076 0.99656587 0.99828228 0.99656587 0.99485076 0.99656587\n",
      "  0.99828228 0.99828228 0.99828228 0.99828228 0.99656587 0.99828228\n",
      "  0.99828228 0.99656587 0.99828228 0.99828228 0.99656587 0.99656587\n",
      "  0.99656587 0.99828228 0.99828228 0.99656587 0.99828228 0.99828228\n",
      "  0.99828228 0.99828228 0.99656587 0.98800319 0.99828228 0.99656587\n",
      "  0.99828228 0.99656587 0.99485076 0.99656587 0.99656587 0.99828228\n",
      "  0.99656587 0.99485076 0.99656587 0.99828228 0.99140548 0.99485076\n",
      "  0.99828228 0.99828228 0.99485076 0.99656587 0.99828228 0.99828228\n",
      "  0.99656587 0.99656587 0.99828228 0.99828228 0.99828228 0.99142442\n",
      "  0.99485076 0.99828228 0.99828228 0.99485076 0.99656587 0.99313695\n",
      "  0.99656587 0.99313695 0.99828228 0.99828228 0.99485076 0.99656587\n",
      "  0.99656587 0.99485076 0.99656587 0.99828228 0.99485076 0.99313695\n",
      "  0.98971317 0.99313695 0.99656587 0.99313695 0.99313695 0.99828228\n",
      "  0.99142442 0.99142442 0.99485076 0.99313695 0.99313695 0.99656587\n",
      "  0.98971317 0.99656587 0.99656587 0.99485076 0.99656587 0.99313695\n",
      "  0.99313695 0.99485076 0.99656587 0.99656587 0.99142442 0.99313695\n",
      "  0.99656587 0.99485076 0.99485076 0.98625019 0.99485076 0.98971317\n",
      "  0.99313695 0.99142442 0.99485076 0.99485076 0.99313695 0.99313695\n",
      "  0.99485076 0.99142442 0.98800319 0.99313695 0.99313695 0.99313695\n",
      "  0.99142442 0.99142442 0.98971317 0.98629446 0.98117575 0.99142442\n",
      "  0.99142442 0.98800319 0.99142442 0.99142442 0.98458699 0.98800319\n",
      "  0.98971317 0.98971317 0.98800319 0.98971317 0.98800319 0.98458699\n",
      "  0.98971317 0.98458699 0.98971317 0.98971317 0.98800319 0.98629446\n",
      "  0.98629446 0.98800319 0.98629446 0.98800319 0.98288075 0.98288075\n",
      "  0.98288075 0.96927442 0.98458699 0.98288075 0.98117575 0.98117575\n",
      "  0.97947196 0.97606802 0.97266887 0.96222496 0.96903328 0.97947196\n",
      "  0.97436785 0.97606802 0.96249935]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.96732737 0.9588036  0.98109028 0.98453429 0.9742005  0.97076084\n",
      "  0.95577601 0.96585294 0.97936562 0.96915054 0.97084191 0.98109028\n",
      "  0.97936342 0.97423794 0.97592004 0.98280567 0.95534691 0.98109028\n",
      "  0.97427383 0.98109028 0.97077507 0.97764221 0.97937942 0.98280567\n",
      "  0.98109028 0.98109028 1.         0.98109028 0.96904547 0.97936562\n",
      "  0.98108392 0.98109028 0.9708028  0.98109028 0.98109028 0.96904547\n",
      "  0.98109028 0.98109028 0.97423794 0.98109028 0.98108392 0.98108392\n",
      "  0.98109028 0.98109028 0.98109028 0.98280567 0.98109028 0.97592004\n",
      "  0.98108392 0.98280567 0.98109028 0.97936562 0.97764221 0.97936562\n",
      "  0.98109028 0.98109028 0.98109028 0.98109028 0.98280567 0.98109028\n",
      "  0.98109028 0.97936562 0.98109028 0.98109028 0.98280567 0.98280567\n",
      "  0.97936562 0.98109028 0.98109028 0.97936562 0.98109028 0.98109028\n",
      "  0.98109028 0.98109028 0.97936562 0.97420931 0.98109028 0.97936562\n",
      "  0.98109028 0.97936562 0.98108392 0.97936562 0.98280567 0.98109028\n",
      "  0.97936562 0.97764221 0.97936562 0.98109028 0.97765187 0.98108392\n",
      "  0.98109028 0.98109028 0.97764221 0.98280567 0.98109028 0.98109028\n",
      "  0.97936562 0.97936562 0.98109028 0.98109028 0.98109028 0.97419909\n",
      "  0.98108392 0.98109028 0.98109028 0.97764221 0.97936562 0.97592004\n",
      "  0.98280567 0.97592004 0.98109028 0.98109028 0.97764221 0.98280567\n",
      "  0.98280567 0.98108392 0.98280567 0.98109028 0.97764221 0.97592004\n",
      "  0.97592612 0.97936342 0.97936562 0.97936342 0.97592004 0.98109028\n",
      "  0.97419909 0.97764416 0.98108392 0.97936342 0.97592004 0.97936562\n",
      "  0.97247936 0.98280567 0.98280567 0.98108392 0.97936562 0.97592004\n",
      "  0.97592004 0.97764221 0.98280567 0.97936562 0.97419909 0.97936342\n",
      "  0.97936562 0.97764221 0.98108392 0.96903328 0.97764221 0.97592612\n",
      "  0.97592004 0.98108922 0.97764221 0.98108392 0.97592004 0.97936342\n",
      "  0.97764221 0.97764416 0.97076084 0.97936342 0.97936342 0.97592004\n",
      "  0.97419909 0.97419909 0.97247936 0.9724937  0.96389863 0.97764416\n",
      "  0.97419909 0.97420931 0.97419909 0.98108922 0.9707793  0.97420931\n",
      "  0.97247936 0.97247936 0.97420931 0.97247936 0.97076084 0.97423122\n",
      "  0.97247936 0.97423122 0.97247936 0.97592612 0.97076084 0.9724937\n",
      "  0.96904351 0.98455472 0.9724937  0.97076084 0.96561242 0.96906608\n",
      "  0.97251975 0.95193409 0.9707793  0.96906608 0.96389863 0.96389863\n",
      "  0.96564319 0.96222496 0.9588113  0.94838189 0.95870313 0.962186\n",
      "  0.96051756 0.95876419 0.94512153]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97415895 0.96565555 0.98451389 0.9810474  0.97760898 0.97414898\n",
      "  0.95923129 0.96930059 0.98278331 0.96915055 0.97083764 0.98451389\n",
      "  0.9793259  0.98110198 0.9793259  0.98278331 0.96214984 0.98451389\n",
      "  0.97770805 0.98451389 0.99139726 0.98105398 0.98280567 0.98278331\n",
      "  0.98451389 0.98451389 0.96904547 0.98451389 1.         0.98622665\n",
      "  0.98105398 0.98451389 0.97766356 0.98451389 0.98451389 0.9724533\n",
      "  0.98451389 0.98451389 0.97766356 0.98451389 0.98105398 0.98449898\n",
      "  0.98451389 0.98451389 0.98451389 0.98278331 0.98451389 0.9793259\n",
      "  0.98105398 0.98278331 0.98451389 0.98278331 0.98105398 0.98622665\n",
      "  0.98451389 0.98451389 0.98451389 0.98451389 0.98278331 0.98451389\n",
      "  0.98451389 0.98278331 0.98451389 0.98451389 0.98278331 0.98278331\n",
      "  0.98278331 0.98451389 0.98451389 0.98622665 0.98451389 0.98451389\n",
      "  0.98451389 0.98451389 0.98278331 0.97414898 0.98451389 0.98278331\n",
      "  0.98451389 0.98278331 0.98105398 0.98278331 0.98278331 0.98451389\n",
      "  0.98278331 0.98105398 0.98278331 0.98451389 0.97763051 0.98105398\n",
      "  0.98451389 0.98451389 0.98449898 0.98278331 0.98451389 0.98451389\n",
      "  0.98278331 0.98278331 0.98451389 0.98451389 0.98451389 0.9810474\n",
      "  0.98105398 0.98451389 0.98451389 0.98105398 0.98278331 0.9793259\n",
      "  0.98278331 0.9793259  0.98451389 0.98451389 0.98105398 0.98278331\n",
      "  0.98278331 0.98449898 0.98278331 0.98451389 0.98105398 0.9793259\n",
      "  0.9758734  0.9793259  0.98278331 0.9793259  0.9793259  0.98451389\n",
      "  0.97759904 0.97759904 0.98105398 0.9793259  0.9793259  0.98278331\n",
      "  0.9758734  0.98278331 0.98278331 0.98105398 0.98278331 0.9793259\n",
      "  0.98277257 0.98105398 0.98278331 0.98278331 0.97759904 0.9793259\n",
      "  0.98278331 0.98105398 0.98105398 0.97243255 0.98105398 0.9758734\n",
      "  0.9793259  0.97759904 0.98449898 0.98105398 0.9793259  0.98277257\n",
      "  0.98105398 0.97759904 0.97414898 0.9793259  0.9793259  0.98277257\n",
      "  0.9810474  0.97759904 0.97932346 0.97242576 0.97072194 0.9810474\n",
      "  0.97759904 0.97414898 0.9810474  0.97759904 0.97070373 0.97760075\n",
      "  0.97932346 0.9758734  0.97414898 0.9758734  0.97414898 0.97415895\n",
      "  0.97932346 0.97415895 0.97932346 0.9758734  0.97414898 0.97242576\n",
      "  0.97242576 0.97760075 0.97587925 0.97760075 0.97243985 0.96898288\n",
      "  0.96898288 0.9552576  0.97070373 0.97243985 0.96726321 0.97418066\n",
      "  0.9655447  0.9690393  0.96214984 0.96211115 0.96209253 0.9690052\n",
      "  0.96386196 0.9690393  0.95885832]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98622665 1.\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 1.         0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99827898 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99827898 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99484084 0.99139248 0.99312369 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99484084 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.99312369 0.98452462 0.99312369 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.99140781 0.98626773 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98455684\n",
      "  0.97938669 0.97596745 0.97255295 0.96557522 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.96581609]\n",
      " [0.98276932 0.97768692 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  1.         0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99310667 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.99139942 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97423392 0.96032556 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96400057]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97944705 0.97083031 0.98969558 0.98283617 0.98282326 0.979414\n",
      "  0.96772069 0.97440325 0.98797882 0.9742979  0.97599379 0.98969558\n",
      "  0.98454913 0.99656649 0.98454913 0.98797882 0.96753692 0.98969558\n",
      "  0.98285438 0.98969558 0.97938526 0.98626334 0.98797849 0.98797882\n",
      "  0.98969558 0.98969558 0.9708028  0.98969558 0.97766356 0.98797882\n",
      "  0.98626334 0.98969558 1.         0.98969558 0.98969558 0.98797882\n",
      "  0.98969558 0.98969558 0.98283243 0.98969558 0.98626334 0.98626334\n",
      "  0.98969558 0.98969558 0.98969558 0.98797882 0.98969558 0.98454913\n",
      "  0.98626334 0.98797882 0.98969558 0.98797882 0.98626334 0.99141724\n",
      "  0.98969558 0.98969558 0.98969558 0.98969558 0.98797882 0.98969558\n",
      "  0.98969558 0.98797882 0.98969558 0.98969558 0.98797882 0.98797882\n",
      "  0.98797882 0.98969558 0.98969558 0.98797882 0.98969558 0.98969558\n",
      "  0.98969558 0.98969558 0.98797882 0.979414   0.98969558 0.98797882\n",
      "  0.98969558 0.98797882 0.98626334 0.98797882 0.98797882 0.98969558\n",
      "  0.98797882 0.98626334 0.98797882 0.98969558 0.98282203 0.98626334\n",
      "  0.98969558 0.98969558 0.98970342 0.98797882 0.98969558 0.98969558\n",
      "  0.98797882 0.98797882 0.98969558 0.98969558 0.98969558 0.98283617\n",
      "  0.98626334 0.98969558 0.98969558 0.98626334 0.98797882 0.98454913\n",
      "  0.98797882 0.98454913 0.98969558 0.98969558 0.98626334 0.98797882\n",
      "  0.98797882 0.98626334 0.98797882 0.98969558 0.98626334 0.98454913\n",
      "  0.98112447 0.98454913 0.98797882 0.98454913 0.98454913 0.98969558\n",
      "  0.98283617 0.98283617 0.98626334 0.98454913 0.98454913 0.98797882\n",
      "  0.98112447 0.98797882 0.98797882 0.98626334 0.98797882 0.98454913\n",
      "  0.98799088 0.98626334 0.98797882 0.98797882 0.98283617 0.98454913\n",
      "  0.98797882 0.98626334 0.98626334 0.97766562 0.98626334 0.98112447\n",
      "  0.98454913 0.98283617 0.98626334 0.98626334 0.98454913 0.98799088\n",
      "  0.98626334 0.98283617 0.979414   0.98454913 0.98454913 0.98799088\n",
      "  0.98283617 0.98283617 0.98112447 0.98115333 0.97603817 0.98627961\n",
      "  0.98283617 0.979414   0.98283617 0.98283617 0.97599676 0.979414\n",
      "  0.98112447 0.98112447 0.979414   0.98112447 0.979414   0.97599676\n",
      "  0.98112447 0.97599676 0.98112447 0.98112447 0.979414   0.97770477\n",
      "  0.97770477 0.979414   0.98115333 0.979414   0.97428997 0.977742\n",
      "  0.97428997 0.9606782  0.97599676 0.977742   0.97258438 0.97603817\n",
      "  0.97087998 0.97093387 0.96407417 0.95709735 0.96045685 0.97087998\n",
      "  0.96577388 0.97093387 0.95737369]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.9810694  0.96565555 0.98795557 0.9810474  0.98105398 0.97760075\n",
      "  0.96607386 0.97272795 0.98622665 0.97258416 0.97427285 0.98795557\n",
      "  0.98621924 0.99141724 0.98277257 0.98622665 0.96908525 0.98795557\n",
      "  0.98114326 0.98795557 0.97418882 0.98449898 0.98624572 0.98622665\n",
      "  0.98795557 0.98795557 0.96904547 0.98795557 0.9724533  0.98622665\n",
      "  0.98449898 0.98795557 0.98797882 0.98795557 0.98795557 1.\n",
      "  0.98795557 0.98795557 0.98110198 0.98795557 0.98449898 0.98449898\n",
      "  0.98795557 0.98795557 0.98795557 0.98622665 0.98795557 0.98277257\n",
      "  0.98449898 0.98622665 0.98795557 0.98622665 0.98449898 0.98622665\n",
      "  0.98795557 0.98795557 0.98795557 0.98795557 0.98622665 0.98795557\n",
      "  0.98795557 0.98622665 0.98795557 0.98795557 0.98622665 0.98622665\n",
      "  0.98622665 0.98795557 0.98795557 0.98622665 0.98795557 0.98795557\n",
      "  0.98795557 0.98795557 0.98622665 0.98105251 0.98795557 0.98622665\n",
      "  0.98795557 0.98622665 0.98449898 0.98966999 0.98622665 0.98795557\n",
      "  0.98622665 0.98449898 0.98622665 0.98795557 0.9810722  0.98449898\n",
      "  0.98795557 0.98795557 0.98449898 0.98622665 0.98795557 0.98795557\n",
      "  0.98622665 0.98622665 0.98795557 0.98795557 0.98795557 0.9810474\n",
      "  0.98449898 0.98795557 0.98795557 0.98449898 0.98622665 0.98277257\n",
      "  0.98622665 0.98621924 0.98795557 0.98795557 0.98449898 0.98622665\n",
      "  0.98622665 0.98449898 0.98622665 0.98795557 0.98449898 0.98621924\n",
      "  0.97932346 0.98277257 0.98966999 0.98277257 0.98621924 0.98795557\n",
      "  0.9810474  0.9810474  0.98794398 0.98621924 0.98621924 0.98622665\n",
      "  0.97932346 0.98622665 0.98622665 0.98449898 0.98622665 0.98277257\n",
      "  0.98621924 0.98794398 0.98622665 0.98622665 0.9810474  0.98277257\n",
      "  0.98622665 0.98449898 0.98449898 0.9793259  0.98794398 0.97932346\n",
      "  0.98277257 0.9810474  0.98449898 0.98449898 0.98621924 0.98277257\n",
      "  0.98449898 0.9810474  0.98105251 0.98277257 0.98277257 0.98277257\n",
      "  0.9810474  0.9810474  0.97932346 0.97587925 0.97072194 0.9810474\n",
      "  0.9810474  0.97760075 0.9810474  0.9810474  0.97415895 0.97760075\n",
      "  0.98622358 0.97932346 0.98105251 0.98277352 0.97760075 0.97415895\n",
      "  0.97932346 0.97761417 0.98277352 0.97932346 0.97760075 0.98278622\n",
      "  0.97933273 0.97760075 0.97587925 0.97760075 0.97243985 0.97935379\n",
      "  0.97243985 0.95872898 0.97761417 0.97243985 0.97418066 0.97418066\n",
      "  0.9724657  0.9690393  0.97255295 0.95171892 0.95864585 0.9690052\n",
      "  0.96386196 0.9690393  0.95190054]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97944705 0.97083031 0.99313236 0.98627961 0.98626334 0.98286084\n",
      "  0.96772069 0.97782571 0.99141724 0.97772661 0.97942408 0.99313236\n",
      "  0.98799088 0.98626594 0.98799088 0.99141724 0.96753692 0.99313236\n",
      "  0.98628468 0.99313236 0.97938526 0.98970342 0.99141363 0.99141724\n",
      "  0.99313236 0.99313236 0.97423794 0.99313236 0.97766356 0.99141724\n",
      "  0.98970342 0.99313236 0.98283243 0.99313236 0.99313236 0.98110198\n",
      "  0.99313236 0.99313236 1.         0.99313236 0.98970342 0.98970342\n",
      "  0.99313236 0.99313236 0.99313236 0.99141724 0.99313236 0.98799088\n",
      "  0.98970342 0.99141724 0.99313236 0.99141724 0.98970342 0.99141724\n",
      "  0.99313236 0.99313236 0.99313236 0.99313236 0.99141724 0.99313236\n",
      "  0.99313236 0.99141724 0.99313236 0.99313236 0.99141724 0.99141724\n",
      "  0.99141724 0.99313236 0.99313236 0.99141724 0.99313236 0.99313236\n",
      "  0.99313236 0.99313236 0.99141724 0.98286084 0.99313236 0.99141724\n",
      "  0.99313236 0.99141724 0.98970342 0.99141724 0.99141724 0.99313236\n",
      "  0.99141724 0.98970342 0.99141724 0.99313236 0.98625881 0.98970342\n",
      "  0.99313236 0.99313236 0.98970342 0.99141724 0.99313236 0.99313236\n",
      "  0.99141724 0.99141724 0.99313236 0.99313236 0.99313236 0.98627961\n",
      "  0.98970342 0.99313236 0.99313236 0.98970342 0.99141724 0.98799088\n",
      "  0.99141724 0.98799088 0.99313236 0.99313236 0.98970342 0.99141724\n",
      "  0.99141724 0.98970342 0.99141724 0.99313236 0.98970342 0.98799088\n",
      "  0.9845696  0.98799088 0.99141724 0.98799088 0.98799088 0.99313236\n",
      "  0.98627961 0.98627961 0.98970342 0.98799088 0.98799088 0.99141724\n",
      "  0.9845696  0.99141724 0.99141724 0.98970342 0.99141724 0.98799088\n",
      "  0.98799088 0.98970342 0.99141724 0.99141724 0.98627961 0.98799088\n",
      "  0.99141724 0.98970342 0.98970342 0.98110737 0.98970342 0.9845696\n",
      "  0.98799088 0.98627961 0.98970342 0.98970342 0.98799088 0.98799088\n",
      "  0.98970342 0.98627961 0.98286084 0.98799088 0.98799088 0.98799088\n",
      "  0.98627961 0.98627961 0.9845696  0.98115333 0.97603817 0.98627961\n",
      "  0.98627961 0.98286084 0.98627961 0.98627961 0.97944705 0.98286084\n",
      "  0.9845696  0.9845696  0.98286084 0.9845696  0.98286084 0.97944705\n",
      "  0.9845696  0.97944705 0.9845696  0.9845696  0.98286084 0.98115333\n",
      "  0.98115333 0.98286084 0.98115333 0.98286084 0.977742   0.977742\n",
      "  0.977742   0.96414463 0.97944705 0.977742   0.97603817 0.97603817\n",
      "  0.97433554 0.97093387 0.96753692 0.95709735 0.9638986  0.97433554\n",
      "  0.96923481 0.97093387 0.95737369]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98622621 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99827898 0.98461357 0.98974257 0.99656258\n",
      "  0.99827732 0.98970342 0.99138064 0.99827898 0.97423392 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 1.         0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  1.         0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.99311699 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99655334 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99827898 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99482898 0.99138064 0.99656258\n",
      "  0.9931059  0.98965588 0.99310667 0.99827732 0.99138064 0.99483398\n",
      "  0.9913841  0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99827898 0.98965588 0.99482898\n",
      "  0.99483398 0.99655334 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99310667 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99827732 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.99311699 0.98965588 0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98622621 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.99311699 0.99139942 0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98622621 0.9845094  0.98279381 0.97933341\n",
      "  0.98107943 0.97418855 0.97423392 0.96032556 0.96724228 0.98107943\n",
      "  0.97941107 0.9776543  0.96400057]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98967588 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98449898 0.99827898\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 1.\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99827898 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 1.         0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99655334 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.9931059  0.98965588 0.9913841  0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.9931059  0.98965588 0.98276932 0.99311699\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.9913841  0.98276932 0.9913841  0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98966355 0.9845094  0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.98279381\n",
      "  0.97761727 0.97418855 0.97423392 0.96379131 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96400057]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 1.\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.98792054 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.98619236 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98101524 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98446543 0.98273973 0.98446543 0.97929197 0.97929197\n",
      "  0.97929197 0.96554834 0.98101524 0.97929197 0.97756991 0.97756991\n",
      "  0.97584903 0.97241083 0.96897729 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97241083 0.95870391]\n",
      " [0.98622621 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99827898 0.98461357 0.98974257 0.99656258\n",
      "  0.99827732 0.98970342 0.99138064 0.99827898 0.97423392 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 1.         0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  1.         0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.99311699 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99655334 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99827898 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99482898 0.99138064 0.99656258\n",
      "  0.9931059  0.98965588 0.99310667 0.99827732 0.99138064 0.99483398\n",
      "  0.9913841  0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99827898 0.98965588 0.99482898\n",
      "  0.99483398 0.99655334 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99310667 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99827732 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.99311699 0.98965588 0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98622621 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.99311699 0.99139942 0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98622621 0.9845094  0.98279381 0.97933341\n",
      "  0.98107943 0.97418855 0.97423392 0.96032556 0.96724228 0.98107943\n",
      "  0.97941107 0.9776543  0.96400057]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 1.         0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 1.         0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99484084 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.99140781 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.99312369 0.98795605 0.98623971\n",
      "  0.9896932  0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98626773 0.98455684 0.98455684\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.99310667 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99655334 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 1.         0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99655334 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.9931059\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99827898 0.99138064\n",
      "  0.99482898 0.99310667 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98966355 0.99138064 0.99138064 0.99482898\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98622621 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.9844891  0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.97081822 0.98276932 0.98105076 0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97076454 0.96379131 0.97069062 0.97761727\n",
      "  0.97594352 0.98112005 0.96400057]\n",
      " [0.98797984 0.97940278 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99485567 0.99311259 0.99655666 0.97602065 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98622665 0.99655666\n",
      "  0.99483398 0.99828064 0.99141724 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 1.\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99827898 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99655927 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99655927\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99655927\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98455684 0.99484084\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.9896932  0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98626773 0.98109812 0.98455684\n",
      "  0.97938669 0.97943152 0.97255295 0.96557522 0.96898587 0.97938669\n",
      "  0.97425961 0.97943152 0.96581609]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 1.         0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98797984 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98797984 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  1.         0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96557522 0.96898587 0.98284719\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98622665 1.\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 1.         0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99827898 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99827898 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99484084 0.99139248 0.99312369 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99484084 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.99312369 0.98452462 0.99312369 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.99140781 0.98626773 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98455684\n",
      "  0.97938669 0.97596745 0.97255295 0.96557522 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.96581609]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 1.         0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 1.         0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99484084 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.99140781 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.99312369 0.98795605 0.98623971\n",
      "  0.9896932  0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98626773 0.98455684 0.98455684\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.97922391 0.96739058 0.98970322 0.98272197 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.99140781 0.97780607 0.98293015 0.98970322\n",
      "  0.99137565 0.98286084 0.98446543 0.99140781 0.96709852 0.98970322\n",
      "  0.98293015 0.98970322 0.97935289 0.98621012 0.98800319 0.99140781\n",
      "  0.98970322 0.98970322 0.97420931 0.98970322 0.97414898 0.98795605\n",
      "  0.98966355 0.98970322 0.979414   0.98970322 0.98970322 0.98105251\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.99311699 0.98966355\n",
      "  0.98970322 0.98970322 0.98970322 0.99140781 0.98970322 0.98446543\n",
      "  0.99311699 0.99140781 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.99140781 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.99140781 0.99140781\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 1.         0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98966355 0.99140781 0.99140781 0.98970322\n",
      "  0.98795605 0.98966355 0.98795605 0.98970322 0.98625311 0.98966355\n",
      "  0.98970322 0.98970322 0.98621012 0.99140781 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98966355 0.98970322 0.98970322 0.98621012 0.99140781 0.98446543\n",
      "  0.99140781 0.98446543 0.98970322 0.98970322 0.98621012 0.99140781\n",
      "  0.99140781 0.98966355 0.99140781 0.98970322 0.98621012 0.98446543\n",
      "  0.98097973 0.98446543 0.99140781 0.98792054 0.98446543 0.98970322\n",
      "  0.98617877 0.98272197 0.98621012 0.99137565 0.98446543 0.98795605\n",
      "  0.98443823 0.99140781 0.99140781 0.98966355 0.98795605 0.98446543\n",
      "  0.98446543 0.98621012 0.99140781 0.99140781 0.98617877 0.98792054\n",
      "  0.98795605 0.98966355 0.98966355 0.98101032 0.98966355 0.98443823\n",
      "  0.98446543 0.98617877 0.98966355 0.98966355 0.98446543 0.98792054\n",
      "  0.98621012 0.98617877 0.98269891 0.98792054 0.99137565 0.98446543\n",
      "  0.98617877 0.98272197 0.98097973 0.98096081 0.97228649 0.98617877\n",
      "  0.98272197 0.98615913 0.98272197 0.98272197 0.97576023 0.98269891\n",
      "  0.98097973 0.98097973 0.9792387  0.98443823 0.9792387  0.97576023\n",
      "  0.98097973 0.97922391 0.98097973 0.98097973 0.98269891 0.97749887\n",
      "  0.97749887 0.98615913 0.98442275 0.9792387  0.97402277 0.98095364\n",
      "  0.97748821 0.96016455 0.97922391 0.97748821 0.97922088 0.97228649\n",
      "  0.97402034 0.97055714 0.97057472 0.95319436 0.96027965 0.97402034\n",
      "  0.97230163 0.97055714 0.95674947]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 1.\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 1.         0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99655927 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98455684 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98797984 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96557522 0.96898587 0.98284719\n",
      "  0.97425961 0.97596745 0.96581609]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99482898 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 1.         0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99310667 1.         0.99138064 0.99482898\n",
      "  0.99310667 0.99655593 0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.9931059  0.98965588 0.98793237 0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.99311699\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.9845094  0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97423392 0.96032556 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96052001]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98966999\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 1.         0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 1.         0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98966592 0.99827898 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.99140781 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.99312369 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98626773\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98455684 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  1.         0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97943152 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98622621 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99827898 0.9811783  0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99483398 0.97423392 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99655334 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 1.         0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99827898 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99655334 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99482898 0.99138064 0.99656258\n",
      "  0.9931059  0.98965588 0.99310667 0.99482898 0.99138064 0.99827898\n",
      "  0.9913841  0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99827898 0.98965588 0.99138064\n",
      "  0.99483398 0.99655334 0.99310667 0.98448397 0.99655334 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99482898 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98622621 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.96734516 0.98622621 0.98105076 0.98279381 0.97933341\n",
      "  0.98107943 0.97418855 0.97076454 0.96032556 0.96724228 0.98107943\n",
      "  0.97594352 0.9776543  0.96400057]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 1.         0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97937401 0.97081441 0.99311992 0.98623693 0.98623253 0.982803\n",
      "  0.96776035 0.97785166 0.99139726 0.98116099 0.98285579 0.99311992\n",
      "  0.9914008  0.98625881 0.98795577 0.99483895 0.96741044 0.99311992\n",
      "  0.98628935 0.99311992 0.98279981 0.98967588 0.99140548 0.99483895\n",
      "  0.99311992 0.99311992 0.97765187 0.99311992 0.97763051 0.99139726\n",
      "  0.99311923 0.99311992 0.98282203 0.99311992 0.99311992 0.9810722\n",
      "  0.99311992 0.99311992 0.98625881 0.99311992 0.99311923 0.99311923\n",
      "  0.99311992 0.99311992 0.99311992 0.99483895 0.99311992 0.98795577\n",
      "  0.99311923 0.99483895 0.99311992 0.99139726 0.98967588 0.99139726\n",
      "  0.99311992 0.99311992 0.99311992 0.99311992 0.99483895 0.99311992\n",
      "  0.99311992 0.99139726 0.99311992 0.99311992 0.99483895 0.99483895\n",
      "  0.99139726 0.99311992 0.99311992 0.99139726 0.99311992 0.99311992\n",
      "  0.99311992 0.99311992 0.99139726 0.98625311 0.99311992 0.99139726\n",
      "  0.99311992 0.99139726 0.99311923 0.99139726 0.99483895 0.99311992\n",
      "  0.99139726 0.98967588 0.99139726 0.99311992 1.         0.99311923\n",
      "  0.99311992 0.99311992 0.98967588 0.99483895 0.99311992 0.99311992\n",
      "  0.99139726 0.99139726 0.99311992 0.99311992 0.99311992 0.98623693\n",
      "  0.99311923 0.99311992 0.99311992 0.98967588 0.99139726 0.98795577\n",
      "  0.99483895 0.98795577 0.99311992 0.99311992 0.98967588 0.99483895\n",
      "  0.99483895 0.99311923 0.99483895 0.99311992 0.98967588 0.98795577\n",
      "  0.98451934 0.98795577 0.99139726 0.98795577 0.98795577 0.99311992\n",
      "  0.98623693 0.98623693 0.98967588 0.9914008  0.98795577 0.99139726\n",
      "  0.98451934 0.99483895 0.99483895 0.99311923 0.99139726 0.98795577\n",
      "  0.98795577 0.98967588 0.99483895 0.99139726 0.98623693 0.9914008\n",
      "  0.99139726 0.98967588 0.99311923 0.98106573 0.98967588 0.98796775\n",
      "  0.98795577 0.98968364 0.98967588 0.99311923 0.98795577 0.9914008\n",
      "  0.98967588 0.98968364 0.98625311 0.9914008  0.9914008  0.98795577\n",
      "  0.98623693 0.98623693 0.98451934 0.98453973 0.97594989 0.98968364\n",
      "  0.98623693 0.98625311 0.98623693 0.98623693 0.97937401 0.98625311\n",
      "  0.98451934 0.98451934 0.982803   0.98451934 0.982803   0.97937401\n",
      "  0.98451934 0.97937401 0.98451934 0.98451934 0.982803   0.98108789\n",
      "  0.98108789 0.98625311 0.98453973 0.982803   0.97766135 0.98111666\n",
      "  0.98111666 0.96400279 0.97937401 0.98111666 0.97594989 0.97940696\n",
      "  0.97423964 0.97082269 0.97087648 0.95697303 0.96384062 0.97423964\n",
      "  0.9725802  0.97082269 0.95720106]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 1.\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99482898 0.99483398 0.99482898 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99482898\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.99655593 0.99310667 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.9913841  0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.98279381\n",
      "  0.97761727 0.97418855 0.97770329 0.96032556 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96052001]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98622621 0.97768692 0.99656258 0.98965588 0.99310667 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.9931435  0.99138064 0.99483398 0.97423392 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99655334 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98449898 0.99483398\n",
      "  0.99310667 0.99656258 0.98970342 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99655334 0.99827898\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 1.         0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.9931059\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99827898 0.99138064\n",
      "  0.99482898 0.99310667 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99482898\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99827732\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.98279381 0.9931059\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.98794426 0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.96734516 0.98276932 0.9845094  0.97933341 0.98279381\n",
      "  0.97761727 0.9776543  0.97076454 0.96725706 0.97069062 0.97761727\n",
      "  0.97594352 0.98112005 0.96748114]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  1.         0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99827898 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96557522 0.97243255 0.97938669\n",
      "  0.97772549 0.97943152 0.96581609]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 1.         0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97943152 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.9931059  0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.99655593 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97419909 0.99313035 0.9810474  0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.9931059  0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98272197 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.9931059  0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 1.\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98445359 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.98618644 0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99484084 0.98792054\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.98618644 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98101714 0.98965588 0.98445359\n",
      "  0.98792054 0.98618644 0.98965588 0.98965588 0.98792054 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.98792054 0.99137224\n",
      "  0.98618644 0.98618644 0.98445359 0.98099157 0.97580759 0.98618644\n",
      "  0.98618644 0.98272197 0.98618644 0.98618644 0.97926237 0.98272197\n",
      "  0.98790868 0.98445359 0.98272197 0.98445359 0.98272197 0.97926237\n",
      "  0.98445359 0.97926237 0.98445359 0.98445359 0.98272197 0.98099157\n",
      "  0.98099157 0.98272197 0.98099157 0.98272197 0.97753439 0.97753439\n",
      "  0.97753439 0.96375263 0.97926237 0.97753439 0.97580759 0.97927136\n",
      "  0.97408198 0.97063426 0.96719117 0.97063426 0.97756544 0.98447861\n",
      "  0.98279589 0.98451077 0.97082473]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  1.         0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.99483582\n",
      "  0.99138064 0.9931059  0.99310667 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97423392 0.96379131 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96052001]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 1.         0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99827732 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99655334 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99827898 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.9896831  0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.98794426 0.98966355 0.9844891  0.98621012 0.98105076 0.9845094\n",
      "  0.98796803 0.96734516 0.98622621 0.98105076 0.97933341 0.98279381\n",
      "  0.9845416  0.97418855 0.97076454 0.96032556 0.96724228 0.97761727\n",
      "  0.97247596 0.97418855 0.96400057]\n",
      " [0.98797984 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 1.         0.98288499 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 0.99655666 0.97602065 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99827898 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99827898 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 1.         0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99655927 0.99311259 0.99828064\n",
      "  0.99484084 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.99312369 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 1.         0.99139248 0.99311259\n",
      "  0.99655666 0.99827898 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98797984 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98797984 0.98281076 0.98455684 0.98109812\n",
      "  0.98284719 0.97596745 0.97255295 0.96211115 0.96898587 0.98284719\n",
      "  0.97772549 0.97943152 0.96581609]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 1.\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.99137224 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98964576 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99311259 0.99311259 0.99137224 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98964576\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.99309997 0.98964996\n",
      "  0.99482898 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98964576 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98964576 0.98101524 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98446543 0.98273973 0.98446543 0.97929197 0.97929197\n",
      "  0.98275229 0.96902308 0.98101524 0.97929197 0.98103198 0.97756991\n",
      "  0.97931288 0.97241083 0.96897729 0.96200853 0.96549987 0.97931288\n",
      "  0.97069348 0.97241083 0.96566842]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.99309997 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 1.         0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.99309997\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.99309997 0.99484582\n",
      "  0.98792054 0.98792054 0.99482898 0.99309997 0.99309997 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.99309997 0.99482898 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.99137224 0.98792054 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98792054 0.98101524\n",
      "  0.98619236 0.98447381 0.98964576 0.98619236 0.98446543 0.98619656\n",
      "  0.98619656 0.98446543 0.98273973 0.98446543 0.97929197 0.97929197\n",
      "  0.98275229 0.96554834 0.98101524 0.97929197 0.98103198 0.97756991\n",
      "  0.97584903 0.97934569 0.97591941 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97587826 0.95870391]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98276932 0.97768692 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99827898 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 1.         0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.98794426 0.97933341 0.98965588\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.9844891  0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.96734516 0.98276932 0.98105076 0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97076454 0.96725706 0.97069062 0.98107943\n",
      "  0.97941107 0.9776543  0.96400057]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98967588 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98449898 0.99827898\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 1.\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99827898 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 1.         0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99655334 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.9931059  0.98965588 0.9913841  0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.9931059  0.98965588 0.98276932 0.99311699\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.9913841  0.98276932 0.9913841  0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98966355 0.9845094  0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.98279381\n",
      "  0.97761727 0.97418855 0.97423392 0.96379131 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96400057]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99655334 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 1.         0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99827898\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99655334 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99138064\n",
      "  0.98965588 0.9931059  0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.9844891  0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.96734516 0.98276932 0.98105076 0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97423392 0.96032556 0.96724228 0.97761727\n",
      "  0.97247596 0.97418855 0.96052001]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.99309997 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.99309997 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 1.\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.99654999 0.99484582\n",
      "  0.98792054 0.98792054 0.99482898 0.99309997 0.99309997 0.99311259\n",
      "  0.98964576 0.99311259 0.99311259 0.99138064 0.99311259 0.99309997\n",
      "  0.99309997 0.99482898 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98964576\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98447381 0.98964576 0.98619236 0.98446543 0.98273973\n",
      "  0.98619656 0.98446543 0.98273973 0.98446543 0.97929197 0.97929197\n",
      "  0.97929197 0.96902308 0.98101524 0.97929197 0.97756991 0.97756991\n",
      "  0.97931288 0.97934569 0.97591941 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97587826 0.95870391]\n",
      " [0.97751071 0.96910323 0.99141615 0.98445359 0.98448065 0.98789673\n",
      "  0.96619616 0.97625055 0.98967363 0.97606575 0.97774754 0.99141615\n",
      "  0.98619236 0.9845696  0.98619236 0.98967363 0.97235513 0.99141615\n",
      "  0.98463136 0.99141615 0.97762253 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97592612 0.99141615 0.9758734  0.98967363\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.97932346\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.98793237\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.98967363 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98097973 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98619236\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98793237 0.98619236\n",
      "  1.         0.98964576 0.98967363 0.98619236 0.98619236 0.99141615\n",
      "  0.98790868 0.99136377 0.98793237 0.98619236 0.98619236 0.98967363\n",
      "  0.98271605 0.98967363 0.98967363 0.98793237 0.98967363 0.98619236\n",
      "  0.98619236 0.98793237 0.98967363 0.98967363 0.98445359 0.98619236\n",
      "  0.98967363 0.98793237 0.98793237 0.98273896 0.98793237 0.98271605\n",
      "  0.98619236 0.99136377 0.98793237 0.98793237 0.98619236 0.98619236\n",
      "  0.98793237 0.98445359 0.98097973 0.98619236 0.98619236 0.98619236\n",
      "  0.98445359 0.98790868 0.98271605 0.97924462 0.97404645 0.98445359\n",
      "  0.98790868 0.98097973 0.98445359 0.98790868 0.98443464 0.98097973\n",
      "  0.98271605 0.98271605 0.98097973 0.98271605 0.98097973 0.97751071\n",
      "  0.98271605 0.97751071 0.98617284 0.98962963 0.98443823 0.98270484\n",
      "  0.97924462 0.98097973 0.97924462 0.98443823 0.97577799 0.97577799\n",
      "  0.97577799 0.96195804 0.98097267 0.9792417  0.97404645 0.97751193\n",
      "  0.97925059 0.96885885 0.96540619 0.95497551 0.96201856 0.97231609\n",
      "  0.96713195 0.96885885 0.95507495]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98792054\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.98799088 0.98964996 0.99311259 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98964576 1.         0.99311259 0.99309997 0.98964996 0.99484582\n",
      "  0.98792054 0.99137224 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.99309997\n",
      "  0.98964996 0.99138064 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.99482394 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.99137224 0.98447381 0.98446543\n",
      "  0.98619236 0.98619236 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98101524 0.98619236 0.99309916 0.98446543 0.98619656\n",
      "  0.98273973 0.98446543 0.98273973 0.98446543 0.97929197 0.97929197\n",
      "  0.97929197 0.96554834 0.98793238 0.97929197 0.97756991 0.98103198\n",
      "  0.97931288 0.97241083 0.97591941 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97241083 0.95870391]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98966999\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 1.         0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 1.         0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98966592 0.99827898 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.99140781 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.99312369 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98626773\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98455684 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98447381 0.97253216 0.99484582 0.99137224 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99655927 0.97947287 0.98459902 0.99484582\n",
      "  0.99309997 0.98799088 0.98964996 0.99311259 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99482898 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99482898 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98792054 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99482898 0.99311259 0.99484582 0.98795577 0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99655927 0.98964996\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.99309997 0.99311259 1.         0.98964996 0.99484582\n",
      "  0.99137224 0.98792054 0.99482898 0.99309997 0.98964996 0.99311259\n",
      "  0.98964576 0.99311259 0.99311259 0.99138064 0.99311259 0.99309997\n",
      "  0.98964996 0.99138064 0.99311259 0.99655927 0.98792054 0.98964996\n",
      "  0.99311259 0.99482898 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.99137224 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.99309997 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98792054 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98446543 0.98447381\n",
      "  0.98619236 0.98793238 0.98619236 0.98964576 0.98446543 0.98273973\n",
      "  0.98273973 0.99137565 0.98619656 0.98446543 0.97929197 0.97929197\n",
      "  0.98275229 0.96554834 0.98447381 0.97929197 0.98103198 0.98103198\n",
      "  0.97931288 0.97241083 0.97244835 0.9585411  0.96894988 0.97931288\n",
      "  0.97416272 0.97587826 0.96218617]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.99309997 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.99309997 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.99654999\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 1.         0.99484582\n",
      "  0.98792054 0.98792054 0.99482898 0.99309997 0.99309997 0.99311259\n",
      "  0.98964576 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.99309997 0.99482898 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98619995 0.99138064 0.98619236\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.98964996 0.99309997\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.98619236 0.99137565 0.98619236 0.98446543 0.98101524\n",
      "  0.98964576 0.98447381 0.98964576 0.98619236 0.98446543 0.98619656\n",
      "  0.98273973 0.98446543 0.98273973 0.98446543 0.97929197 0.98275229\n",
      "  0.97929197 0.96554834 0.98101524 0.97929197 0.98103198 0.97756991\n",
      "  0.97584903 0.98281312 0.97591941 0.9585411  0.96549987 0.97931288\n",
      "  0.97416272 0.97587826 0.96218617]\n",
      " [0.98628114 0.97768473 1.         0.99313035 0.99311923 0.98970322\n",
      "  0.97459965 0.98470309 0.99828064 0.98459296 0.98628935 1.\n",
      "  0.99484582 0.99313236 0.99484582 0.99828064 0.97434252 1.\n",
      "  0.99315646 1.         0.98623985 0.99656258 0.99828228 0.99828064\n",
      "  1.         1.         0.98109028 1.         0.98451389 0.99828064\n",
      "  0.99656258 1.         0.98969558 1.         1.         0.98795557\n",
      "  1.         1.         0.99313236 1.         0.99656258 0.99656258\n",
      "  1.         1.         1.         0.99828064 1.         0.99484582\n",
      "  0.99656258 0.99828064 1.         0.99828064 0.99656258 0.99828064\n",
      "  1.         1.         1.         1.         0.99828064 1.\n",
      "  1.         0.99828064 1.         1.         0.99828064 0.99828064\n",
      "  0.99828064 1.         1.         0.99828064 1.         1.\n",
      "  1.         1.         0.99828064 0.98970322 1.         0.99828064\n",
      "  1.         0.99828064 0.99656258 0.99828064 0.99828064 1.\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99311992 0.99656258\n",
      "  1.         1.         0.99656258 0.99828064 1.         1.\n",
      "  0.99828064 0.99828064 1.         1.         1.         0.99313035\n",
      "  0.99656258 1.         1.         0.99656258 0.99828064 0.99484582\n",
      "  0.99828064 0.99484582 1.         1.         0.99656258 0.99828064\n",
      "  0.99828064 0.99656258 0.99828064 1.         0.99656258 0.99484582\n",
      "  0.99141615 0.99484582 0.99828064 0.99484582 0.99484582 1.\n",
      "  0.99313035 0.99313035 0.99656258 0.99484582 0.99484582 0.99828064\n",
      "  0.99141615 0.99828064 0.99828064 0.99656258 0.99828064 0.99484582\n",
      "  0.99484582 0.99656258 0.99828064 0.99828064 0.99313035 0.99484582\n",
      "  0.99828064 0.99656258 0.99656258 0.98795577 0.99656258 0.99141615\n",
      "  0.99484582 0.99313035 0.99656258 0.99656258 0.99484582 0.99484582\n",
      "  0.99656258 0.99313035 0.98970322 0.99484582 0.99484582 0.99484582\n",
      "  0.99313035 0.99313035 0.99141615 0.98799156 0.98286403 0.99313035\n",
      "  0.99313035 0.98970322 0.99313035 0.99313035 0.98628114 0.98970322\n",
      "  0.99141615 0.99141615 0.98970322 0.99141615 0.98970322 0.98628114\n",
      "  0.99141615 0.98628114 0.99141615 0.99141615 0.98970322 0.98799156\n",
      "  0.98799156 0.98970322 0.98799156 0.98970322 0.98457197 0.98457197\n",
      "  0.98457197 0.97094222 0.98628114 0.98457197 0.98286403 0.98286403\n",
      "  0.98115732 0.97774752 0.97434252 0.96389786 0.97073066 0.98115732\n",
      "  0.97604443 0.97774752 0.9641555 ]\n",
      " [0.9861829  0.97081709 0.99313035 0.98618644 0.98620585 0.98272197\n",
      "  0.96787436 0.97793852 0.99484084 0.97776869 0.98289361 0.99313035\n",
      "  0.99137224 0.98627961 0.98792054 0.99139248 0.97413669 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97419909 0.99313035 0.97759904 0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.9931059  0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.9931059  0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98617877 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.9931059  0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99484084 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98790868 0.98792054 0.99139248 0.99137224 0.98792054 0.99313035\n",
      "  1.         0.98618644 0.98965588 0.99137224 0.98792054 0.99139248\n",
      "  0.98790868 0.99139248 0.99139248 0.98965588 0.99139248 0.98792054\n",
      "  0.98792054 0.98965588 0.99139248 0.99484084 0.98618644 0.98792054\n",
      "  0.99139248 0.99655593 0.98965588 0.98101714 0.98965588 0.98445359\n",
      "  0.98792054 0.98618644 0.98965588 0.98965588 0.98792054 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.99137224 0.98792054\n",
      "  0.98618644 0.98618644 0.98790868 0.98099157 0.97580759 0.98618644\n",
      "  0.98618644 0.98617877 0.98618644 0.98618644 0.97926237 0.98272197\n",
      "  0.98445359 0.98445359 0.98272197 0.98445359 0.98272197 0.97926237\n",
      "  0.98445359 0.98272264 0.98790868 0.98790868 0.98272197 0.98099157\n",
      "  0.98099157 0.98617877 0.98445009 0.98272197 0.97753439 0.97753439\n",
      "  0.97753439 0.96375263 0.98272264 0.9809964  0.97927136 0.97927136\n",
      "  0.97754752 0.97063426 0.96719117 0.95675776 0.96375863 0.97754752\n",
      "  0.97238308 0.97410339 0.96037285]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98620585 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97764416 0.99313035 0.97759904 0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98272197 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.99137224\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.99136377 0.99137224 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 1.         0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99139248 0.99137224\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.99309322 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98792054 0.98965588 0.98790868\n",
      "  0.98792054 0.99309322 0.98965588 0.98965588 0.99137224 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.98792054 0.98792054\n",
      "  0.98618644 0.98963983 0.98445359 0.98099157 0.97580759 0.98618644\n",
      "  0.99309322 0.98272197 0.98618644 0.98963983 0.98964316 0.98272197\n",
      "  0.98445359 0.98790868 0.98272197 0.98445359 0.98272197 0.97926237\n",
      "  0.99136377 0.97926237 0.98445359 0.98790868 0.98963557 0.98790862\n",
      "  0.98099157 0.98272197 0.98099157 0.98963557 0.97753439 0.97753439\n",
      "  0.97753439 0.96722907 0.9861829  0.97753439 0.97927136 0.97580759\n",
      "  0.98101307 0.97063426 0.96719117 0.95675776 0.96375863 0.97754752\n",
      "  0.96891215 0.97063426 0.96037285]\n",
      " [0.98276932 0.97424845 0.99656258 0.9931059  0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98794398\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99482898 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99482898\n",
      "  0.98793237 0.99138064 0.99483398 0.99482898 0.99482898 0.99656258\n",
      "  0.98965588 0.98965588 1.         0.99482898 0.99482898 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99482898 0.99655334 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.99311699 0.98793237 0.98621012 0.98622621\n",
      "  0.98793237 0.9896831  0.9913841  0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.9844891  0.98621012 0.98105076 0.98105076\n",
      "  0.9845094  0.96734516 0.98276932 0.98105076 0.97933341 0.97933341\n",
      "  0.97761727 0.9776543  0.97423392 0.96032556 0.97069062 0.97761727\n",
      "  0.97247596 0.9776543  0.96052001]\n",
      " [0.98447381 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99655927 0.9829098  0.98803755 0.99484582\n",
      "  1.         0.98799088 0.98964996 0.99655927 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98451075 0.99138064 0.99313695 0.99655927\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.9793259  0.99311259\n",
      "  0.99482898 0.99484582 0.98454913 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99827732 0.99482898\n",
      "  0.99484582 0.99484582 0.99484582 0.99655927 0.99484582 0.98964996\n",
      "  0.99827732 0.99655927 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99655927 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99655927 0.99655927\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.99137565 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99482898 0.99311259 0.99655927 0.99484582\n",
      "  0.99311259 0.99482898 0.99311259 0.99484582 0.9914008  0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99655927 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99482898 0.99484582 0.99484582 0.99138064 0.99655927 0.98964996\n",
      "  0.99655927 0.99309997 0.99484582 0.99484582 0.99138064 0.99655927\n",
      "  0.99655927 0.99482898 0.99655927 0.99484582 0.99138064 0.99309997\n",
      "  0.98619236 0.98964996 0.99311259 0.99309997 0.99309997 0.99484582\n",
      "  0.99137224 0.98792054 0.99482898 1.         0.99309997 0.99311259\n",
      "  0.98964576 0.99655927 0.99655927 0.99482898 0.99311259 0.98964996\n",
      "  0.99309997 0.99482898 0.99655927 0.99655927 0.98792054 0.99309997\n",
      "  0.99311259 0.99482898 0.99482898 0.98274993 0.99138064 0.98964576\n",
      "  0.98964996 0.99137224 0.99138064 0.99482898 0.98964996 0.99309997\n",
      "  0.99138064 0.99137224 0.98446543 0.99309997 0.99654999 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98619656 0.97756991 0.99137224\n",
      "  0.98792054 0.99137565 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98793238 0.98964576 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.99137565 0.98965339 0.98446543 0.97929197 0.98275229\n",
      "  0.98275229 0.96554834 0.98447381 0.98275229 0.98103198 0.97756991\n",
      "  0.97931288 0.97587826 0.97591941 0.9585411  0.96549987 0.97931288\n",
      "  0.97763196 0.97934569 0.96218617]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.99309997 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99827732 0.99311259 0.98964996\n",
      "  0.99311259 0.99309997 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.99309997\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.99309997 0.99484582\n",
      "  0.98792054 0.98792054 0.99482898 0.99309997 1.         0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.99309997 0.99827732 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99655927 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.99139095 0.98964576 0.98619236 0.98446543 0.98273973\n",
      "  0.98619656 0.98792054 0.98273973 0.98446543 0.97929197 0.98275229\n",
      "  0.98621261 0.96554834 0.98447381 0.97929197 0.97756991 0.98103198\n",
      "  0.98277673 0.97587826 0.97244835 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97587826 0.96218617]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99827898 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99827898 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 1.\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99827898 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98097267 0.96910323 0.99141615 0.98445359 0.98448065 0.98097973\n",
      "  0.96619616 0.97625055 0.99312369 0.97606575 0.98118945 0.99141615\n",
      "  0.98964576 0.9845696  0.98619236 0.98967363 0.96888066 0.99141615\n",
      "  0.98463136 0.99141615 0.97762253 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97247936 0.99141615 0.9758734  0.98967363\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.97932346\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.9913841  0.98793237\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.9913841  0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.98967363 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98443823 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.9913841  0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.99312369 0.98964576\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98793237 0.98964576\n",
      "  0.98271605 0.98619236 0.98967363 0.98964576 0.98964576 0.99141615\n",
      "  0.98790868 0.98445359 0.98793237 0.98964576 0.98619236 0.98967363\n",
      "  1.         0.98967363 0.98967363 0.98793237 0.98967363 0.98964576\n",
      "  0.98619236 0.98793237 0.98967363 0.99312369 0.98790868 0.98619236\n",
      "  0.98967363 0.9913841  0.98793237 0.98273896 0.98793237 0.98617284\n",
      "  0.98619236 0.98445359 0.98793237 0.98793237 0.98619236 0.98964576\n",
      "  0.98793237 0.98445359 0.98097973 0.98619236 0.98964576 0.98619236\n",
      "  0.98445359 0.98445359 0.98271605 0.97924462 0.97404645 0.98445359\n",
      "  0.98445359 0.98443823 0.98445359 0.98445359 0.97751071 0.98789673\n",
      "  0.98271605 0.98271605 0.98443823 0.98617284 0.98097973 0.97751071\n",
      "  0.98617284 0.98097267 0.98617284 0.98271605 0.98443823 0.98270484\n",
      "  0.98270484 0.98443823 0.98270484 0.98097973 0.9792417  0.9792417\n",
      "  0.9792417  0.96543619 0.98097267 0.97577799 0.98097741 0.97404645\n",
      "  0.98618509 0.97232969 0.97235513 0.95497551 0.96201856 0.97925059\n",
      "  0.97407725 0.97232969 0.9620463 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98966355\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99827898 0.97423392 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 1.         0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99310667 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.98965588 0.98965588 0.9913841  0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97423392 0.96032556 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96052001]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99483398 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99827898 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99827898 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99827898 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99484084\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99311259 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 1.         0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  0.99655666 0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99655927\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98452462 0.98281076 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97255295 0.96557522 0.97243255 0.97938669\n",
      "  0.97772549 0.97943152 0.96581609]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.99309997\n",
      "  0.98619236 0.99309997 0.99311259 0.99309997 0.98964996 0.99484582\n",
      "  0.98792054 0.99137224 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98964576 0.99311259 0.99311259 0.99138064 0.99311259 1.\n",
      "  0.98964996 0.99138064 0.99311259 0.99311259 0.99137224 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98619995 0.99138064 0.98964576\n",
      "  0.98964996 0.99137224 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.99137224 0.98446543 0.98792054 0.98792054 0.98447381 0.98446543\n",
      "  0.98619236 0.98619236 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98964576 0.98101524 0.98619236 0.98964576 0.98792054 0.98619656\n",
      "  0.98619656 0.98446543 0.98273973 0.98792054 0.97929197 0.97929197\n",
      "  0.97929197 0.96902308 0.98447381 0.97929197 0.97756991 0.98103198\n",
      "  0.97931288 0.97241083 0.97591941 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97241083 0.95870391]\n",
      " [0.98447381 0.9759723  0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.99309997 0.99143263 0.98964996 0.99311259 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98451075 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.98277257 0.99311259\n",
      "  0.99138064 0.99484582 0.98799088 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99482898 0.99655927\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99482898 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.99309997 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.99309997\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.99309997 0.99484582\n",
      "  0.98792054 0.98792054 0.99482898 0.99309997 0.99309997 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  1.         0.99482898 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.98964996 0.99309997\n",
      "  0.99138064 0.98792054 0.98792054 0.98964996 0.98964996 0.99309997\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.98103198 0.99137224\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98447381 0.98446543\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98447381 0.98964576 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98446543 0.98619656 0.98446543 0.97929197 0.97929197\n",
      "  0.97929197 0.96902308 0.98101524 0.98275229 0.97756991 0.98103198\n",
      "  0.97584903 0.97934569 0.97244835 0.96200853 0.96549987 0.97584903\n",
      "  0.97069348 0.98281312 0.96218617]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98794398\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99655334 0.99483398 0.99138064\n",
      "  0.99483398 0.99482898 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99482898\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99482898 0.99656258\n",
      "  0.98965588 0.98965588 0.99655334 0.99482898 0.99827732 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99482898 1.         0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98966355 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.9896831  0.9913841  0.98793237 0.98621012 0.9844891\n",
      "  0.98794426 0.98966355 0.9844891  0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.98105076 0.97933341 0.98279381\n",
      "  0.98107943 0.9776543  0.97423392 0.96032556 0.96724228 0.97761727\n",
      "  0.97247596 0.9776543  0.96400057]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98631861 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 1.         0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98795557 0.99483398 0.99656587 1.\n",
      "  0.99828064 0.99828064 0.98280567 0.99828064 0.98278331 0.99655666\n",
      "  0.99827898 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99827898\n",
      "  0.99828064 0.99828064 0.99828064 1.         0.99828064 0.99311259\n",
      "  0.99827898 1.         0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 1.         0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 1.         1.\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99827898 0.99655666 1.         0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483895 0.99827898\n",
      "  0.99828064 0.99828064 0.99483398 1.         0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99827898 0.99828064 0.99828064 0.99483398 0.99655666 0.99311259\n",
      "  1.         0.99311259 0.99828064 0.99828064 0.99483398 1.\n",
      "  1.         0.99827898 1.         0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.98967363 1.         1.         0.99827898 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 1.         0.99655666 0.99139248 0.99655927\n",
      "  0.99655666 0.99483398 0.99827898 0.98621924 0.99483398 0.99312369\n",
      "  0.99311259 0.99484084 0.99483398 0.99827898 0.99311259 0.99655927\n",
      "  0.99483398 0.99484084 0.98795605 0.99655927 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.9896932  0.98109812 0.99484084\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.99140781\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98452462 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98626773\n",
      "  0.98626773 0.96914312 0.98452462 0.98626773 0.98109812 0.98109812\n",
      "  0.97938669 0.97596745 0.97602065 0.96211115 0.96898587 0.97938669\n",
      "  0.97772549 0.97596745 0.9623372 ]\n",
      " [0.98797984 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 1.         0.98288499 0.98801366 0.99828064\n",
      "  0.99655927 0.99141724 0.99311259 0.99655666 0.97602065 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99827898 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99827898 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.99140781 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99827898 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99483398 1.         0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99655927 0.99311259 0.99828064\n",
      "  0.99484084 0.99139248 0.99483398 0.99655927 0.99311259 0.99655666\n",
      "  0.99312369 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 1.         0.99139248 0.99311259\n",
      "  0.99655666 0.99827898 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99655927 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.99140781 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98797984 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.99140781 0.9896932  0.98795605 0.98281076 0.98281076\n",
      "  0.98281076 0.96914312 0.98797984 0.98281076 0.98455684 0.98109812\n",
      "  0.98284719 0.97596745 0.97255295 0.96211115 0.96898587 0.98284719\n",
      "  0.97772549 0.97943152 0.96581609]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98620585 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97419909 0.99313035 0.97759904 0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98617877 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.99137224\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98445359 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.99309322 0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98790868 0.99139248 0.99139248 0.98965588 0.99139248 0.99137224\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 1.         0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98446884 0.98965588 0.98790868\n",
      "  0.98792054 0.98618644 0.9931059  0.98965588 0.99137224 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.98792054 0.98792054\n",
      "  0.98618644 0.98618644 0.98445359 0.98099157 0.97580759 0.98618644\n",
      "  0.98963983 0.98272197 0.98618644 0.98618644 0.98272264 0.98617877\n",
      "  0.98445359 0.98790868 0.98272197 0.98790868 0.98272197 0.97926237\n",
      "  0.99136377 0.97926237 0.98790868 0.98445359 0.98963557 0.98445009\n",
      "  0.98099157 0.98272197 0.98099157 0.98617877 0.9809964  0.97753439\n",
      "  0.97753439 0.96722907 0.98272264 0.97753439 0.97927136 0.97580759\n",
      "  0.97754752 0.97410339 0.96719117 0.95675776 0.96375863 0.97754752\n",
      "  0.96891215 0.97063426 0.96037285]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.9829098  0.98459902 0.99484582\n",
      "  0.99309997 0.98799088 0.98964996 0.99655927 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98451075 0.99138064 0.99313695 0.99655927\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.9793259  0.99311259\n",
      "  0.99482898 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99482898 0.99482898\n",
      "  0.99484582 0.99484582 0.99484582 0.99655927 0.99484582 0.98964996\n",
      "  0.99482898 0.99655927 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99655927 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99655927 0.99655927\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98792054 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99482898 0.99311259 0.99655927 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.9914008  0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99655927 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99482898 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99655927 0.98964996 0.99484582 0.99484582 0.99138064 0.99655927\n",
      "  0.99655927 0.99482898 0.99655927 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.98792054 0.99138064 0.99309997 0.98964996 0.99311259\n",
      "  0.98619236 0.99655927 0.99655927 0.99482898 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99655927 0.99311259 0.98792054 1.\n",
      "  0.99311259 0.99138064 0.99482898 0.98274993 0.99138064 0.98964576\n",
      "  0.99309997 0.99137224 0.99138064 0.99482898 0.98964996 0.99309997\n",
      "  0.99138064 0.99137224 0.98446543 0.99309997 0.99309997 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98619656 0.97756991 0.99137224\n",
      "  0.98792054 0.98792054 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98964576 0.98446543 0.98619236 0.98446543 0.98447381\n",
      "  0.98619236 0.98101524 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98792054 0.98619656 0.98446543 0.97929197 0.98275229\n",
      "  0.98621261 0.96554834 0.98101524 0.98275229 0.97756991 0.97756991\n",
      "  0.97584903 0.97241083 0.97244835 0.9585411  0.96549987 0.97584903\n",
      "  0.97416272 0.97241083 0.95870391]\n",
      " [0.98452462 0.97596597 0.99828064 0.99139248 0.99138898 0.98795605\n",
      "  0.97291644 0.98301003 0.99655666 0.98288499 0.98457846 0.99828064\n",
      "  0.99311259 0.99141724 0.99311259 0.99655666 0.97255295 0.99828064\n",
      "  0.99144887 0.99828064 0.98451389 0.99483398 0.99656587 0.99655666\n",
      "  0.99828064 0.99828064 0.97936562 0.99828064 0.98278331 0.99655666\n",
      "  0.99483398 0.99828064 0.98797882 0.99828064 0.99828064 0.98622665\n",
      "  0.99828064 0.99828064 0.99141724 0.99828064 0.99483398 0.99483398\n",
      "  0.99828064 0.99828064 0.99828064 0.99655666 0.99828064 0.99311259\n",
      "  0.99483398 0.99655666 0.99828064 0.99655666 0.99483398 0.99655666\n",
      "  0.99828064 0.99828064 0.99828064 0.99828064 0.99655666 0.99828064\n",
      "  0.99828064 0.99655666 0.99828064 0.99828064 0.99655666 0.99655666\n",
      "  0.99655666 0.99828064 0.99828064 0.99655666 0.99828064 0.99828064\n",
      "  0.99828064 0.99828064 0.99655666 0.98795605 0.99828064 0.99655666\n",
      "  0.99828064 0.99655666 0.99483398 0.99655666 0.99655666 0.99828064\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99139726 0.99483398\n",
      "  0.99828064 0.99828064 0.99483398 0.99655666 0.99828064 0.99828064\n",
      "  0.99655666 0.99655666 0.99828064 0.99828064 0.99828064 0.99139248\n",
      "  0.99483398 0.99828064 0.99828064 0.99827898 0.99655666 0.99311259\n",
      "  0.99655666 0.99311259 0.99828064 0.99828064 0.99483398 0.99655666\n",
      "  0.99655666 0.99483398 0.99655666 0.99828064 0.99483398 0.99311259\n",
      "  0.98967363 0.99311259 0.99655666 0.99311259 0.99311259 0.99828064\n",
      "  0.99139248 0.99139248 0.99483398 0.99311259 0.99655927 0.99655666\n",
      "  0.98967363 0.99655666 0.99655666 0.99483398 0.99655666 0.99311259\n",
      "  0.99311259 0.99483398 0.99655666 0.99655666 0.99139248 0.99311259\n",
      "  1.         0.99483398 0.99483398 0.98621924 0.99483398 0.98967363\n",
      "  0.99311259 0.99139248 0.99483398 0.99483398 0.99311259 0.99311259\n",
      "  0.99483398 0.99139248 0.98795605 0.99311259 0.99311259 0.99311259\n",
      "  0.99139248 0.99139248 0.98967363 0.98623971 0.98109812 0.99139248\n",
      "  0.99139248 0.98795605 0.99139248 0.99139248 0.98452462 0.98795605\n",
      "  0.98967363 0.98967363 0.98795605 0.98967363 0.98795605 0.98452462\n",
      "  0.98967363 0.98797984 0.98967363 0.98967363 0.98795605 0.98623971\n",
      "  0.98623971 0.98795605 0.98623971 0.98795605 0.98281076 0.98281076\n",
      "  0.98626773 0.96914312 0.98797984 0.98281076 0.98109812 0.98109812\n",
      "  0.98284719 0.97596745 0.97255295 0.96211115 0.96898587 0.97938669\n",
      "  0.97425961 0.97596745 0.9623372 ]\n",
      " [0.98622621 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99827898 0.9811783  0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99483398 0.97423392 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99655334 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99655334 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99827898 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99482898 0.99138064 0.99656258\n",
      "  0.99655593 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.9913841  0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99827898 0.98965588 0.99138064\n",
      "  0.99483398 1.         0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99482898 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98622621 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.96734516 0.98622621 0.98105076 0.98279381 0.97933341\n",
      "  0.98107943 0.97418855 0.97076454 0.96032556 0.96724228 0.98107943\n",
      "  0.97594352 0.9776543  0.96400057]\n",
      " [0.98622621 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99138064 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99655334 0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 1.         0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99310667 0.99655334 0.99138064 0.99482898\n",
      "  0.99310667 0.9931059  0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.98965588 0.98965588 0.9913841  0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.99311699 0.98965588 0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.99139942 0.98621012 0.98105076 0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97423392 0.96032556 0.96724228 0.98107943\n",
      "  0.97941107 0.97418855 0.96400057]\n",
      " [0.9740981  0.96565189 0.98795577 0.98101714 0.98103563 0.97755521\n",
      "  0.9627046  0.9727664  0.98621924 0.97259899 0.97428343 0.98795577\n",
      "  0.98274993 0.98110737 0.98274993 0.98621924 0.96203516 0.98795577\n",
      "  0.98116049 0.98795577 0.97417569 0.98448397 0.98625019 0.98621924\n",
      "  0.98795577 0.98795577 0.96903328 0.98795577 0.97243255 0.98621924\n",
      "  0.98448397 0.98795577 0.97766562 0.98795577 0.98795577 0.9793259\n",
      "  0.98795577 0.98795577 0.98110737 0.98795577 0.98448397 0.98448397\n",
      "  0.98795577 0.98795577 0.98795577 0.98621924 0.98795577 0.98274993\n",
      "  0.98448397 0.98621924 0.98795577 0.98621924 0.98448397 0.98621924\n",
      "  0.98795577 0.98795577 0.98795577 0.98795577 0.98621924 0.98795577\n",
      "  0.98795577 0.98621924 0.98795577 0.98795577 0.98621924 0.98621924\n",
      "  0.98621924 0.98795577 0.98795577 0.98621924 0.98795577 0.98795577\n",
      "  0.98795577 0.98795577 0.98621924 0.98101032 0.98795577 0.98621924\n",
      "  0.98795577 0.98621924 0.98448397 0.98966592 0.98621924 0.98795577\n",
      "  0.98621924 0.98448397 0.98621924 0.98795577 0.98106573 0.98448397\n",
      "  0.98795577 0.98795577 0.98448397 0.98621924 0.98795577 0.98795577\n",
      "  0.98621924 0.98621924 0.98795577 0.98795577 0.98795577 0.98101714\n",
      "  0.98448397 0.98795577 0.98795577 0.98448397 0.98621924 0.98274993\n",
      "  0.98621924 0.98274993 0.98795577 0.98795577 0.98448397 0.98621924\n",
      "  0.98621924 0.98448397 0.98621924 0.98795577 0.98448397 0.98274993\n",
      "  0.98273896 0.98274993 0.98966592 0.98274993 0.98619995 0.98795577\n",
      "  0.98101714 0.98792054 0.98448397 0.98274993 0.98274993 0.98621924\n",
      "  0.98273896 0.98621924 0.98621924 0.98448397 0.98621924 0.98619995\n",
      "  0.98274993 0.98448397 0.98621924 0.98621924 0.98446884 0.98274993\n",
      "  0.98621924 0.98448397 0.98448397 1.         0.9879323  0.97928556\n",
      "  0.98274993 0.98446884 0.98448397 0.98448397 0.98274993 0.98619995\n",
      "  0.98448397 0.98101714 0.98101032 0.98274993 0.98274993 0.98274993\n",
      "  0.98101714 0.98446884 0.97928556 0.97582606 0.97064575 0.98101714\n",
      "  0.98792054 0.97755521 0.98101714 0.98101714 0.98101524 0.97755521\n",
      "  0.97928556 0.97928556 0.98101032 0.98273896 0.97755521 0.9740981\n",
      "  0.98619236 0.9740981  0.97928556 0.97928556 0.98446543 0.98273973\n",
      "  0.97582606 0.97755521 0.97582606 0.98446543 0.97237134 0.97929197\n",
      "  0.97237134 0.95859885 0.97755667 0.97237134 0.97756991 0.97064575\n",
      "  0.97238518 0.9689434  0.96550622 0.9585411  0.96549987 0.97238518\n",
      "  0.96722424 0.96547596 0.95522165]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98794398\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99827898 0.99483398 0.99656258\n",
      "  0.99483398 0.99655334 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99655334 0.99138064\n",
      "  0.98793237 0.99138064 0.99827898 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99827898\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.9879323  1.         0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98966355 0.99138064 0.99138064 0.99138064\n",
      "  0.98965588 0.98965588 0.98793237 0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98621012 0.9913841  0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.9844891  0.98621012 0.98105076 0.9845094\n",
      "  0.98105076 0.96734516 0.98276932 0.98105076 0.98279381 0.97933341\n",
      "  0.97761727 0.97418855 0.97076454 0.96032556 0.96724228 0.97761727\n",
      "  0.97247596 0.97418855 0.96052001]\n",
      " [0.97751071 0.96910323 0.99141615 0.98445359 0.98448065 0.98097973\n",
      "  0.96619616 0.97625055 0.98967363 0.97950606 0.98118945 0.99141615\n",
      "  0.98964576 0.9845696  0.98619236 0.99312369 0.96540619 0.99141615\n",
      "  0.98463136 0.99141615 0.98107094 0.98793237 0.98971317 0.99312369\n",
      "  0.99141615 0.99141615 0.97592612 0.99141615 0.9758734  0.98967363\n",
      "  0.9913841  0.99141615 0.98112447 0.99141615 0.99141615 0.97932346\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.9913841  0.9913841\n",
      "  0.99141615 0.99141615 0.99141615 0.99312369 0.99141615 0.98619236\n",
      "  0.9913841  0.99312369 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.99312369 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.99312369 0.99312369\n",
      "  0.98967363 0.99141615 0.99141615 0.98967363 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98443823 0.99141615 0.98967363\n",
      "  0.99141615 0.99312369 0.9913841  0.98967363 0.99312369 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98796775 0.9913841\n",
      "  0.99141615 0.99141615 0.98793237 0.99312369 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.99483582 0.99141615 0.99141615 0.98793237 0.98967363 0.98964576\n",
      "  0.99312369 0.98619236 0.99141615 0.99141615 0.98793237 0.99312369\n",
      "  0.99312369 0.9913841  0.99312369 0.99141615 0.98793237 0.98964576\n",
      "  0.98271605 0.98619236 0.98967363 0.98619236 0.98619236 0.99141615\n",
      "  0.98445359 0.98790868 0.98793237 0.98964576 0.98619236 0.98967363\n",
      "  0.98617284 0.99312369 0.99312369 0.9913841  0.98967363 0.98964576\n",
      "  0.98619236 0.98793237 0.99312369 0.98967363 0.98790868 0.98964576\n",
      "  0.98967363 0.98793237 0.9913841  0.97928556 0.98793237 1.\n",
      "  0.98619236 0.98790868 0.98793237 0.9913841  0.98964576 0.98964576\n",
      "  0.98793237 0.98790868 0.98097973 0.99309916 0.98964576 0.98619236\n",
      "  0.98445359 0.98445359 0.98271605 0.98270484 0.97751193 0.98790868\n",
      "  0.98445359 0.98443823 0.98445359 0.98445359 0.97751071 0.98443823\n",
      "  0.98271605 0.98617284 0.98097973 0.98271605 0.98097973 0.97751071\n",
      "  0.98617284 0.98097267 0.98271605 0.98271605 0.98097973 0.97924462\n",
      "  0.98270484 0.98443823 0.98270484 0.98097973 0.97577799 0.9792417\n",
      "  0.9792417  0.96891435 0.97751071 0.9792417  0.97751193 0.97404645\n",
      "  0.97578334 0.96885885 0.97235513 0.96191718 0.96201856 0.97925059\n",
      "  0.9706046  0.96885885 0.9620463 ]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.98799088 0.98964996 0.99311259 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.98792054 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99311259 0.99311259 0.98792054 0.99309997\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  1.         0.98792054 0.99138064 0.99138064 0.98964996 0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.99309916 0.98446543 0.98619236 0.98446543 0.98447381\n",
      "  0.98619236 0.98101524 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98446543 0.98273973 0.98446543 0.97929197 0.97929197\n",
      "  0.98275229 0.96554834 0.98101524 0.97929197 0.97756991 0.97756991\n",
      "  0.97584903 0.97241083 0.96897729 0.9585411  0.96549987 0.97584903\n",
      "  0.97069348 0.97241083 0.95870391]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98620585 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.98120731 0.98289361 0.99313035\n",
      "  0.99137224 0.98627961 0.98792054 0.99484084 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.98279022 0.98965588 0.99142442 0.99484084\n",
      "  0.99313035 0.99313035 0.98108922 0.99313035 0.97759904 0.99139248\n",
      "  0.9931059  0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.9931059  0.9931059\n",
      "  0.99313035 0.99313035 0.99313035 0.99484084 0.99313035 0.98792054\n",
      "  0.9931059  0.99484084 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99484084 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99484084 0.99484084\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98617877 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.9931059  0.99139248 0.99484084 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98968364 0.99655593\n",
      "  0.99313035 0.99313035 0.98965588 0.99484084 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.9931059  0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99484084 0.98792054 0.99313035 0.99313035 0.98965588 0.99484084\n",
      "  0.99484084 0.9931059  0.99484084 0.99313035 0.98965588 0.98792054\n",
      "  0.99136377 0.99482394 0.99139248 0.99137224 0.98792054 0.99313035\n",
      "  0.98618644 0.99309322 0.98965588 0.99137224 0.98792054 0.99139248\n",
      "  0.98445359 0.99484084 0.99484084 0.9931059  0.99139248 0.99137224\n",
      "  0.98792054 0.98965588 0.99484084 0.99139248 0.98618644 0.99137224\n",
      "  0.99139248 0.98965588 0.9931059  0.98446884 0.98965588 0.98790868\n",
      "  0.98792054 1.         0.98965588 0.9931059  0.98792054 0.99137224\n",
      "  0.98965588 0.98963983 0.98272197 0.99137224 0.99137224 0.98792054\n",
      "  0.98618644 0.98963983 0.98445359 0.98445009 0.97580759 0.98963983\n",
      "  0.98963983 0.98617877 0.98618644 0.98963983 0.9861829  0.98617877\n",
      "  0.98445359 0.98445359 0.98272197 0.98445359 0.98272197 0.97926237\n",
      "  0.98445359 0.97926237 0.98445359 0.99136377 0.98617877 0.98445009\n",
      "  0.98099157 0.98617877 0.98445009 0.98617877 0.97753439 0.9809964\n",
      "  0.9809964  0.96375263 0.98272264 0.9809964  0.97580759 0.97927136\n",
      "  0.98101307 0.97063426 0.97413669 0.95675776 0.96375863 0.97408198\n",
      "  0.97238308 0.97063426 0.95688889]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.9811783  0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98449898 0.99827898\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99827898 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99655334 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99483398 0.9931059  0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 1.         0.99310667 0.99138064 0.99138064\n",
      "  0.99310667 0.98965588 0.98621012 0.99138064 0.99138064 0.99138064\n",
      "  0.9931059  0.98965588 0.9913841  0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.9931059  0.98965588 0.98276932 0.98966355\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.9913841  0.98276932 0.9913841  0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.9844891  0.98966355 0.9845094  0.98105076\n",
      "  0.98105076 0.96734516 0.98276932 0.98105076 0.97933341 0.98279381\n",
      "  0.97761727 0.9776543  0.97076454 0.96379131 0.96724228 0.97761727\n",
      "  0.97247596 0.97418855 0.96400057]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98630571 0.99656258\n",
      "  0.99482898 0.98970342 0.99482898 0.99827898 0.97076454 0.99656258\n",
      "  0.98974257 0.99656258 0.98623253 0.99310667 0.99485076 0.99827898\n",
      "  0.99656258 0.99656258 0.98108392 0.99656258 0.98105398 0.99483398\n",
      "  0.99655334 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99655334 0.99655334\n",
      "  0.99656258 0.99656258 0.99656258 0.99827898 0.99656258 0.99138064\n",
      "  0.99655334 0.99827898 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99827898 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99827898 0.99827898\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98966355 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 1.         0.99483398 0.99827898 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99311923 0.99655334\n",
      "  0.99656258 0.99656258 0.99310667 0.99827898 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99655334 0.99656258 0.99656258 0.99310667 0.99483398 0.99138064\n",
      "  0.99827898 0.99138064 0.99656258 0.99656258 0.99310667 0.99827898\n",
      "  0.99827898 0.99655334 0.99827898 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99482898 0.99138064 0.99483398\n",
      "  0.98793237 0.99827898 0.99827898 0.99655334 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99827898 0.99483398 0.98965588 0.99482898\n",
      "  0.99483398 0.99310667 0.99655334 0.98448397 0.99310667 0.9913841\n",
      "  0.99138064 0.9931059  0.99310667 1.         0.99138064 0.99482898\n",
      "  0.99310667 0.99655593 0.98621012 0.99482898 0.99482898 0.99138064\n",
      "  0.9931059  0.98965588 0.98793237 0.98794426 0.97933341 0.9931059\n",
      "  0.98965588 0.98966355 0.98965588 0.98965588 0.98276932 0.99311699\n",
      "  0.98793237 0.98793237 0.98621012 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98966355 0.98794426 0.98621012 0.9845094  0.9845094\n",
      "  0.9845094  0.96734516 0.98276932 0.9845094  0.97933341 0.97933341\n",
      "  0.97761727 0.97418855 0.97423392 0.96032556 0.96724228 0.97761727\n",
      "  0.97594352 0.97418855 0.96052001]\n",
      " [0.98447381 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.98799088 0.98964996 0.99311259 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98106573 0.99138064 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.9793259  0.99311259\n",
      "  0.99138064 0.99484582 0.98454913 0.99484582 0.99484582 0.98621924\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99138064 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.99309997\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.99137224 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99311259 0.99311259 0.99137224 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98964576\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 1.         0.98964996\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.97756991 0.98792054\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98447381 0.98446543\n",
      "  0.98964576 0.98964576 0.98446543 0.98964576 0.98446543 0.98101524\n",
      "  0.98964576 0.98101524 0.98964576 0.98619236 0.98792054 0.98619656\n",
      "  0.98619656 0.98446543 0.98273973 0.98446543 0.97929197 0.98275229\n",
      "  0.97929197 0.97249782 0.98447381 0.97929197 0.98103198 0.98103198\n",
      "  0.98277673 0.97241083 0.97244835 0.9585411  0.96549987 0.97931288\n",
      "  0.97069348 0.97241083 0.96218617]\n",
      " [0.98447381 0.9759723  0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.9829098  0.98459902 0.99484582\n",
      "  0.99309997 0.99143263 0.98964996 0.99655927 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98795577 0.99138064 0.99313695 0.99655927\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.98277257 0.99311259\n",
      "  0.99482898 0.99484582 0.98799088 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99482898 0.99482898\n",
      "  0.99484582 0.99484582 0.99484582 0.99655927 0.99484582 0.98964996\n",
      "  0.99482898 0.99655927 0.99484582 0.99311259 0.99138064 0.99655927\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99655927 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99655927 0.99655927\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98792054 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99482898 0.99311259 0.99655927 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.9914008  0.99482898\n",
      "  0.99484582 0.99484582 0.99482898 0.99655927 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99482898 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99655927 0.98964996 0.99484582 0.99484582 0.99138064 0.99655927\n",
      "  0.99655927 0.99482898 0.99655927 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.99309997 0.99484582\n",
      "  0.98792054 0.98792054 0.99138064 0.99309997 0.98964996 0.99311259\n",
      "  0.98964576 0.99655927 0.99655927 0.99482898 0.99311259 0.98964996\n",
      "  0.99309997 0.99138064 0.99655927 0.99311259 0.98792054 0.99309997\n",
      "  0.99311259 0.99138064 0.99482898 0.98619995 0.99138064 0.98964576\n",
      "  0.98964996 0.99137224 0.99138064 0.99482898 0.98964996 1.\n",
      "  0.99138064 0.99137224 0.98446543 0.99309997 0.99309997 0.99309997\n",
      "  0.98792054 0.98792054 0.98619236 0.98619656 0.98103198 0.99482394\n",
      "  0.98792054 0.98792054 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98619236 0.98792054 0.98619236 0.98446543 0.98101524\n",
      "  0.98964576 0.98101524 0.98619236 0.98619236 0.98446543 0.98619656\n",
      "  0.98273973 0.98792054 0.98965339 0.98446543 0.97929197 0.98621261\n",
      "  0.98275229 0.96554834 0.98101524 0.98621261 0.98103198 0.98103198\n",
      "  0.97584903 0.97934569 0.97591941 0.96200853 0.96549987 0.97931288\n",
      "  0.97763196 0.97587826 0.96566842]\n",
      " [0.98276932 0.97424845 0.99656258 0.98965588 0.98966001 0.98621012\n",
      "  0.97123449 0.98131825 0.99483398 0.98461357 0.98286884 0.99656258\n",
      "  0.99138064 0.98970342 0.99138064 0.99483398 0.97423392 0.99656258\n",
      "  0.98974257 0.99656258 0.98278918 0.99310667 0.99485076 0.99483398\n",
      "  0.99656258 0.99656258 0.97764221 0.99656258 0.98105398 0.99483398\n",
      "  0.99310667 0.99656258 0.98626334 0.99656258 0.99656258 0.98449898\n",
      "  0.99656258 0.99656258 0.98970342 0.99656258 0.99310667 0.99310667\n",
      "  0.99656258 0.99656258 0.99656258 0.99483398 0.99656258 0.99138064\n",
      "  0.99310667 0.99483398 0.99656258 0.99483398 0.99310667 0.99483398\n",
      "  0.99656258 0.99656258 0.99656258 0.99656258 0.99483398 0.99656258\n",
      "  0.99656258 0.99483398 0.99656258 0.99656258 0.99483398 0.99483398\n",
      "  0.99483398 0.99656258 0.99656258 0.99483398 0.99656258 0.99656258\n",
      "  0.99656258 0.99656258 0.99483398 0.98621012 0.99656258 0.99483398\n",
      "  0.99656258 0.99483398 0.99310667 0.99483398 0.99483398 0.99656258\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.98967588 0.99310667\n",
      "  0.99656258 0.99656258 0.99310667 0.99483398 0.99656258 0.99656258\n",
      "  0.99483398 0.99483398 0.99656258 0.99656258 0.99656258 0.98965588\n",
      "  0.99310667 0.99656258 0.99656258 0.99310667 0.99483398 0.99482898\n",
      "  0.99483398 0.99138064 0.99656258 0.99656258 0.99310667 0.99483398\n",
      "  0.99483398 0.99310667 0.99483398 0.99656258 0.99310667 0.99138064\n",
      "  0.98793237 0.99138064 0.99483398 0.99138064 0.99138064 0.99656258\n",
      "  0.98965588 0.98965588 0.99310667 0.99138064 0.99138064 0.99483398\n",
      "  0.98793237 0.99483398 0.99483398 0.99310667 0.99483398 0.99138064\n",
      "  0.99138064 0.99310667 0.99483398 0.99483398 0.98965588 0.99138064\n",
      "  0.99483398 0.99310667 0.99310667 0.98448397 0.99310667 0.98793237\n",
      "  0.99138064 0.98965588 0.99310667 0.99310667 0.99138064 0.99138064\n",
      "  1.         0.98965588 0.98621012 0.99138064 0.99138064 0.99138064\n",
      "  0.98965588 0.98965588 0.9913841  0.9844891  0.97933341 0.98965588\n",
      "  0.98965588 0.98621012 0.98965588 0.98965588 0.98276932 0.98621012\n",
      "  0.98793237 0.98793237 0.98966355 0.98793237 0.98621012 0.98276932\n",
      "  0.98793237 0.98276932 0.98793237 0.98793237 0.98621012 0.9844891\n",
      "  0.9844891  0.98621012 0.9844891  0.98621012 0.98105076 0.98105076\n",
      "  0.98105076 0.96734516 0.98276932 0.9845094  0.97933341 0.98279381\n",
      "  0.97761727 0.97418855 0.97076454 0.96725706 0.96724228 0.97761727\n",
      "  0.97247596 0.97418855 0.96400057]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98620585 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.98120731 0.98289361 0.99313035\n",
      "  0.99137224 0.98627961 0.99137224 0.99484084 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.98279022 0.98965588 0.99142442 0.99484084\n",
      "  0.99313035 0.99313035 0.97764416 0.99313035 0.97759904 0.99139248\n",
      "  0.9931059  0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.9931059  0.9931059\n",
      "  0.99313035 0.99313035 0.99313035 0.99484084 0.99313035 0.98792054\n",
      "  0.9931059  0.99484084 0.99313035 0.99484084 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99484084 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99484084 0.99484084\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99484084 0.98617877 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.99655593 0.99139248 0.99484084 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98968364 0.9931059\n",
      "  0.99313035 0.99313035 0.98965588 0.99484084 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.9931059  0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99484084 0.99137224 0.99313035 0.99313035 0.98965588 0.99484084\n",
      "  0.99484084 0.9931059  0.99484084 0.99313035 0.98965588 0.98792054\n",
      "  0.98445359 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.98618644 0.98965588 0.99137224 0.98792054 0.99139248\n",
      "  0.98445359 0.99484084 0.99484084 0.9931059  0.99139248 0.98792054\n",
      "  0.98792054 0.98965588 0.99484084 0.99139248 0.98618644 0.99137224\n",
      "  0.99139248 0.98965588 0.9931059  0.98101714 0.98965588 0.98790868\n",
      "  0.98792054 0.98963983 0.98965588 0.99655593 0.98792054 0.99137224\n",
      "  0.98965588 1.         0.98272197 0.99137224 0.99137224 0.98792054\n",
      "  0.98963983 0.98618644 0.98445359 0.98445009 0.97580759 0.98963983\n",
      "  0.98618644 0.98617877 0.98618644 0.98618644 0.97926237 0.98963557\n",
      "  0.98445359 0.98445359 0.98617877 0.98445359 0.98617877 0.97926237\n",
      "  0.98445359 0.97926237 0.98445359 0.98790868 0.98272197 0.98445009\n",
      "  0.98445009 0.98617877 0.98445009 0.98272197 0.9809964  0.9809964\n",
      "  0.98445841 0.96375263 0.97926237 0.98445841 0.97927136 0.97927136\n",
      "  0.97408198 0.97410339 0.97413669 0.95675776 0.96375863 0.97408198\n",
      "  0.97238308 0.97063426 0.95688889]\n",
      " [0.97576023 0.96739058 0.98970322 0.98272197 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.98795605 0.97436405 0.97604293 0.98970322\n",
      "  0.98446543 0.98286084 0.98446543 0.98795605 0.96362233 0.98970322\n",
      "  0.98293015 0.98970322 0.97590277 0.98621012 0.98800319 0.98795605\n",
      "  0.98970322 0.98970322 0.97076084 0.98970322 0.97414898 0.98795605\n",
      "  0.98621012 0.98970322 0.979414   0.98970322 0.98970322 0.98105251\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.98621012 0.98621012\n",
      "  0.98970322 0.98970322 0.98970322 0.98795605 0.98970322 0.98446543\n",
      "  0.98621012 0.98795605 0.98970322 0.98795605 0.98966355 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.98795605 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.98795605 0.98795605\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.98269891 0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98621012 0.99140781 0.98795605 0.98970322\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.98625311 0.98621012\n",
      "  0.98970322 0.98970322 0.98621012 0.98795605 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98621012 0.98970322 0.98970322 0.98621012 0.98795605 0.98446543\n",
      "  0.98795605 0.98792054 0.98970322 0.98970322 0.98621012 0.98795605\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.98621012 0.98446543\n",
      "  0.98097973 0.98446543 0.99140781 0.98446543 0.98446543 0.98970322\n",
      "  0.98272197 0.98272197 0.98621012 0.98446543 0.98446543 0.98795605\n",
      "  0.98097973 0.98795605 0.98795605 0.98621012 0.98795605 0.98446543\n",
      "  0.98792054 0.98621012 0.98795605 0.98795605 0.98272197 0.98446543\n",
      "  0.98795605 0.98621012 0.98621012 0.98101032 0.98966355 0.98097973\n",
      "  0.98446543 0.98272197 0.98621012 0.98621012 0.98446543 0.98446543\n",
      "  0.98621012 0.98272197 1.         0.98446543 0.98446543 0.98446543\n",
      "  0.98272197 0.98272197 0.98097973 0.97749887 0.97228649 0.98272197\n",
      "  0.98272197 0.9792387  0.98617877 0.98272197 0.97922391 0.9792387\n",
      "  0.98443823 0.98097973 0.9792387  0.98443823 0.98615913 0.97576023\n",
      "  0.98097973 0.97576023 0.98097973 0.98097973 0.9792387  0.97749887\n",
      "  0.98096081 0.9792387  0.97749887 0.9792387  0.97402277 0.97748821\n",
      "  0.97402277 0.96364442 0.97576023 0.97748821 0.98615527 0.97575368\n",
      "  0.97055137 0.96708458 0.96362233 0.95319436 0.96027965 0.97055137\n",
      "  0.96535289 0.97055714 0.95326207]\n",
      " [0.98101524 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.9829098  0.98459902 0.99484582\n",
      "  0.99309997 0.98799088 0.98964996 0.99655927 0.96897729 0.99484582\n",
      "  0.98803755 0.99484582 0.98451075 0.99138064 0.99313695 0.99655927\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.9793259  0.99311259\n",
      "  0.99482898 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99482898 0.99482898\n",
      "  0.99484582 0.99484582 0.99484582 0.99655927 0.99484582 0.98964996\n",
      "  0.99482898 0.99655927 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99655927 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99655927 0.99655927\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98792054 0.99484582 0.99311259\n",
      "  0.99484582 0.99655927 0.99482898 0.99311259 0.99655927 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.9914008  0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99655927 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99482898 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99655927 0.98964996 0.99484582 0.99484582 0.99138064 0.99655927\n",
      "  0.99655927 0.99482898 0.99655927 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.98792054 0.99138064 0.99309997 0.98964996 0.99311259\n",
      "  0.98619236 0.99655927 0.99655927 0.99482898 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99655927 0.99311259 0.98792054 0.99309997\n",
      "  0.99311259 0.99138064 0.99482898 0.98274993 0.99138064 0.99309916\n",
      "  0.98964996 0.99137224 0.99138064 0.99482898 0.98964996 0.99309997\n",
      "  0.99138064 0.99137224 0.98446543 1.         0.99309997 0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98619656 0.98103198 0.99137224\n",
      "  0.98792054 0.98792054 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98619236 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98447381 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98792054 0.98619656 0.98446543 0.97929197 0.98275229\n",
      "  0.98275229 0.96554834 0.98101524 0.98275229 0.97756991 0.97756991\n",
      "  0.97584903 0.97241083 0.97244835 0.96200853 0.96549987 0.97931288\n",
      "  0.97416272 0.97241083 0.96218617]\n",
      " [0.98447381 0.97253216 0.99484582 0.98792054 0.9879323  0.98446543\n",
      "  0.9695538  0.97962775 0.99655927 0.9829098  0.98803755 0.99484582\n",
      "  0.99654999 0.98799088 0.98964996 0.99655927 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98451075 0.99138064 0.99313695 0.99655927\n",
      "  0.99484582 0.99484582 0.97936342 0.99484582 0.9793259  0.99311259\n",
      "  0.99482898 0.99484582 0.98454913 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99827732 0.99482898\n",
      "  0.99484582 0.99484582 0.99484582 0.99655927 0.99484582 0.98964996\n",
      "  0.99827732 0.99655927 0.99484582 0.99311259 0.99138064 0.99311259\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99655927 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99655927 0.99655927\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.99137565 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99482898 0.99311259 0.99655927 0.99484582\n",
      "  0.99311259 0.99482898 0.99311259 0.99484582 0.9914008  0.99482898\n",
      "  0.99484582 0.99484582 0.99138064 0.99655927 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.98792054\n",
      "  0.99482898 0.99484582 0.99484582 0.99138064 0.99655927 0.98964996\n",
      "  0.99655927 0.98964996 0.99484582 0.99484582 0.99138064 0.99655927\n",
      "  0.99655927 0.99482898 0.99655927 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.99309997 0.98964996 0.99484582\n",
      "  0.99137224 0.98792054 0.99138064 0.99654999 0.98964996 0.99311259\n",
      "  0.98964576 0.99655927 0.99655927 0.99482898 0.99311259 0.98964996\n",
      "  0.98964996 0.99138064 0.99655927 0.99655927 0.98792054 0.99309997\n",
      "  0.99311259 0.99482898 0.99482898 0.98274993 0.99138064 0.98964576\n",
      "  0.98964996 0.99137224 0.99138064 0.99482898 0.98964996 0.99309997\n",
      "  0.99138064 0.99137224 0.98446543 0.99309997 1.         0.98964996\n",
      "  0.98792054 0.98792054 0.98619236 0.98619656 0.97756991 0.99137224\n",
      "  0.98792054 0.99137565 0.98792054 0.98792054 0.98101524 0.98792054\n",
      "  0.98619236 0.98619236 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98447381 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.99137565 0.98965339 0.98446543 0.97929197 0.98275229\n",
      "  0.98275229 0.96554834 0.98447381 0.98275229 0.98103198 0.97756991\n",
      "  0.97931288 0.97587826 0.97244835 0.9585411  0.96549987 0.97931288\n",
      "  0.97763196 0.97587826 0.96218617]\n",
      " [0.98447381 0.9759723  0.99484582 0.98792054 0.99138064 0.98446543\n",
      "  0.9695538  0.97962775 0.99311259 0.97947287 0.98116049 0.99484582\n",
      "  0.98964996 0.99143263 0.98964996 0.99311259 0.97244835 0.99484582\n",
      "  0.98803755 0.99484582 0.98451075 0.99482898 0.99313695 0.99311259\n",
      "  0.99484582 0.99484582 0.97592004 0.99484582 0.98277257 0.99311259\n",
      "  0.99138064 0.99484582 0.98799088 0.99484582 0.99484582 0.98277257\n",
      "  0.99484582 0.99484582 0.98799088 0.99484582 0.99138064 0.99138064\n",
      "  0.99484582 0.99484582 0.99484582 0.99311259 0.99484582 0.98964996\n",
      "  0.99138064 0.99311259 0.99484582 0.99311259 0.99482898 0.99655927\n",
      "  0.99484582 0.99484582 0.99484582 0.99484582 0.99311259 0.99484582\n",
      "  0.99484582 0.99311259 0.99484582 0.99484582 0.99311259 0.99311259\n",
      "  0.99311259 0.99484582 0.99484582 0.99311259 0.99484582 0.99484582\n",
      "  0.99484582 0.99484582 0.99311259 0.98446543 0.99484582 0.99311259\n",
      "  0.99484582 0.99311259 0.99138064 0.99311259 0.99311259 0.99484582\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.98795577 0.99138064\n",
      "  0.99484582 0.99484582 0.99827732 0.99311259 0.99484582 0.99484582\n",
      "  0.99311259 0.99311259 0.99484582 0.99484582 0.99484582 0.99137224\n",
      "  0.99138064 0.99484582 0.99484582 0.99138064 0.99311259 0.98964996\n",
      "  0.99311259 0.98964996 0.99484582 0.99484582 0.99138064 0.99311259\n",
      "  0.99311259 0.99138064 0.99311259 0.99484582 0.99138064 0.98964996\n",
      "  0.98619236 0.98964996 0.99311259 0.98964996 0.98964996 0.99484582\n",
      "  0.98792054 0.98792054 0.99138064 0.98964996 0.98964996 0.99311259\n",
      "  0.98619236 0.99311259 0.99311259 0.99138064 0.99655927 0.98964996\n",
      "  0.99309997 0.99138064 0.99311259 0.99311259 0.98792054 0.98964996\n",
      "  0.99311259 0.99138064 0.99138064 0.98274993 0.99138064 0.98619236\n",
      "  0.98964996 0.98792054 0.99138064 0.99138064 0.98964996 0.99309997\n",
      "  0.99138064 0.98792054 0.98446543 0.98964996 0.98964996 1.\n",
      "  0.98792054 0.98792054 0.98619236 0.98273973 0.98103198 0.99137224\n",
      "  0.98792054 0.98446543 0.98792054 0.98792054 0.98101524 0.98446543\n",
      "  0.98619236 0.98619236 0.98446543 0.98619236 0.98446543 0.98101524\n",
      "  0.98619236 0.98101524 0.98619236 0.98619236 0.98446543 0.98273973\n",
      "  0.98273973 0.98446543 0.98619656 0.98446543 0.97929197 0.97929197\n",
      "  0.97929197 0.96554834 0.98101524 0.98275229 0.97756991 0.98103198\n",
      "  0.97584903 0.97587826 0.96897729 0.96547596 0.96894988 0.97584903\n",
      "  0.97416272 0.97934569 0.96566842]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98620585 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.99137224 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.98279022 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97419909 0.99313035 0.9810474  0.99484084\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.9931059\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99484084 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98617877 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.9931059  0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.9931059  0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98445359 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.98618644 0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99139248 0.98792054\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.98618644 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98101714 0.98965588 0.98445359\n",
      "  0.98792054 0.98618644 0.9931059  0.9931059  0.98792054 0.98792054\n",
      "  0.98965588 0.98963983 0.98272197 0.98792054 0.98792054 0.98792054\n",
      "  1.         0.98618644 0.98790868 0.98099157 0.97580759 0.98618644\n",
      "  0.98618644 0.98272197 0.98963983 0.98618644 0.97926237 0.98963557\n",
      "  0.98445359 0.98445359 0.98272197 0.98445359 0.98272197 0.97926237\n",
      "  0.98790868 0.97926237 0.98790868 0.98445359 0.98272197 0.98099157\n",
      "  0.98099157 0.98272197 0.98099157 0.98617877 0.98445841 0.97753439\n",
      "  0.97753439 0.96375263 0.97926237 0.97753439 0.97580759 0.97927136\n",
      "  0.97408198 0.97063426 0.96719117 0.96022688 0.96375863 0.97408198\n",
      "  0.96891215 0.97063426 0.96037285]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98965588 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97419909 0.99313035 0.97759904 0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98272197 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.9931059  0.98792054\n",
      "  0.98790868 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.98963983 0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99139248 0.98792054\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.98618644 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98446884 0.98965588 0.98445359\n",
      "  0.98792054 0.98963983 0.98965588 0.98965588 0.98792054 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.98792054 0.98792054\n",
      "  0.98618644 1.         0.98445359 0.98099157 0.97580759 0.98963983\n",
      "  0.99654661 0.98272197 0.98618644 0.98963983 0.9861829  0.98272197\n",
      "  0.98445359 0.98445359 0.98272197 0.99136377 0.98272197 0.98272264\n",
      "  0.98445359 0.98272264 0.98445359 0.98445359 0.98963557 0.98099157\n",
      "  0.98099157 0.98272197 0.98099157 0.98617877 0.9809964  0.9809964\n",
      "  0.98445841 0.96375263 0.97926237 0.97753439 0.97580759 0.97580759\n",
      "  0.97754752 0.97063426 0.97066393 0.95675776 0.96375863 0.97408198\n",
      "  0.97238308 0.97063426 0.95688889]\n",
      " [0.98443464 0.96910323 0.99141615 0.98445359 0.98448065 0.98443823\n",
      "  0.96619616 0.97625055 0.98967363 0.97950606 0.97774754 0.99141615\n",
      "  0.98619236 0.9845696  0.98619236 0.98967363 0.9758296  0.99141615\n",
      "  0.98463136 0.99141615 0.98107094 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97247936 0.99141615 0.97932346 0.99312369\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.97932346\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.9913841\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.99312369 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98097973 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98619236\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.9913841  0.98967363 0.99141615 0.98793237 0.98619236\n",
      "  0.98271605 0.98619236 0.98967363 0.98619236 0.98619236 0.99141615\n",
      "  0.98790868 0.98445359 0.98793237 0.98619236 0.98619236 0.98967363\n",
      "  0.98271605 0.98967363 0.98967363 0.9913841  0.98967363 0.98619236\n",
      "  0.98619236 0.98793237 0.98967363 0.98967363 0.98445359 0.98619236\n",
      "  0.98967363 0.98793237 0.9913841  0.97928556 0.98793237 0.98271605\n",
      "  0.98619236 0.98445359 0.9913841  0.98793237 0.98619236 0.98619236\n",
      "  0.9913841  0.98445359 0.98097973 0.98619236 0.98619236 0.98619236\n",
      "  0.98790868 0.98445359 1.         0.97924462 0.97404645 0.98445359\n",
      "  0.98445359 0.98443823 0.98790868 0.98445359 0.97751071 0.98443823\n",
      "  0.98271605 0.98271605 0.98443823 0.98271605 0.98097973 0.97751071\n",
      "  0.98617284 0.97751071 0.98617284 0.98271605 0.98097973 0.97924462\n",
      "  0.97924462 0.98097973 0.98270484 0.98443823 0.9792417  0.97577799\n",
      "  0.97577799 0.96195804 0.97751071 0.9792417  0.97404645 0.98097741\n",
      "  0.97231609 0.96885885 0.96540619 0.96191718 0.96201856 0.97578334\n",
      "  0.9706046  0.96885885 0.9620463 ]\n",
      " [0.97401093 0.97257299 0.98799156 0.98099157 0.98103395 0.97749887\n",
      "  0.96284343 0.97287834 0.98623971 0.97610731 0.97778487 0.98799156\n",
      "  0.98619656 0.98115333 0.98965339 0.9896932  0.96183958 0.98799156\n",
      "  0.9812302  0.98799156 0.97763606 0.9844891  0.98629446 0.9896932\n",
      "  0.98799156 0.98799156 0.9724937  0.98799156 0.97242576 0.98623971\n",
      "  0.99139942 0.98799156 0.98115333 0.98799156 0.98799156 0.97587925\n",
      "  0.98799156 0.98799156 0.98115333 0.98799156 0.98794426 0.98794426\n",
      "  0.98799156 0.98799156 0.98799156 0.9896932  0.98799156 0.98273973\n",
      "  0.98794426 0.9896932  0.98799156 0.98623971 0.9844891  0.98623971\n",
      "  0.98799156 0.98799156 0.98799156 0.98799156 0.9896932  0.98799156\n",
      "  0.98799156 0.98623971 0.98799156 0.98799156 0.9896932  0.9896932\n",
      "  0.98623971 0.98799156 0.98799156 0.98623971 0.98799156 0.98799156\n",
      "  0.98799156 0.98799156 0.98623971 0.98096081 0.98799156 0.98623971\n",
      "  0.98799156 0.98623971 0.98794426 0.98623971 0.9896932  0.98799156\n",
      "  0.98623971 0.9844891  0.98623971 0.98799156 0.98453973 0.98794426\n",
      "  0.98799156 0.98799156 0.9844891  0.9896932  0.98799156 0.98799156\n",
      "  0.98623971 0.98623971 0.98799156 0.98799156 0.98799156 0.98099157\n",
      "  0.98794426 0.98799156 0.98799156 0.9844891  0.98623971 0.98273973\n",
      "  0.9896932  0.98273973 0.98799156 0.98799156 0.98794426 0.9896932\n",
      "  0.9896932  0.98794426 0.9896932  0.98799156 0.9844891  0.98273973\n",
      "  0.97924462 0.98273973 0.98623971 0.98273973 0.98273973 0.98799156\n",
      "  0.98099157 0.98099157 0.9844891  0.98619656 0.98273973 0.98623971\n",
      "  0.97924462 0.9896932  0.9896932  0.98794426 0.98623971 0.98273973\n",
      "  0.98273973 0.9844891  0.9896932  0.98623971 0.98099157 0.98619656\n",
      "  0.98623971 0.9844891  0.98794426 0.97582606 0.9844891  0.98270484\n",
      "  0.98273973 0.98445009 0.9844891  0.98794426 0.98273973 0.98619656\n",
      "  0.9844891  0.98445009 0.97749887 0.98619656 0.98619656 0.98273973\n",
      "  0.98099157 0.98099157 0.97924462 1.         0.97052769 0.98445009\n",
      "  0.98099157 0.98442275 0.98099157 0.98099157 0.97401093 0.98096081\n",
      "  0.97924462 0.97924462 0.97749887 0.97924462 0.97749887 0.97401093\n",
      "  0.97924462 0.97401093 0.97924462 0.97924462 0.97749887 0.97575431\n",
      "  0.97575431 0.98096081 0.97921798 0.97749887 0.97226873 0.97920305\n",
      "  0.97573589 0.95837215 0.97401093 0.97573589 0.97052769 0.97052769\n",
      "  0.9687878  0.96531144 0.96531751 0.95488858 0.95854188 0.9722585\n",
      "  0.97052716 0.96531144 0.95493938]\n",
      " [0.9722407  0.96400397 0.98286403 0.97580759 0.97587301 0.97228649\n",
      "  0.95782341 0.96782925 0.98109812 0.9675694  0.96923665 0.98286403\n",
      "  0.97756991 0.97949196 0.97756991 0.98109812 0.95998111 0.98286403\n",
      "  0.97613777 0.98286403 0.97249283 0.97933341 0.98117575 0.98109812\n",
      "  0.98286403 0.98286403 0.96389863 0.98286403 0.97072194 0.98109812\n",
      "  0.97933341 0.98286403 0.97603817 0.98286403 0.98286403 0.97072194\n",
      "  0.98286403 0.98286403 0.97603817 0.98286403 0.97933341 0.97933341\n",
      "  0.98286403 0.98286403 0.98286403 0.98109812 0.98286403 0.97756991\n",
      "  0.97933341 0.98109812 0.98286403 0.98109812 0.97933341 0.98455684\n",
      "  0.98286403 0.98286403 0.98286403 0.98286403 0.98109812 0.98286403\n",
      "  0.98286403 0.98109812 0.98286403 0.98286403 0.98109812 0.98109812\n",
      "  0.98109812 0.98286403 0.98286403 0.98109812 0.98286403 0.98286403\n",
      "  0.98286403 0.98286403 0.98109812 0.97228649 0.98286403 0.98109812\n",
      "  0.98286403 0.98455684 0.97933341 0.98109812 0.98109812 0.98286403\n",
      "  0.98109812 0.97933341 0.98109812 0.98286403 0.97594989 0.97933341\n",
      "  0.98286403 0.98286403 0.98279381 0.98109812 0.98286403 0.98286403\n",
      "  0.98109812 0.98109812 0.98286403 0.98286403 0.98286403 0.97580759\n",
      "  0.97933341 0.98286403 0.98286403 0.97933341 0.98109812 0.97756991\n",
      "  0.98109812 0.97756991 0.98286403 0.98286403 0.97933341 0.98109812\n",
      "  0.98109812 0.97933341 0.98109812 0.98286403 0.97933341 0.97756991\n",
      "  0.97404645 0.97756991 0.98109812 0.97756991 0.97756991 0.98286403\n",
      "  0.97580759 0.97580759 0.97933341 0.97756991 0.97756991 0.98109812\n",
      "  0.97404645 0.98109812 0.98109812 0.97933341 0.98109812 0.97756991\n",
      "  0.98103198 0.97933341 0.98109812 0.98109812 0.97580759 0.97756991\n",
      "  0.98109812 0.97933341 0.97933341 0.97064575 0.97933341 0.97751193\n",
      "  0.97756991 0.97580759 0.97933341 0.97933341 0.97756991 0.98103198\n",
      "  0.97933341 0.97580759 0.97228649 0.98103198 0.97756991 0.98103198\n",
      "  0.97580759 0.97580759 0.97404645 0.97052769 1.         0.97927136\n",
      "  0.97580759 0.97228649 0.97580759 0.97580759 0.96877004 0.97228649\n",
      "  0.97404645 0.97404645 0.97228649 0.97404645 0.97228649 0.96877004\n",
      "  0.97404645 0.9722407  0.97404645 0.97404645 0.97228649 0.97052769\n",
      "  0.97052769 0.97228649 0.97399661 0.97228649 0.96701353 0.96701353\n",
      "  0.96701353 0.9530014  0.96877004 0.97048595 0.96525815 0.96873234\n",
      "  0.9635039  0.96347827 0.95649791 0.9530396  0.95333536 0.96697986\n",
      "  0.95824777 0.96347827 0.95300982]\n",
      " [0.98272264 0.97425891 0.99313035 0.98618644 0.98965588 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.98120731 0.98289361 0.99313035\n",
      "  0.99137224 0.98972305 0.98792054 0.99484084 0.97066393 0.99313035\n",
      "  0.98633382 0.99313035 0.98623693 0.98965588 0.99142442 0.99484084\n",
      "  0.99313035 0.99313035 0.97764416 0.99313035 0.9810474  0.99139248\n",
      "  0.9931059  0.99313035 0.98627961 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.9931059  0.9931059\n",
      "  0.99313035 0.99313035 0.99313035 0.99484084 0.99313035 0.98792054\n",
      "  0.9931059  0.99484084 0.99313035 0.99139248 0.98965588 0.99484084\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99484084 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99484084 0.99484084\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98617877 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.9931059  0.99139248 0.99484084 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98968364 0.9931059\n",
      "  0.99313035 0.99313035 0.9931059  0.99484084 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.9931059  0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99484084 0.98792054 0.99313035 0.99313035 0.98965588 0.99484084\n",
      "  0.99484084 0.9931059  0.99484084 0.99313035 0.98965588 0.98792054\n",
      "  0.98445359 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.98618644 0.98965588 0.99137224 0.98792054 0.99139248\n",
      "  0.98445359 0.99484084 0.99484084 0.9931059  0.99139248 0.98792054\n",
      "  0.99137224 0.98965588 0.99484084 0.99139248 0.98618644 0.99137224\n",
      "  0.99139248 0.98965588 0.9931059  0.98101714 0.98965588 0.98790868\n",
      "  0.98792054 0.98963983 0.98965588 0.9931059  0.98792054 0.99482394\n",
      "  0.98965588 0.98963983 0.98272197 0.99137224 0.99137224 0.99137224\n",
      "  0.98618644 0.98963983 0.98445359 0.98445009 0.97927136 1.\n",
      "  0.98963983 0.98617877 0.98618644 0.98963983 0.97926237 0.98617877\n",
      "  0.98790868 0.98445359 0.98272197 0.98790868 0.98617877 0.97926237\n",
      "  0.98445359 0.98272264 0.98445359 0.98445359 0.98272197 0.98099157\n",
      "  0.98099157 0.98617877 0.98790862 0.98272197 0.97753439 0.9809964\n",
      "  0.98445841 0.96375263 0.97926237 0.98445841 0.97580759 0.97927136\n",
      "  0.97408198 0.97410339 0.97066393 0.96022688 0.96375863 0.97408198\n",
      "  0.97238308 0.97410339 0.96037285]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98965588 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97419909 0.99313035 0.97759904 0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98272197 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98790868 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.99309322 0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99139248 0.99137224\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.98963983 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98792054 0.98965588 0.98445359\n",
      "  0.98792054 0.98963983 0.98965588 0.98965588 0.98792054 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.98792054 0.98792054\n",
      "  0.98618644 0.99654661 0.98445359 0.98099157 0.97580759 0.98963983\n",
      "  1.         0.98272197 0.98618644 0.98963983 0.98964316 0.98272197\n",
      "  0.98445359 0.98445359 0.98272197 0.99136377 0.98272197 0.98272264\n",
      "  0.98790868 0.98272264 0.98445359 0.98445359 0.99309237 0.98445009\n",
      "  0.98099157 0.98272197 0.98099157 0.98963557 0.9809964  0.9809964\n",
      "  0.98445841 0.96375263 0.98272264 0.97753439 0.97580759 0.97580759\n",
      "  0.97754752 0.97063426 0.96719117 0.95675776 0.96375863 0.97408198\n",
      "  0.97238308 0.97063426 0.95688889]\n",
      " [0.98268759 0.9708358  0.98970322 0.98272197 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.99140781 0.97780607 0.98293015 0.98970322\n",
      "  0.99137565 0.98286084 0.98446543 0.99140781 0.96709852 0.98970322\n",
      "  0.98293015 0.98970322 0.97935289 0.98621012 0.98800319 0.99140781\n",
      "  0.98970322 0.98970322 0.97420931 0.98970322 0.97414898 0.98795605\n",
      "  0.98966355 0.98970322 0.979414   0.98970322 0.98970322 0.97760075\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.99311699 0.98966355\n",
      "  0.98970322 0.98970322 0.98970322 0.99140781 0.98970322 0.98446543\n",
      "  0.99311699 0.99140781 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.99140781 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.99140781 0.99140781\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.98615913 0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98966355 0.98795605 0.99140781 0.98970322\n",
      "  0.98795605 0.98966355 0.98795605 0.98970322 0.98625311 0.98966355\n",
      "  0.98970322 0.98970322 0.98621012 0.99140781 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98966355 0.98970322 0.98970322 0.98621012 0.99140781 0.98446543\n",
      "  0.99140781 0.98446543 0.98970322 0.98970322 0.98966355 0.99140781\n",
      "  0.99140781 0.98966355 0.99140781 0.98970322 0.98621012 0.98446543\n",
      "  0.98097973 0.98446543 0.98795605 0.98792054 0.98446543 0.98970322\n",
      "  0.98617877 0.98272197 0.98621012 0.99137565 0.98446543 0.98795605\n",
      "  0.98443823 0.99140781 0.99140781 0.98966355 0.98795605 0.98446543\n",
      "  0.98446543 0.98621012 0.99140781 0.99140781 0.98272197 0.98792054\n",
      "  0.98795605 0.98966355 0.99311699 0.97755521 0.98621012 0.98443823\n",
      "  0.98446543 0.98617877 0.98621012 0.98966355 0.98446543 0.98792054\n",
      "  0.98621012 0.98617877 0.9792387  0.98792054 0.99137565 0.98446543\n",
      "  0.98272197 0.98272197 0.98443823 0.98442275 0.97228649 0.98617877\n",
      "  0.98272197 1.         0.98272197 0.98272197 0.97576023 0.98269891\n",
      "  0.98097973 0.98097973 0.9792387  0.98097973 0.9792387  0.97576023\n",
      "  0.98097973 0.97922391 0.98097973 0.98097973 0.9792387  0.97749887\n",
      "  0.97749887 0.98615913 0.9878847  0.98269891 0.97402277 0.97748821\n",
      "  0.97748821 0.96016455 0.97922391 0.97748821 0.97575368 0.97228649\n",
      "  0.97402034 0.96708458 0.96709852 0.95666692 0.96027965 0.98095828\n",
      "  0.97925036 0.97055714 0.96023687]\n",
      " [0.97926237 0.97081709 0.99313035 0.98618644 0.98620585 0.98617877\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.97066393 0.99313035\n",
      "  0.98633382 0.99313035 0.98279022 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.97419909 0.99313035 0.9810474  0.99484084\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.9931059\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99484084 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98272197 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.9931059  0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98445359 0.98792054 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.98618644 0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99139248 0.98792054\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.98618644 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98101714 0.98965588 0.98445359\n",
      "  0.98792054 0.98618644 0.9931059  0.98965588 0.98792054 0.98792054\n",
      "  0.98965588 0.98618644 0.98617877 0.98792054 0.98792054 0.98792054\n",
      "  0.98963983 0.98618644 0.98790868 0.98099157 0.97580759 0.98618644\n",
      "  0.98618644 0.98272197 1.         0.98618644 0.97926237 0.98617877\n",
      "  0.98790868 0.98445359 0.98272197 0.98445359 0.98617877 0.98272264\n",
      "  0.98790868 0.97926237 0.98790868 0.98445359 0.98272197 0.98099157\n",
      "  0.98099157 0.98272197 0.98099157 0.98963557 0.9809964  0.9809964\n",
      "  0.97753439 0.96375263 0.97926237 0.9809964  0.97927136 0.97927136\n",
      "  0.97408198 0.97063426 0.96719117 0.96022688 0.96375863 0.97408198\n",
      "  0.96891215 0.97063426 0.96037285]\n",
      " [0.97926237 0.97081709 0.99313035 0.99309322 0.98965588 0.98272197\n",
      "  0.96787436 0.97793852 0.99139248 0.97776869 0.97945339 0.99313035\n",
      "  0.98792054 0.98627961 0.98792054 0.99139248 0.96719117 0.99313035\n",
      "  0.98633382 0.99313035 0.97934352 0.98965588 0.99142442 0.99139248\n",
      "  0.99313035 0.99313035 0.98108922 0.99313035 0.97759904 0.99139248\n",
      "  0.98965588 0.99313035 0.98283617 0.99313035 0.99313035 0.9810474\n",
      "  0.99313035 0.99313035 0.98627961 0.99313035 0.98965588 0.98965588\n",
      "  0.99313035 0.99313035 0.99313035 0.99139248 0.99313035 0.98792054\n",
      "  0.98965588 0.99139248 0.99313035 0.99139248 0.98965588 0.99139248\n",
      "  0.99313035 0.99313035 0.99313035 0.99313035 0.99139248 0.99313035\n",
      "  0.99313035 0.99139248 0.99313035 0.99313035 0.99139248 0.99139248\n",
      "  0.99139248 0.99313035 0.99313035 0.99139248 0.99313035 0.99313035\n",
      "  0.99313035 0.99313035 0.99139248 0.98272197 0.99313035 0.99139248\n",
      "  0.99313035 0.99139248 0.98965588 0.99139248 0.99139248 0.99313035\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98623693 0.98965588\n",
      "  0.99313035 0.99313035 0.98965588 0.99139248 0.99313035 0.99313035\n",
      "  0.99139248 0.99139248 0.99313035 0.99313035 0.99313035 0.98618644\n",
      "  0.98965588 0.99313035 0.99313035 0.98965588 0.99139248 0.98792054\n",
      "  0.99139248 0.98792054 0.99313035 0.99313035 0.98965588 0.99139248\n",
      "  0.99139248 0.98965588 0.99139248 0.99313035 0.98965588 0.98792054\n",
      "  0.98790868 0.99137224 0.99139248 0.98792054 0.98792054 0.99313035\n",
      "  0.98618644 0.98963983 0.98965588 0.98792054 0.98792054 0.99139248\n",
      "  0.98445359 0.99139248 0.99139248 0.98965588 0.99139248 0.98792054\n",
      "  0.98792054 0.98965588 0.99139248 0.99139248 0.98618644 0.98792054\n",
      "  0.99139248 0.98965588 0.98965588 0.98101714 0.98965588 0.98445359\n",
      "  0.98792054 0.98963983 0.98965588 0.98965588 0.98792054 0.98792054\n",
      "  0.98965588 0.98618644 0.98272197 0.98792054 0.98792054 0.98792054\n",
      "  0.98618644 0.98963983 0.98445359 0.98099157 0.97580759 0.98963983\n",
      "  0.98963983 0.98272197 0.98618644 1.         0.98272264 0.98272197\n",
      "  0.98445359 0.98445359 0.98272197 0.98790868 0.98272197 0.97926237\n",
      "  0.98445359 0.98272264 0.98445359 0.98790868 0.98272197 0.98445009\n",
      "  0.98099157 0.98617877 0.98099157 0.98272197 0.97753439 0.97753439\n",
      "  0.9809964  0.96375263 0.98272264 0.97753439 0.97580759 0.97580759\n",
      "  0.97754752 0.97063426 0.96719117 0.95675776 0.96375863 0.97408198\n",
      "  0.96891215 0.97063426 0.95688889]\n",
      " [0.97226281 0.96396884 0.98628114 0.97926237 0.97931243 0.97576023\n",
      "  0.96116889 0.97119409 0.98452462 0.97096431 0.97263737 0.98628114\n",
      "  0.98101524 0.97944705 0.98101524 0.98452462 0.96005794 0.98628114\n",
      "  0.97953149 0.98628114 0.97246688 0.98276932 0.98458699 0.98452462\n",
      "  0.98628114 0.98628114 0.9707793  0.98628114 0.97070373 0.98452462\n",
      "  0.98276932 0.98628114 0.97599676 0.98628114 0.98628114 0.97415895\n",
      "  0.98628114 0.98628114 0.97944705 0.98628114 0.98276932 0.98276932\n",
      "  0.98628114 0.98628114 0.98628114 0.98452462 0.98628114 0.98101524\n",
      "  0.98276932 0.98452462 0.98628114 0.98452462 0.98622621 0.98452462\n",
      "  0.98628114 0.98628114 0.98628114 0.98628114 0.98452462 0.98628114\n",
      "  0.98628114 0.98797984 0.98628114 0.98628114 0.98452462 0.98452462\n",
      "  0.98452462 0.98628114 0.98628114 0.98452462 0.98628114 0.98628114\n",
      "  0.98628114 0.98628114 0.98452462 0.97576023 0.98628114 0.98452462\n",
      "  0.98628114 0.98452462 0.98276932 0.98452462 0.98452462 0.98628114\n",
      "  0.98452462 0.98276932 0.98452462 0.98628114 0.97937401 0.98276932\n",
      "  0.98628114 0.98628114 0.98276932 0.98452462 0.98628114 0.98628114\n",
      "  0.98452462 0.98452462 0.98628114 0.98628114 0.98628114 0.97926237\n",
      "  0.98276932 0.98628114 0.98628114 0.98276932 0.98452462 0.98101524\n",
      "  0.98452462 0.98101524 0.98628114 0.98628114 0.98276932 0.98452462\n",
      "  0.98452462 0.98276932 0.98452462 0.98628114 0.98276932 0.98101524\n",
      "  0.98443464 0.98447381 0.98452462 0.98101524 0.98101524 0.98628114\n",
      "  0.97926237 0.98964316 0.98276932 0.98101524 0.98101524 0.98452462\n",
      "  0.97751071 0.98452462 0.98452462 0.98276932 0.98452462 0.98447381\n",
      "  0.98447381 0.98276932 0.98452462 0.98452462 0.98272264 0.98101524\n",
      "  0.98452462 0.98276932 0.98276932 0.98101524 0.98276932 0.97751071\n",
      "  0.98101524 0.9861829  0.98276932 0.98276932 0.98447381 0.98101524\n",
      "  0.98276932 0.97926237 0.97922391 0.98101524 0.98101524 0.98101524\n",
      "  0.97926237 0.9861829  0.97751071 0.97401093 0.96877004 0.97926237\n",
      "  0.98964316 0.97576023 0.97926237 0.98272264 1.         0.97576023\n",
      "  0.97751071 0.97751071 0.97576023 0.98443464 0.97576023 0.97919711\n",
      "  0.98097267 0.97226281 0.98097267 0.98097267 0.98961495 0.98094175\n",
      "  0.97401093 0.97576023 0.97401093 0.98268759 0.97398475 0.97398475\n",
      "  0.97398475 0.96354755 0.98266426 0.97398475 0.96877004 0.96877004\n",
      "  0.97744269 0.96353943 0.96005794 0.9496353  0.95680525 0.96702537\n",
      "  0.96527597 0.96701546 0.94963944]\n",
      " [0.97576023 0.96739058 0.98970322 0.98272197 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.98795605 0.97780607 0.97948654 0.98970322\n",
      "  0.98792054 0.98286084 0.98792054 0.99140781 0.96362233 0.98970322\n",
      "  0.98293015 0.98970322 0.982803   0.98621012 0.98800319 0.99140781\n",
      "  0.98970322 0.98970322 0.97420931 0.98970322 0.97760075 0.99140781\n",
      "  0.98966355 0.98970322 0.979414   0.98970322 0.98970322 0.97760075\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.98966355 0.99311699\n",
      "  0.98970322 0.98970322 0.98970322 0.99140781 0.98970322 0.98446543\n",
      "  0.98966355 0.99140781 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.99140781 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.99140781 0.99140781\n",
      "  0.98795605 0.98970322 0.98970322 0.99140781 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.98269891 0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.99311699 0.98795605 0.99140781 0.98970322\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.98625311 0.98966355\n",
      "  0.98970322 0.98970322 0.98621012 0.99140781 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98966355 0.98970322 0.98970322 0.98621012 0.98795605 0.98792054\n",
      "  0.99140781 0.98446543 0.98970322 0.98970322 0.98621012 0.99140781\n",
      "  0.99140781 0.99311699 0.99140781 0.98970322 0.98621012 0.98446543\n",
      "  0.98097973 0.98446543 0.98795605 0.98446543 0.98446543 0.98970322\n",
      "  0.98272197 0.98272197 0.98621012 0.98792054 0.98446543 0.98795605\n",
      "  0.98789673 0.99140781 0.99140781 0.98966355 0.98795605 0.98446543\n",
      "  0.98446543 0.98621012 0.99140781 0.98795605 0.98617877 0.98792054\n",
      "  0.98795605 0.98621012 0.98966355 0.97755521 0.98621012 0.98443823\n",
      "  0.98446543 0.98617877 0.98966355 0.99311699 0.98446543 0.98792054\n",
      "  0.98621012 0.98963557 0.9792387  0.98792054 0.98792054 0.98446543\n",
      "  0.98963557 0.98272197 0.98443823 0.98096081 0.97228649 0.98617877\n",
      "  0.98272197 0.98269891 0.98617877 0.98272197 0.97576023 1.\n",
      "  0.98097973 0.98097973 0.9792387  0.98443823 0.9792387  0.97576023\n",
      "  0.98443823 0.97576023 0.98789673 0.98097973 0.98269891 0.97749887\n",
      "  0.97749887 0.98269891 0.98096081 0.98269891 0.98441907 0.97748821\n",
      "  0.98095364 0.96016455 0.97576023 0.97748821 0.97228649 0.97575368\n",
      "  0.97748931 0.96708458 0.96709852 0.95666692 0.96027965 0.97055137\n",
      "  0.96882726 0.96708458 0.95674947]\n",
      " [0.98443464 0.96910323 0.99141615 0.98445359 0.98448065 0.98097973\n",
      "  0.96619616 0.97625055 0.98967363 0.97606575 0.97774754 0.99141615\n",
      "  0.98619236 0.9845696  0.98619236 0.98967363 0.97235513 0.99141615\n",
      "  0.98463136 0.99141615 0.97762253 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97247936 0.99141615 0.97932346 0.98967363\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.98622358\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.98793237\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.98967363 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98097973 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98790868\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98619236\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98793237 0.98619236\n",
      "  0.98271605 0.98619236 0.98967363 0.98619236 0.98619236 0.99141615\n",
      "  0.98445359 0.98445359 0.98793237 0.98619236 0.98619236 0.98967363\n",
      "  0.98271605 0.98967363 0.98967363 0.98793237 0.98967363 0.98619236\n",
      "  0.98619236 0.98793237 0.98967363 0.98967363 0.98445359 0.98619236\n",
      "  0.98967363 0.98793237 0.98793237 0.97928556 0.98793237 0.98271605\n",
      "  0.98619236 0.98445359 0.98793237 0.98793237 0.98964576 0.98619236\n",
      "  0.98793237 0.98445359 0.98443823 0.98619236 0.98619236 0.98619236\n",
      "  0.98445359 0.98445359 0.98271605 0.97924462 0.97404645 0.98790868\n",
      "  0.98445359 0.98097973 0.98790868 0.98445359 0.97751071 0.98097973\n",
      "  1.         0.98271605 0.98097973 0.98271605 0.98789673 0.97751071\n",
      "  0.98271605 0.97751071 0.98271605 0.98271605 0.98097973 0.98616507\n",
      "  0.98270484 0.98097973 0.97924462 0.98097973 0.97577799 0.9792417\n",
      "  0.97577799 0.96195804 0.98097267 0.9792417  0.97751193 0.97751193\n",
      "  0.97578334 0.96885885 0.97235513 0.95844635 0.96547196 0.97578334\n",
      "  0.9706046  0.97232969 0.95856062]\n",
      " [0.98097267 0.97254675 0.99141615 0.98445359 0.98448065 0.98097973\n",
      "  0.96619616 0.97625055 0.98967363 0.97606575 0.97774754 0.99141615\n",
      "  0.98619236 0.9845696  0.98619236 0.98967363 0.96540619 0.99141615\n",
      "  0.98463136 0.99141615 0.98107094 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97247936 0.99141615 0.9758734  0.98967363\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.97932346\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.98793237\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.98967363 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98097973 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98964576\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98793237 0.98619236\n",
      "  0.98271605 0.98619236 0.98967363 0.98619236 0.98619236 0.99141615\n",
      "  0.98445359 0.98790868 0.98793237 0.98619236 0.98619236 0.98967363\n",
      "  0.98271605 0.98967363 0.98967363 0.98793237 0.98967363 0.98619236\n",
      "  0.98619236 0.98793237 0.98967363 0.98967363 0.98790868 0.98964576\n",
      "  0.98967363 0.98793237 0.98793237 0.97928556 0.98793237 0.98617284\n",
      "  0.99309916 0.98445359 0.98793237 0.98793237 0.98964576 0.98619236\n",
      "  0.98793237 0.98445359 0.98097973 0.98619236 0.98619236 0.98619236\n",
      "  0.98445359 0.98445359 0.98271605 0.97924462 0.97404645 0.98445359\n",
      "  0.98445359 0.98097973 0.98445359 0.98445359 0.97751071 0.98097973\n",
      "  0.98271605 1.         0.98097973 0.98271605 0.98097973 0.98097267\n",
      "  0.98617284 0.97751071 0.98271605 0.98271605 0.98097973 0.97924462\n",
      "  0.97924462 0.98097973 0.97924462 0.98097973 0.97577799 0.97577799\n",
      "  0.9792417  0.96543619 0.97751071 0.97577799 0.97751193 0.97404645\n",
      "  0.97231609 0.96885885 0.96540619 0.95844635 0.96547196 0.97578334\n",
      "  0.9706046  0.97232969 0.9620463 ]\n",
      " [0.97576023 0.96739058 0.98970322 0.98617877 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.98795605 0.97780607 0.97604293 0.98970322\n",
      "  0.98792054 0.98286084 0.98446543 0.98795605 0.96709852 0.98970322\n",
      "  0.98293015 0.98970322 0.97590277 0.98621012 0.98800319 0.98795605\n",
      "  0.98970322 0.98970322 0.97420931 0.98970322 0.97414898 0.98795605\n",
      "  0.98621012 0.98970322 0.979414   0.98970322 0.98970322 0.98105251\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.98621012 0.98621012\n",
      "  0.98970322 0.98970322 0.98970322 0.98795605 0.98970322 0.98446543\n",
      "  0.98621012 0.98795605 0.98970322 0.99140781 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.98795605 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.98795605 0.98795605\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.99140781 0.9792387  0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98621012 0.98795605 0.98795605 0.98970322\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.982803   0.98621012\n",
      "  0.98970322 0.98970322 0.98621012 0.98795605 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98621012 0.98970322 0.98970322 0.98621012 0.98795605 0.98446543\n",
      "  0.98795605 0.98792054 0.98970322 0.98970322 0.98621012 0.98795605\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.98621012 0.98792054\n",
      "  0.98097973 0.98446543 0.98795605 0.98792054 0.99137565 0.98970322\n",
      "  0.98272197 0.98272197 0.99311699 0.98792054 0.98792054 0.98795605\n",
      "  0.98443823 0.98795605 0.98795605 0.98621012 0.98795605 0.98446543\n",
      "  0.98792054 0.98966355 0.98795605 0.98795605 0.98272197 0.98446543\n",
      "  0.98795605 0.98621012 0.98621012 0.98101032 0.98621012 0.98097973\n",
      "  0.98446543 0.98272197 0.98621012 0.98621012 0.98446543 0.98792054\n",
      "  0.98966355 0.98617877 0.9792387  0.98446543 0.98446543 0.98446543\n",
      "  0.98272197 0.98272197 0.98443823 0.97749887 0.97228649 0.98272197\n",
      "  0.98272197 0.9792387  0.98272197 0.98272197 0.97576023 0.9792387\n",
      "  0.98097973 0.98097973 1.         0.98097973 0.9792387  0.97922391\n",
      "  0.98443823 0.98268759 0.98443823 0.98443823 0.9792387  0.98096081\n",
      "  0.98096081 0.98269891 0.97749887 0.9792387  0.97402277 0.97748821\n",
      "  0.97748821 0.96016455 0.97576023 0.98095364 0.97922088 0.97922088\n",
      "  0.97055137 0.97402969 0.97057472 0.95666692 0.96373476 0.97402034\n",
      "  0.96882726 0.97055714 0.95674947]\n",
      " [0.97751071 0.96910323 0.99141615 0.98445359 0.98793237 0.98097973\n",
      "  0.96619616 0.97625055 0.98967363 0.97606575 0.97774754 0.99141615\n",
      "  0.98619236 0.9845696  0.98619236 0.98967363 0.96540619 0.99141615\n",
      "  0.98463136 0.99141615 0.97762253 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97247936 0.99141615 0.9758734  0.98967363\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.98277352\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.98793237\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.98967363 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98443823 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.99312369 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98619236\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98793237 0.98619236\n",
      "  0.98271605 0.98619236 0.99312369 0.98619236 0.98619236 0.99141615\n",
      "  0.98445359 0.98445359 0.98793237 0.98619236 0.98619236 0.98967363\n",
      "  0.98617284 0.98967363 0.98967363 0.98793237 0.98967363 0.98619236\n",
      "  0.98619236 0.98793237 0.98967363 0.98967363 0.98790868 0.98619236\n",
      "  0.98967363 0.98793237 0.98793237 0.98273896 0.9913841  0.98271605\n",
      "  0.98619236 0.98445359 0.98793237 0.98793237 0.98964576 0.98619236\n",
      "  0.98793237 0.98445359 0.98443823 0.98619236 0.98619236 0.98619236\n",
      "  0.98445359 0.99136377 0.98271605 0.97924462 0.97404645 0.98790868\n",
      "  0.99136377 0.98097973 0.98445359 0.98790868 0.98443464 0.98443823\n",
      "  0.98271605 0.98271605 0.98097973 1.         0.98097973 0.98097267\n",
      "  0.98271605 0.98097267 0.98962963 0.98271605 0.99135524 0.97924462\n",
      "  0.97924462 0.98097973 0.97924462 0.98097973 0.98270542 0.98270542\n",
      "  0.98270542 0.96543619 0.97751071 0.97577799 0.97751193 0.97404645\n",
      "  0.97925059 0.96885885 0.96540619 0.95497551 0.96201856 0.97231609\n",
      "  0.9706046  0.96885885 0.95507495]\n",
      " [0.97576023 0.96739058 0.98970322 0.98272197 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.98795605 0.97436405 0.97604293 0.98970322\n",
      "  0.98446543 0.98286084 0.98446543 0.98795605 0.96362233 0.98970322\n",
      "  0.98293015 0.98970322 0.97590277 0.98621012 0.98800319 0.98795605\n",
      "  0.98970322 0.98970322 0.97076084 0.98970322 0.97414898 0.98795605\n",
      "  0.98621012 0.98970322 0.979414   0.98970322 0.98970322 0.97760075\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.98621012 0.98621012\n",
      "  0.98970322 0.98970322 0.98970322 0.98795605 0.98970322 0.98446543\n",
      "  0.98621012 0.98795605 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.98795605 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.98795605 0.98795605\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.9792387  0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98621012 0.98795605 0.98795605 0.98970322\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.982803   0.98621012\n",
      "  0.98970322 0.98970322 0.98621012 0.98795605 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98621012 0.98970322 0.98970322 0.98621012 0.98795605 0.98446543\n",
      "  0.98795605 0.98792054 0.98970322 0.98970322 0.98621012 0.98795605\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.98621012 0.98446543\n",
      "  0.98097973 0.98446543 0.98795605 0.98446543 0.98446543 0.98970322\n",
      "  0.98272197 0.98272197 0.98621012 0.98446543 0.98446543 0.98795605\n",
      "  0.98097973 0.98795605 0.98795605 0.98621012 0.98795605 0.98446543\n",
      "  0.98446543 0.98621012 0.98795605 0.98795605 0.98272197 0.98446543\n",
      "  0.98795605 0.98621012 0.98621012 0.97755521 0.98621012 0.98097973\n",
      "  0.98446543 0.98272197 0.98621012 0.98621012 0.98446543 0.98446543\n",
      "  0.98621012 0.98617877 0.98615913 0.98446543 0.98446543 0.98446543\n",
      "  0.98272197 0.98272197 0.98097973 0.97749887 0.97228649 0.98617877\n",
      "  0.98272197 0.9792387  0.98617877 0.98272197 0.97576023 0.9792387\n",
      "  0.98789673 0.98097973 0.9792387  0.98097973 1.         0.97576023\n",
      "  0.98097973 0.97576023 0.98097973 0.98097973 0.9792387  0.98442275\n",
      "  0.97749887 0.9792387  0.97749887 0.9792387  0.97402277 0.97402277\n",
      "  0.97748821 0.96016455 0.97922391 0.98095364 0.97922088 0.97228649\n",
      "  0.97055137 0.97402969 0.96709852 0.95319436 0.96027965 0.97055137\n",
      "  0.96535289 0.96708458 0.95326207]\n",
      " [0.97226281 0.96396884 0.98628114 0.9861829  0.97931243 0.98268759\n",
      "  0.96116889 0.97119409 0.98452462 0.97096431 0.97263737 0.98628114\n",
      "  0.98101524 0.97944705 0.98101524 0.98452462 0.96701728 0.98628114\n",
      "  0.97953149 0.98628114 0.97246688 0.98276932 0.98458699 0.98452462\n",
      "  0.98628114 0.98628114 0.97423122 0.98628114 0.97415895 0.98452462\n",
      "  0.98276932 0.98628114 0.97599676 0.98628114 0.98628114 0.97415895\n",
      "  0.98628114 0.98628114 0.97944705 0.98628114 0.98276932 0.98276932\n",
      "  0.98628114 0.98628114 0.98628114 0.98452462 0.98628114 0.98101524\n",
      "  0.98276932 0.98452462 0.98628114 0.98452462 0.98276932 0.98452462\n",
      "  0.98628114 0.98628114 0.98628114 0.98628114 0.98452462 0.98628114\n",
      "  0.98628114 0.98452462 0.98628114 0.98628114 0.98452462 0.98452462\n",
      "  0.98452462 0.98628114 0.98628114 0.98452462 0.98628114 0.98628114\n",
      "  0.98628114 0.98628114 0.98452462 0.97576023 0.98628114 0.98452462\n",
      "  0.98628114 0.98452462 0.98276932 0.98452462 0.98452462 0.98628114\n",
      "  0.98452462 0.98276932 0.98452462 0.98628114 0.97937401 0.98276932\n",
      "  0.98628114 0.98628114 0.98276932 0.98452462 0.98628114 0.98628114\n",
      "  0.98452462 0.98452462 0.98628114 0.98628114 0.98628114 0.97926237\n",
      "  0.98276932 0.98628114 0.98628114 0.98276932 0.98452462 0.98101524\n",
      "  0.98452462 0.98101524 0.98628114 0.98628114 0.98276932 0.98452462\n",
      "  0.98452462 0.98276932 0.98452462 0.98628114 0.98276932 0.98101524\n",
      "  0.97751071 0.98101524 0.98452462 0.98447381 0.98101524 0.98628114\n",
      "  0.97926237 0.97926237 0.98622621 0.98101524 0.98101524 0.98452462\n",
      "  0.97751071 0.98452462 0.98452462 0.98276932 0.98452462 0.98101524\n",
      "  0.98101524 0.98276932 0.98452462 0.98452462 0.97926237 0.98447381\n",
      "  0.98452462 0.98276932 0.98276932 0.9740981  0.98276932 0.97751071\n",
      "  0.98447381 0.97926237 0.98276932 0.98276932 0.98101524 0.98101524\n",
      "  0.98276932 0.97926237 0.97576023 0.98101524 0.98101524 0.98101524\n",
      "  0.97926237 0.98272264 0.97751071 0.97401093 0.96877004 0.97926237\n",
      "  0.98272264 0.97576023 0.98272264 0.97926237 0.97919711 0.97576023\n",
      "  0.97751071 0.98097267 0.97922391 0.98097267 0.97576023 1.\n",
      "  0.97751071 0.97919711 0.97751071 0.97751071 0.97922391 0.97401093\n",
      "  0.97401093 0.98268759 0.97401093 0.98268759 0.97398475 0.97745365\n",
      "  0.98092255 0.95658083 0.97226281 0.97398475 0.96877004 0.96877004\n",
      "  0.96702537 0.96701546 0.96005794 0.95311133 0.96372239 0.96702537\n",
      "  0.96527597 0.96353943 0.94963944]\n",
      " [0.97751071 0.96910323 0.99141615 0.98445359 0.98448065 0.98097973\n",
      "  0.96619616 0.97625055 0.98967363 0.97606575 0.97774754 0.99141615\n",
      "  0.98619236 0.9845696  0.98619236 0.98967363 0.96540619 0.99141615\n",
      "  0.98463136 0.99141615 0.98107094 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97247936 0.99141615 0.97932346 0.99312369\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.97932346\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.9913841\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.99312369 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98097973 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98964576\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.9913841  0.98967363 0.99141615 0.98793237 0.98619236\n",
      "  0.98271605 0.98619236 0.98967363 0.98619236 0.98964576 0.99141615\n",
      "  0.98445359 0.99136377 0.98793237 0.98619236 0.98619236 0.98967363\n",
      "  0.98617284 0.98967363 0.98967363 0.98793237 0.98967363 0.98964576\n",
      "  0.98619236 0.98793237 0.98967363 0.98967363 0.99136377 0.98619236\n",
      "  0.98967363 0.98793237 0.98793237 0.98619236 0.98793237 0.98617284\n",
      "  0.98619236 0.98445359 0.9913841  0.98793237 0.98964576 0.98964576\n",
      "  0.98793237 0.98445359 0.98097973 0.98619236 0.98619236 0.98619236\n",
      "  0.98790868 0.98445359 0.98617284 0.97924462 0.97404645 0.98445359\n",
      "  0.98790868 0.98097973 0.98790868 0.98445359 0.98097267 0.98443823\n",
      "  0.98271605 0.98617284 0.98443823 0.98271605 0.98097973 0.97751071\n",
      "  1.         0.97751071 0.98617284 0.98271605 0.98443823 0.98616507\n",
      "  0.97924462 0.98097973 0.97924462 0.98789673 0.9792417  0.9792417\n",
      "  0.97577799 0.96543619 0.98097267 0.97577799 0.98097741 0.97751193\n",
      "  0.97231609 0.97580052 0.96888066 0.95844635 0.96201856 0.97925059\n",
      "  0.9706046  0.96885885 0.96553197]\n",
      " [0.97572996 0.96396884 0.98628114 0.9861829  0.98276932 0.97576023\n",
      "  0.96116889 0.97119409 0.98797984 0.97096431 0.97608443 0.98628114\n",
      "  0.98793238 0.97944705 0.98101524 0.98452462 0.96353761 0.98628114\n",
      "  0.97953149 0.98628114 0.97246688 0.98276932 0.98458699 0.98452462\n",
      "  0.98628114 0.98628114 0.97423122 0.98628114 0.97415895 0.98452462\n",
      "  0.98276932 0.98628114 0.97599676 0.98628114 0.98628114 0.97761417\n",
      "  0.98628114 0.98628114 0.97944705 0.98628114 0.98622621 0.98276932\n",
      "  0.98628114 0.98628114 0.98628114 0.98452462 0.98628114 0.98101524\n",
      "  0.98622621 0.98452462 0.98628114 0.98452462 0.98276932 0.98452462\n",
      "  0.98628114 0.98628114 0.98628114 0.98628114 0.98452462 0.98628114\n",
      "  0.98628114 0.98452462 0.98628114 0.98628114 0.98452462 0.98452462\n",
      "  0.98452462 0.98628114 0.98628114 0.98452462 0.98628114 0.98628114\n",
      "  0.98628114 0.98628114 0.98452462 0.97922391 0.98628114 0.98452462\n",
      "  0.98628114 0.98797984 0.98276932 0.98452462 0.98452462 0.98628114\n",
      "  0.98452462 0.98622621 0.98452462 0.98628114 0.97937401 0.98276932\n",
      "  0.98628114 0.98628114 0.98276932 0.98452462 0.98628114 0.98628114\n",
      "  0.98452462 0.98452462 0.98628114 0.98628114 0.98628114 0.97926237\n",
      "  0.98276932 0.98628114 0.98628114 0.9896831  0.98797984 0.98101524\n",
      "  0.98452462 0.98447381 0.98628114 0.98628114 0.98276932 0.98452462\n",
      "  0.98452462 0.98276932 0.98452462 0.98628114 0.98276932 0.98447381\n",
      "  0.97751071 0.98101524 0.98452462 0.98793238 0.98447381 0.98628114\n",
      "  0.98272264 0.97926237 0.9896831  0.98793238 0.99139095 0.98452462\n",
      "  0.98097267 0.98452462 0.98452462 0.98276932 0.98452462 0.98101524\n",
      "  0.98447381 0.9896831  0.98452462 0.98797984 0.97926237 0.98101524\n",
      "  0.98797984 0.98622621 0.98276932 0.9740981  0.98276932 0.98097267\n",
      "  0.98101524 0.97926237 0.98276932 0.98276932 0.98101524 0.98101524\n",
      "  0.98276932 0.97926237 0.97576023 0.98447381 0.98447381 0.98101524\n",
      "  0.97926237 0.98272264 0.97751071 0.97401093 0.9722407  0.98272264\n",
      "  0.98272264 0.97922391 0.97926237 0.98272264 0.97226281 0.97576023\n",
      "  0.97751071 0.97751071 0.98268759 0.98097267 0.97576023 0.97919711\n",
      "  0.97751071 1.         0.98097267 0.97751071 0.97576023 0.97401093\n",
      "  0.97747634 0.98961495 0.97747634 0.97576023 0.97051585 0.97398475\n",
      "  0.98439145 0.95658083 0.97919711 0.97051585 0.9722407  0.9722407\n",
      "  0.97744269 0.97049149 0.96353761 0.95658736 0.96372239 0.97397025\n",
      "  0.96527597 0.97049149 0.96011213]\n",
      " [0.97751071 0.96910323 0.99141615 0.98445359 0.98448065 0.98097973\n",
      "  0.96619616 0.97625055 0.98967363 0.97606575 0.97774754 0.99141615\n",
      "  0.98964576 0.9845696  0.98619236 0.98967363 0.96540619 0.99141615\n",
      "  0.98463136 0.99141615 0.98107094 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97247936 0.99141615 0.97932346 0.99312369\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.98277352\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.9913841\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.98967363 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.99312369 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.98967363 0.98097973 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.98793237\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98619236\n",
      "  0.98967363 0.98964576 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.9913841  0.98967363 0.99141615 0.98793237 0.98964576\n",
      "  0.98617284 0.98619236 0.98967363 0.98619236 0.98964576 0.99141615\n",
      "  0.98790868 0.98445359 0.9913841  0.98964576 0.98964576 0.98967363\n",
      "  0.98617284 0.98967363 0.98967363 0.98793237 0.98967363 0.98619236\n",
      "  0.98964576 0.9913841  0.98967363 0.98967363 0.98790868 0.98619236\n",
      "  0.98967363 0.98793237 0.98793237 0.97928556 0.98793237 0.98271605\n",
      "  0.98619236 0.98445359 0.9913841  0.98793237 0.98964576 0.98619236\n",
      "  0.98793237 0.98445359 0.98097973 0.98619236 0.98619236 0.98619236\n",
      "  0.98790868 0.98445359 0.98617284 0.97924462 0.97404645 0.98445359\n",
      "  0.98445359 0.98097973 0.98790868 0.98445359 0.98097267 0.98789673\n",
      "  0.98271605 0.98271605 0.98443823 0.98962963 0.98097973 0.97751071\n",
      "  0.98617284 0.98097267 1.         0.98617284 0.98789673 0.97924462\n",
      "  0.97924462 0.98097973 0.97924462 0.98443823 0.98270542 0.97577799\n",
      "  0.97577799 0.96543619 0.97751071 0.9792417  0.97404645 0.98097741\n",
      "  0.97925059 0.97232969 0.96888066 0.95844635 0.96201856 0.97231609\n",
      "  0.96713195 0.97232969 0.95856062]\n",
      " [0.97751071 0.96910323 0.99141615 0.98445359 0.98448065 0.98097973\n",
      "  0.96619616 0.97625055 0.98967363 0.97606575 0.97774754 0.99141615\n",
      "  0.98619236 0.9845696  0.98619236 0.98967363 0.96540619 0.99141615\n",
      "  0.98463136 0.99141615 0.97762253 0.98793237 0.98971317 0.98967363\n",
      "  0.99141615 0.99141615 0.97592612 0.99141615 0.9758734  0.98967363\n",
      "  0.98793237 0.99141615 0.98112447 0.99141615 0.99141615 0.97932346\n",
      "  0.99141615 0.99141615 0.9845696  0.99141615 0.98793237 0.98793237\n",
      "  0.99141615 0.99141615 0.99141615 0.98967363 0.99141615 0.98619236\n",
      "  0.98793237 0.98967363 0.99141615 0.99312369 0.98793237 0.98967363\n",
      "  0.99141615 0.99141615 0.99141615 0.99141615 0.98967363 0.99141615\n",
      "  0.99141615 0.98967363 0.99141615 0.99141615 0.98967363 0.98967363\n",
      "  0.98967363 0.99141615 0.99141615 0.98967363 0.99141615 0.99141615\n",
      "  0.99141615 0.99141615 0.99312369 0.98097973 0.99141615 0.98967363\n",
      "  0.99141615 0.98967363 0.98793237 0.98967363 0.98967363 0.99141615\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98451934 0.9913841\n",
      "  0.99141615 0.99141615 0.98793237 0.98967363 0.99141615 0.99141615\n",
      "  0.98967363 0.98967363 0.99141615 0.99141615 0.99141615 0.98445359\n",
      "  0.98793237 0.99141615 0.99141615 0.98793237 0.98967363 0.98619236\n",
      "  0.98967363 0.98619236 0.99141615 0.99141615 0.98793237 0.98967363\n",
      "  0.98967363 0.98793237 0.98967363 0.99141615 0.98793237 0.98619236\n",
      "  0.98962963 0.99309916 0.98967363 0.98964576 0.98619236 0.99141615\n",
      "  0.98790868 0.98790868 0.98793237 0.98619236 0.98619236 0.98967363\n",
      "  0.98271605 0.98967363 0.98967363 0.98793237 0.98967363 0.98964576\n",
      "  0.98619236 0.98793237 0.98967363 0.98967363 0.98445359 0.98619236\n",
      "  0.98967363 0.98793237 0.98793237 0.97928556 0.98793237 0.98271605\n",
      "  0.98619236 0.99136377 0.98793237 0.98793237 0.98619236 0.98619236\n",
      "  0.98793237 0.98790868 0.98097973 0.98619236 0.98619236 0.98619236\n",
      "  0.98445359 0.98445359 0.98271605 0.97924462 0.97404645 0.98445359\n",
      "  0.98445359 0.98097973 0.98445359 0.98790868 0.98097267 0.98097973\n",
      "  0.98271605 0.98271605 0.98443823 0.98271605 0.98097973 0.97751071\n",
      "  0.98271605 0.97751071 0.98617284 1.         0.98097973 0.98270484\n",
      "  0.98616507 0.98097973 0.97924462 0.98097973 0.97577799 0.97577799\n",
      "  0.97577799 0.96195804 0.98097267 0.98616913 0.97751193 0.98444288\n",
      "  0.97578334 0.96885885 0.96888066 0.95497551 0.96201856 0.97231609\n",
      "  0.96713195 0.96885885 0.95507495]\n",
      " [0.97576023 0.96739058 0.98970322 0.98272197 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.98795605 0.97436405 0.97604293 0.98970322\n",
      "  0.98446543 0.98286084 0.98446543 0.98795605 0.96362233 0.98970322\n",
      "  0.98293015 0.98970322 0.97590277 0.98621012 0.98800319 0.98795605\n",
      "  0.98970322 0.98970322 0.97076084 0.98970322 0.97414898 0.98795605\n",
      "  0.98621012 0.98970322 0.979414   0.98970322 0.98970322 0.97760075\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.98621012 0.98621012\n",
      "  0.98970322 0.98970322 0.98970322 0.98795605 0.98970322 0.98446543\n",
      "  0.98621012 0.98795605 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.98795605 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.98795605 0.98795605\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.98269891 0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98621012 0.98795605 0.98795605 0.98970322\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.982803   0.98621012\n",
      "  0.98970322 0.98970322 0.98621012 0.98795605 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98621012 0.98970322 0.98970322 0.98621012 0.98795605 0.98446543\n",
      "  0.98795605 0.98446543 0.98970322 0.98970322 0.98621012 0.98795605\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.98621012 0.98446543\n",
      "  0.98443823 0.98446543 0.98795605 0.98446543 0.98446543 0.98970322\n",
      "  0.98272197 0.98963557 0.98621012 0.98446543 0.98446543 0.98795605\n",
      "  0.98443823 0.98795605 0.98795605 0.98621012 0.98795605 0.98792054\n",
      "  0.98446543 0.98621012 0.98795605 0.98795605 0.98963557 0.98446543\n",
      "  0.98795605 0.98621012 0.98621012 0.98446543 0.98621012 0.98097973\n",
      "  0.98446543 0.98617877 0.98621012 0.98621012 0.98792054 0.98446543\n",
      "  0.98621012 0.98272197 0.9792387  0.98446543 0.98446543 0.98446543\n",
      "  0.98272197 0.98963557 0.98097973 0.97749887 0.97228649 0.98272197\n",
      "  0.99309237 0.9792387  0.98272197 0.98272197 0.98961495 0.98269891\n",
      "  0.98097973 0.98097973 0.9792387  0.99135524 0.9792387  0.97922391\n",
      "  0.98443823 0.97576023 0.98789673 0.98097973 1.         0.98096081\n",
      "  0.97749887 0.9792387  0.97749887 0.98615913 0.98095364 0.97748821\n",
      "  0.97748821 0.96364442 0.97922391 0.97402277 0.97228649 0.97228649\n",
      "  0.98095828 0.96708458 0.96709852 0.95319436 0.96027965 0.97055137\n",
      "  0.96882726 0.96708458 0.95326207]\n",
      " [0.98094175 0.96567912 0.98799156 0.98099157 0.98103395 0.97749887\n",
      "  0.96284343 0.97287834 0.98623971 0.97266357 0.97433954 0.98799156\n",
      "  0.98273973 0.98115333 0.98273973 0.98623971 0.96879543 0.98799156\n",
      "  0.9812302  0.98799156 0.97418422 0.9844891  0.98629446 0.98623971\n",
      "  0.98799156 0.98799156 0.9724937  0.98799156 0.97242576 0.98623971\n",
      "  0.9844891  0.98799156 0.97770477 0.98799156 0.98799156 0.98278622\n",
      "  0.98799156 0.98799156 0.98115333 0.98799156 0.9844891  0.9844891\n",
      "  0.98799156 0.98799156 0.98799156 0.98623971 0.98799156 0.98273973\n",
      "  0.9844891  0.98623971 0.98799156 0.98623971 0.9844891  0.98623971\n",
      "  0.98799156 0.98799156 0.98799156 0.98799156 0.98623971 0.98799156\n",
      "  0.98799156 0.98623971 0.98799156 0.98799156 0.98623971 0.98623971\n",
      "  0.98623971 0.98799156 0.98799156 0.98623971 0.98799156 0.98799156\n",
      "  0.98799156 0.98799156 0.98623971 0.97749887 0.98799156 0.98623971\n",
      "  0.98799156 0.98623971 0.9844891  0.98623971 0.98623971 0.98799156\n",
      "  0.98623971 0.9844891  0.98623971 0.98799156 0.98108789 0.9844891\n",
      "  0.98799156 0.98799156 0.9844891  0.98623971 0.98799156 0.98799156\n",
      "  0.98623971 0.98623971 0.98799156 0.98799156 0.98799156 0.98099157\n",
      "  0.9844891  0.98799156 0.98799156 0.9844891  0.98623971 0.98273973\n",
      "  0.98623971 0.98619656 0.98799156 0.98799156 0.9844891  0.98623971\n",
      "  0.98623971 0.9844891  0.98623971 0.98799156 0.9844891  0.98273973\n",
      "  0.98270484 0.98619656 0.98623971 0.98273973 0.98619656 0.98799156\n",
      "  0.98099157 0.98790862 0.9844891  0.98273973 0.98273973 0.98623971\n",
      "  0.98270484 0.98623971 0.98623971 0.9844891  0.98623971 0.98619656\n",
      "  0.98273973 0.9844891  0.98623971 0.98623971 0.98445009 0.98273973\n",
      "  0.98623971 0.9844891  0.9844891  0.98273973 0.9844891  0.97924462\n",
      "  0.98273973 0.98445009 0.9844891  0.9844891  0.98619656 0.98619656\n",
      "  0.9844891  0.98445009 0.97749887 0.98273973 0.98273973 0.98273973\n",
      "  0.98099157 0.98099157 0.97924462 0.97575431 0.97052769 0.98099157\n",
      "  0.98445009 0.97749887 0.98099157 0.98445009 0.98094175 0.97749887\n",
      "  0.98616507 0.97924462 0.98096081 0.97924462 0.98442275 0.97401093\n",
      "  0.98616507 0.97401093 0.97924462 0.98270484 0.98096081 1.\n",
      "  0.97921798 0.97749887 0.97575431 0.98096081 0.97226873 0.97920305\n",
      "  0.97573589 0.95837215 0.98787257 0.97573589 0.97399661 0.97399661\n",
      "  0.9757292  0.9757343  0.97575129 0.95141429 0.95854188 0.9722585\n",
      "  0.96705106 0.96531144 0.95493938]\n",
      " [0.97747634 0.96567912 0.98799156 0.98099157 0.98103395 0.97749887\n",
      "  0.96284343 0.97287834 0.98623971 0.97266357 0.97433954 0.98799156\n",
      "  0.98273973 0.98115333 0.98273973 0.98623971 0.96531751 0.98799156\n",
      "  0.9812302  0.98799156 0.97418422 0.9844891  0.98629446 0.98623971\n",
      "  0.98799156 0.98799156 0.96904351 0.98799156 0.97242576 0.98623971\n",
      "  0.9844891  0.98799156 0.97770477 0.98799156 0.98799156 0.97933273\n",
      "  0.98799156 0.98799156 0.98115333 0.98799156 0.9844891  0.9844891\n",
      "  0.98799156 0.98799156 0.98799156 0.98623971 0.98799156 0.98273973\n",
      "  0.9844891  0.98623971 0.98799156 0.9896932  0.9844891  0.98623971\n",
      "  0.98799156 0.98799156 0.98799156 0.98799156 0.98623971 0.98799156\n",
      "  0.98799156 0.98623971 0.98799156 0.98799156 0.98623971 0.98623971\n",
      "  0.98623971 0.98799156 0.98799156 0.98623971 0.98799156 0.98799156\n",
      "  0.98799156 0.98799156 0.9896932  0.97749887 0.98799156 0.98623971\n",
      "  0.98799156 0.98623971 0.9844891  0.98623971 0.98623971 0.98799156\n",
      "  0.98623971 0.9844891  0.98623971 0.98799156 0.98108789 0.9844891\n",
      "  0.98799156 0.98799156 0.9844891  0.98623971 0.98799156 0.98799156\n",
      "  0.98623971 0.98623971 0.98799156 0.98799156 0.98799156 0.98099157\n",
      "  0.9844891  0.98799156 0.98799156 0.98794426 0.98623971 0.98273973\n",
      "  0.98623971 0.98619656 0.98799156 0.98799156 0.9844891  0.98623971\n",
      "  0.98623971 0.9844891  0.98623971 0.98799156 0.9844891  0.98619656\n",
      "  0.97924462 0.98273973 0.98623971 0.98273973 0.98273973 0.98799156\n",
      "  0.98099157 0.98099157 0.9844891  0.98273973 0.98619656 0.98623971\n",
      "  0.98270484 0.98623971 0.98623971 0.9844891  0.98623971 0.98619656\n",
      "  0.98273973 0.98794426 0.98623971 0.98623971 0.98099157 0.98273973\n",
      "  0.98623971 0.9844891  0.9844891  0.97582606 0.9844891  0.98270484\n",
      "  0.98273973 0.98099157 0.9844891  0.9844891  0.98619656 0.98273973\n",
      "  0.9844891  0.98445009 0.98096081 0.98273973 0.98273973 0.98273973\n",
      "  0.98099157 0.98099157 0.97924462 0.97575431 0.97052769 0.98099157\n",
      "  0.98099157 0.97749887 0.98099157 0.98099157 0.97401093 0.97749887\n",
      "  0.98270484 0.97924462 0.98096081 0.97924462 0.97749887 0.97401093\n",
      "  0.97924462 0.97747634 0.97924462 0.98616507 0.97749887 0.97921798\n",
      "  1.         0.98096081 0.97575431 0.97749887 0.97226873 0.97920305\n",
      "  0.97573589 0.96185376 0.97747634 0.97920305 0.97746554 0.98093446\n",
      "  0.9791999  0.96531144 0.96879543 0.95141429 0.95854188 0.9687878\n",
      "  0.96357496 0.96531144 0.95493938]\n",
      " [0.97922391 0.96739058 0.98970322 0.99309237 0.98275669 0.9792387\n",
      "  0.96451919 0.97456383 0.99140781 0.97780607 0.98293015 0.98970322\n",
      "  0.99137565 0.98286084 0.98446543 0.99140781 0.96709852 0.98970322\n",
      "  0.98293015 0.98970322 0.97935289 0.98621012 0.98800319 0.99140781\n",
      "  0.98970322 0.98970322 0.98455472 0.98970322 0.97760075 0.98795605\n",
      "  0.98966355 0.98970322 0.979414   0.98970322 0.98970322 0.97760075\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.99311699 0.98966355\n",
      "  0.98970322 0.98970322 0.98970322 0.99140781 0.98970322 0.98446543\n",
      "  0.99311699 0.99140781 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.99140781 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.99140781 0.99140781\n",
      "  0.98795605 0.98970322 0.98970322 0.98795605 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.98615913 0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98966355 0.98795605 0.99140781 0.98970322\n",
      "  0.98795605 0.98966355 0.98795605 0.98970322 0.98625311 0.98966355\n",
      "  0.98970322 0.98970322 0.98621012 0.99140781 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98966355 0.98970322 0.98970322 0.98966355 0.99140781 0.98446543\n",
      "  0.99140781 0.98446543 0.98970322 0.98970322 0.98621012 0.99140781\n",
      "  0.99140781 0.98966355 0.99140781 0.98970322 0.98621012 0.98446543\n",
      "  0.98097973 0.98446543 0.98795605 0.99137565 0.98446543 0.98970322\n",
      "  0.98617877 0.98272197 0.98966355 0.99137565 0.98792054 0.98795605\n",
      "  0.98443823 0.99140781 0.99140781 0.98966355 0.98795605 0.98446543\n",
      "  0.98446543 0.98966355 0.99140781 0.99140781 0.98272197 0.98792054\n",
      "  0.98795605 0.98966355 0.98966355 0.97755521 0.98621012 0.98443823\n",
      "  0.98446543 0.98617877 0.98621012 0.98966355 0.98446543 0.98792054\n",
      "  0.98621012 0.98617877 0.9792387  0.98792054 0.99137565 0.98446543\n",
      "  0.98272197 0.98272197 0.98097973 0.98096081 0.97228649 0.98617877\n",
      "  0.98272197 0.98615913 0.98272197 0.98617877 0.97576023 0.98269891\n",
      "  0.98097973 0.98097973 0.98269891 0.98097973 0.9792387  0.98268759\n",
      "  0.98097973 0.98961495 0.98097973 0.98097973 0.9792387  0.97749887\n",
      "  0.98096081 1.         0.98442275 0.9792387  0.97402277 0.98095364\n",
      "  0.98441907 0.96016455 0.97922391 0.97748821 0.97575368 0.97575368\n",
      "  0.97748931 0.97055714 0.96709852 0.95666692 0.96718987 0.97402034\n",
      "  0.97230163 0.97055714 0.96023687]\n",
      " [0.98440716 0.96912606 0.98799156 0.98099157 0.98103395 0.97749887\n",
      "  0.96284343 0.97287834 0.9896932  0.97610731 0.9812302  0.98799156\n",
      "  0.98965339 0.98460189 0.98273973 0.9896932  0.97227336 0.98799156\n",
      "  0.9812302  0.98799156 0.98108789 0.9844891  0.98629446 0.9896932\n",
      "  0.98799156 0.98799156 0.9724937  0.98799156 0.97587925 0.98623971\n",
      "  0.98794426 0.98799156 0.98115333 0.98799156 0.98799156 0.97587925\n",
      "  0.98799156 0.98799156 0.98115333 0.98799156 0.99139942 0.98794426\n",
      "  0.98799156 0.98799156 0.98799156 0.9896932  0.98799156 0.98273973\n",
      "  0.99139942 0.9896932  0.98799156 0.98623971 0.9844891  0.9896932\n",
      "  0.98799156 0.98799156 0.98799156 0.98799156 0.9896932  0.98799156\n",
      "  0.98799156 0.98623971 0.98799156 0.98799156 0.9896932  0.9896932\n",
      "  0.98623971 0.98799156 0.98799156 0.98623971 0.98799156 0.98799156\n",
      "  0.98799156 0.98799156 0.98623971 0.98442275 0.98799156 0.98623971\n",
      "  0.98799156 0.98623971 0.98794426 0.98623971 0.9896932  0.98799156\n",
      "  0.98623971 0.98794426 0.98623971 0.98799156 0.98453973 0.98794426\n",
      "  0.98799156 0.98799156 0.98794426 0.9896932  0.98799156 0.98799156\n",
      "  0.98623971 0.98623971 0.98799156 0.98799156 0.98799156 0.98099157\n",
      "  0.98794426 0.98799156 0.98799156 0.9844891  0.9896932  0.98273973\n",
      "  0.9896932  0.98273973 0.98799156 0.98799156 0.9844891  0.9896932\n",
      "  0.9896932  0.98794426 0.9896932  0.98799156 0.9844891  0.98273973\n",
      "  0.97924462 0.98273973 0.98623971 0.98619656 0.98273973 0.98799156\n",
      "  0.98445009 0.98099157 0.9844891  0.98965339 0.98273973 0.98623971\n",
      "  0.98270484 0.9896932  0.9896932  0.98794426 0.98623971 0.98273973\n",
      "  0.98619656 0.9844891  0.9896932  0.9896932  0.98099157 0.98619656\n",
      "  0.98623971 0.98794426 0.99139942 0.97582606 0.9844891  0.98270484\n",
      "  0.98273973 0.98445009 0.9844891  0.98794426 0.98273973 0.98965339\n",
      "  0.9844891  0.98445009 0.97749887 0.98619656 0.98965339 0.98619656\n",
      "  0.98099157 0.98099157 0.98270484 0.97921798 0.97399661 0.98790862\n",
      "  0.98099157 0.9878847  0.98099157 0.98099157 0.97401093 0.98096081\n",
      "  0.97924462 0.97924462 0.97749887 0.97924462 0.97749887 0.97401093\n",
      "  0.97924462 0.97747634 0.97924462 0.97924462 0.97749887 0.97575431\n",
      "  0.97575431 0.98442275 1.         0.97749887 0.97226873 0.97573589\n",
      "  0.97573589 0.95837215 0.97747634 0.97920305 0.97399661 0.97399661\n",
      "  0.9722585  0.96878573 0.96531751 0.95488858 0.95854188 0.9791999\n",
      "  0.97400326 0.97226002 0.9654068 ]\n",
      " [0.97576023 0.96739058 0.98970322 0.98272197 0.98275669 0.98615913\n",
      "  0.96451919 0.97456383 0.98795605 0.97436405 0.97604293 0.98970322\n",
      "  0.98446543 0.98286084 0.98446543 0.98795605 0.97057472 0.98970322\n",
      "  0.98293015 0.98970322 0.97935289 0.98621012 0.98800319 0.98795605\n",
      "  0.98970322 0.98970322 0.97076084 0.98970322 0.97760075 0.99140781\n",
      "  0.98621012 0.98970322 0.979414   0.98970322 0.98970322 0.97760075\n",
      "  0.98970322 0.98970322 0.98286084 0.98970322 0.98621012 0.98966355\n",
      "  0.98970322 0.98970322 0.98970322 0.98795605 0.98970322 0.98446543\n",
      "  0.98621012 0.98795605 0.98970322 0.98795605 0.98621012 0.98795605\n",
      "  0.98970322 0.98970322 0.98970322 0.98970322 0.98795605 0.98970322\n",
      "  0.98970322 0.98795605 0.98970322 0.98970322 0.98795605 0.98795605\n",
      "  0.98795605 0.98970322 0.98970322 0.99140781 0.98970322 0.98970322\n",
      "  0.98970322 0.98970322 0.98795605 0.9792387  0.98970322 0.98795605\n",
      "  0.98970322 0.98795605 0.98621012 0.98795605 0.98795605 0.98970322\n",
      "  0.98795605 0.98621012 0.98795605 0.98970322 0.982803   0.98621012\n",
      "  0.98970322 0.98970322 0.98621012 0.98795605 0.98970322 0.98970322\n",
      "  0.98795605 0.98795605 0.98970322 0.98970322 0.98970322 0.98272197\n",
      "  0.98621012 0.98970322 0.98970322 0.98621012 0.98795605 0.98446543\n",
      "  0.98795605 0.98446543 0.98970322 0.98970322 0.98621012 0.98795605\n",
      "  0.98795605 0.98966355 0.98795605 0.98970322 0.98621012 0.98446543\n",
      "  0.98443823 0.98446543 0.98795605 0.98446543 0.98446543 0.98970322\n",
      "  0.98272197 0.98963557 0.98621012 0.98446543 0.98446543 0.98795605\n",
      "  0.98097973 0.98795605 0.98795605 0.98621012 0.98795605 0.98792054\n",
      "  0.98446543 0.98621012 0.98795605 0.98795605 0.98617877 0.98446543\n",
      "  0.98795605 0.98621012 0.98621012 0.98446543 0.98621012 0.98097973\n",
      "  0.98446543 0.98617877 0.98966355 0.98621012 0.98446543 0.98446543\n",
      "  0.98621012 0.98272197 0.9792387  0.98446543 0.98446543 0.98446543\n",
      "  0.98617877 0.98617877 0.98443823 0.97749887 0.97228649 0.98272197\n",
      "  0.98963557 0.98269891 0.98963557 0.98272197 0.98268759 0.98269891\n",
      "  0.98097973 0.98097973 0.9792387  0.98097973 0.9792387  0.98268759\n",
      "  0.98789673 0.97576023 0.98443823 0.98097973 0.98615913 0.98096081\n",
      "  0.97749887 0.9792387  0.97749887 1.         0.97748821 0.97748821\n",
      "  0.97402277 0.96016455 0.97922391 0.97402277 0.97228649 0.97575368\n",
      "  0.97402034 0.96708458 0.96362233 0.95666692 0.96027965 0.97055137\n",
      "  0.96535289 0.96708458 0.95674947]\n",
      " [0.97051585 0.96225974 0.98457197 0.97753439 0.97759212 0.97402277\n",
      "  0.95949555 0.96951107 0.98281076 0.96926626 0.97093641 0.98457197\n",
      "  0.97929197 0.977742   0.98275229 0.98281076 0.95827738 0.98457197\n",
      "  0.97783402 0.98457197 0.97420604 0.98105076 0.98288075 0.98281076\n",
      "  0.98457197 0.98457197 0.96561242 0.98457197 0.97243985 0.98626773\n",
      "  0.98105076 0.98457197 0.97428997 0.98457197 0.98457197 0.97243985\n",
      "  0.98457197 0.98457197 0.977742   0.98457197 0.98105076 0.9845094\n",
      "  0.98457197 0.98457197 0.98457197 0.98281076 0.98457197 0.97929197\n",
      "  0.98105076 0.98281076 0.98457197 0.98281076 0.98105076 0.98281076\n",
      "  0.98457197 0.98457197 0.98457197 0.98457197 0.98281076 0.98457197\n",
      "  0.98457197 0.98281076 0.98457197 0.98457197 0.98281076 0.98281076\n",
      "  0.98281076 0.98457197 0.98457197 0.98626773 0.98457197 0.98457197\n",
      "  0.98457197 0.98457197 0.98281076 0.97402277 0.98457197 0.98281076\n",
      "  0.98457197 0.98281076 0.9845094  0.98281076 0.98281076 0.98457197\n",
      "  0.98281076 0.98105076 0.98281076 0.98457197 0.97766135 0.98105076\n",
      "  0.98457197 0.98457197 0.98105076 0.98281076 0.98457197 0.98457197\n",
      "  0.98281076 0.98281076 0.98457197 0.98457197 0.98457197 0.97753439\n",
      "  0.98105076 0.98457197 0.98457197 0.98105076 0.98281076 0.97929197\n",
      "  0.98281076 0.97929197 0.98457197 0.98457197 0.98105076 0.98281076\n",
      "  0.98281076 0.9845094  0.98281076 0.98457197 0.98105076 0.97929197\n",
      "  0.97577799 0.97929197 0.98281076 0.97929197 0.97929197 0.98457197\n",
      "  0.97753439 0.97753439 0.98105076 0.97929197 0.97929197 0.98281076\n",
      "  0.9792417  0.98281076 0.98281076 0.98105076 0.98281076 0.97929197\n",
      "  0.97929197 0.98105076 0.98281076 0.98281076 0.9809964  0.97929197\n",
      "  0.98281076 0.98105076 0.98105076 0.97237134 0.98105076 0.97577799\n",
      "  0.97929197 0.97753439 0.9845094  0.9845094  0.97929197 0.97929197\n",
      "  0.98105076 0.9809964  0.97402277 0.97929197 0.97929197 0.97929197\n",
      "  0.98445841 0.9809964  0.9792417  0.97226873 0.96701353 0.97753439\n",
      "  0.9809964  0.97402277 0.9809964  0.97753439 0.97398475 0.98441907\n",
      "  0.97577799 0.97577799 0.97402277 0.98270542 0.97402277 0.97398475\n",
      "  0.9792417  0.97051585 0.98270542 0.97577799 0.98095364 0.97226873\n",
      "  0.97226873 0.97402277 0.97226873 0.97748821 1.         0.97223477\n",
      "  0.97223477 0.95479058 0.97051585 0.96876412 0.96701353 0.97048595\n",
      "  0.96873827 0.96176852 0.95827738 0.95133516 0.95506975 0.96526407\n",
      "  0.96350201 0.96176852 0.95132234]\n",
      " [0.97398475 0.96225974 0.98457197 0.97753439 0.97759212 0.97748821\n",
      "  0.95949555 0.96951107 0.98281076 0.97271346 0.97438522 0.98457197\n",
      "  0.98275229 0.977742   0.97929197 0.98626773 0.96524024 0.98457197\n",
      "  0.97783402 0.98457197 0.97420604 0.98105076 0.98288075 0.98626773\n",
      "  0.98457197 0.98457197 0.96906608 0.98457197 0.96898288 0.98281076\n",
      "  0.9845094  0.98457197 0.977742   0.98457197 0.98457197 0.97935379\n",
      "  0.98457197 0.98457197 0.977742   0.98457197 0.9845094  0.9845094\n",
      "  0.98457197 0.98457197 0.98457197 0.98626773 0.98457197 0.97929197\n",
      "  0.9845094  0.98626773 0.98457197 0.98281076 0.98105076 0.98281076\n",
      "  0.98457197 0.98457197 0.98457197 0.98457197 0.98626773 0.98457197\n",
      "  0.98457197 0.98281076 0.98457197 0.98457197 0.98626773 0.98626773\n",
      "  0.98281076 0.98457197 0.98457197 0.98281076 0.98457197 0.98457197\n",
      "  0.98457197 0.98457197 0.98281076 0.98095364 0.98457197 0.98281076\n",
      "  0.98457197 0.98281076 0.9845094  0.98626773 0.98626773 0.98457197\n",
      "  0.98281076 0.98105076 0.98281076 0.98457197 0.98111666 0.9845094\n",
      "  0.98457197 0.98457197 0.98105076 0.98626773 0.98457197 0.98457197\n",
      "  0.98281076 0.98281076 0.98457197 0.98457197 0.98457197 0.97753439\n",
      "  0.9845094  0.98457197 0.98457197 0.9845094  0.98281076 0.97929197\n",
      "  0.98626773 0.97929197 0.98457197 0.98457197 0.98105076 0.98626773\n",
      "  0.98626773 0.9845094  0.98626773 0.98457197 0.98105076 0.97929197\n",
      "  0.97577799 0.97929197 0.98626773 0.97929197 0.98275229 0.98457197\n",
      "  0.97753439 0.97753439 0.98105076 0.98275229 0.98275229 0.98281076\n",
      "  0.9792417  0.98626773 0.98626773 0.9845094  0.98281076 0.97929197\n",
      "  0.97929197 0.9845094  0.98626773 0.98281076 0.97753439 0.98275229\n",
      "  0.98281076 0.98105076 0.9845094  0.97929197 0.9845094  0.9792417\n",
      "  0.97929197 0.9809964  0.98105076 0.9845094  0.98275229 0.98621261\n",
      "  0.98105076 0.9809964  0.97748821 0.98275229 0.98275229 0.97929197\n",
      "  0.97753439 0.9809964  0.97577799 0.97920305 0.96701353 0.9809964\n",
      "  0.9809964  0.97748821 0.9809964  0.97753439 0.97398475 0.97748821\n",
      "  0.9792417  0.97577799 0.97748821 0.98270542 0.97402277 0.97745365\n",
      "  0.9792417  0.97398475 0.97577799 0.97577799 0.97748821 0.97920305\n",
      "  0.97920305 0.98095364 0.97573589 0.97748821 0.97223477 1.\n",
      "  0.97917608 0.95479058 0.97398475 0.97223477 0.97395837 0.97395837\n",
      "  0.97221246 0.96524631 0.96872167 0.94785737 0.95506975 0.96873827\n",
      "  0.97046121 0.96176852 0.954815  ]\n",
      " [0.97051585 0.96225974 0.98457197 0.9809964  0.98105076 0.97402277\n",
      "  0.95949555 0.96951107 0.98281076 0.97271346 0.97438522 0.98457197\n",
      "  0.98275229 0.977742   0.97929197 0.98626773 0.95827738 0.98457197\n",
      "  0.97783402 0.98457197 0.97420604 0.98105076 0.98288075 0.98626773\n",
      "  0.98457197 0.98457197 0.97251975 0.98457197 0.96898288 0.98281076\n",
      "  0.9845094  0.98457197 0.97428997 0.98457197 0.98457197 0.97243985\n",
      "  0.98457197 0.98457197 0.977742   0.98457197 0.9845094  0.9845094\n",
      "  0.98457197 0.98457197 0.98457197 0.98626773 0.98457197 0.97929197\n",
      "  0.9845094  0.98626773 0.98457197 0.98281076 0.98105076 0.98281076\n",
      "  0.98457197 0.98457197 0.98457197 0.98457197 0.98626773 0.98457197\n",
      "  0.98457197 0.98281076 0.98457197 0.98457197 0.98626773 0.98626773\n",
      "  0.98281076 0.98457197 0.98457197 0.98281076 0.98457197 0.98457197\n",
      "  0.98457197 0.98457197 0.98281076 0.97748821 0.98457197 0.98281076\n",
      "  0.98457197 0.98281076 0.9845094  0.98281076 0.98626773 0.98457197\n",
      "  0.98281076 0.98105076 0.98281076 0.98457197 0.98111666 0.9845094\n",
      "  0.98457197 0.98457197 0.98105076 0.98626773 0.98457197 0.98457197\n",
      "  0.98281076 0.98281076 0.98457197 0.98457197 0.98457197 0.97753439\n",
      "  0.9845094  0.98457197 0.98457197 0.98796803 0.98281076 0.98275229\n",
      "  0.98626773 0.98275229 0.98457197 0.98457197 0.98105076 0.98626773\n",
      "  0.98626773 0.9845094  0.98626773 0.98457197 0.98105076 0.97929197\n",
      "  0.97577799 0.97929197 0.98281076 0.98275229 0.97929197 0.98457197\n",
      "  0.97753439 0.97753439 0.9845094  0.98275229 0.98621261 0.98281076\n",
      "  0.9792417  0.98626773 0.98626773 0.9845094  0.98281076 0.97929197\n",
      "  0.97929197 0.9845094  0.98626773 0.98281076 0.97753439 0.98621261\n",
      "  0.98626773 0.98105076 0.9845094  0.97237134 0.98105076 0.9792417\n",
      "  0.98275229 0.9809964  0.98105076 0.9845094  0.97929197 0.98275229\n",
      "  0.98105076 0.98445841 0.97402277 0.98275229 0.98275229 0.97929197\n",
      "  0.97753439 0.98445841 0.97577799 0.97573589 0.96701353 0.98445841\n",
      "  0.98445841 0.97748821 0.97753439 0.9809964  0.97398475 0.98095364\n",
      "  0.97577799 0.9792417  0.97748821 0.98270542 0.97748821 0.98092255\n",
      "  0.97577799 0.98439145 0.97577799 0.97577799 0.97748821 0.97573589\n",
      "  0.97573589 0.98441907 0.97573589 0.97402277 0.97223477 0.97917608\n",
      "  1.         0.95479058 0.97398475 0.97223477 0.96701353 0.97048595\n",
      "  0.97568666 0.96524631 0.96524024 0.94785737 0.95853006 0.96526407\n",
      "  0.96698161 0.96176852 0.95132234]\n",
      " [0.95658083 0.94862812 0.97094222 0.96375263 0.96387211 0.96016455\n",
      "  0.94615108 0.95608981 0.96914312 0.95572421 0.95737119 0.97094222\n",
      "  0.96554834 0.96414463 0.96554834 0.96914312 0.94407103 0.97094222\n",
      "  0.96429755 0.97094222 0.95706336 0.96734516 0.96927442 0.96914312\n",
      "  0.97094222 0.97094222 0.95193409 0.97094222 0.9552576  0.96914312\n",
      "  0.96734516 0.97094222 0.9606782  0.97094222 0.97094222 0.95872898\n",
      "  0.97094222 0.97094222 0.96414463 0.97094222 0.96734516 0.96734516\n",
      "  0.97094222 0.97094222 0.97094222 0.96914312 0.97094222 0.96554834\n",
      "  0.96734516 0.96914312 0.97094222 0.96914312 0.97081822 0.96914312\n",
      "  0.97094222 0.97094222 0.97094222 0.97094222 0.96914312 0.97094222\n",
      "  0.97094222 0.96914312 0.97094222 0.97094222 0.96914312 0.96914312\n",
      "  0.96914312 0.97094222 0.97094222 0.96914312 0.97094222 0.97094222\n",
      "  0.97094222 0.97094222 0.96914312 0.96016455 0.97094222 0.96914312\n",
      "  0.97094222 0.96914312 0.96734516 0.96914312 0.96914312 0.97094222\n",
      "  0.96914312 0.96734516 0.96914312 0.97094222 0.96400279 0.96734516\n",
      "  0.97094222 0.97094222 0.96734516 0.96914312 0.97094222 0.97094222\n",
      "  0.96914312 0.96914312 0.97094222 0.97094222 0.97094222 0.96375263\n",
      "  0.96734516 0.97094222 0.97094222 0.96734516 0.96914312 0.96902308\n",
      "  0.96914312 0.96554834 0.97094222 0.97094222 0.96734516 0.96914312\n",
      "  0.96914312 0.96734516 0.96914312 0.97094222 0.96734516 0.96902308\n",
      "  0.96195804 0.96554834 0.96914312 0.96554834 0.96554834 0.97094222\n",
      "  0.96375263 0.96722907 0.96734516 0.96554834 0.96554834 0.96914312\n",
      "  0.96543619 0.96914312 0.96914312 0.96734516 0.96914312 0.96902308\n",
      "  0.96902308 0.96734516 0.96914312 0.96914312 0.96722907 0.96554834\n",
      "  0.96914312 0.96734516 0.96734516 0.95859885 0.96734516 0.96891435\n",
      "  0.96554834 0.96375263 0.96734516 0.96734516 0.97249782 0.96554834\n",
      "  0.96734516 0.96375263 0.96364442 0.96554834 0.96554834 0.96554834\n",
      "  0.96375263 0.96375263 0.96195804 0.95837215 0.9530014  0.96375263\n",
      "  0.96375263 0.96016455 0.96375263 0.96375263 0.96354755 0.96016455\n",
      "  0.96195804 0.96543619 0.96016455 0.96543619 0.96016455 0.95658083\n",
      "  0.96543619 0.95658083 0.96543619 0.96195804 0.96364442 0.95837215\n",
      "  0.96185376 0.96016455 0.95837215 0.96016455 0.95479058 0.95479058\n",
      "  0.95479058 1.         0.95658083 0.95479058 0.95648829 0.9530014\n",
      "  0.95819062 0.9476401  0.94756697 0.93367096 0.94122514 0.95470194\n",
      "  0.94585506 0.95113239 0.93689469]\n",
      " [0.97919711 0.96396884 0.98628114 0.97926237 0.97931243 0.97922391\n",
      "  0.96116889 0.97119409 0.98797984 0.97096431 0.97608443 0.98628114\n",
      "  0.98447381 0.97944705 0.98101524 0.98452462 0.97049695 0.98628114\n",
      "  0.97953149 0.98628114 0.97246688 0.98276932 0.98458699 0.98452462\n",
      "  0.98628114 0.98628114 0.9707793  0.98628114 0.97070373 0.98452462\n",
      "  0.98276932 0.98628114 0.97599676 0.98628114 0.98628114 0.97761417\n",
      "  0.98628114 0.98628114 0.97944705 0.98628114 0.98622621 0.98276932\n",
      "  0.98628114 0.98628114 0.98628114 0.98452462 0.98628114 0.98101524\n",
      "  0.98622621 0.98452462 0.98628114 0.98452462 0.98276932 0.98452462\n",
      "  0.98628114 0.98628114 0.98628114 0.98628114 0.98452462 0.98628114\n",
      "  0.98628114 0.98797984 0.98628114 0.98628114 0.98452462 0.98452462\n",
      "  0.98452462 0.98628114 0.98628114 0.98452462 0.98628114 0.98628114\n",
      "  0.98628114 0.98628114 0.98452462 0.97922391 0.98628114 0.98452462\n",
      "  0.98628114 0.98452462 0.98276932 0.98452462 0.98452462 0.98628114\n",
      "  0.98452462 0.98622621 0.98452462 0.98628114 0.97937401 0.98276932\n",
      "  0.98628114 0.98628114 0.98276932 0.98452462 0.98628114 0.98628114\n",
      "  0.98452462 0.98452462 0.98628114 0.98628114 0.98628114 0.97926237\n",
      "  0.98276932 0.98628114 0.98628114 0.98622621 0.98797984 0.98101524\n",
      "  0.98452462 0.98101524 0.98628114 0.98628114 0.98276932 0.98452462\n",
      "  0.98452462 0.98276932 0.98452462 0.98628114 0.98276932 0.98101524\n",
      "  0.98097267 0.98793238 0.98452462 0.98447381 0.98101524 0.98628114\n",
      "  0.98272264 0.9861829  0.98276932 0.98447381 0.98447381 0.98452462\n",
      "  0.98097267 0.98452462 0.98452462 0.98276932 0.98452462 0.98447381\n",
      "  0.98101524 0.98276932 0.98452462 0.98797984 0.98272264 0.98101524\n",
      "  0.98797984 0.98622621 0.98276932 0.97755667 0.98276932 0.97751071\n",
      "  0.98101524 0.98272264 0.98276932 0.98276932 0.98447381 0.98101524\n",
      "  0.98276932 0.97926237 0.97576023 0.98101524 0.98447381 0.98101524\n",
      "  0.97926237 0.97926237 0.97751071 0.97401093 0.96877004 0.97926237\n",
      "  0.98272264 0.97922391 0.97926237 0.98272264 0.98266426 0.97576023\n",
      "  0.98097267 0.97751071 0.97576023 0.97751071 0.97922391 0.97226281\n",
      "  0.98097267 0.97919711 0.97751071 0.98097267 0.97922391 0.98787257\n",
      "  0.97747634 0.97922391 0.97747634 0.97922391 0.97051585 0.97398475\n",
      "  0.97398475 0.95658083 1.         0.97398475 0.9722407  0.9722407\n",
      "  0.98091514 0.96701546 0.96701728 0.9496353  0.95680525 0.97049781\n",
      "  0.96527597 0.96701546 0.95313034]\n",
      " [0.97398475 0.96571015 0.98457197 0.97753439 0.97759212 0.97402277\n",
      "  0.95949555 0.96951107 0.98281076 0.97616067 0.97438522 0.98457197\n",
      "  0.98275229 0.98119404 0.97929197 0.98626773 0.96524024 0.98457197\n",
      "  0.97783402 0.98457197 0.97766135 0.98105076 0.98288075 0.98626773\n",
      "  0.98457197 0.98457197 0.96906608 0.98457197 0.97243985 0.98281076\n",
      "  0.9845094  0.98457197 0.977742   0.98457197 0.98457197 0.97243985\n",
      "  0.98457197 0.98457197 0.977742   0.98457197 0.9845094  0.9845094\n",
      "  0.98457197 0.98457197 0.98457197 0.98626773 0.98457197 0.97929197\n",
      "  0.9845094  0.98626773 0.98457197 0.98626773 0.98105076 0.98626773\n",
      "  0.98457197 0.98457197 0.98457197 0.98457197 0.98626773 0.98457197\n",
      "  0.98457197 0.98281076 0.98457197 0.98457197 0.98626773 0.98626773\n",
      "  0.98281076 0.98457197 0.98457197 0.98281076 0.98457197 0.98457197\n",
      "  0.98457197 0.98457197 0.98626773 0.97748821 0.98457197 0.98281076\n",
      "  0.98457197 0.98281076 0.9845094  0.98281076 0.98626773 0.98457197\n",
      "  0.98281076 0.98105076 0.98281076 0.98457197 0.98111666 0.9845094\n",
      "  0.98457197 0.98457197 0.9845094  0.98626773 0.98457197 0.98457197\n",
      "  0.98281076 0.98281076 0.98457197 0.98457197 0.98457197 0.97753439\n",
      "  0.9845094  0.98457197 0.98457197 0.98105076 0.98281076 0.97929197\n",
      "  0.98626773 0.97929197 0.98457197 0.98457197 0.98105076 0.98626773\n",
      "  0.98626773 0.9845094  0.98626773 0.98457197 0.98105076 0.97929197\n",
      "  0.9792417  0.97929197 0.98281076 0.97929197 0.97929197 0.98457197\n",
      "  0.9809964  0.97753439 0.98105076 0.98275229 0.97929197 0.98281076\n",
      "  0.97577799 0.98626773 0.98626773 0.9845094  0.98281076 0.97929197\n",
      "  0.98275229 0.98105076 0.98626773 0.98281076 0.97753439 0.98275229\n",
      "  0.98281076 0.98105076 0.9845094  0.97237134 0.98105076 0.9792417\n",
      "  0.97929197 0.9809964  0.98105076 0.9845094  0.97929197 0.98621261\n",
      "  0.9845094  0.98445841 0.97748821 0.98275229 0.98275229 0.98275229\n",
      "  0.97753439 0.97753439 0.9792417  0.97573589 0.97048595 0.98445841\n",
      "  0.97753439 0.97748821 0.9809964  0.97753439 0.97398475 0.97748821\n",
      "  0.9792417  0.97577799 0.98095364 0.97577799 0.98095364 0.97398475\n",
      "  0.97577799 0.97051585 0.9792417  0.98616913 0.97402277 0.97573589\n",
      "  0.97920305 0.97748821 0.97920305 0.97402277 0.96876412 0.97223477\n",
      "  0.97223477 0.95479058 0.97398475 1.         0.97395837 0.9809032\n",
      "  0.96526407 0.9687241  0.96175881 0.95481294 0.95506975 0.96526407\n",
      "  0.96350201 0.96524631 0.95132234]\n",
      " [0.9722407  0.9605518  0.98286403 0.97580759 0.97587301 0.97228649\n",
      "  0.95782341 0.96782925 0.98455684 0.9675694  0.97268721 0.98286403\n",
      "  0.98103198 0.97603817 0.97756991 0.98109812 0.95998111 0.98286403\n",
      "  0.97613777 0.98286403 0.96903576 0.97933341 0.98117575 0.98109812\n",
      "  0.98286403 0.98286403 0.96389863 0.98286403 0.96726321 0.98109812\n",
      "  0.97933341 0.98286403 0.97258438 0.98286403 0.98286403 0.97418066\n",
      "  0.98286403 0.98286403 0.97603817 0.98286403 0.98279381 0.97933341\n",
      "  0.98286403 0.98286403 0.98286403 0.98109812 0.98286403 0.97756991\n",
      "  0.98279381 0.98109812 0.98286403 0.98455684 0.97933341 0.98109812\n",
      "  0.98286403 0.98286403 0.98286403 0.98286403 0.98109812 0.98286403\n",
      "  0.98286403 0.98109812 0.98286403 0.98286403 0.98109812 0.98109812\n",
      "  0.98109812 0.98286403 0.98286403 0.98109812 0.98286403 0.98286403\n",
      "  0.98286403 0.98286403 0.98455684 0.97922088 0.98286403 0.98109812\n",
      "  0.98286403 0.98109812 0.97933341 0.98455684 0.98109812 0.98286403\n",
      "  0.98109812 0.98279381 0.98109812 0.98286403 0.97594989 0.97933341\n",
      "  0.98286403 0.98286403 0.97933341 0.98109812 0.98286403 0.98286403\n",
      "  0.98109812 0.98109812 0.98286403 0.98286403 0.98286403 0.97580759\n",
      "  0.97933341 0.98286403 0.98286403 0.97933341 0.98455684 0.98103198\n",
      "  0.98109812 0.98103198 0.98286403 0.98286403 0.97933341 0.98109812\n",
      "  0.98109812 0.97933341 0.98109812 0.98286403 0.97933341 0.97756991\n",
      "  0.97404645 0.97756991 0.98455684 0.98103198 0.98103198 0.98286403\n",
      "  0.97927136 0.97927136 0.97933341 0.98103198 0.97756991 0.98109812\n",
      "  0.98097741 0.98109812 0.98109812 0.97933341 0.98109812 0.97756991\n",
      "  0.97756991 0.97933341 0.98109812 0.98455684 0.97927136 0.97756991\n",
      "  0.98109812 0.98279381 0.97933341 0.97756991 0.98279381 0.97751193\n",
      "  0.97756991 0.97580759 0.97933341 0.97933341 0.98103198 0.98103198\n",
      "  0.97933341 0.97927136 0.98615527 0.97756991 0.98103198 0.97756991\n",
      "  0.97580759 0.97580759 0.97404645 0.97052769 0.96525815 0.97580759\n",
      "  0.97580759 0.97575368 0.97927136 0.97580759 0.96877004 0.97228649\n",
      "  0.97751193 0.97751193 0.97922088 0.97751193 0.97922088 0.96877004\n",
      "  0.98097741 0.9722407  0.97404645 0.97751193 0.97228649 0.97399661\n",
      "  0.97746554 0.97575368 0.97399661 0.97228649 0.96701353 0.97395837\n",
      "  0.96701353 0.95648829 0.9722407  0.97395837 1.         0.96873234\n",
      "  0.96697986 0.96347827 0.95998111 0.94608049 0.95333536 0.97393179\n",
      "  0.96521051 0.96347827 0.95650425]\n",
      " [0.97571137 0.96400397 0.98286403 0.97580759 0.97933341 0.97228649\n",
      "  0.95782341 0.96782925 0.98109812 0.97101836 0.96923665 0.98286403\n",
      "  0.97756991 0.97949196 0.97756991 0.98109812 0.96694751 0.98286403\n",
      "  0.97613777 0.98286403 0.97594989 0.98279381 0.98117575 0.98109812\n",
      "  0.98286403 0.98286403 0.96389863 0.98286403 0.97418066 0.98455684\n",
      "  0.97933341 0.98286403 0.97603817 0.98286403 0.98286403 0.97418066\n",
      "  0.98286403 0.98286403 0.97603817 0.98286403 0.97933341 0.98279381\n",
      "  0.98286403 0.98286403 0.98286403 0.98109812 0.98286403 0.97756991\n",
      "  0.97933341 0.98109812 0.98286403 0.98455684 0.97933341 0.98455684\n",
      "  0.98286403 0.98286403 0.98286403 0.98286403 0.98109812 0.98286403\n",
      "  0.98286403 0.98109812 0.98286403 0.98286403 0.98109812 0.98109812\n",
      "  0.98109812 0.98286403 0.98286403 0.98455684 0.98286403 0.98286403\n",
      "  0.98286403 0.98286403 0.98455684 0.97228649 0.98286403 0.98109812\n",
      "  0.98286403 0.98109812 0.97933341 0.98109812 0.98109812 0.98286403\n",
      "  0.98109812 0.97933341 0.98109812 0.98286403 0.97940696 0.98279381\n",
      "  0.98286403 0.98286403 0.98279381 0.98109812 0.98286403 0.98286403\n",
      "  0.98109812 0.98109812 0.98286403 0.98286403 0.98286403 0.97927136\n",
      "  0.97933341 0.98286403 0.98286403 0.98279381 0.98109812 0.97756991\n",
      "  0.98109812 0.97756991 0.98286403 0.98286403 0.97933341 0.98109812\n",
      "  0.98109812 0.98279381 0.98109812 0.98286403 0.97933341 0.97756991\n",
      "  0.97751193 0.98103198 0.98109812 0.98103198 0.97756991 0.98286403\n",
      "  0.97927136 0.97580759 0.97933341 0.97756991 0.98103198 0.98109812\n",
      "  0.97404645 0.98109812 0.98109812 0.97933341 0.98109812 0.98103198\n",
      "  0.98103198 0.98279381 0.98109812 0.98109812 0.97580759 0.97756991\n",
      "  0.98109812 0.97933341 0.97933341 0.97064575 0.97933341 0.97404645\n",
      "  0.97756991 0.97927136 0.98279381 0.97933341 0.98103198 0.98103198\n",
      "  0.98279381 0.97927136 0.97575368 0.97756991 0.97756991 0.98103198\n",
      "  0.97927136 0.97580759 0.98097741 0.97052769 0.96873234 0.97927136\n",
      "  0.97580759 0.97228649 0.97927136 0.97580759 0.96877004 0.97575368\n",
      "  0.97751193 0.97404645 0.97922088 0.97404645 0.97228649 0.96877004\n",
      "  0.97751193 0.9722407  0.98097741 0.98444288 0.97228649 0.97399661\n",
      "  0.98093446 0.97575368 0.97399661 0.97575368 0.97048595 0.97395837\n",
      "  0.97048595 0.9530014  0.9722407  0.9809032  0.96873234 1.\n",
      "  0.97045582 0.96347827 0.96346431 0.95999872 0.95679744 0.96697986\n",
      "  0.96172914 0.96695783 0.95999868]\n",
      " [0.97397025 0.95884502 0.98115732 0.97408198 0.9741551  0.97055137\n",
      "  0.95615245 0.96614865 0.98284719 0.96587374 0.97099041 0.98115732\n",
      "  0.97931288 0.97433554 0.97584903 0.97938669 0.96168947 0.98115732\n",
      "  0.97444273 0.98115732 0.96732196 0.97761727 0.97947196 0.97938669\n",
      "  0.98115732 0.98115732 0.96564319 0.98115732 0.9655447  0.97938669\n",
      "  0.97761727 0.98115732 0.97087998 0.98115732 0.98115732 0.9724657\n",
      "  0.98115732 0.98115732 0.97433554 0.98115732 0.98107943 0.97761727\n",
      "  0.98115732 0.98115732 0.98115732 0.97938669 0.98115732 0.97584903\n",
      "  0.98107943 0.97938669 0.98115732 0.97938669 0.97761727 0.97938669\n",
      "  0.98115732 0.98115732 0.98115732 0.98115732 0.97938669 0.98115732\n",
      "  0.98115732 0.97938669 0.98115732 0.98115732 0.97938669 0.97938669\n",
      "  0.97938669 0.98115732 0.98115732 0.97938669 0.98115732 0.98115732\n",
      "  0.98115732 0.98115732 0.97938669 0.97402034 0.98115732 0.97938669\n",
      "  0.98115732 0.97938669 0.97761727 0.97938669 0.97938669 0.98115732\n",
      "  0.97938669 0.98107943 0.97938669 0.98115732 0.97423964 0.97761727\n",
      "  0.98115732 0.98115732 0.97761727 0.97938669 0.98115732 0.98115732\n",
      "  0.97938669 0.97938669 0.98115732 0.98115732 0.98115732 0.97408198\n",
      "  0.97761727 0.98115732 0.98115732 0.9845416  0.98284719 0.97931288\n",
      "  0.97938669 0.97584903 0.98115732 0.98115732 0.97761727 0.97938669\n",
      "  0.97938669 0.97761727 0.97938669 0.98115732 0.97761727 0.97931288\n",
      "  0.97925059 0.97931288 0.97938669 0.97931288 0.97584903 0.98115732\n",
      "  0.97754752 0.98101307 0.97761727 0.97931288 0.98277673 0.97938669\n",
      "  0.98618509 0.97938669 0.97938669 0.97761727 0.97938669 0.97931288\n",
      "  0.97584903 0.98107943 0.97938669 0.98284719 0.97754752 0.97584903\n",
      "  0.98284719 0.98107943 0.97761727 0.97238518 0.97761727 0.97578334\n",
      "  0.97584903 0.98101307 0.97761727 0.97761727 0.98277673 0.97584903\n",
      "  0.97761727 0.97408198 0.97055137 0.97584903 0.97931288 0.97584903\n",
      "  0.97408198 0.97754752 0.97231609 0.9687878  0.9635039  0.97408198\n",
      "  0.97754752 0.97402034 0.97408198 0.97754752 0.97744269 0.97748931\n",
      "  0.97578334 0.97231609 0.97055137 0.97925059 0.97055137 0.96702537\n",
      "  0.97231609 0.97744269 0.97925059 0.97578334 0.98095828 0.9757292\n",
      "  0.9791999  0.97748931 0.9722585  0.97402034 0.96873827 0.97221246\n",
      "  0.97568666 0.95819062 0.98091514 0.96526407 0.96697986 0.97045582\n",
      "  1.         0.95823    0.96168947 0.94430465 0.95160208 0.96522258\n",
      "  0.95995737 0.96171134 0.95120566]\n",
      " [0.96701546 0.9588924  0.97774752 0.97410339 0.9707228  0.96708458\n",
      "  0.95281405 0.96279101 0.97596745 0.96248594 0.96414449 0.97774752\n",
      "  0.97587826 0.974393   0.97241083 0.97596745 0.95465446 0.97774752\n",
      "  0.97105627 0.97774752 0.96736028 0.97418855 0.97606802 0.97596745\n",
      "  0.97774752 0.97774752 0.96222496 0.97774752 0.9690393  0.97596745\n",
      "  0.97418855 0.97774752 0.97093387 0.97774752 0.97774752 0.9690393\n",
      "  0.97774752 0.97774752 0.97093387 0.97774752 0.97418855 0.97418855\n",
      "  0.97774752 0.97774752 0.97774752 0.97596745 0.97774752 0.97241083\n",
      "  0.97418855 0.97596745 0.97774752 0.97596745 0.97418855 0.97943152\n",
      "  0.97774752 0.97774752 0.97774752 0.97774752 0.97596745 0.97774752\n",
      "  0.97774752 0.97596745 0.97774752 0.97774752 0.97596745 0.97596745\n",
      "  0.97596745 0.97774752 0.97774752 0.97596745 0.97774752 0.97774752\n",
      "  0.97774752 0.97774752 0.97596745 0.97055714 0.97774752 0.97596745\n",
      "  0.97774752 0.97596745 0.97418855 0.97596745 0.97596745 0.97774752\n",
      "  0.97943152 0.97418855 0.97596745 0.97774752 0.97082269 0.97418855\n",
      "  0.97774752 0.97774752 0.9776543  0.97596745 0.97774752 0.97774752\n",
      "  0.97596745 0.97596745 0.97774752 0.97774752 0.97774752 0.97063426\n",
      "  0.97418855 0.97774752 0.97774752 0.97418855 0.97596745 0.97241083\n",
      "  0.97596745 0.97934569 0.97774752 0.97774752 0.97418855 0.97596745\n",
      "  0.97596745 0.97418855 0.97596745 0.97774752 0.97418855 0.97934569\n",
      "  0.96885885 0.97241083 0.97596745 0.97241083 0.98281312 0.97774752\n",
      "  0.97063426 0.97063426 0.9776543  0.97587826 0.97587826 0.97596745\n",
      "  0.97232969 0.97596745 0.97596745 0.97418855 0.97596745 0.97241083\n",
      "  0.97934569 0.9776543  0.97596745 0.97596745 0.97410339 0.97241083\n",
      "  0.97596745 0.97418855 0.97418855 0.9689434  0.97418855 0.96885885\n",
      "  0.97241083 0.97063426 0.9776543  0.97418855 0.97241083 0.97934569\n",
      "  0.97418855 0.97410339 0.96708458 0.97241083 0.97587826 0.97587826\n",
      "  0.97063426 0.97063426 0.96885885 0.96531144 0.96347827 0.97410339\n",
      "  0.97063426 0.96708458 0.97063426 0.97063426 0.96353943 0.96708458\n",
      "  0.96885885 0.96885885 0.97402969 0.96885885 0.97402969 0.96701546\n",
      "  0.97580052 0.97049149 0.97232969 0.96885885 0.96708458 0.9757343\n",
      "  0.96531144 0.97055714 0.96878573 0.96708458 0.96176852 0.96524631\n",
      "  0.96524631 0.9476401  0.96701546 0.9687241  0.96347827 0.96347827\n",
      "  0.95823    1.         0.96512022 0.94772594 0.95160624 0.96171134\n",
      "  0.95641707 0.96166569 0.94760042]\n",
      " [0.97049695 0.95202929 0.97434252 0.96719117 0.96729517 0.96709852\n",
      "  0.94948028 0.95943809 0.97255295 0.9625607  0.96421506 0.97434252\n",
      "  0.97591941 0.96753692 0.96897729 0.97602065 0.96158537 0.97434252\n",
      "  0.96767457 0.97434252 0.96394439 0.97076454 0.97266887 0.97602065\n",
      "  0.97434252 0.97434252 0.9588113  0.97434252 0.96214984 0.97255295\n",
      "  0.97423392 0.97434252 0.96407417 0.97434252 0.97434252 0.97255295\n",
      "  0.97434252 0.97434252 0.96753692 0.97434252 0.97423392 0.97423392\n",
      "  0.97434252 0.97434252 0.97434252 0.97602065 0.97434252 0.96897729\n",
      "  0.97423392 0.97602065 0.97434252 0.97255295 0.97076454 0.97255295\n",
      "  0.97434252 0.97434252 0.97434252 0.97434252 0.97602065 0.97434252\n",
      "  0.97434252 0.97255295 0.97434252 0.97434252 0.97602065 0.97602065\n",
      "  0.97255295 0.97434252 0.97434252 0.97255295 0.97434252 0.97434252\n",
      "  0.97434252 0.97434252 0.97255295 0.97057472 0.97434252 0.97255295\n",
      "  0.97434252 0.97255295 0.97423392 0.97255295 0.97602065 0.97434252\n",
      "  0.97255295 0.97076454 0.97255295 0.97434252 0.97087648 0.97770329\n",
      "  0.97434252 0.97434252 0.97076454 0.97602065 0.97434252 0.97434252\n",
      "  0.97255295 0.97255295 0.97434252 0.97434252 0.97434252 0.96719117\n",
      "  0.97423392 0.97434252 0.97434252 0.97076454 0.97255295 0.96897729\n",
      "  0.97602065 0.97591941 0.97434252 0.97434252 0.97076454 0.97602065\n",
      "  0.97602065 0.97423392 0.97602065 0.97434252 0.97423392 0.97591941\n",
      "  0.96540619 0.97591941 0.97255295 0.97244835 0.97591941 0.97434252\n",
      "  0.96719117 0.96719117 0.97423392 0.97591941 0.97244835 0.97255295\n",
      "  0.97235513 0.97602065 0.97602065 0.97423392 0.97255295 0.97591941\n",
      "  0.97244835 0.97423392 0.97602065 0.97255295 0.96719117 0.97244835\n",
      "  0.97255295 0.97076454 0.97423392 0.96550622 0.97076454 0.97235513\n",
      "  0.96897729 0.97413669 0.97076454 0.97423392 0.97244835 0.97591941\n",
      "  0.97076454 0.97413669 0.96362233 0.97244835 0.97244835 0.96897729\n",
      "  0.96719117 0.97066393 0.96540619 0.96531751 0.95649791 0.97066393\n",
      "  0.96719117 0.96709852 0.96719117 0.96719117 0.96005794 0.96709852\n",
      "  0.97235513 0.96540619 0.97057472 0.96540619 0.96709852 0.96005794\n",
      "  0.96888066 0.96353761 0.96888066 0.96888066 0.96709852 0.97575129\n",
      "  0.96879543 0.96709852 0.96531751 0.96362233 0.95827738 0.96872167\n",
      "  0.96524024 0.94756697 0.96701728 0.96175881 0.95998111 0.96346431\n",
      "  0.96168947 0.96512022 1.         0.93721153 0.94467985 0.95820449\n",
      "  0.95637144 0.95465446 0.9404957 ]\n",
      " [0.95658736 0.94851989 0.96389786 0.96022688 0.96379131 0.95319436\n",
      "  0.93904648 0.94899901 0.96211115 0.95212307 0.95032092 0.96389786\n",
      "  0.9585411  0.96055648 0.9585411  0.96211115 0.9441887  0.96389786\n",
      "  0.95723271 0.96389786 0.96043545 0.96725706 0.96222496 0.96211115\n",
      "  0.96389786 0.96389786 0.94838189 0.96389786 0.96211115 0.96557522\n",
      "  0.96032556 0.96389786 0.95709735 0.96389786 0.96389786 0.95171892\n",
      "  0.96389786 0.96389786 0.95709735 0.96389786 0.96032556 0.96379131\n",
      "  0.96389786 0.96389786 0.96389786 0.96211115 0.96389786 0.9585411\n",
      "  0.96032556 0.96211115 0.96389786 0.96211115 0.96379131 0.96557522\n",
      "  0.96389786 0.96389786 0.96389786 0.96389786 0.96211115 0.96389786\n",
      "  0.96389786 0.96211115 0.96389786 0.96389786 0.96211115 0.96211115\n",
      "  0.96557522 0.96389786 0.96389786 0.96557522 0.96389786 0.96389786\n",
      "  0.96389786 0.96389786 0.96211115 0.95319436 0.96389786 0.96211115\n",
      "  0.96389786 0.96557522 0.96032556 0.96211115 0.96211115 0.96389786\n",
      "  0.96211115 0.96032556 0.96211115 0.96389786 0.95697303 0.96032556\n",
      "  0.96389786 0.96389786 0.96725706 0.96211115 0.96389786 0.96389786\n",
      "  0.96557522 0.96211115 0.96389786 0.96389786 0.96389786 0.97063426\n",
      "  0.96379131 0.96389786 0.96389786 0.96032556 0.96211115 0.96200853\n",
      "  0.96211115 0.9585411  0.96389786 0.96389786 0.96725706 0.96211115\n",
      "  0.96211115 0.96379131 0.96211115 0.96389786 0.96032556 0.9585411\n",
      "  0.95497551 0.9585411  0.96211115 0.9585411  0.9585411  0.96389786\n",
      "  0.95675776 0.95675776 0.96032556 0.9585411  0.9585411  0.96211115\n",
      "  0.95497551 0.96211115 0.96211115 0.96032556 0.96557522 0.9585411\n",
      "  0.96200853 0.96032556 0.96211115 0.96211115 0.95675776 0.9585411\n",
      "  0.96211115 0.96032556 0.96032556 0.9585411  0.96032556 0.96191718\n",
      "  0.9585411  0.95675776 0.96379131 0.96032556 0.9585411  0.96200853\n",
      "  0.96725706 0.95675776 0.95319436 0.96200853 0.9585411  0.96547596\n",
      "  0.96022688 0.95675776 0.96191718 0.95488858 0.9530396  0.96022688\n",
      "  0.95675776 0.95666692 0.96022688 0.95675776 0.9496353  0.95666692\n",
      "  0.95844635 0.95844635 0.95666692 0.95497551 0.95319436 0.95311133\n",
      "  0.95844635 0.95658736 0.95844635 0.95497551 0.95319436 0.95141429\n",
      "  0.95141429 0.95666692 0.95488858 0.95666692 0.95133516 0.94785737\n",
      "  0.94785737 0.93367096 0.9496353  0.95481294 0.94608049 0.95999872\n",
      "  0.94430465 0.94772594 0.93721153 1.         0.97934569 0.96519268\n",
      "  0.9703641  0.9721205  0.96859945]\n",
      " [0.96026382 0.9484512  0.97073066 0.97066203 0.97069062 0.96027965\n",
      "  0.94558159 0.955613   0.96898587 0.9554143  0.95709077 0.97073066\n",
      "  0.96549987 0.9638986  0.96549987 0.96898587 0.94467985 0.97073066\n",
      "  0.96396783 0.97073066 0.9603956  0.97413895 0.96903328 0.96898587\n",
      "  0.97073066 0.97073066 0.95870313 0.97073066 0.96209253 0.96898587\n",
      "  0.96724228 0.97073066 0.96045685 0.97073066 0.97073066 0.95864585\n",
      "  0.97073066 0.97073066 0.9638986  0.97073066 0.96724228 0.96724228\n",
      "  0.97073066 0.97073066 0.97073066 0.96898587 0.97073066 0.96549987\n",
      "  0.96724228 0.96898587 0.97073066 0.96898587 0.97069062 0.96898587\n",
      "  0.97073066 0.97073066 0.97073066 0.97073066 0.96898587 0.97073066\n",
      "  0.97073066 0.96898587 0.97073066 0.97073066 0.96898587 0.96898587\n",
      "  0.96898587 0.97073066 0.97073066 0.96898587 0.97073066 0.97073066\n",
      "  0.97073066 0.97073066 0.96898587 0.96027965 0.97073066 0.96898587\n",
      "  0.97073066 0.96898587 0.96724228 0.96898587 0.96898587 0.97073066\n",
      "  0.96898587 0.96724228 0.96898587 0.97073066 0.96384062 0.96724228\n",
      "  0.97073066 0.97073066 0.97069062 0.96898587 0.97073066 0.97073066\n",
      "  0.97243255 0.96898587 0.97073066 0.97073066 0.97073066 0.97756544\n",
      "  0.96724228 0.97073066 0.97073066 0.96724228 0.96898587 0.96549987\n",
      "  0.96898587 0.96549987 0.97073066 0.97073066 0.97069062 0.96898587\n",
      "  0.96898587 0.96724228 0.96898587 0.97073066 0.96724228 0.96549987\n",
      "  0.96201856 0.96549987 0.96898587 0.96894988 0.96549987 0.97073066\n",
      "  0.96375863 0.96375863 0.97069062 0.96549987 0.96549987 0.96898587\n",
      "  0.96201856 0.96898587 0.96898587 0.96724228 0.97243255 0.96549987\n",
      "  0.96549987 0.96724228 0.96898587 0.96898587 0.96375863 0.96549987\n",
      "  0.96898587 0.96724228 0.96724228 0.96549987 0.96724228 0.96201856\n",
      "  0.96549987 0.96375863 0.96724228 0.96724228 0.96549987 0.96549987\n",
      "  0.96724228 0.96375863 0.96027965 0.96549987 0.96549987 0.96894988\n",
      "  0.96375863 0.96375863 0.96201856 0.95854188 0.95333536 0.96375863\n",
      "  0.96375863 0.96027965 0.96375863 0.96375863 0.95680525 0.96027965\n",
      "  0.96547196 0.96547196 0.96373476 0.96201856 0.96027965 0.96372239\n",
      "  0.96201856 0.96372239 0.96201856 0.96201856 0.96027965 0.95854188\n",
      "  0.95854188 0.96718987 0.95854188 0.96027965 0.95506975 0.95506975\n",
      "  0.95853006 0.94122514 0.95680525 0.95506975 0.95333536 0.95679744\n",
      "  0.95160208 0.95160624 0.94467985 0.97934569 1.         0.96199363\n",
      "  0.97416272 0.97587826 0.96218617]\n",
      " [0.97397025 0.96229896 0.98115732 0.97408198 0.97761727 0.97055137\n",
      "  0.95615245 0.96614865 0.98284719 0.96587374 0.97099041 0.98115732\n",
      "  0.97931288 0.97433554 0.97584903 0.97938669 0.96168947 0.98115732\n",
      "  0.97444273 0.98115732 0.96732196 0.98107943 0.97947196 0.97938669\n",
      "  0.98115732 0.98115732 0.962186   0.98115732 0.9690052  0.97938669\n",
      "  0.97761727 0.98115732 0.97087998 0.98115732 0.98115732 0.9690052\n",
      "  0.98115732 0.98115732 0.97433554 0.98115732 0.98107943 0.97761727\n",
      "  0.98115732 0.98115732 0.98115732 0.97938669 0.98115732 0.97584903\n",
      "  0.98107943 0.97938669 0.98115732 0.97938669 0.97761727 0.97938669\n",
      "  0.98115732 0.98115732 0.98115732 0.98115732 0.97938669 0.98115732\n",
      "  0.98115732 0.97938669 0.98115732 0.98115732 0.97938669 0.97938669\n",
      "  0.98284719 0.98115732 0.98115732 0.97938669 0.98115732 0.98115732\n",
      "  0.98115732 0.98115732 0.97938669 0.97402034 0.98115732 0.97938669\n",
      "  0.98115732 0.98284719 0.97761727 0.97938669 0.97938669 0.98115732\n",
      "  0.97938669 0.98107943 0.97938669 0.98115732 0.97423964 0.97761727\n",
      "  0.98115732 0.98115732 0.97761727 0.97938669 0.98115732 0.98115732\n",
      "  0.97938669 0.97938669 0.98115732 0.98115732 0.98115732 0.98447861\n",
      "  0.97761727 0.98115732 0.98115732 0.97761727 0.98284719 0.97931288\n",
      "  0.97938669 0.97584903 0.98115732 0.98115732 0.98107943 0.97938669\n",
      "  0.97938669 0.97761727 0.97938669 0.98115732 0.97761727 0.97584903\n",
      "  0.97231609 0.97584903 0.97938669 0.97931288 0.97931288 0.98115732\n",
      "  0.97754752 0.97754752 0.97761727 0.97931288 0.97584903 0.97938669\n",
      "  0.97925059 0.97938669 0.97938669 0.97761727 0.97938669 0.97584903\n",
      "  0.97584903 0.97761727 0.97938669 0.98284719 0.97754752 0.97584903\n",
      "  0.97938669 0.98107943 0.98107943 0.97238518 0.97761727 0.97925059\n",
      "  0.97584903 0.97408198 0.97761727 0.97761727 0.97931288 0.97931288\n",
      "  0.97761727 0.97408198 0.97055137 0.97931288 0.97931288 0.97584903\n",
      "  0.97408198 0.97408198 0.97578334 0.9722585  0.96697986 0.97408198\n",
      "  0.97408198 0.98095828 0.97408198 0.97408198 0.96702537 0.97055137\n",
      "  0.97578334 0.97578334 0.97402034 0.97231609 0.97055137 0.96702537\n",
      "  0.97925059 0.97397025 0.97231609 0.97231609 0.97055137 0.9722585\n",
      "  0.9687878  0.97402034 0.9791999  0.97055137 0.96526407 0.96873827\n",
      "  0.96526407 0.95470194 0.97049781 0.96526407 0.97393179 0.96697986\n",
      "  0.96522258 0.96171134 0.95820449 0.96519268 0.96199363 1.\n",
      "  0.9808563  0.97215536 0.97567922]\n",
      " [0.97223167 0.95719084 0.97604443 0.96891215 0.97594352 0.96535289\n",
      "  0.95114659 0.96111396 0.97772549 0.96424988 0.96936483 0.97604443\n",
      "  0.97763196 0.96923481 0.97069348 0.97772549 0.95288103 0.97604443\n",
      "  0.96936483 0.97604443 0.96911598 0.97941107 0.97436785 0.97772549\n",
      "  0.97604443 0.97604443 0.96051756 0.97604443 0.96386196 0.97425961\n",
      "  0.97594352 0.97604443 0.96577388 0.97604443 0.97604443 0.96386196\n",
      "  0.97604443 0.97604443 0.96923481 0.97604443 0.97941107 0.97594352\n",
      "  0.97604443 0.97604443 0.97604443 0.97772549 0.97604443 0.97069348\n",
      "  0.97941107 0.97772549 0.97604443 0.97425961 0.97594352 0.97425961\n",
      "  0.97604443 0.97604443 0.97604443 0.97604443 0.97772549 0.97604443\n",
      "  0.97604443 0.97425961 0.97604443 0.97604443 0.97772549 0.97772549\n",
      "  0.97425961 0.97604443 0.97604443 0.97425961 0.97604443 0.97604443\n",
      "  0.97604443 0.97604443 0.97425961 0.97230163 0.97604443 0.97425961\n",
      "  0.97604443 0.97425961 0.97594352 0.97425961 0.97772549 0.97604443\n",
      "  0.97425961 0.97594352 0.97425961 0.97604443 0.9725802  0.97594352\n",
      "  0.97604443 0.97604443 0.97594352 0.97772549 0.97604443 0.97604443\n",
      "  0.97772549 0.97425961 0.97604443 0.97604443 0.97604443 0.98279589\n",
      "  0.97594352 0.97604443 0.97604443 0.97247596 0.97772549 0.97069348\n",
      "  0.97772549 0.97069348 0.97604443 0.97604443 0.97941107 0.97772549\n",
      "  0.97772549 0.97594352 0.97772549 0.97604443 0.97247596 0.97069348\n",
      "  0.96713195 0.97069348 0.97425961 0.97416272 0.97416272 0.97604443\n",
      "  0.97238308 0.96891215 0.97247596 0.97763196 0.97069348 0.97425961\n",
      "  0.97407725 0.97772549 0.97772549 0.97594352 0.97772549 0.97069348\n",
      "  0.97069348 0.97247596 0.97772549 0.97772549 0.96891215 0.97416272\n",
      "  0.97425961 0.97594352 0.97941107 0.96722424 0.97247596 0.9706046\n",
      "  0.97069348 0.97238308 0.97247596 0.97594352 0.97069348 0.97763196\n",
      "  0.97247596 0.97238308 0.96535289 0.97416272 0.97763196 0.97416272\n",
      "  0.96891215 0.97238308 0.9706046  0.97052716 0.95824777 0.97238308\n",
      "  0.97238308 0.97925036 0.96891215 0.96891215 0.96527597 0.96882726\n",
      "  0.9706046  0.9706046  0.96882726 0.9706046  0.96535289 0.96527597\n",
      "  0.9706046  0.96527597 0.96713195 0.96713195 0.96882726 0.96705106\n",
      "  0.96357496 0.97230163 0.97400326 0.96535289 0.96350201 0.97046121\n",
      "  0.96698161 0.94585506 0.96527597 0.96350201 0.96521051 0.96172914\n",
      "  0.95995737 0.95641707 0.95637144 0.9703641  0.97416272 0.9808563\n",
      "  1.         0.98431112 0.97731429]\n",
      " [0.97396752 0.9588924  0.97774752 0.97063426 0.9776543  0.96708458\n",
      "  0.95281405 0.96279101 0.97943152 0.96248594 0.96760038 0.97774752\n",
      "  0.97934569 0.974393   0.97241083 0.97596745 0.95814305 0.97774752\n",
      "  0.97105627 0.97774752 0.97082269 0.98112005 0.97606802 0.97596745\n",
      "  0.97774752 0.97774752 0.95876419 0.97774752 0.9690393  0.97596745\n",
      "  0.97418855 0.97774752 0.97093387 0.97774752 0.97774752 0.9690393\n",
      "  0.97774752 0.97774752 0.97093387 0.97774752 0.9776543  0.97418855\n",
      "  0.97774752 0.97774752 0.97774752 0.97596745 0.97774752 0.97241083\n",
      "  0.9776543  0.97596745 0.97774752 0.97596745 0.98112005 0.97943152\n",
      "  0.97774752 0.97774752 0.97774752 0.97774752 0.97596745 0.97774752\n",
      "  0.97774752 0.97596745 0.97774752 0.97774752 0.97596745 0.97596745\n",
      "  0.97596745 0.97774752 0.97774752 0.97596745 0.97774752 0.97774752\n",
      "  0.97774752 0.97774752 0.97596745 0.97055714 0.97774752 0.97596745\n",
      "  0.97774752 0.97596745 0.97418855 0.97596745 0.97596745 0.97774752\n",
      "  0.97596745 0.9776543  0.97596745 0.97774752 0.97082269 0.97418855\n",
      "  0.97774752 0.97774752 0.98112005 0.97596745 0.97774752 0.97774752\n",
      "  0.97943152 0.97943152 0.97774752 0.97774752 0.97774752 0.98451077\n",
      "  0.97418855 0.97774752 0.97774752 0.97418855 0.97943152 0.97241083\n",
      "  0.97596745 0.97587826 0.97774752 0.97774752 0.9776543  0.97596745\n",
      "  0.97596745 0.97418855 0.97596745 0.97774752 0.97418855 0.97587826\n",
      "  0.96885885 0.97241083 0.97596745 0.97587826 0.97587826 0.97774752\n",
      "  0.97410339 0.97063426 0.9776543  0.97934569 0.97587826 0.97596745\n",
      "  0.97232969 0.97596745 0.97596745 0.97418855 0.97943152 0.97241083\n",
      "  0.98281312 0.9776543  0.97596745 0.97943152 0.97063426 0.97241083\n",
      "  0.97596745 0.9776543  0.97418855 0.96547596 0.97418855 0.96885885\n",
      "  0.97241083 0.97063426 0.97418855 0.97418855 0.97241083 0.97587826\n",
      "  0.97418855 0.97063426 0.97055714 0.97241083 0.97587826 0.97934569\n",
      "  0.97063426 0.97063426 0.96885885 0.96531144 0.96347827 0.97410339\n",
      "  0.97063426 0.97055714 0.97063426 0.97063426 0.96701546 0.96708458\n",
      "  0.97232969 0.97232969 0.97055714 0.96885885 0.96708458 0.96353943\n",
      "  0.96885885 0.97049149 0.97232969 0.96885885 0.96708458 0.96531144\n",
      "  0.96531144 0.97055714 0.97226002 0.96708458 0.96176852 0.96176852\n",
      "  0.96176852 0.95113239 0.96701546 0.96524631 0.96347827 0.96695783\n",
      "  0.96171134 0.96166569 0.95465446 0.9721205  0.97587826 0.97215536\n",
      "  0.98431112 1.         0.97559912]\n",
      " [0.96360302 0.95225568 0.9641555  0.95688889 0.96400057 0.95326207\n",
      "  0.93950607 0.9494069  0.96581609 0.9489805  0.9540866  0.9641555\n",
      "  0.96218617 0.96084761 0.95870391 0.9623372  0.9475027  0.9641555\n",
      "  0.95755727 0.9641555  0.96067828 0.96748114 0.96249935 0.9623372\n",
      "  0.9641555  0.9641555  0.94512153 0.9641555  0.95885832 0.96581609\n",
      "  0.96400057 0.9641555  0.95737369 0.9641555  0.9641555  0.95190054\n",
      "  0.9641555  0.9641555  0.95737369 0.9641555  0.96400057 0.96400057\n",
      "  0.9641555  0.9641555  0.9641555  0.9623372  0.9641555  0.95870391\n",
      "  0.96400057 0.9623372  0.9641555  0.9623372  0.96400057 0.96581609\n",
      "  0.9641555  0.9641555  0.9641555  0.9641555  0.9623372  0.9641555\n",
      "  0.9641555  0.9623372  0.9641555  0.9641555  0.9623372  0.9623372\n",
      "  0.9623372  0.9641555  0.9641555  0.96581609 0.9641555  0.9641555\n",
      "  0.9641555  0.9641555  0.9623372  0.95674947 0.9641555  0.9623372\n",
      "  0.9641555  0.96581609 0.96052001 0.9623372  0.9623372  0.9641555\n",
      "  0.9623372  0.96400057 0.9623372  0.9641555  0.95720106 0.96052001\n",
      "  0.9641555  0.9641555  0.96748114 0.9623372  0.9641555  0.9641555\n",
      "  0.96581609 0.9623372  0.9641555  0.9641555  0.9641555  0.97082473\n",
      "  0.96052001 0.9641555  0.9641555  0.96400057 0.96581609 0.96566842\n",
      "  0.9623372  0.95870391 0.9641555  0.9641555  0.96400057 0.9623372\n",
      "  0.9623372  0.96400057 0.9623372  0.9641555  0.96052001 0.95870391\n",
      "  0.95507495 0.95870391 0.9623372  0.96218617 0.96218617 0.9641555\n",
      "  0.96037285 0.96037285 0.96052001 0.96218617 0.96218617 0.9623372\n",
      "  0.9620463  0.9623372  0.9623372  0.96052001 0.96581609 0.95870391\n",
      "  0.96218617 0.96400057 0.9623372  0.96581609 0.96037285 0.95870391\n",
      "  0.9623372  0.96400057 0.96400057 0.95522165 0.96052001 0.9620463\n",
      "  0.95870391 0.95688889 0.96400057 0.96052001 0.96218617 0.96566842\n",
      "  0.96400057 0.95688889 0.95326207 0.96218617 0.96218617 0.96566842\n",
      "  0.96037285 0.95688889 0.9620463  0.95493938 0.95300982 0.96037285\n",
      "  0.95688889 0.96023687 0.96037285 0.95688889 0.94963944 0.95674947\n",
      "  0.95856062 0.9620463  0.95674947 0.95507495 0.95326207 0.94963944\n",
      "  0.96553197 0.96011213 0.95856062 0.95507495 0.95326207 0.95493938\n",
      "  0.95493938 0.96023687 0.9654068  0.95674947 0.95132234 0.954815\n",
      "  0.95132234 0.93689469 0.95313034 0.95132234 0.95650425 0.95999868\n",
      "  0.95120566 0.94760042 0.9404957  0.96859945 0.96218617 0.97567922\n",
      "  0.97731429 0.97559912 1.        ]]\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#print columns corresponding to each key in cluster_id_to_feature_ids\n",
    "for key in cluster_id_to_feature_ids.keys():\n",
    "    if 'GC_00001531' in [gene_cluster_presence_absence.columns[i] for i in cluster_id_to_feature_ids[key]]:\n",
    "        print (key, [gene_cluster_presence_absence.columns[i] for i in cluster_id_to_feature_ids[key]])\n",
    "        clustered_GCs = [gene_cluster_presence_absence.columns[i] for i in cluster_id_to_feature_ids[key]]\n",
    "    if 'GC_00001292' in [gene_cluster_presence_absence.columns[i] for i in cluster_id_to_feature_ids[key]]:\n",
    "        clustered_GCs2 = [gene_cluster_presence_absence.columns[i] for i in cluster_id_to_feature_ids[key]]\n",
    "\n",
    "\n",
    "cl1 = spearmanr(gene_cluster_presence_absence.loc[:, clustered_GCs]).correlation\n",
    "cl2 = spearmanr(gene_cluster_presence_absence.loc[:, clustered_GCs2]).correlation\n",
    "cl12 = spearmanr(gene_cluster_presence_absence.loc[:, clustered_GCs], gene_cluster_presence_absence.loc[:, clustered_GCs2]).correlation\n",
    "\n",
    "#cl1 and cl2 are highly correlated. this implies that the selection still needs work. both should be high in the list. I have to implement again the \"leave one out\" approach\n",
    "print (cl1.shape)\n",
    "print (cl2.shape)\n",
    "print (cl12.shape)\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print (cl12)\n",
    "\n",
    "#check the importance of GC_00001531 and GC_00001292 in the decision tree\n",
    "print (forest_importances.loc['GC_00001292'])\n",
    "print (forest_importances.loc['GC_00000402'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008 1008 252 252\n",
      "19800 1008 19800 252\n",
      "1.0\n",
      "item\n",
      "GC_00001829    0.029800\n",
      "GC_00001744    0.027851\n",
      "GC_00001929    0.021824\n",
      "GC_00002152    0.020377\n",
      "GC_00002189    0.019661\n",
      "                 ...   \n",
      "GC_00001820    0.001808\n",
      "GC_00004009    0.001759\n",
      "GC_00001089    0.001710\n",
      "GC_00007846    0.001612\n",
      "GC_00000363    0.001547\n",
      "Length: 100, dtype: float64\n",
      "0.009610864231422545\n",
      "25.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "GC_00001935    0.007215\n",
      "GC_00002236    0.007117\n",
      "GC_00001929    0.007055\n",
      "GC_00001294    0.006998\n",
      "GC_00001150    0.006762\n",
      "                 ...   \n",
      "GC_00001335    0.004288\n",
      "GC_00002406    0.004274\n",
      "GC_00005803    0.004268\n",
      "GC_00001958    0.004251\n",
      "GC_00002160    0.004238\n",
      "Length: 100, dtype: float64\n",
      "0.004838763311271672\n",
      "55.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGdCAYAAADzOWwgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1UklEQVR4nO3df1AV973/8dcJP44/iqtI4EAkhhhjNGCaYgrY3Pob8ZbS1ExNasvoXGu0iRCqTlqT24RmWrHpVNNitcaxmqgpmXsTa+7UkmCtJhbxx8mlATXexGijhh/GwEFSelDY7x/5uvXwQwGBc2Cfj5mdcXffu+fzWfnx4rO/HKZpmgIAALCxm/zdAAAAAH8jEAEAANsjEAEAANsjEAEAANsjEAEAANsjEAEAANsjEAEAANsjEAEAANsL9ncD+orm5mZ9/PHHCgsLk8Ph8HdzAABAB5imqYsXLyomJkY33dT+OBCBqIM+/vhjxcbG+rsZAACgC86cOaMRI0a0u55A1EFhYWGSPj+gQ4YM8XNrAABAR9TV1Sk2Ntb6Pd4eAlEHXTlNNmTIEAIRAAB9zPUud+GiagAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHt+DUTr16/X+PHjrWf7pKSk6E9/+pO1fv78+XI4HD5TcnKyzz68Xq+ysrIUERGhwYMHKyMjQ2fPnvWpqampUWZmpgzDkGEYyszMVG1tbW90EQAA9AF+DUQjRozQqlWrdOTIER05ckRTp07VN77xDR09etSqSUtLU0VFhTXt2rXLZx85OTnasWOHCgoKtH//ftXX1ys9PV1NTU1Wzdy5c1VaWqrCwkIVFhaqtLRUmZmZvdZPAAAQ2BymaZr+bsTVwsPD9Ytf/EILFizQ/PnzVVtbqz/84Q9t1no8Ht18883aunWrHnroIUn/eufYrl27NHPmTB0/flzjxo1TSUmJkpKSJEklJSVKSUnRe++9pzFjxnSoXXV1dTIMQx6PhydVAwDQR3T093fAXEPU1NSkgoICffbZZ0pJSbGW7927V5GRkbrzzju1cOFCVVdXW+vcbrcuXbqk1NRUa1lMTIzi4+NVXFwsSTpw4IAMw7DCkCQlJyfLMAyrpi1er1d1dXU+EwAA6J/8HojKysr0hS98QU6nU4sXL9aOHTs0btw4SdKsWbO0fft27dmzR7/85S91+PBhTZ06VV6vV5JUWVmp0NBQDRs2zGefUVFRqqystGoiIyNbfW5kZKRV05a8vDzrmiPDMHjTPQAA/ZjfX+46ZswYlZaWqra2Vq+++qrmzZunffv2ady4cdZpMEmKj4/XhAkTNHLkSP3xj3/U7Nmz292naZo+L3Fr64VuLWtaWrFihZYuXWrNX3lbLgAA6H/8HohCQ0N1xx13SJImTJigw4cP61e/+pU2bNjQqjY6OlojR47U+++/L0lyuVxqbGxUTU2NzyhRdXW1Jk6caNVUVVW12tf58+cVFRXVbrucTqecTucN9Q3ob7xer9xut8+yxMREvlcA9Hl+P2XWkmma1imxli5cuKAzZ84oOjpa0uc/iENCQlRUVGTVVFRUqLy83ApEKSkp8ng8OnTokFVz8OBBeTweqwZAx7jdbmWv26mnd5br6Z3lyl63s1VAAoC+yK8jRE8++aRmzZql2NhYXbx4UQUFBdq7d68KCwtVX1+v3NxcPfjgg4qOjtbp06f15JNPKiIiQt/85jclSYZhaMGCBVq2bJmGDx+u8PBwLV++XAkJCZo+fbokaezYsUpLS9PChQutUadHHnlE6enpHb7DDMC/DL1llCJGJfi7GQDQrfwaiKqqqpSZmamKigoZhqHx48ersLBQM2bMUENDg8rKyvTSSy+ptrZW0dHRmjJlil555RWFhYVZ+1izZo2Cg4M1Z84cNTQ0aNq0adqyZYuCgoKsmu3btys7O9u6Gy0jI0Nr167t9f4CAIDAFHDPIQpUPIcIkIqLi/X0znJrhOiTk2V69hvxnH4GELD63HOIAAAA/IVABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbM+vgWj9+vUaP368hgwZoiFDhiglJUV/+tOfrPWmaSo3N1cxMTEaOHCgJk+erKNHj/rsw+v1KisrSxERERo8eLAyMjJ09uxZn5qamhplZmbKMAwZhqHMzEzV1tb2RhcBAEAf4NdANGLECK1atUpHjhzRkSNHNHXqVH3jG9+wQs9zzz2n1atXa+3atTp8+LBcLpdmzJihixcvWvvIycnRjh07VFBQoP3796u+vl7p6elqamqyaubOnavS0lIVFhaqsLBQpaWlyszM7PX+AgCAwOQwTdP0dyOuFh4erl/84hf6j//4D8XExCgnJ0c//OEPJX0+GhQVFaWf//znWrRokTwej26++WZt3bpVDz30kCTp448/VmxsrHbt2qWZM2fq+PHjGjdunEpKSpSUlCRJKikpUUpKit577z2NGTOmQ+2qq6uTYRjyeDwaMmRIz3QeCHDFxcV6eme5IkYlSJI+OVmmZ78Rr4kTJ/q5ZQDQto7+/g6Ya4iamppUUFCgzz77TCkpKTp16pQqKyuVmppq1TidTk2aNEnFxcWSJLfbrUuXLvnUxMTEKD4+3qo5cOCADMOwwpAkJScnyzAMq6YtXq9XdXV1PhMAAOif/B6IysrK9IUvfEFOp1OLFy/Wjh07NG7cOFVWVkqSoqKifOqjoqKsdZWVlQoNDdWwYcOuWRMZGdnqcyMjI62atuTl5VnXHBmGodjY2BvqJwAACFx+D0RjxoxRaWmpSkpK9P3vf1/z5s3TsWPHrPUOh8On3jTNVstaalnTVv319rNixQp5PB5rOnPmTEe7BAAA+hi/B6LQ0FDdcccdmjBhgvLy8nTPPffoV7/6lVwulyS1GsWprq62Ro1cLpcaGxtVU1NzzZqqqqpWn3v+/PlWo09Xczqd1t1vVyYAANA/+T0QtWSaprxer+Li4uRyuVRUVGSta2xs1L59+6wLOBMTExUSEuJTU1FRofLycqsmJSVFHo9Hhw4dsmoOHjwoj8fDhaAAAECSFOzPD3/yySc1a9YsxcbG6uLFiyooKNDevXtVWFgoh8OhnJwcrVy5UqNHj9bo0aO1cuVKDRo0SHPnzpUkGYahBQsWaNmyZRo+fLjCw8O1fPlyJSQkaPr06ZKksWPHKi0tTQsXLtSGDRskSY888ojS09M7fIcZAADo3/waiKqqqpSZmamKigoZhqHx48ersLBQM2bMkCQ98cQTamho0KOPPqqamholJSXpzTffVFhYmLWPNWvWKDg4WHPmzFFDQ4OmTZumLVu2KCgoyKrZvn27srOzrbvRMjIytHbt2t7tLAAACFgB9xyiQMVziACeQwSg7+lzzyECAADwFwIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwvWB/NwBA39V8+ZLKyspaLU9MTJTT6fRDiwCgawhEALqsruoj5Z9ukOtDh7Ws9txJ/fpRaeLEiX5sGQB0DoEIwA0Jc8UpYlSCv5sBADeEa4gAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtBfu7AQACk9frldvt9llWVlam5mY/NQgAepBfR4jy8vJ03333KSwsTJGRkXrggQd04sQJn5r58+fL4XD4TMnJyT41Xq9XWVlZioiI0ODBg5WRkaGzZ8/61NTU1CgzM1OGYcgwDGVmZqq2tranuwj0WW63W9nrdurpneXWtOa1t9Xwj3/4u2kA0O38Goj27dunxx57TCUlJSoqKtLly5eVmpqqzz77zKcuLS1NFRUV1rRr1y6f9Tk5OdqxY4cKCgq0f/9+1dfXKz09XU1NTVbN3LlzVVpaqsLCQhUWFqq0tFSZmZm90k+grxp6yyhFjEqwpi/cfIu/mwQAPcKvp8wKCwt95jdv3qzIyEi53W599atftZY7nU65XK429+HxeLRp0yZt3bpV06dPlyRt27ZNsbGx2r17t2bOnKnjx4+rsLBQJSUlSkpKkiRt3LhRKSkpOnHihMaMGdNDPQQAAH1BQF1U7fF4JEnh4eE+y/fu3avIyEjdeeedWrhwoaqrq611brdbly5dUmpqqrUsJiZG8fHxKi4uliQdOHBAhmFYYUiSkpOTZRiGVQMAAOwrYC6qNk1TS5cu1f3336/4+Hhr+axZs/Stb31LI0eO1KlTp/TjH/9YU6dOldvtltPpVGVlpUJDQzVs2DCf/UVFRamyslKSVFlZqcjIyFafGRkZadW05PV65fV6rfm6urru6CYAAAhAAROIlixZonfffVf79+/3Wf7QQw9Z/46Pj9eECRM0cuRI/fGPf9Ts2bPb3Z9pmnI4HNb81f9ur+ZqeXl5+slPftLZbgAAgD4oIE6ZZWVl6fXXX9df/vIXjRgx4pq10dHRGjlypN5//31JksvlUmNjo2pqanzqqqurFRUVZdVUVVW12tf58+etmpZWrFghj8djTWfOnOlK1wAAQB/g10BkmqaWLFmi1157TXv27FFcXNx1t7lw4YLOnDmj6OhoSVJiYqJCQkJUVFRk1VRUVKi8vFwTJ06UJKWkpMjj8ejQoUNWzcGDB+XxeKyalpxOp4YMGeIzAQCA/smvp8wee+wxvfzyy9q5c6fCwsKs63kMw9DAgQNVX1+v3NxcPfjgg4qOjtbp06f15JNPKiIiQt/85jet2gULFmjZsmUaPny4wsPDtXz5ciUkJFh3nY0dO1ZpaWlauHChNmzYIEl65JFHlJ6ezh1mAADAv4Fo/fr1kqTJkyf7LN+8ebPmz5+voKAglZWV6aWXXlJtba2io6M1ZcoUvfLKKwoLC7Pq16xZo+DgYM2ZM0cNDQ2aNm2atmzZoqCgIKtm+/btys7Otu5Gy8jI0Nq1a3u+kwAAIOD5NRCZpnnN9QMHDtQbb7xx3f0MGDBA+fn5ys/Pb7cmPDxc27Zt63QbAQBA/xcQF1UDAAD4E4EIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYnl8DUV5enu677z6FhYUpMjJSDzzwgE6cOOFTY5qmcnNzFRMTo4EDB2ry5Mk6evSoT43X61VWVpYiIiI0ePBgZWRk6OzZsz41NTU1yszMlGEYMgxDmZmZqq2t7ekuAgCAPsCvgWjfvn167LHHVFJSoqKiIl2+fFmpqan67LPPrJrnnntOq1ev1tq1a3X48GG5XC7NmDFDFy9etGpycnK0Y8cOFRQUaP/+/aqvr1d6erqampqsmrlz56q0tFSFhYUqLCxUaWmpMjMze7W/AAAgMAX788MLCwt95jdv3qzIyEi53W599atflWmaev755/XUU09p9uzZkqQXX3xRUVFRevnll7Vo0SJ5PB5t2rRJW7du1fTp0yVJ27ZtU2xsrHbv3q2ZM2fq+PHjKiwsVElJiZKSkiRJGzduVEpKik6cOKExY8b0bscBAEBACahriDwejyQpPDxcknTq1ClVVlYqNTXVqnE6nZo0aZKKi4slSW63W5cuXfKpiYmJUXx8vFVz4MABGYZhhSFJSk5OlmEYVk1LXq9XdXV1PhMAAOifuhSIbr/9dl24cKHV8traWt1+++1daohpmlq6dKnuv/9+xcfHS5IqKyslSVFRUT61UVFR1rrKykqFhoZq2LBh16yJjIxs9ZmRkZFWTUt5eXnW9UaGYSg2NrZL/QIAAIGvS4Ho9OnTPtfnXOH1enXu3LkuNWTJkiV699139fvf/77VOofD4TNvmmarZS21rGmr/lr7WbFihTwejzWdOXOmI90AAAB9UKeuIXr99detf7/xxhsyDMOab2pq0p///GfddtttnW5EVlaWXn/9db311lsaMWKEtdzlckn6fIQnOjraWl5dXW2NGrlcLjU2NqqmpsZnlKi6uloTJ060aqqqqlp97vnz51uNPl3hdDrldDo73RcAAND3dCoQPfDAA5I+H22ZN2+ez7qQkBDddttt+uUvf9nh/ZmmqaysLO3YsUN79+5VXFycz/q4uDi5XC4VFRXp3nvvlSQ1NjZq3759+vnPfy5JSkxMVEhIiIqKijRnzhxJUkVFhcrLy/Xcc89JklJSUuTxeHTo0CF9+ctfliQdPHhQHo/HCk0AAMC+OhWImpubJX0eVA4fPqyIiIgb+vDHHntML7/8snbu3KmwsDDreh7DMDRw4EA5HA7l5ORo5cqVGj16tEaPHq2VK1dq0KBBmjt3rlW7YMECLVu2TMOHD1d4eLiWL1+uhIQE666zsWPHKi0tTQsXLtSGDRskSY888ojS09O5wwwAAHTttvtTp051y4evX79ekjR58mSf5Zs3b9b8+fMlSU888YQaGhr06KOPqqamRklJSXrzzTcVFhZm1a9Zs0bBwcGaM2eOGhoaNG3aNG3ZskVBQUFWzfbt25WdnW3djZaRkaG1a9d2Sz8AAEDf1uXnEP35z3/Wn//8Z1VXV1sjR1f87ne/69A+TNO8bo3D4VBubq5yc3PbrRkwYIDy8/OVn5/fbk14eLi2bdvWoXYBAAB76VIg+slPfqJnn31WEyZMUHR09HXv+AIAAAhkXQpEv/3tb7VlyxZefQEAAPqFLj2HqLGxkbuzAABAv9GlQPS9731PL7/8cne3BQAAwC+6dMrsn//8p1544QXt3r1b48ePV0hIiM/61atXd0vjAAAAekOXAtG7776rL37xi5Kk8vJyn3VcYA0AAPqaLgWiv/zlL93dDgAAAL/p0jVEAAAA/UmXRoimTJlyzVNje/bs6XKDAAAAeluXAtGV64euuHTpkkpLS1VeXt7qpa8AAACBrkuBaM2aNW0uz83NVX19/Q01CAAAoLd16zVE3/3udzv8HjMAAIBA0a2B6MCBAxowYEB37hIAAKDHdemU2ezZs33mTdNURUWFjhw5oh//+Mfd0jAAAIDe0qVAZBiGz/xNN92kMWPG6Nlnn1Vqamq3NAwAAKC3dCkQbd68ubvbAQAA4DddCkRXuN1uHT9+XA6HQ+PGjdO9997bXe0CAADoNV0KRNXV1Xr44Ye1d+9eDR06VKZpyuPxaMqUKSooKNDNN9/c3e0E0MO8Xq/cbrc1X1ZWpuZmPzYIAHpRl+4yy8rKUl1dnY4ePapPP/1UNTU1Ki8vV11dnbKzs7u7jQB6gdvtVva6nXp6Z7me3lmuNa+9rYZ//MPfzQKAXtGlEaLCwkLt3r1bY8eOtZaNGzdOv/nNb7ioGujDht4yShGjEiRJtedO+rk1ANB7ujRC1NzcrJCQkFbLQ0JC1MwYOwAA6GO6FIimTp2qxx9/XB9//LG17Ny5c/rBD36gadOmdVvjAAAAekOXAtHatWt18eJF3XbbbRo1apTuuOMOxcXF6eLFi8rPz+/uNgIAAPSoLl1DFBsbq3feeUdFRUV67733ZJqmxo0bp+nTp3d3+wAAAHpcp0aI9uzZo3Hjxqmurk6SNGPGDGVlZSk7O1v33Xef7r77br399ts90lAAAICe0qlA9Pzzz2vhwoUaMmRIq3WGYWjRokVavXp1tzUOAACgN3QqEP3tb39TWlpau+tTU1N9HuwGAADQF3QqEFVVVbV5u/0VwcHBOn/+/A03CgAAoDd1KhDdcsstKisra3f9u+++q+jo6BtuFAAAQG/qVCD693//dz399NP65z//2WpdQ0ODnnnmGaWnp3db4wAAAHpDp267/8///E+99tpruvPOO7VkyRKNGTNGDodDx48f129+8xs1NTXpqaee6qm2AgAA9IhOBaKoqCgVFxfr+9//vlasWCHTNCVJDodDM2fO1Lp16xQVFdUjDQUAAOgpnX4w48iRI7Vr1y7V1NTogw8+kGmaGj16tIYNG9YT7QMAAOhxXXpStSQNGzZM9913X3e2BQAAwC+69C4zAACA/oRABAAAbK/Lp8wAoC3Nly+1el5ZYmKinE6nn1oEANdHIALQreqqPlL+6Qa5PnRIkmrPndSvH5UmTpzo55YBQPsIRAC6XZgrThGjEvzdDADoMK4hAgAAtufXQPTWW2/p61//umJiYuRwOPSHP/zBZ/38+fPlcDh8puTkZJ8ar9errKwsRUREaPDgwcrIyNDZs2d9ampqapSZmSnDMGQYhjIzM1VbW9vDvQMAAH2FXwPRZ599pnvuuUdr165ttyYtLU0VFRXWtGvXLp/1OTk52rFjhwoKCrR//37V19crPT1dTU1NVs3cuXNVWlqqwsJCFRYWqrS0VJmZmT3WLwAA0Lf49RqiWbNmadasWdescTqdcrlcba7zeDzatGmTtm7dqunTp0uStm3bptjYWO3evVszZ87U8ePHVVhYqJKSEiUlJUmSNm7cqJSUFJ04cUJjxozp3k4BAIA+J+CvIdq7d68iIyN15513auHChaqurrbWud1uXbp0SampqdaymJgYxcfHq7i4WJJ04MABGYZhhSFJSk5OlmEYVk1bvF6v6urqfCYAANA/BXQgmjVrlrZv3649e/bol7/8pQ4fPqypU6fK6/VKkiorKxUaGtrqPWpRUVGqrKy0aiIjI1vtOzIy0qppS15ennXNkWEYio2N7caeAQCAQBLQt90/9NBD1r/j4+M1YcIEjRw5Un/84x81e/bsdrczTVMOh8Oav/rf7dW0tGLFCi1dutSar6urIxQBANBPBfQIUUvR0dEaOXKk3n//fUmSy+VSY2OjampqfOqqq6sVFRVl1VRVVbXa1/nz562atjidTg0ZMsRnAgAA/VOfCkQXLlzQmTNnFB0dLenz1wGEhISoqKjIqqmoqFB5ebn1VNyUlBR5PB4dOnTIqjl48KA8Hg9PzgUAAJL8fMqsvr5eH3zwgTV/6tQplZaWKjw8XOHh4crNzdWDDz6o6OhonT59Wk8++aQiIiL0zW9+U5JkGIYWLFigZcuWafjw4QoPD9fy5cuVkJBg3XU2duxYpaWlaeHChdqwYYMk6ZFHHlF6ejp3mAEAAEl+DkRHjhzRlClTrPkr1+zMmzdP69evV1lZmV566SXV1tYqOjpaU6ZM0SuvvKKwsDBrmzVr1ig4OFhz5sxRQ0ODpk2bpi1btigoKMiq2b59u7Kzs6270TIyMq757CMAAGAvfg1EkydPlmma7a5/4403rruPAQMGKD8/X/n5+e3WhIeHa9u2bV1qIwAA6P/61DVEAAAAPYFABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbC/Y3w0A0Pu8Xq/cbrfPsrKyMjU3+6lBAOBnBCLAhtxut7LX7dTQW0ZZy86Wvq1hdyT6sVUA4D8EIsCmht4yShGjEqz52nMn/dgaAPAvriECAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC259dA9NZbb+nrX/+6YmJi5HA49Ic//MFnvWmays3NVUxMjAYOHKjJkyfr6NGjPjVer1dZWVmKiIjQ4MGDlZGRobNnz/rU1NTUKDMzU4ZhyDAMZWZmqra2tod7BwAA+gq/BqLPPvtM99xzj9auXdvm+ueee06rV6/W2rVrdfjwYblcLs2YMUMXL160anJycrRjxw4VFBRo//79qq+vV3p6upqamqyauXPnqrS0VIWFhSosLFRpaakyMzN7vH8AAKBv8OurO2bNmqVZs2a1uc40TT3//PN66qmnNHv2bEnSiy++qKioKL388statGiRPB6PNm3apK1bt2r69OmSpG3btik2Nla7d+/WzJkzdfz4cRUWFqqkpERJSUmSpI0bNyolJUUnTpzQmDFjeqezAAAgYAXsNUSnTp1SZWWlUlNTrWVOp1OTJk1ScXGxpM9fUHnp0iWfmpiYGMXHx1s1Bw4ckGEYVhiSpOTkZBmGYdW0xev1qq6uzmcCAAD9U8AGosrKSklSVFSUz/KoqChrXWVlpUJDQzVs2LBr1kRGRrbaf2RkpFXTlry8POuaI8MwFBsbe0P9AQAAgStgA9EVDofDZ940zVbLWmpZ01b99fazYsUKeTweazpz5kwnWw4AAPqKgA1ELpdLklqN4lRXV1ujRi6XS42NjaqpqblmTVVVVav9nz9/vtXo09WcTqeGDBniMwEAgP4pYANRXFycXC6XioqKrGWNjY3at2+fJk6cKElKTExUSEiIT01FRYXKy8utmpSUFHk8Hh06dMiqOXjwoDwej1UDAADsza93mdXX1+uDDz6w5k+dOqXS0lKFh4fr1ltvVU5OjlauXKnRo0dr9OjRWrlypQYNGqS5c+dKkgzD0IIFC7Rs2TINHz5c4eHhWr58uRISEqy7zsaOHau0tDQtXLhQGzZskCQ98sgjSk9P5w4zAAAgyc+B6MiRI5oyZYo1v3TpUknSvHnztGXLFj3xxBNqaGjQo48+qpqaGiUlJenNN99UWFiYtc2aNWsUHBysOXPmqKGhQdOmTdOWLVsUFBRk1Wzfvl3Z2dnW3WgZGRntPvsIAADYj18D0eTJk2WaZrvrHQ6HcnNzlZub227NgAEDlJ+fr/z8/HZrwsPDtW3bthtpKgAA6McC9hoiAACA3kIgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAthfs7wYA6N+aL19SWVlZq+WJiYlyOp1+aBEAtEYgAtCj6qo+Uv7pBrk+dFjLas+d1K8flSZOnOjHlgHAvxCIAPS4MFecIkYl+LsZANAuAhFgA16vV26325ovKytTc7MfGwQAAYZABNiA2+1W9rqdGnrLKEnS2dK3NeyORD+3CgACB4EIsImht4yyTlvVnjvp59YAQGDhtnsAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7AR2IcnNz5XA4fCaXy2WtN01Tubm5iomJ0cCBAzV58mQdPXrUZx9er1dZWVmKiIjQ4MGDlZGRobNnz/Z2VwAAQAAL6EAkSXfffbcqKiqsqayszFr33HPPafXq1Vq7dq0OHz4sl8ulGTNm6OLFi1ZNTk6OduzYoYKCAu3fv1/19fVKT09XU1OTP7oDAAACULC/G3A9wcHBPqNCV5imqeeff15PPfWUZs+eLUl68cUXFRUVpZdfflmLFi2Sx+PRpk2btHXrVk2fPl2StG3bNsXGxmr37t2aOXNmr/YFAAAEpoAfIXr//fcVExOjuLg4Pfzww/rwww8lSadOnVJlZaVSU1OtWqfTqUmTJqm4uFiS5Ha7denSJZ+amJgYxcfHWzUAel/z5UsqKytTcXGxNXm9Xn83C4CNBfQIUVJSkl566SXdeeedqqqq0k9/+lNNnDhRR48eVWVlpSQpKirKZ5uoqCj9/e9/lyRVVlYqNDRUw4YNa1VzZfv2eL1enx/QdXV13dElAJLqqj5S/ukGuT50SJJqz53Urx+VJk6c6OeWAbCrgA5Es2bNsv6dkJCglJQUjRo1Si+++KKSk5MlSQ6Hw2cb0zRbLWupIzV5eXn6yU9+0sWWA7ieMFecIkYl+LsZACCpD5wyu9rgwYOVkJCg999/37quqOVIT3V1tTVq5HK51NjYqJqamnZr2rNixQp5PB5rOnPmTDf2BAAABJI+FYi8Xq+OHz+u6OhoxcXFyeVyqaioyFrf2Nioffv2WcPuiYmJCgkJ8ampqKhQeXn5dYfmnU6nhgwZ4jMBfYHX6/W5Nqe4uFhlZWVqbjb93TQACFgBfcps+fLl+vrXv65bb71V1dXV+ulPf6q6ujrNmzdPDodDOTk5WrlypUaPHq3Ro0dr5cqVGjRokObOnStJMgxDCxYs0LJlyzR8+HCFh4dr+fLlSkhIsO46A/obt9ut7HU7NfSWUdays6Vva9gdiX5sFQAEtoAORGfPntW3v/1tffLJJ7r55puVnJyskpISjRw5UpL0xBNPqKGhQY8++qhqamqUlJSkN998U2FhYdY+1qxZo+DgYM2ZM0cNDQ2aNm2atmzZoqCgIH91C+hxQ28Z5XN9Tu25k35sDQAEvoAORAUFBddc73A4lJubq9zc3HZrBgwYoPz8fOXn53dz6wAAQH/Rp64hAgAA6AkEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsB/WBGAPbQfPmSysrKWi1PTEyU0+n0Q4sA2A2BCIDf1VV9pPzTDXJ96LCW1Z47qV8/quu+iBkAugOBCEBACHPF+bx/DQB6E4EI6OO8Xq/cbrc1X1ZWpuZmPzaom7R1Go1TaAB6CoEI6OPcbrey1+3U0FtGSZLOlr6tYXck+rlVN67laTROoQHoSQQioB8Yesso63RT7bmTfm5N9+E0GoDewm33AADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9rjLDECfwOs9APQkAhHQh7R8CKPUfx7EeD283gNATyIQAX1Iy4cwSv3nQYwdwXOJAPQUAhHQx1z9EEapfz2IEQD8hYuqAQCA7TFCBKDP4gWwALoLgQgIYP31TfbdhRfAAuguBCIggPXXN9l3Jy60BtAdCERAgOuvb7LvCTyrCEBXEYgA9Bs8qwhAVxGIAPQrnEID0BUEIgD9GneiAegIAhEQIOz8Wo6exJ1oADqCQAQECLu/lqMnXX0ajQuvAbSFQAQEEF7L0fPauvD6049OaNHkMiUk/OvYE5AAeyEQAX7CQxf9p+WF17XnTir/zaNWSGorIDU2NkqSQkND25y/giAF9E0EIsBPeOhiYLk6JLUMSJJ0tvQtBX8hXK474tucv7Id1ycBfROBCOgF7V0wPST6dh66GKDaGkUKMVw+/19Xz0utr09qaxSprWWMKgH+RyACekBbp8NeeOukho24w1rGiFD/0/L6pLZGkVoua+v0nERIAnobgQjopLZGe1r+8mrvdBgXTPd/LU+9tRxFamukqeXpuZan3tr6mpMITUB3IhAB19Deqa6rR3va+guf02HojJan51qeemtrhJHQBHQvWwWidevW6Re/+IUqKip099136/nnn9e//du/+btZ6CUdGdlp6VrPBrr2BbicDkPXtT711nqEsSOhiccJAB1nm0D0yiuvKCcnR+vWrdNXvvIVbdiwQbNmzdKxY8d06623+rt5/U5X/1ptuV1Xb23u6shOy89rOdIjtT3a09YFuMCNaHnqraWOhKaeepxAR76/GbFCX2ObQLR69WotWLBA3/ve9yRJzz//vN544w2tX79eeXl5fm5d7+iuH1Ad2U9bIystfxi39YO3ZWhp66LUruzn8311ZGSn5a3VjPQgcF0vNLVV05XHCbT8nuvIaFRHajpyF15H79TrqWDXXQiIgc8WgaixsVFut1s/+tGPfJanpqaquLi4zW28Xq+8Xq817/F4JEl1dXXd3r6DBw92+z7bcvToUeW/+hcNCndZy/7xaaWyHpyiu+++u1v3c/ToUTVd8uqyt8GquVh9Vj/93TENdb0jSbpw+piCBnxBQ13/GqG7cPqYjJF3K+z/b9d0+ZIclxpveD9X9lV75oScITdJkjwVpxU8eJjPvlt+XsttrO3qPL77uWqeGmoCuqYDX/Md+Z5r+f3V1Zq2vnevXtaRmo5u19bPqe74mdgRvflZfVVSUlKP7PfK723TNK9daNrAuXPnTEnmX//6V5/lP/vZz8w777yzzW2eeeYZUxITExMTExNTP5jOnDlzzaxgixGiKxwOh8+8aZqtll2xYsUKLV261Jpvbm7Wp59+quHDh7e7TaCpq6tTbGyszpw5oyFDhvi7OX0Cx6xzOF6dw/HqPI5Z53C8WjNNUxcvXlRMTMw162wRiCIiIhQUFKTKykqf5dXV1YqKimpzG6fT2eq87tChQ3uqiT1qyJAhfGN0EsesczhencPx6jyOWedwvHwZhnHdmpuuW9EPhIaGKjExUUVFRT7Li4qKeOcQAACwxwiRJC1dulSZmZmaMGGCUlJS9MILL+ijjz7S4sWL/d00AADgZ7YJRA899JAuXLigZ599VhUVFYqPj9euXbs0cuRIfzetxzidTj3zzDPc0tkJHLPO4Xh1Dser8zhmncPx6jqHaV7vPjQAAID+zRbXEAEAAFwLgQgAANgegQgAANgegQgAANgegagPqampUWZmpgzDkGEYyszMVG1t7TW3MU1Tubm5iomJ0cCBAzV58mQdPXrUp8br9SorK0sREREaPHiwMjIydPbs2Tb35/V69cUvflEOh0OlpaXd1LOe4a/jdfr0aS1YsEBxcXEaOHCgRo0apWeeecZ62WQgWbduneLi4jRgwAAlJibq7bffvmb9vn37lJiYqAEDBuj222/Xb3/721Y1r776qsaNGyen06lx48Zpx44dN/y5gcIfxysvL0/33XefwsLCFBkZqQceeEAnTpzo1n71FH99fV2Rl5cnh8OhnJycG+1Kr/HXMTt37py++93vavjw4Ro0aJC++MUvtvky2n6tG14Vhl6SlpZmxsfHm8XFxWZxcbEZHx9vpqenX3ObVatWmWFhYearr75qlpWVmQ899JAZHR1t1tXVWTWLFy82b7nlFrOoqMh85513zClTppj33HOPefny5Vb7y87ONmfNmmVKMv/3f/+3u7vYrfx1vP70pz+Z8+fPN9944w3z5MmT5s6dO83IyEhz2bJlPdrfziooKDBDQkLMjRs3mseOHTMff/xxc/Dgwebf//73Nus//PBDc9CgQebjjz9uHjt2zNy4caMZEhJi/vd//7dVU1xcbAYFBZkrV640jx8/bq5cudIMDg42S0pKuvy5gcJfx2vmzJnm5s2bzfLycrO0tNT82te+Zt56661mfX19j/f5RvjreF1x6NAh87bbbjPHjx9vPv744z3VzW7lr2P26aefmiNHjjTnz59vHjx40Dx16pS5e/du84MPPujxPgcSAlEfcezYMVOSzxfxgQMHTEnme++91+Y2zc3NpsvlMletWmUt++c//2kahmH+9re/NU3TNGtra82QkBCzoKDAqjl37px50003mYWFhT7727Vrl3nXXXeZR48eDfhAFAjH62rPPfecGRcXd6Pd6lZf/vKXzcWLF/ssu+uuu8wf/ehHbdY/8cQT5l133eWzbNGiRWZycrI1P2fOHDMtLc2nZubMmebDDz/c5c8NFP46Xi1VV1ebksx9+/Z1tgu9yp/H6+LFi+bo0aPNoqIic9KkSX0mEPnrmP3whz8077///httfp/HKbM+4sCBAzIMQ0lJSday5ORkGYah4uLiNrc5deqUKisrlZqaai1zOp2aNGmStY3b7dalS5d8amJiYhQfH++z36qqKi1cuFBbt27VoEGDurt73c7fx6slj8ej8PDwG+1Wt2lsbJTb7fbphySlpqa2248DBw60qp85c6aOHDmiS5cuXbPmyj678rmBwF/Hqy0ej0eSAurrqSV/H6/HHntMX/va1zR9+vQb7Uqv8ecxe/311zVhwgR961vfUmRkpO69915t3LixO7rVpxCI+ojKykpFRka2Wh4ZGdnqpbVXbyOp1Qtso6KirHWVlZUKDQ3VsGHD2q0xTVPz58/X4sWLNWHChBvuS2/w5/Fq6eTJk8rPzw+o18R88sknampqumZfW6qsrGyz/vLly/rkk0+uWXNln1353EDgr+PVkmmaWrp0qe6//37Fx8d3tTs9zp/Hq6CgQO+8847y8vK6oyu9xp/H7MMPP9T69es1evRovfHGG1q8eLGys7P10ksvdUfX+gwCkZ/l5ubK4XBcczpy5IgkyeFwtNreNM02l1+t5fqObHN1TX5+vurq6rRixYrOdK1H9IXjdbWPP/5YaWlp+ta3vqXvfe971+ter+tsX9uqb7m8I/vsyjEOBP46XlcsWbJE7777rn7/+993qt3+0tvH68yZM3r88ce1bds2DRgw4Iba7i/++Bprbm7Wl770Ja1cuVL33nuvFi1apIULF2r9+vVd7kdfZJt3mQWqJUuW6OGHH75mzW233aZ3331XVVVVrdadP3++Vfq/wuVySfr8L4To6GhreXV1tbWNy+VSY2OjampqfEY9qqurNXHiREnSnj17VFJS0urdOBMmTNB3vvMdvfjiix3oaffoC8frio8//lhTpkyxXiYcSCIiIhQUFNTqL8+r+9qSy+Vqsz44OFjDhw+/Zs2VfXblcwOBv47X1bKysvT666/rrbfe0ogRI26kOz3OX8fL7XarurpaiYmJ1vqmpia99dZbWrt2rbxer4KCgm64fz3Bn19j0dHRGjdunE/N2LFj9eqrr3a5P30RI0R+FhERobvuuuua04ABA5SSkiKPx6NDhw5Z2x48eFAej6fVL+Ir4uLi5HK5VFRUZC1rbGzUvn37rG0SExMVEhLiU1NRUaHy8nKr5te//rX+9re/qbS0VKWlpdq1a5ck6ZVXXtHPfvazbj8m19IXjpf0+S2skydP1pe+9CVt3rxZN90UWN9qoaGhSkxM9OmHJBUVFbV7fFJSUlrVv/nmm5owYYJCQkKuWXNln1353EDgr+Mlff7X/JIlS/Taa69pz549iouL644u9Sh/Ha9p06aprKzM+llVWlpq/eFWWloasGFI8u/X2Fe+8pVWj3L4v//7v3798vM29eYV3LgxaWlp5vjx480DBw6YBw4cMBMSElrdRj5mzBjztddes+ZXrVplGoZhvvbaa2ZZWZn57W9/u83byEeMGGHu3r3bfOedd8ypU6e2e9u9aZrmqVOnAv4uM9P03/E6d+6ceccdd5hTp041z549a1ZUVFhTILlyi++mTZvMY8eOmTk5OebgwYPN06dPm6Zpmj/60Y/MzMxMq/7KLb4/+MEPzGPHjpmbNm1qdYvvX//6VzMoKMhctWqVefz4cXPVqlXt3nbf3ucGKn8dr+9///umYRjm3r17fb6W/vGPf/Re57vAX8erpb50l5m/jtmhQ4fM4OBg82c/+5n5/vvvm9u3bzcHDRpkbtu2rfc6HwAIRH3IhQsXzO985ztmWFiYGRYWZn7nO98xa2pqfGokmZs3b7bmm5ubzWeeecZ0uVym0+k0v/rVr5plZWU+2zQ0NJhLliwxw8PDzYEDB5rp6enmRx991G47+kog8tfx2rx5sympzSnQ/OY3vzFHjhxphoaGml/60pd8buWeN2+eOWnSJJ/6vXv3mvfee68ZGhpq3nbbbeb69etb7fO//uu/zDFjxpghISHmXXfdZb766qud+txA5o/j1d7X0tVft4HKX19fV+tLgcg0/XfM/ud//seMj483nU6nedddd5kvvPBCt/ct0DlM8/9fgQUAAGBTgXVhAwAAgB8QiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO39P+cXW6IhyMfjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "GC_00001294    0.039448\n",
      "GC_00001929    0.039331\n",
      "GC_00001935    0.038915\n",
      "GC_00001318    0.038546\n",
      "GC_00002161    0.038342\n",
      "                 ...   \n",
      "GC_00001617    0.029612\n",
      "GC_00002900    0.029593\n",
      "GC_00000402    0.029578\n",
      "GC_00001342    0.029519\n",
      "GC_00002358    0.029360\n",
      "Length: 100, dtype: float64\n",
      "0.029578155316890484\n",
      "98.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gene_cluster_presence_absence_sel = gene_cluster_presence_absence.loc[:, selected_features_columns]\n",
    "\n",
    "X_train, y_train, x_test, y_test = train_test_split(gene_cluster_presence_absence_sel, taxa_df, test_frac=0.2)\n",
    "print (len(X_train), len(y_train), len(x_test), len(y_test))\n",
    "print (len(X_train.columns), len(y_train), len(x_test.columns), len(y_test))\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "clf_tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_tree.predict(x_test)\n",
    "\n",
    "#evaluate the model\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "forest_rank_importances = forest_importances.rank(ascending=False)\n",
    "print (forest_importances.sort_values(ascending=False)[:100])\n",
    "print (forest_importances.loc['GC_00000402'])\n",
    "print (forest_rank_importances['GC_00000402'])\n",
    "forest_importances_red = forest_importances[forest_importances>0.0005]\n",
    "sns.histplot(forest_importances_red, bins=100)\n",
    "plt.show()\n",
    "\n",
    "#create classifier using ridgeclassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = RidgeClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "importances = clf.coef_\n",
    "ridge_importances = pd.Series(importances[0], index=selected_features_columns)\n",
    "ridge_rank_importances = ridge_importances.rank(ascending=False)\n",
    "print (ridge_importances.sort_values(ascending=False)[:100])\n",
    "print (ridge_importances.loc['GC_00000402'])\n",
    "print (ridge_rank_importances['GC_00000402'])\n",
    "\n",
    "sns.histplot(ridge_importances, bins=100)\n",
    "plt.show()\n",
    "\n",
    "#create classifier using logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "importances = clf.coef_\n",
    "logReg_importances = pd.Series(importances[0], index=selected_features_columns)\n",
    "logReg_rank_importances = logReg_importances.rank(ascending=False)\n",
    "print (logReg_importances.sort_values(ascending=False)[:100])\n",
    "print (logReg_importances.loc['GC_00000402'])\n",
    "print (logReg_rank_importances['GC_00000402'])\n",
    "\n",
    "sns.histplot(logReg_importances, bins=100)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "decision_tree_importance_dict = {}\n",
    "ridge_importances_dict = {}\n",
    "logReg_importances_dict = {}\n",
    "\n",
    "#repeat the analysis 100 times and record the results (with different test and train test splits)\n",
    "for iteration in range(1000):\n",
    "    X_train, X_test, y_train, y_test = tts(gc_matrix, taxa_labels, test_size=0.2)\n",
    "\n",
    "    #train the model\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    importances = clf.feature_importances_\n",
    "    forest_importances = pd.Series(importances, index=gene_cluster_presence_absence.columns)\n",
    "    forest_ranked = forest_importances.rank(ascending=False)\n",
    "    decision_tree_importance_dict[iteration] = forest_importances\n",
    "\n",
    "    #create classifier using ridgeclassifier\n",
    "    clf = RidgeClassifier().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    importances = clf.coef_\n",
    "    ridge_importances = pd.Series(importances[0], index=gene_cluster_presence_absence.columns)\n",
    "    ridge_ranked = ridge_importances.rank(ascending=False)\n",
    "    ridge_importances_dict[iteration] = ridge_importances\n",
    "\n",
    "    #create classifier using logistic regression\n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    importances = clf.coef_\n",
    "    logReg_importances = pd.Series(importances[0], index=gene_cluster_presence_absence.columns)\n",
    "    logReg_ranked = logReg_importances.rank(ascending=False)\n",
    "    logReg_importances_dict[iteration] = logReg_importances\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "S\n",
      "Virul_fac_BrkB\n",
      "ribonuclease BN\n",
      "ko:K07058\n"
     ]
    }
   ],
   "source": [
    "#plot the decision tree\n",
    "# find out which one gave always the same result\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "fig = plot_tree(clf_tree, feature_names=gene_cluster_presence_absence.columns, class_names=['Other', 'Sphingomonadaceae'], filled=True)\n",
    "plt.show()\n",
    "\n",
    "print (gene_cluster_presence_absence.loc[sphingo_list, 'GC_00001531'].sum()/len(sphingo_list))\n",
    "print (gene_cluster_presence_absence.loc[non_sphingo_list, 'GC_00001531'].sum()/len(non_sphingo_list))\n",
    "#print (annotation_dict_CAZy_reformat['GC_00001531'])\n",
    "print (annotation_dict_COG_reformat['GC_00001531'])\n",
    "print (annotation_dict_PFAM_reformat['GC_00001531'])\n",
    "print (annotation_dict_description_reformat['GC_00001531'])\n",
    "print (annotation_dict_KEGG_reformat['GC_00001531'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             purity_sphingo  purity_non_sphingo  ratio\n",
      "item                                                  \n",
      "GC_00001619             1.0            0.000000  805.0\n",
      "GC_00001581             1.0            0.000000  805.0\n",
      "GC_00001543             1.0            0.000000  805.0\n",
      "GC_00001545             1.0            0.000000  805.0\n",
      "GC_00001548             1.0            0.000000  805.0\n",
      "...                     ...                 ...    ...\n",
      "GC_00018482             0.0            0.057143    0.0\n",
      "GC_00018481             0.0            0.052174    0.0\n",
      "GC_00018479             0.0            0.059627    0.0\n",
      "GC_00018478             0.0            0.063354    0.0\n",
      "GC_00038560             0.0            0.024845    0.0\n",
      "\n",
      "[37060 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "purity_df = pd.DataFrame(0, index=gene_cluster_presence_absence.columns, columns=['purity_sphingo', 'purity_non_sphingo', 'ratio'])\n",
    "\n",
    "for gc in gene_cluster_presence_absence.columns:\n",
    "    purity_df.loc[gc, 'purity_sphingo'] = gene_cluster_presence_absence.loc[sphingo_list, gc].sum()/len(sphingo_list)\n",
    "    purity_df.loc[gc, 'purity_non_sphingo'] = gene_cluster_presence_absence.loc[non_sphingo_list, gc].sum()/len(non_sphingo_list)\n",
    "    if purity_df.loc[gc, 'purity_non_sphingo'] > 0:\n",
    "        \n",
    "        purity_df.loc[gc, 'ratio'] = purity_df.loc[gc, 'purity_sphingo']/purity_df.loc[gc, 'purity_non_sphingo']\n",
    "    elif purity_df.loc[gc, 'purity_sphingo'] > 0:\n",
    "        purity_df.loc[gc, 'ratio'] = purity_df.loc[gc, 'purity_sphingo']/(1/len(non_sphingo_list))\n",
    "\n",
    "print (purity_df.sort_values(by='ratio', ascending=False))\n",
    "\n",
    "purity_df.to_csv('purity_df.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             purity_sphingo  purity_non_sphingo  weighted_ratio\n",
      "item                                                           \n",
      "GC_00001545        1.000000            0.000000        1.000000\n",
      "GC_00001563        1.000000            0.000000        1.000000\n",
      "GC_00001550        1.000000            0.000000        1.000000\n",
      "GC_00001549        1.000000            0.000000        1.000000\n",
      "GC_00001548        1.000000            0.000000        1.000000\n",
      "...                     ...                 ...             ...\n",
      "GC_00000642        0.002198            0.824845       -0.822647\n",
      "GC_00000015        0.008791            0.832298       -0.823507\n",
      "GC_00000523        0.002198            0.862112       -0.859914\n",
      "GC_00000542        0.002198            0.891925       -0.889728\n",
      "GC_00000519        0.013187            0.914286       -0.901099\n",
      "\n",
      "[37060 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "weighted_purity_df = pd.DataFrame(0, index=gene_cluster_presence_absence.columns, columns=['purity_sphingo', 'purity_non_sphingo', 'weighted_ratio'])\n",
    "\n",
    "for gc in gene_cluster_presence_absence.columns:\n",
    "    #weighted_ratio represents the ratio in the form of a value between -1 (present in all non-sphingo, absent in all sphingo) and 1 (present in all sphingo, absent in all non-sphingo), 0 is neutral (equally present in both)\n",
    "    weighted_purity_df.loc[gc, 'purity_sphingo'] = gene_cluster_presence_absence.loc[sphingo_list, gc].sum()/len(sphingo_list)\n",
    "    weighted_purity_df.loc[gc, 'purity_non_sphingo'] = gene_cluster_presence_absence.loc[non_sphingo_list, gc].sum()/len(non_sphingo_list)\n",
    "    if weighted_purity_df.loc[gc, 'purity_non_sphingo'] == 0:\n",
    "        weighted_purity_df.loc[gc, 'weighted_ratio'] = weighted_purity_df.loc[gc, 'purity_sphingo']\n",
    "    elif weighted_purity_df.loc[gc, 'purity_sphingo'] == 0:\n",
    "        weighted_purity_df.loc[gc, 'weighted_ratio'] = -1*weighted_purity_df.loc[gc, 'purity_non_sphingo']\n",
    "    if weighted_purity_df.loc[gc, 'purity_sphingo'] != 0 and weighted_purity_df.loc[gc, 'purity_non_sphingo'] != 0:\n",
    "        weighted_purity_df.loc[gc, 'weighted_ratio'] = weighted_purity_df.loc[gc, 'purity_sphingo']-weighted_purity_df.loc[gc, 'purity_non_sphingo']\n",
    "\n",
    "print (weighted_purity_df.sort_values(by='weighted_ratio', ascending=False))        \n",
    "\n",
    "purity_df.to_csv('weighted_purity_df.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
      "/tmp/ipykernel_2769852/2151510862.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030173337347843476\n",
      "36.0\n",
      "0.019185868863397956\n",
      "25.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAALlCAYAAACM+PPAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADwPUlEQVR4nOzdd5yU5dn28d/07Z3dpSy9SxNQBMUOihpLLEQTTJ6okagxiKZgicYk8lqixthb7GISY0sQAQuKNEFAeoddYJftfaff7x+zO7JsYYHZ3Znh+H4+PE+Yuebea1bKwTnnfV4mwzAMRERERESkU5g7ewMiIiIiIsczBXIRERERkU6kQC4iIiIi0okUyEVEREREOpECuYiIiIhIJ1IgFxERERHpRArkIiIiIiKdSIFcRERERKQTKZCLiIiIiHQiBXIRERERkU6kQC4iIiIi0okUyEVEREREOpECuYiIiIhIJ1IgFxERERHpRArkIiIiIiKdSIFcRERERKQTKZCLiIiIiHQiBXIRERERkU6kQC4iIiIi0okUyCVqvfL1Lm7/55rO3oaIiIhIq6ydvQGR9rJoaxGbC6o6exsiIiIirVKFXKLWjqIaymrcGIbR2VsRERERaZECuUQlt9fP3rJanF4/tW5fZ29HREREpEUK5BKVcktr8NcXxkuq3Z27GREREZFWKJBLVNpRVBP838U1rk7ciYiIiEjrFMglKu0sqsFsCvzvUlXIRUREJIwpkEtUyq+oo1tKLAAlqpCLiIhIGFMgl6hU4/IR77CSGGOlWBVyERERCWMK5BKVat1eYqxmkmJslNYokIuIiEj4UiCXqFTj8uKwWUiKtVJSrZYVERERCV86qVOiUo3bR7zdginGppYVERERCWuqkEtUqnF5ibFZSHBYKatVIBcREZHwpQq5RKVatw+H1YzXb+D06KROERERCV8K5BKVatyBCrnH58fp8Xf2dkRERERapEAuUanO7SPGZgHA6VWFXERERMKXArlEHb/foM7tw2Ez4zcMXKqQi4iISBhTIJeo4/T6MIAYqwWfeshFREQkzGnKikSdGlcggMfYLNgtgRs7vT5VyUVERCQ8KZBL1Kl1ewGIsZmxWwO/xJ1eBXIREREJTwrkEnUOrZADalsRERGRsKVALlEnWCG3Wr6vkCuQi4iISJhSIJeoU+NuqJCbD6qQq2VFREREwpMCuUSdWlegQu6wWbCpQi4iIiJhToFcok6wQm4146gP5C4dDiQiIiJhSoFcok6t24vVYsJqUcuKiIiIhD8Fcok6tW4fsTYLgG7qFBERkbCnQC5Rp9blJaZJIFeFXERERMKTArlEnRq3L9iqojnkIiIiEu4UyCXqOD2+YGXcYjZhNoFTN3WKiIhImFIgl6jj9PiDlXGTyYTdaqbOrUAuIiIi4UmBXKKOy/t9hRwCbSsur3rIRUREJDwpkEvUcXr82Cym4M/tVrN6yEVERCRsKZBL1HF6fNgsB1XIFchFREQkjCmQS9Rxer6fsgLgsFo09lBERETClgK5RB2n19+oh9xmMalCLiIiImFLgVyijsvjw3bITZ1O3dQpIiIiYUqBXKLOoS0rNot6yEVERCR8KZBL1HF6/bqpU0RERCKGArlEnYNP6oT6lhUFchEREQlTCuQSddxef+OWFatZU1ZEREQkbCmQS1QxDAPXIVNWrGYTbt3UKSIiImFKgVyiiqs+eB98UqfNYsbtUyAXERGR8KRALlGloVf80DnkqpCLiIhIuFIgl6jS0Ct+cA+5xawKuYiIiIQvBXKJKi6vKuQiIiISWRTIJao0VMhthxwMpEAuIiIi4UqBXKJKcz3kVosJj1pWREREJEwpkEtUCQbygyvkZjNev4Hfb3TWtkRERERapEAuUcVZ35pyaIUc0I2dIiIiEpYUyCWquOor5If2kIMCuYiIiIQnBXKJKsEKuaWZCrlu7BQREZEwpEAuUaXZg4HM9RVyBXIREREJQwrkElVcHh8WswmL2RR8TBVyERERCWcK5BJVXF5/o3YVUA+5iIiIhDcFcokqTo+vUbsKgNWsCrmIiIiELwVyiSpOj79JIG+okLsUyEVERCQMKZBLVHF6fE1aVtRDLiIiIuFMgVyiisvrx2YxNXpMPeQiIiISzhTIJaq01kPuUYVcREREwpACuUSVQIVcU1ZEREQkciiQS1RxenwtB3JVyEVERCQMKZBLVGn2pk6NPRQREZEwpkAuUaW5mzrNZhNmE7jUsiIiIiJhSIFcokpdMzd1QqBtRRVyERERCUcK5BJVXJ6mN3WCArmIiIiELwVyiSpOb0sVcpMCuYiIiIQlBXKJKi6Pv8lNnVBfIff5OmFHIiIiIq1TIJeo4vL6sDVTIbeqQi4iIiJhSoFcooqzpQq5WT3kIiIiEp4UyCWquJs5qRPqK+QaeygiIiJhSIFcoobH58dnGNitpibPWc1m3F6jE3YlIiIi0joFcokaTk/gps3mWlZUIRcREZFwpUAuUcNV3yPe8k2dmrIiIiIi4UeBXKJGaxVy3dQpIiIi4UqBXKJGQ4W8pZYVlwK5iIiIhCEFcokaDRXy5lpWVCEXERGRcKVALlHD6WmtQm5WhVxERETCkgK5RA1X/U2b9uYq5DqpU0RERMKUArlEDVd9hbz5g4HMGnsoIiIiYUmBXKJGsELe3JQVVchFREQkTCmQS9QI9pA3N4fcrAq5iIiIhCcFcokaDVNWrBZTk+dUIRcREZFwpUAuUcPl9WOzmDCbmgZyq9mMRxVyERERCUMK5BI1nB5fs+0qoAq5iIiIhC8FcokaLq+/2Rs6ITBlxes38PuNDt6ViIiISOsUyCVqHK5CDujGThEREQk7CuQSNeo8PhxWS7PPWc2BX+oK5CIiIhJuFMglajg9PhyHq5Crj1xERETCjAK5RI06d8stK9b63nIFchEREQk3CuQSNWrdvhZv6lSFXERERMKVArlEjbpWb+pUD7mIiIiEJwVyiRqttqyYVSEXERGR8KRALlGjrtWbOgOPuxTIRUREJMwokEvUCFTIWxh7qB5yERERCVMK5BI12lIh96iHXERERMKMArlEjdZO6lQPuYiIiIQrBXKJGm2pkGvKioiIiIQbBXKJCoZh4PT4Dz/2UBVyERERCTMK5BIVGqanOFq6qVMtKyIiIhKmFMglKtS5fQA4Wjip02w2YTaBSy0rIiIiEmYUyCUq1HoCgbyllhUItK2oQi4iIiLhRoFcokKwQq5ALiIiIhFGgVyigrNNFXKTArmIiIiEHQVyiQp1noYKefM3dUJ9hdzn66gtiYiIiLSJArlEhYaWldYq5FZVyEVERCQMKZBLVAhWyG2ttKyY1UMuIiIi4UeBXKKC03P4mzqtFhNun9FRWxIRERFpEwVyiQoNLSu2FuaQA1g1ZUVERETCkAK5RIU6jw+H1YzZZGpxjc1swq2DgURERCTMKJBLVGgI5K0JVMg1ZUVERETCiwK5RIVal6/VCSsAVrOmrIiIiEj4USCXqFDt8hJrb3kGOQT6y10K5CIiIhJmFMglKlS7vMTaDhfITQrkIiIiEnYUyCUq1Li8xBwmkNut5uB4RBEREZFwoUAuUaG6LYHcokAuIiIi4UeBXKJClbMNLStW9ZCLiIhI+FEgl6hQ04YeclXIRUREJBwpkEtUaFPLitWMy6MKuYiIiIQXBXKJCoEpK63/crZZzDh1MJCIiIiEGQVyiXiGYVDr8h12DrndYsbjM/D7jQ7amYiIiMjhKZBLxHN5/fgMo00tKw3rRURERMKFArlEvCqnF6ANBwMFfrnrxk4REREJJwrkEvFqXPWB/HAtK1YToAq5iIiIhBcFcol41fWBvC0HA4Eq5CIiIhJeFMgl4gUr5G3sIdekFREREQknCuQS8arb2LLS0EOuWeQiIiISThTIJeJVt7VCrpYVERERCUMK5BLxalw+TIDD2vov5+9bVlQhFxERkfChQC4Rr9rlIdZuwWQytbru+5YVVchFREQkfCiQS8SrrPMS77Aedp0q5CIiIhKOFMgl4pXWukloQyDXwUAiIiISjhTIJeKV17pJbEMgt5hNWMwmHQwkIiIiYUWBXCJeSbWb+JjDB3IITFpRD7mIiIiEEwVyiXhlbayQQ2ASi1pWREREJJwokEvEK6/1kNjGCrnNasapg4FEREQkjCiQS0QzDCNQIY+xtWm93WLG5VWFXERERMKHArlEtFq3D4/PaNOUFQiMPlSFXERERMKJArlEtNIaN0DbW1YsJvWQi4iISFhRIJeIVl7rAWhzy4rNYtbYQxEREQkrCuQS0cpqAxXyNresWDRlRURERMKLArlEtIZAfmRTVhTIRUREJHwokEtEK6txY7OYcFjb9ks5xmqmxq1ALiIiIuFDgVwiWkGli9Q4OyaTqU3rY2wWqpyedt6ViIiISNspkEtE219eR3qCvc3r4+wWalyqkIuIiEj4UCCXiLa3rJaMeEeb18fYLFS7vO24IxEREZEjo0AuEW1/uZOMxLYH8li7hRqXF8Mw2nFXIiIiIm2nQC4Ry+PzU1jlPKKWlVibBa/f0CxyERERCRsK5BKxCiqc+A3oknBkLSsANWpbERERkTChQC4Ra195HQAZRxDIY+sDufrIRUREJFwokEvE2lcWCORH1LJiVyAXERGR8KJALhFrZ3E1afF2HFZLm18TG2xZ0ehDERERCQ8K5BKx1uZV0Ccj/oheExNsWdHhQCIiIhIeFMglIhmGwXd7y+l7hIE8Ltiyogq5iIiIhAcFcolIeaV1VDq99O1yZIHcYTVjAqqd6iEXERGR8KBALhFp7d5yAPpmJBzR60wmEzE2i8YeioiISNhQIJeI9PH6fHqmxZEUazvi18bZLVQpkIuIiEiYUCCXiFNe62bBxgOcPqDLUb1eFXIREREJJwrkEnFeXrwLvwGnDcg4qtfH2S3qIRcREZGwoUAuEWXVnlKe+nwHl47qRvJRtKsAOGxmqt0K5CIiIhIeFMglYuwtq+WG11bRPyuBS0/sftTXibNbqajVHHIREREJDwrkEjHu+3ADJmDmpIFYzUf/Szc1zk5BhTN0GxMRERE5BgrkEhGW7ihh4aZCfjyuF0kxR9eq0iAtzsaBSgVyERERCQ8K5BIR/rUyj24psZzSN+2Yr5Uab6fK5aVWfeQiIiISBhTIJezVuX3M21DAqf3SMZlMx3y99Hg7gNpWREREJCwokEvYW7S1iFq3j/H90kNyvVQFchEREQkjCuQS9pbtLCEryUHX5NiQXC+tIZCrj1xERETCgAK5hL0Vu0oZmJUYsus5rBbiHRYFchEREQkLCuQS1qqcHjYXVDI4Oymk102Pd6hlRURERMKCArmEtW9zy/EbMDg7dBVyCNzYuau4JqTXFBERETkaCuQS1tbvqyDObqFrckxIrzuiRwpLd5RQXusO6XVFREREjpQCuYS1jfsr6ZUeF5Jxhwc7pW8afsPg6S928MSn2/hs84GQXl9ERESkraydvQGR1qzfX8GQrqHtHwdIibMzskcKz3+5E4fVjMvr56HLR3DVSTkh/1oiIiIirVEgl7BV7fKyp6SWKcOy2+X6t00aSLXLS1KMjae/2M4j87dw2eju2Cz64EhEREQ6jpKHhK3N+ZUA9E6Pb5fr2yxmUuPsWMwmLhnVncIqF/PWF7TL1xIRERFpiQK5hK1NBVVYzCa6p4TmQKDW9EyLY1B2Iu9+u7fdv5aIiIjIwRTIJWxtLaiiW0oM1g5qIRnbK5WlO0qoc/s65OuJiIiIgAK5hLEtBVX0SInrsK83umcqLq+fJTuKO+xrioiIiCiQS1gyDIMtB6rokdr+7SoNuibH0DU5hk83F3bY1xQRERFRIJewVFTloqLOQ05ax1XITSYTw7sn89XWog77miIiIiIK5BKWthyoAiAnteMCOcDwHsnkldWxp6SmQ7+uiIiIHL8UyCUsbc6vwmE1k5nk6NCvO7RrEhaziS+3qY9cREREOoYCuYSlTQWV9EyLw2wydejXjbNbGZiVwJdqWxEREZEOokAuYWlTfiU9OrhdpcHIHiks3laMy6vxhyIiItL+FMgl7Hh9frYXVtOzA2/oPNionBTqPD6+2VXWKV9fREREji8K5BJ2dhXX4PEZ9EzvnEDeMy2O9AQ7Czcd6JSvLyIiIscXBXIJO+v3VwB0WoXcZDJxUu80/rcuH5/f6JQ9iIiIyPFDgVzCztq8Cromx5DgsHbaHsb3TaeoysU3u0s7bQ8iIiJyfFAgl7CzJq+cvhnxnbqHAZkJZCY6+PeqvZ26DxEREYl+CuQSVjw+P5vyK+nbJaFT92EymThrcCYfrtlPWY27U/ciIiIi0U2BXMLKloIqXF4//To5kAOcPSgTA4M3l+/p7K2IiIhIFFMgl7CybGcJdouZPp3csgKQFGvjrEGZPPflTirqPJ29HREREYlSCuQSVr7aVszg7ETs1vD4pXnpid1xe/08+dm2zt6KiIiIRKnwSD0igNvrZ8WuUk7oltTZWwlKjbNz6ajuvLx4NxvqxzGKiIiIhJICuYSNlbtLqfP4GNY9ubO30shFI7rSPTWG295Zg9Pj6+ztiIiISJRRIJew8cGa/WQlOcKif/xgVouZm88awK7iGv7wwXoMQ4cFiYiISOgokEtYcHp8/G9dPqf2y8BkMnX2dpromRbHdaf15Z8r9/Lsop2dvR0RERGJIp13FKLIQd5bvY8al5fT+md09lZadMbALhRWOXlw3ma8Pj+3nN0/LP/xICIiIpFFgVw6ncvr4++fbuOUvul0TYnt7O206orRPbCYTPx1wVbW7atg9g+Hk57g6OxtiYiISARTy4p0ukc+2UJhlYvLR/fo7K0clslk4oejezBz0kCW7izh7L8u4q3lufj86isXERGRo2MydIeadKK3V+Qy6z/r+Mm4Xlw4omtnb+eIVNZ5eHPFHr7cWsygrERunzyQc4dkYTYf320sbq+fJTuKySutZUBWIuP6pKm1R0REpBUK5NIpiqtd/HX+Vt5ekcvkoVn8dEJvzBEa2rYXVjPnm1w27K8kJzWW84dlM7pnKn26xNMzLY44e+R2hrm8PgorXSTF2EiOs7W61unx8ebyXJ75YjvF1W7MJvAbMK5PGk/9eDQZau0RERFplgK5dJgqp4clO0r4ZH0Bc9flYzKZuPrknpw7JDMqKqhbD1TxxZZCvttbQUmNO/h41+QYRvZIZlzfdCYOyKBfl4Swfr8en5+FGw/wzso8vt5ejMcX+COif2YCl4zsxqUndicnLS64vqzGzftr9vHClzspqHRy+oAuTBnelR4psazbV8FzX+4gOc7Gv26cQJdEhXIREZFDKZBLu6mo8/BtbhkrdpWyZEcx6/dW4jMMuqfEclr/DM4ZkkliTOtV10hVUefhQKWTggoneWW17CiqZnthNR6fQVaSg/F90xndK5UhXZPolR5HRryj01pd/H6DvLJa1u2r4OvtJXyyoYDSGjcDshI4pU86PVJjqXJ6WZtXzordpbi8fnqmxZGdFEN5nZsdhTUYGIzvl85lJ/ag+yE35h6odPLHjzbQPSWWd24cT7wjcj8xEBERaQ8K5HJYuSW1rN1bTnG1C6vZRJfEGLqnxJKeYMdqNlHt8lJQ6SSvtJadxTXsKKxmS0EVeWV1AKTE2RiSncTQbkkM755MVlJMJ7+jzuHy+tiUX8X6fRVsKahkd0kt3vqbQU1ArN2C1WzCMMAATCawWcw4rGbsVjMmwOc3gq+xW80kxtjIiLeTlmAnOdZGvN0aXG+zmLFaAtfzGwZur59at49Kp4fyWg+FVU72lzvZV1aH2+cHoFtKDKN7pnL6gC6NquANnB4fa/LK2Xqgiso6D7F2K30y4hndM4WUOHuL7313SQ33f7SRsb1TeeHascTYLKH+9oqIiEQsBXJpxOnxsa+8ji0FVSzfWcLnW4rILa0FwGE14/UbLU4UMQFdEh10TY6he2ocvdPj6N8lgezkmLBu0egsXp+f/RVOCiudVNR5cHr8+AwDswlMmPAbBh6fH4/PwOv3YxhgMZswm0yYTIHWkhqXjyqnhyqnlxq3F5fXj8frx+PzB/5b1f/2tphMWC0mHFYLcXYL8Q4rybE20uLtZCU66JocS6/0uFZD9bHasL+Chz/ZwsgeKfzt6lF0TQ7vEZciIiIdRYG8gxiGQVVVVfDnWwtrWLStJPBc/f8x6tf5D/rfgdeCv/7nvvpA7D3o/zdUQJt8TQLtCD4jUFn1+Py4vX7qPIFKaZXLS0Wdlxq3r8V9d01yMLx7IgO6xJHgsGIYUOXyUlrjodrlxWcYxFjNpMTaSI+3Y7UoeEvLthfV8O6aAwDkpMYwsnsSXRLsXDw8k35d4oPrEhMT9Y84ERE5biiQd5DKykqSk5ODP+9+0ytYE8P3VEqRjuQu3EX+P34V/HlFRQVJSUmduCMREZGOo0DeQRoq5JWVleTk5JCXl6fA0YH0fe88R/O9V4VcRESOJxp30EFMJlOjMJKUlKRg2An0fe88+t6LiIg0z9zZGxAREREROZ4pkIuIiIiIdCIF8g7mcDi49957cTh0YmFH0ve98+h7LyIi0jrd1CkiIiIi0olUIRcRERER6UQK5CIiIiIinUiBXERERESkEymQi4iIiIh0IgVyEREREZFOpEDeQQzDoLKyEg21EREREZGDKZB3kKqqKpKTk6mqqursrYiIiIhIGFEgFxERERHpRArkIiIiIiKdSIFcRERERKQTKZCLiIiIiHQiBXIRERERkU6kQC4iIiIi0omsnb0BEYlehmGwYX8li7YWse1AFdUuH5lJDs4Y2IXJQ7MwmUydvUUREZFOF3EV8qeffpo+ffoQExPDmDFj+Oqrr1pdv2jRIsaMGUNMTAx9+/bl2WefbbLm3XffZejQoTgcDoYOHcp7773X6PlnnnmGESNGkJSURFJSEuPHj+fjjz8O6fsSiSYur48Xv9rJOX9dxEV/X8zDn2zh/TX7WbjpAG8tz+XG11dx/383dvY2RUREwkJEBfJ33nmHGTNmcNddd7F69WomTpzIlClTyM3NbXb9rl27uOCCC5g4cSKrV6/mzjvv5NZbb+Xdd98Nrlm6dClTp05l2rRprF27lmnTpnHVVVexfPny4JoePXrw//7f/2PlypWsXLmSs88+m0suuYQNGza0+3sWiTRfbClk8mNf8uf/bWJncQ12q5nJQ7P4/ZTBPHDZcH5ySk8AXlmym/3ldZ28WxERkc5nMiLoLPdx48YxevRonnnmmeBjQ4YM4dJLL2X27NlN1v/ud7/jww8/ZNOmTcHHpk+fztq1a1m6dCkAU6dOpbKyslHF+/zzzyc1NZW33367xb2kpaXx8MMPc91117Vp75WVlSQnJ1NRUUFSUlKbXiMSSQzD4LEFW3nis+0AZCY6mHHuQC4Z1Y14x/fdcbVuL0P/8AkAn91+Bn27JHTKfqXtcktq+Xh9Pjee0a+ztyIiEpUipkLudrtZtWoVkydPbvT45MmTWbJkSbOvWbp0aZP15513HitXrsTj8bS6pqVr+nw+5syZQ01NDePHjz/atyMSdR6ctyUYxn86vhef3XEm14zr2SiMAzzxaWBN95RY+mTEd/g+5ch9vD6f2R9vxu+PmPqNiEhEiZibOouLi/H5fGRlZTV6PCsri4KCgmZfU1BQ0Ox6r9dLcXExXbt2bXHNoddct24d48ePx+l0kpCQwHvvvcfQoUNb3K/L5cLlcgV/XllZ2ab3KRKJFm0t4tlFOwD486XD+MkpvZpd98ayPcF1d184RDd1RojCqsCfZU6vjzh7xPy1ISISMSKmQt7g0L/ADcNo9S/15tYf+nhbrjlo0CDWrFnDsmXL+OUvf8lPf/pTNm5s+aa02bNnk5ycHPyRk5PT+hsTiWAvLd4FwI/H9Ww2jPv8BrM/3sTd768H4KYz+zFleNcO3aMcvaL6QF7r9nXyTkREolPEBPKMjAwsFkuTynVhYWGTCneD7OzsZtdbrVbS09NbXXPoNe12O/3792fs2LHMnj2bkSNH8re//a3F/c6aNYuKiorgj7y8vDa/V5FIs6u4GoAzBnZp8lxeaS3TXlrOc4t2AnDzWf34zXmDOnR/cmwaKuR1CuQiIu0iYj57tNvtjBkzhgULFnDZZZcFH1+wYAGXXHJJs68ZP348H330UaPH5s+fz9ixY7HZbME1CxYs4Lbbbmu0ZsKECa3uxzCMRi0ph3I4HDgcjsO+L5FocEqfdPJK9zLzn2v5wchCctLicHv97C6uYf7GA9S6fcTYzDx0xUguHtmts7crR6ioygmoQi4i0l4iJpADzJw5k2nTpjF27FjGjx/P888/T25uLtOnTwcCVel9+/bx2muvAYGJKk8++SQzZ87khhtuYOnSpbz00kuNpqf8+te/5vTTT+fBBx/kkksu4YMPPmDhwoUsXrw4uObOO+9kypQp5OTkUFVVxZw5c/jiiy+YN29ex34DRMLU7ZMHsamgkvX7Knl7RdNPg4Z3T+aJq0/UTZwRqqFlpcbt7eSdiIhEp4gK5FOnTqWkpIT777+f/Px8hg0bxty5c+nVK9Czmp+f32gmeZ8+fZg7dy633XYbTz31FN26deOJJ57g8ssvD66ZMGECc+bM4e677+aee+6hX79+vPPOO4wbNy645sCBA0ybNo38/HySk5MZMWIE8+bNY9KkSR335kXCWHZyDB/efBpfbC3km91lFFa6qHR62Li/kvyKOtbtq+Dal5dz7Sm9ue60PpjNupkzUjg9PiqdgSCulhURkfYRUXPII5nmkMvxwu83eHTBVp7+YjvNTcn748Un8NMJvTt8X3J09pbVctqDnwPwwrVjmTS0+Xt2RETk6EXMTZ0iEv4Mw+D+/27kyc8DYfyyE7uz6DdnsuYPk/jlmYFDZV5durtzNylHpKFdBQKHOomISOgpkItIyMz5Jo9XluzGZIKHLh/BY1NH0Ss9npQ4O6f1zwDA69OHcpHk4ECulhURkfYRUT3kIhK+Kmo9PDB3EwC/O38wV53UePb+B2v2ATCmV2qH702OXnG1GxNgt5qpUSAXEWkXqpCLSEh8sqGAKqeXAZkJ3DCxb6Pn9pfX8f7q/QD85JSenbE9OUp1Hh92q5lYm4U6tayIiLQLBXIRCYm8sloAxvZOw3LIFJU53+Th9vk5uU8aY3qldcb25Ci5vX7sVjMOm1lzyEVE2okCuYiERK/0wIzxzzYfoMrpafTct3vKAPjhid07fF9ybNxePzazGYfVokAuItJOFMhFJCQuGtGVXulxHKh08eyiHY2ec/v8AMTYLJ2xNTkGLq8Pq8WEw2rWlBURkXaiQC4iIRFjs3DH5EEAfLy+oNFzAzITANiYX9nh+5Jj4/b6sVnUsiIi0p4UyEUkZNLj7QD4DjkR6MSegckqDa0rEjncPj82i0ktKyIi7UiBXERCZunOEgCGdU9u9PionMDP1++vaBLWJbwFK+RWVchFRNqLArmIhITfb/DBmsBow8mHHK/eJyOBGJsZp8fPruKaztieHCWX11/fQ26hxqUechGR9qBALiIhsXRnCbmltSQ6rEw6JJBbzCZO6Baokq/YVdoZ25Oj1DBlJcZm1kmdIiLtRIFcRELiXyvzAPjBqG7E2ZseAnzukEBIf2XJLjz1U1ck/B1cIa/1qEIuItIeFMhF5JjVuX3M33gAgCvG9Gh2zdSTckiJs7H1QDWvLd3TkduTYxAYexiYsqIKuYhI+1AgF5Fj9tW2ImrdPrqnxHJiTkqza9Li7fz2vMEAPP35dtxeVckjQcNNnTG6qVNEpN0okIvIMVu4KVAdnzQ0C5PJ1OK6K8f2INFhpaTGzc7i6o7anhwDl9ePzWzCajGr1UhEpJ0okIvIMfH7DT7bXAjQ5GbOQ1nNJiyWQGD3+jT+MBK4vX6sFjNWswm/0XTGvIiIHDsFchE5JhvzKymudhNvt3BS77RW127YX0l5rQeH1Uz/+tM7Jby5vD7slkCFHFCVXESkHSiQi8gxWbojcBjQ+H7p2K2t/5Hy4lc7ATh3aBYxNku7702OXUOF3FLfiqRALiISegrkInJMNuZXAjCqhZs5G+woqubDtYGDg6af3q+9tyUh4vb5sVlMWC0NgVwtKyIioaZALiLHZF95HQA90+NbXffEp9vwG4F55MN7JHfE1iQEXJ7ve8gBvKqQi4iEnAK5iByT4moXAJmJjhbX5JbUBqvjM84d0CH7ktBw+/zYLWYs9YHcrUAuIhJyCuQickwq6zwAJMfaWlzz9je5GAZMHJDBsO6qjkcSd/1Jnd/f1KmWFRGRUFMgF5FjYq8Pag3BvDlz1+UDcPXJPTtkTxIafr+B129gM6tlRUSkPSmQi8gxGVs/6vCFr3bhb2ZGdVmNmz0ltQCcNiCjQ/cmx6ahPcVmVcuKiEh7UiAXkWPyi9P7YrOYWLjpAA/O29zk+Rq3FwhU0hMd1o7enhwDl7c+kJtNwQq5WlZEREIv4gL5008/TZ8+fYiJiWHMmDF89dVXra5ftGgRY8aMISYmhr59+/Lss882WfPuu+8ydOhQHA4HQ4cO5b333mv0/OzZsznppJNITEwkMzOTSy+9lC1btoT0fYlEqmHdk3nkypEAPPflTlbuLm30fJdEB3aLGbfPH6yUS2Rw1wfywJSVwF8XalkREQm9iArk77zzDjNmzOCuu+5i9erVTJw4kSlTppCbm9vs+l27dnHBBRcwceJEVq9ezZ133smtt97Ku+++G1yzdOlSpk6dyrRp01i7di3Tpk3jqquuYvny5cE1ixYt4uabb2bZsmUsWLAAr9fL5MmTqampaff3LBIJLhnVnfNPyAbgy23FjZ5zWC3BGeVf7yg+9KUSxoItKwfNIVfLiohI6EVUIH/00Ue57rrruP766xkyZAiPP/44OTk5PPPMM82uf/bZZ+nZsyePP/44Q4YM4frrr+fnP/85jzzySHDN448/zqRJk5g1axaDBw9m1qxZnHPOOTz++OPBNfPmzeNnP/sZJ5xwAiNHjuQf//gHubm5rFq1qr3fskjEiK9vRzGMpi0NY3unArCp/hAhiQwujw8A20FzyNWyIiISehETyN1uN6tWrWLy5MmNHp88eTJLlixp9jVLly5tsv68885j5cqVeDyeVte0dE2AiooKANLS0lpc43K5qKysbPRDJFpVOT18sqEAgFP6pjd5Pi3eXr/O26H7kmNzcIXcoikrIiLtJmICeXFxMT6fj6ysrEaPZ2VlUVBQ0OxrCgoKml3v9XopLi5udU1L1zQMg5kzZ3LaaacxbNiwFvc7e/ZskpOTgz9ycnIO+x5FItVrS/dQ7fLSPzOB8c0E8sKqwOFBqXH2jt6aHIPmesg9CuQiIiEXMYG8gclkavRzwzCaPHa49Yc+fiTXvOWWW/juu+94++23W93nrFmzqKioCP7Iy8trdb1IpPL6/LyyZDcAt5zVH7O56e+dzQVVAAzISujIrckxCk5ZsZgP6iFXy4qISKhFzAyyjIwMLBZLk8p1YWFhkwp3g+zs7GbXW61W0tPTW13T3DV/9atf8eGHH/Lll1/So0ePVvfrcDhwOFo+SlwkWnybW05RlYu0eDsXDO/a7JrdxYEboAdkJnbk1uQYuQ8ae6iWFRGR9hMxFXK73c6YMWNYsGBBo8cXLFjAhAkTmn3N+PHjm6yfP38+Y8eOxWaztbrm4GsahsEtt9zCf/7zHz777DP69OkTirckEhV2FFUDMKJHMnZr83+klNW6AUhPUMtKJDm4ZcUSvKlTgVxEJNQipkIOMHPmTKZNm8bYsWMZP348zz//PLm5uUyfPh0ItIns27eP1157DYDp06fz5JNPMnPmTG644QaWLl3KSy+91Kjd5Ne//jWnn346Dz74IJdccgkffPABCxcuZPHixcE1N998M2+99RYffPABiYmJwYp6cnIysbGxHfgdEAk/lmZaVA7VEOLsloipAQgHt6yYMJtMmE2asiIi0h4iKpBPnTqVkpIS7r//fvLz8xk2bBhz586lV69eAOTn5zeaSd6nTx/mzp3LbbfdxlNPPUW3bt144oknuPzyy4NrJkyYwJw5c7j77ru555576NevH++88w7jxo0LrmkYq3jmmWc22s8//vEPfvazn7XfGxaJALWuwOQUawvB3OPz4/QEgl28TuqMKC7v92MPG/6/KuQiIqEXcX873nTTTdx0003NPvfKK680eeyMM87g22+/bfWaV1xxBVdccUWLzzc3V1lEAr83PvouH4CRPVKaXbO3rA6AGJuZlFhbR21NQsB90E2dEPhHlwK5iEjo6fNjETlq76/Zx6o9ZTisZq4Y2/yNzhv2B+b2D8xKbHYCi4Qvt8+P2fR9W5LFbFLLiohIO1AgF5GjUlbj5o8fbQQC4w67Jjd/P8Xq3HKg5Qq6hC+P1x+sjkPg5k5VyEVEQk+BXESOyqMLtlJe62FwdiLTz+zX4rqGCvmIHskdtTUJEY/PaHRvgFpWRETahwK5iBwxn9/gw7X7AbjzgiGNqqiHyq9wAtA7I75D9iah4/b5sR5cITeb8KplRUQk5BTIReSIub1+Kuo8AAztltTqWqcnMKkj1mZp931JaLm9/kYVcovFhFsVchGRkFMgF5EjFmu30D8zAYA3lu1pda2/vqBq0v2cEcfj82O1HNyyoh5yEZH2oEAuIkflV2f3B+DN5bmtjgatcwcq5HH2iJuyetzz+PxYzWpZERFpbwrkInJUxvdLB6CoykVdfVvKoQzDoLr+4KAEHQoUcTw+o1GF3GJWy4qISHtQIBeRo/LhmsBNnb3T41qsfptMpmDveGGVs8P2JqHh9h3SQ6455CIi7UKBXESO2Nfbi3lk/hYAfnF6yyMPAU7tnwHAf77d1+77ktDyeJtrWVGFXEQk1PQZsogc1oFKJ/PWF7C5oIqN+ZWszSsH4KxBXfjRSTmtvvbHp/Rk4aYDzFmRy++nDG51RKKEl0Nv6rTopk4RkXahQC4iLfL4/Dz8yRZe/GpncFoKgNkEl4/uwZ8vG4bZ3Pr4lDMGdMFuMVPj9rG/vI5e6ZpHHincPj+WQw4GcnsVyEVEQk2BXESa5fL6+PXba5i3oQCAE3umcGq/DPpnJnBK33Syk2PadJ3SWnfwRsDkWFu77VdCz+01mswhVw+5iEjoKZCLSBN+v8Fd761n3oYC7BYzf71qJD8Y2e2orvX28lwAhndPJiXOHsptSjtrbuxhwxhLEREJHQVyEWniuS938u9VezGb4Nlpozl7cNZRXaew0slzX+4E4PqJfUK5RekAbu+hBwNp7KGISHvQ3VUi0shX24p46JPNAPzx4hOOOowDPLZwG9UuLyNzUvjBiKOrsEvn8TQZe2jWwUAiIu1AgVxEggqrnNz2zhoMA6aOzeEnp/Q66ms5PT4+WBMYdThryuDD3vwp4cft82O1NG5Z0ZQVEZHQUyAXESBwquasd9dRXO1mcHYif7zkBEymow/Ru0tqqHX7SHRYGdcnLYQ7lY5yaIXcalHLiohIe1AgFxEAPttcyKebC7FbzDxx9YnE1J+webQagpzFYjqmYC+dx3PIlJXAwUBqWRERCTUFchHBMAz+On8rAP93Wm8GZiUe8zUbQrhHc6sj1qEtKxa1rIiItAsFchFhY34lG/MribGZ+eUZ/UJzzf2VADoIKIK5D21ZMZvxKpCLiIScArmI8G1uOQAn90kP2azwhgOFJg7MCMn1pON5vIfc1KmDgURE2oUCuYhQ6/ICoT1J88stRQCcf0J2yK4pHavp2EO1rIiItAcFchGhf2YCAMt3llDr9obkmtX118lIcITketLxPD6jycFAqpCLiISeArmIcGr/DLolx1BY5eLJz7aH5JojeqQA8K+VeSG5nnS85g4G8hkGhqFQLiISSgrkIkKMzcK9F58AwD++3k2169ir5Dee3jdwvSW7cXp8x3w96ViGYeD1G1jNjaesAKqSi4iEWMQF8qeffpo+ffoQExPDmDFj+Oqrr1pdv2jRIsaMGUNMTAx9+/bl2WefbbLm3XffZejQoTgcDoYOHcp7773X6Pkvv/ySH/zgB3Tr1g2TycT7778fyrckEhZO7h04vKfO46MmBIH8/BOyyUpyUOX08m1u2TFfTzpWwwFAh7asAOojFxEJsYgK5O+88w4zZszgrrvuYvXq1UycOJEpU6aQm5vb7Ppdu3ZxwQUXMHHiRFavXs2dd97Jrbfeyrvvvhtcs3TpUqZOncq0adNYu3Yt06ZN46qrrmL58uXBNTU1NYwcOZInn3yy3d+jdB6Pz3/cfhTv9xvc88F6APpmxJOZeOx932azieHdUwDYUVRzzNeTjtVQBT/0YCBAhwOJiISYtbM3cCQeffRRrrvuOq6//noAHn/8cT755BOeeeYZZs+e3WT9s88+S8+ePXn88ccBGDJkCCtXruSRRx7h8ssvD15j0qRJzJo1C4BZs2axaNEiHn/8cd5++20ApkyZwpQpUzrgHUpH8vsNPt1cyDvf5LJqTxlltR6sZhMDsxKZelIOV5/cE7s1ov7NelQMw+DeDzfw3+/ysZhNPHzliJCdrJkaF5jaUlnnCcn1pOM0HOjUqGWlvlru8atCLiISShGTNtxuN6tWrWLy5MmNHp88eTJLlixp9jVLly5tsv68885j5cqVeDyeVte0dM22crlcVFZWNvoh4WPj/koufmoxN7y2koWbCimrDfx68PoNNuZXcu+HG7j4ycVsL6zu5J22L7/f4K731/P6sj2YTPDXK0cypldayK7v8wcqqRZzaAK+dByPWlZERDpMxFTIi4uL8fl8ZGVlNXo8KyuLgoKCZl9TUFDQ7Hqv10txcTFdu3ZtcU1L12yr2bNn88c//vGYriHt44M1+/jtv7/D5fWT4LDy41N6ctHwbvRIjaXa5eXzLYU8vnAbmwuquPqFZfzzxvH0yYi+0yYNw+CPH23greW5mE3w4OUjuPTE7iH9GoVVLgDS40Nz2JB0nO97yA86GKi+Wq6WFRGR0IqYCnmDQz9KNwyj1Y/Xm1t/6ONHes22mDVrFhUVFcEfeXka/dbZDMPghS938us5a3B5/Zw1qAtf/OZMZk0ZwvAeyaTG28lJi+Pa8b2Zf9vpDM5OpKjKxbUvL6ew0tnZ2w+591bv49Wlgcr4w1eM5MqxOSG9vr/+0waAAVmJIb22tL/mesgbPulwq0IuIhJSERPIMzIysFgsTSrXhYWFTSrcDbKzs5tdb7VaSU9Pb3VNS9dsK4fDQVJSUqMf0nmqXV5u/9da/jJ3EwD/d2pvXvrpSS0eWpOR4OD168bRMy2OvNI6Ln7ya9bklXfgjtuXYRg8OG8zAL8+ZwCXj+kR8q+xYX8lpTVu4u0WTuimX/+RJtiy0kwgV4VcRCS0IiaQ2+12xowZw4IFCxo9vmDBAiZMmNDsa8aPH99k/fz58xk7diw2m63VNS1dUyLPoq1FnPfYl/zn232YTXD3hUP4w0VDMR+mr7lLooPXrzuZfl3iKah0cuWzS3hp8a6omMRSXuvhQGWgneSacT3b5Wt8vqUQgNMGZGCzRMwfNVLP7W2uZUU95CIi7SGi/pacOXMmL774Ii+//DKbNm3itttuIzc3l+nTpwOBNpFrr702uH769Ons2bOHmTNnsmnTJl5++WVeeukl7rjjjuCaX//618yfP58HH3yQzZs38+CDD7Jw4UJmzJgRXFNdXc2aNWtYs2YNEBinuGbNmhbHLUp4KKxy8qu3V/PTl1ewr7yOHqmxzPnFeK6f2LfNLUm90uN5/+ZTmTIsG4/P4E//3cijC7a2887bX3KsjX5dAn3xoTqZ81ArdpUCcNqALu1yfWlf7lYq5ArkIiKhFTE3dQJMnTqVkpIS7r//fvLz8xk2bBhz586lV69eAOTn5zcKyX369GHu3LncdtttPPXUU3Tr1o0nnngiOPIQYMKECcyZM4e7776be+65h379+vHOO+8wbty44JqVK1dy1llnBX8+c+ZMAH7605/yyiuvtPO7lqPxxZZCZv5zLaU1bswm+NmEPtw+eSDxjiP/JZ8YY+PpH4/mha928sDczfz9s+3Uun38fsrgiK38ms0m7rxgCNe9upLXlu6hR2osvzi9X0i/xp7SwOzxwdnqH49E3489PGjKSv2vd68/8j8lEhEJJyYjGj5/jwCVlZUkJydTUVGhfvJ29sayPdz9fuCQmyFdk3jo8hEM75Eckms//+UOHpgb6L0e3zedZ38yhuT6WduR6KnPt/PwJ1sAuPWcAdx27oCQzSAffu8nVLm8fHr7GfTrkhCSa0rHWbytmJ+8tJwnfnQiXeoPijpQ6WTGO2t46/pxTOif0ck7FBGJHpFZ3hNpwYKNB4Jh/OqTe/LeTRNCFsYBfnF6P579yWji7RaW7izhF6+vbHV9YaWTLQVV1LqP/Sj69nDTmf34zXmDAHji0228vSI004AqnR6qXIH3HIpTP6XjNTeHPNiyogq5iEhIRVTLikhrPD4/f/xoAwA/OaUnf7pkWMiqvQc7f1hXMpNi+OHTS1i+q5Q6t49YuyX4vGEYfLGliKc+387KPWUAJMZYeeTKkZx3QnbI93MsTCYTN5/Vn4o6D89/uZN5GwpCcpPnqvr33SM1lsSYyP0E4XjWXA958KZOr3rIRURCSYFcosbX24vZW1ZHerydOy8Y0i5hvEFOahwAJhMYfF8t3LC/gofmbWHR1qLg83E2C1VOL796azUPXzmC84dl47Bamr1uZ+lSP/4xVB1sy3aWAIG2HolM3489/P6D1ODYQ78CuYhIKCmQS9T416q9AFw4oitx9vb9pd0QSAwDHpq3hRibhVV7Svlmd6AybLOY+L9T+3DdaX1Ij7dz05vfMn/jAX49Zw0Ws4nuKbEM6ZrI1JNyOHvwsc28P1Z1bh//+HoXAOcMzgzJNdfklgNwUp+0kFxPOl5zLSsN4dyjOeQiIiGlQC5RYeHGA/zvu3wArgrxiZPN6ZocyzmDM/l0cyGvLNkdfNxsggtHdOP2SQPpnREffPzv15zI3z/dzjsr8yiqcpFbWktuaS2fbDjArCmDufGM0E44aSvDMPjjRxvYX+Gke0osPzo5NDPJ95TUAjAgUzdzRqqGOeQWjT0UEWl3CuQS8T7fUshNb30LwLXjezGse+hu4mzN364+kX+tzGNnUQ1mE/TPTODsIVl0T4ltstZhtXDHeYO4ffJACqtc7Cqu4YM1+3l7RS4PztvMuUOzOmUSyQtf7WTON3mYTPDQFSOIsYWmlaa6/obOlDh7SK4nHc/tM7CYTZhNTXvIdVKniEhoKZBLRHtt6W7u+3ADfgMmDc3irguHdNjXTnBY+b9T+xzRa0wmE1lJMWQlxXBK33QKK518urmQG19fxU8n9KayzsOOomq2Hagmt7SWKqcHh9VC/8wEzh+WzXWn9QlJaPb4/DzyyRae+3InAL8/fzCnhnCMnd1qBtf3VVaJPC6PD/shc/bNZhNm0/c3fIqISGgokEtEMgyDhz/ZwtNf7ADg8tE9mP3D4YEgGEHuu/gEvs0tY3thNffUj2s8VJ3Hx7p9FazbV8G89QX84/9OIiPh6EcJLttZwn0fbmBzQRUAMycN5Ben9z3q6zUnJdZGaY2b8lp3SK8rHcft82OzNL0x2mI24VUgFxEJKQVyiUiPLtgaDOO3TxrILWf3b9epKu0lJy2O/906kVeX7GZncQ0JDit9MuIZmJVIn4x4UuNsVLu8rNhVyoPzNrNuXwUz5qzh9etOPqL36/H5+XRTIS9+tTM4ijEt3s6fLx3GBcO7hv6N1W9N46ojl9vrD57MeTCr2ayTOkVEQkyBXCLOu6v28vfPtgNw/yUncO343p27oWPULSWWWRe03GqTCfTtksDY3qlc9PfFLN5ezF3vr+cPFw1tsX3F7fWTV1bL6txyFm8r4outRZTXeoDABJipJ+Vw+6RBpMaHvsfb5zfYV1YHQNfkmJBfXzqG29t8hdxqMallRUQkxBTIJaJsL6zmrvfXAXDr2f0jPowfif6Zifzl0uHc8e+1vLU8ly+3FnHZid3JTHRQUOlkZ1ENeWW1FFS4KKlxcehI8YwEO1eNzeFnE3qTmdR+QXlXcQ0ur584u4WctLh2+zrSvlxeP7ZmKuSBlhVVyEVEQkmBXCKGy+vjtnfW4PT4mTggg1+fO7Czt9ThLh/Tg8QYK3e/v569ZXXBTwqaE2uzMLhrIqf0TeeMgV04qXdaoxF27SW/IlAdz0mN65CvJ+3D3UIgt5pNGnsoIhJiCuQSEfx+g1n/Wce6fRWkxNl4+IqRRxT2nB4fX2wpYtHWIjYXVFJW48bl9ePy+vF4/VgtJtLi7QzOTuKswZlcOLwrsfbwOk2zweQTsjm1fwZz1+WzfFcpVU4PGQkO+nZJoFdaHNnJMWQnx5Aeb++UvvqGMXn+EJ36KZ3D7fUHxxwezGo262AgEZEQO+JAvnfvXp555hmWLFlCQUFBYIxbVhYTJkxg+vTp5OS0/6EscnxxeX3c+Z/1/OfbfZhN8LcfnUh2G3uTK2o9vPDVTt5cvoey+h7qlpTVethRVMP/1uUze+4mfjahNz87tTeJMbZQvI2QindYuXJsDld2wCFIRyreEfhjpdbt6+SdyLFw+/yNTulsoCkrIiKhd0SBfPHixUyZMoWcnBwmT57M5MmTMQyDwsJC3n//ff7+97/z8ccfc+qpp7bXfuU4s6u4htveWcOavHLMJvjrVSM5Y2CXw77O5zd4c/keHl2wNXgzY9fkGKYM68qYXql0SXQQYzPjsFqwWUx4/QYHKp2s2lPGv1ftZW9ZHX9dsJVXl+7mutP6cu34XsGgKa0rqwmMOowL008YpG1cXp9aVkREOsgRJYzbbruN66+/nscee6zF52fMmME333wTks3J8cvr8/P6sj08NG8LdR4fSTFW/n7N6DaF8a0Hqvj9u9/xbW45AAOzEpg5aSDnDslqdoxbg4FZiUwc0IWbz+rP3HX5PL5wG7uKa3hw3mZeX7qbP106jHOGZIXqLbY7n99g5e5Slu0sZW9ZLfEOK+cOyeLU/unt2sqycNMBAEb0SGm3ryHtL9Cy0kwgt5jwaOyhiEhIHVEgX79+PW+88UaLz9944408++yzx7wpOb6t2FXKfR9uYGN+JQAT+qXz0BUj6JHa+sQOr8/Pi4t38ej8rbh9fhIdVn5z/iCuOblnq0H8UDaLmUtGdWfKsK58sGYff/t0G3vL6rju1ZVMO6UXd104JGRHzLcHl9fHq0t284+vd5Nf4Wz03CtLdnPFmB48fMWIdgnl+RV1vPvtXgAuH9095NeXjuNqYeyhxWzCoxNYRURC6ogCedeuXVmyZAmDBg1q9vmlS5fStWs7HDIix4WdRdU8NG8L8zYUAJAca+M35wUCtfkwN3CuySvn7vfXsX5fIMSfPTiTP186jG4psUe9H7vVzJVjc7hoRDceXbCFFxfv4vVle1i5p4y//WgUA7MSj/ra7eXzLYXcUz+BBQLfwzMGdmFAZgL7yuuY800e/161l5+c0otROSkh/dqGYfCHDzbg9PgZ2yuV8f3SQ3p96Vitjj1UhVxEJKSOKJDfcccdTJ8+nVWrVjFp0iSysrIwmUwUFBSwYMECXnzxRR5//PF22qpEq8IqJ39buI053+Th8xuYTfCjk3syc9LAVo+INwyD1XnlvPjVTuau+z7E33XBEK4c2yNkFeBYu4W7LhzKhP4Z3P7PtWzKr+SCv33FdRP7MOOcgWEzjWXOilzufG8dfgOykhzcPmkQl5zYDYf1+/2V1br5ZMMBlu0sCXkg/9fKvSzYeACbxcRfLhsekSenyvdcXh9xzXwSZFEPuYhIyB1RIL/ppptIT0/nscce47nnnsPnC0xRsFgsjBkzhtdee42rrrqqXTYq0cfl9fGPr3fzxKfbghM5zhmcye+mDG6x+uz1+dmwv5Ivtxbx7rd72V1SC4DZBJed2IPfnT+o3Q69OWtQJvN+PZE731vPwk0HeG7RThZsOMDDV45gTK+0dvmabVVR5+GeD9bjN+CqsT247+ITiLM3/e3d3GOhsL+8jvv/uxGA2yYNZFB2+H16IEfG7fVjszZfIVcgFxEJrSP+23nq1KlMnToVj8dDcXExABkZGdhs4TcaTsLXV9uKuPO9deSVBlorRuakMGvKYE7p27TNodbtZdnOEt5fvZ/PtxRS5fQGn4u1WTjvhCx+eWb/FkNgrdvLgUoX5bVu6jw+PD4Dn9+P2+unxuWj1u3F5zdIjbczpldqq73qmUkxvPjTsSzceIC73l/HzuIarnh2Kb84vS+3TxqEvZkA0xEKKpzB2dAthXEITK0B6H4MrTzNeWDuJqpdXkblpDD99H4hvbZ0DrfXj62FOeQ6qVNEJLSOulxms9nULy5HxDAMvs0t5/99vIlvdpcBgdaK35w3mB+e2L1Rn7jfb7BidymvLtnNp5sLcR90E1lSjJWxvdO4cHhXzh+W3Wgcod9vsLO4hi+3FrFkRzHr9lVwoNJ1RPu8+uQc7v3BCa3euHnu0CxO6p3G/f/dyLvf7uW5RTvZuL+SF64d2yk3fPbJiCcnLZa80jqe/3InM5o5xbSoysX6fRUAIW1XKaxy8vH6QMvQA5cNP2y/v0QGt9ff7M3QFrMJtyrkIiIhpcHK0q58foPthdXMXZfPf7/bz46iQIXWbjFzzbie3HHeIBIOCtROj483lu3hlSW7gzcmAnRLjmHS0CwuHtWdUTkpWMwmDMOg0unlm92lfLO7lOU7S/k2t6xRBb2B1WzCZjFjtZiwW8zE2S0kx9lIjbMTb7diNkN+hZPVueW8vSIPr8/g4StHtvrekuNs/PWqkUw+IYvb3lnDV9uKufeDDTx4xYgQfffazm4189vzBvOrt1fz9Bc7+MHIbvTrkhB83unx8bt3v8PrNzixZwo5aa1PrDkS7327D1/9dYd2SwrZdaVzuX2tTFlRhVxEJKQUyOWYeH1+NuVX8d2+cnYW1bC/vI7SGjeVTi8VtW4Kq1yNJjLYLWYuGdWNO84bRNZBvd61bi/Pf7mT15fuoaT+YJl4u4WLR3XnyjE9qKhzszqvgpe/3kV+eR3F1W6KqlzUeZqeBmk2BY5vP/jrev0GXr8P6g/rLKmBvLI6Ruak8Msz+zGhXwYAn246wHWvruTdb/dy6zkD2hRczzshm+enjWXay8t5Z2Uek4Zmce7Qjp9XftGIrvxzZR5fbStm2ovLmXHuQJLjbGzYX8m/VuaRX+HEYTVz5wVDQvY1i6pcvLh4FwA/Oin8Tg2Vo+fyND9lxWo26RRWEZEQUyCXI+by+vjfd/n897t8lu8soeYwfzk7rGYm9EvnohHdmHRCFkkHHUXv8fl5bekenlu0g8KqQGtJt+QYfnV2f5Ji7by3eh/XvLgMp6flj8jj7BZsFjMVdYG07TfAb7RewbNbAlW+tXnlXPPCch66YgRXjc3hnCFZnNI3jWU7S5m7Lp8bz2hbP/RpAzL4vwl9ePnrXdz81rfcecEQfjzuyOafHyuTycSjV43iqueWsqu4ht+++12j57smx/D41FGc1Ds0N6DuK6/jhldXUlTlom9GPJeeqLnj0SRQIddJnSIiHSHiAvnTTz/Nww8/TH5+PieccAKPP/44EydObHH9okWLmDlzJhs2bKBbt2789re/Zfr06Y3WvPvuu9xzzz3s2LGDfv368Ze//IXLLrvsmL5uNHJ7/by5fA/PLdpJQeX3B84kxlgZlZPCoKxEuqfGkpHgICnWRnKsjcxEB1lJMVgO6Ss2DIN56wv464KtbC+sBgI3Gv5uymDibGYeXbAteDAQQFq8naxEB2azCafHR3mtJ1hJD1Trjqxi567/yH1kj2TW7q3gjx9u4MxBXchMjOGiEd1YtrOUf63ayw0T+7a5J/r3Uwazp6SGTzcXcu+HG/jP6n3MueGUDh2L2CXRwX9+OYFXluxmyY5i3D6DXmlxnDGwCxeO6Bqy/vYFGw/w23+vpazWQ1q8nRd/OrbReEWJfIEe8uZaVnRTp4hIqEVUIH/nnXeYMWMGTz/9NKeeeirPPfccU6ZMYePGjfTs2bPJ+l27dnHBBRdwww038MYbb/D1119z00030aVLFy6//HIgcJjR1KlT+dOf/sRll13Ge++9x1VXXcXixYsZN27cUX3daLRhfwW/+dd3wZCcnRTD1Sf35JwhmQzpmtQkcLfm29wyHvx4M8t3lQKBsH3H5EFMGZ7Fn/67if98uw8ITFDJSnaQVxpogymtD+AHi7GZW62et8RiMuEzDHaX1DIgM4FthdUs3VHCJaO6c/Gobjz48Wa2F1bz/pp9/HB0jzZd024188K1Y3lz+R4enLeFtXnlPPHZNn53/uAj3t+xSI23c9ukgdw2qemNncfK4/Pzl/9t4pUluwEY3j2Zp388OqQ96dL5/H4Dr9/AZlaFXESkI5gM4zCf7YeRcePGMXr0aJ555pngY0OGDOHSSy9l9uzZTdb/7ne/48MPP2TTpk3Bx6ZPn87atWtZunQpEBjjWFlZyccffxxcc/7555Oamsrbb799VF+3OZWVlSQnJ1NRUUFSUuTc+GYYBq8t3cOf/7cRj88gJS5weuYVY3occUV064EqHvlkC/M3HgACrSy/OL0v10/si8vrY9qLK9hyoAoTMLxHMuv2VtDwi7Nfl3hOzEnBbDax9UA1G/MrG01eaQsTYBAIFF6/gd1ixu3zc/agTD7bUsjvpwxmen2LylOfb+fhT7aQGmdj/m1n0CWx5QOKmvPQvM08/cUOTuufwRvXjzui14Yrp8fHda9+w9fbSwC4YWIf7jhvkCrjUcjp8TH4nnncfFZ/Tuuf0ei5N5btYcP+Cr74zVmdtDsRkejTOUOTj4Lb7WbVqlVMnjy50eOTJ09myZIlzb5m6dKlTdafd955rFy5Eo/H0+qahmsezdeNFm6vn9/8+zvu/XADHp/BpKFZLLjtDH48rtcRhbDCKid3/Gst5z3+JfM3HsBsChxe89kdZ3L75EFYzCZ++vI3bDlQRZdEBxcM78p39WH8ByO7Mf+203nw8hGs2VvBP1fuZU1eOW6vn+wkB7FtbMEwmQJh3Gb5/mZPjz8Q6H1G4P87DpohfsPEvgztmkRZrYeH5m1u83uFwI2un28pAkI7XrAzGYbBb/79HV9vLyHebuGFa8dy14VDFcajlKv+H7vNziG3aMqKiEioRUwgLy4uxufzkZXVeHpFVlYWBQUFzb6moKCg2fVerzd4qFFLaxqueTRfF8DlclFZWdnoRySpdXu57tVv+PeqvVjMJu6+cAjPTxtzxJXif63M45y/LuLfq/ZiGHD+Cdl8MuN0HrpiZPBwmqc+386m/EoyEhw8efWJ/G9dPgCPXDmSv199ImYT/PTlFWwvrCbRYeVnE3rztx+Nosrppc7jI8bW/C/j0T1TuPmsQMW74XOgg4OEYcCAzAS2FwZGMfbOiA8+Z7ea+fNlwwB499u9FFe3fZb5E58F3k9yrI2fn9anza8LZws3FfLR2v3YLCZe+tlJTOqEKTLScRo+fWppDrnXr5YVEZFQiphA3sBkanpz4KGPHW79oY+35ZpH+nVnz55NcnJy8EdOTuSMhHN6fFz/6kq+2lZMnN3Ciz8dy/UT+7b6fpvz+MKt/Obf31Hl9DK8ezLv33wqz04bw4Cs70/UNAyDt1fkAvCXy4YF+8QHZCZwxZhA7/brS/dQ4/Yxskcyi39/NvddfAL//S6fGreP3ulxOD3+Rj3sdquZF68dy39uOpWBWYm01t4+vl86+8rriLNbOKVP41NCR/dMZXB2In4DVtYfZHQ4y3eW8PfPtgFw/yUnkBZvb9PrwpnT4+NP/90IwPUT+zZ7mqpEl4aDf5qbQ241m1UhFxEJsYgJ5BkZGVgsliZV6cLCwibV6wbZ2dnNrrdaraSnp7e6puGaR/N1AWbNmkVFRUXwR15eXtveaCfz+w1ue2cNS3YEWhNev+5kzhqUecTXWbm7lMcXBoLprWf35/2bT222fcPp8VNeG2gfOrFnCsO6JwOwo6iaLQVVAFS5Agf99EyPJykmcB/ytgOB51LrA6/voJnjbq+fgkon17ywjF/PWYO/hewwokcyby7bA8BNZ/ZrMg3F5zeorv/azQWTQ1XUebjtnTUYBlw+ugeXjIr8MYB+f6BVJbe0luykGG4+q39nb0k6gKt+vn9LFXLd1CkiEloRE8jtdjtjxoxhwYIFjR5fsGABEyZMaPY148ePb7J+/vz5jB07FpvN1uqahmsezdcFcDgcJCUlNfoRCZ76fDsfry/AbjHz4k9PYkyvo5tZ/eHa/QCcOySLmfV94s2JtVsYVF8xf/GrXeSkxXH+Cdn4DbjzvXX4/AaX1c+3/mjtfn7y0nK2HqiiW327S3X9qZzW+us3fJm731/Pkh0lLe4vOdbGd3sr8BmBPvXph8wbNwyD+z/awN6yOpJjbW2qCv/xww3sr3DSKz2OP15ywmHXhzunx8ev3l7NR2v3YzWbePSqkY1OVZXo1VAhtzdbITdp7KGISIhFTCAHmDlzJi+++CIvv/wymzZt4rbbbiM3Nzc4V3zWrFlce+21wfXTp09nz549zJw5k02bNvHyyy/z0ksvcccddwTX/PrXv2b+/Pk8+OCDbN68mQcffJCFCxcyY8aMNn/daLFubwWPLdwKwJ8vG8b4fkffmtBwCmdRlRN/SyXqejPOHQDA81/u5H/f5XPPD4aS4LCyak8Z9364nlP6pnPH5IHYLWa+3l7CBX/7ivT6ynhBRWAeekM3zWG+FBCo8FXUebBbzcyaMpgnfjSqUSVwV3EN015awatLA9Xze38wlPjDBNH/fZfPf1bvw2wiKoJrXmktVz67lP+ty8dmMfHY1FFMOGTahkSv1nrINfZQRCT0IiqQT506lccff5z777+fUaNG8eWXXzJ37lx69eoFQH5+Prm5ucH1ffr0Ye7cuXzxxReMGjWKP/3pTzzxxBPBGeQAEyZMYM6cOfzjH/9gxIgRvPLKK7zzzjvBGeRt+brRwDAM7v5gPf76ivFVY4+t5/2yE7sTZ7ewdm8Fz3+1s9W1U4Z35Ren9wXgN/9ei9fn5y+XDcNkgjeW5XLmw19Q7fLx2NSRnD04E6/f4KPv8kmNs1Hl8uKwHllPq89vMConhY9/PZEbz+iHyWTCMAzW5JVz+z/XMunRRSzeXkyMzcxfrxx52DnkO4qq+f1/Aqdi3nRm/6P+VCFcLN9ZwsVPLmbdvgpS42y8ft04fjCyW2dvSzqQOzhlpelfETaLGa/fOOw/tEVEpO0iag55JAv3OeSfbjrAda+uJM5u4Ys7ziSzvsJ9LN5Ytoe731+P2QSzfzicqSe1fIiS1+fnmheXs2JXKSN7JPPWDafw5dYi7vlgPcXV3x8I1CcjjqFdk4OTWBxWc3BEW1vE2y3cPnkQU4Zns7esjl1FNazbV8GX24rYU1IbXHfGwC7cd/EJ9Dlo8kpz8kpruebFZeSV1jGmVypzfnFKs8eNR4r/fZfPjHdW4/EZDO+ezDM/GU2PVB36c7xZsr2Ya15czuNTRwU/7Wrw1bYinv5iB5v/dH7ITn4VETneRfbn6hIyLy3eBcBPTukVkjAO8ONxPdmUX8mby3P53bvr+GxzIXdfOLTZUx2tFjOPXjWSC59YzNq9FUx7aTl/+9GJfPXbs1m46QALNx3g002F7CquZVdxLX0y4sgrrQuG8YZO19b+dTmyRzK9M+J54aud3F8/NeRgMTYz552Qzc8m9ObEnqmHfX+LtxUz4501FFe76JUex3PTxkR0GH992R7urf+UZMqwbB69alSTG13l+BCcQ97Mr+eGx1xevwK5iEiIKJALByqdwRsgrx0fujYck8nEny4ZRnZSDI9/uo1PNhzgiy1F3H3hEKaN791kfY/UOF79+clMe3E53+aWc/Zfv+CMgZmM75fOT07pxT0XDeX1pXt4dtEOdhUHqtkpcTbq3L5GVfJDw3mXBAfxjkD7zNq9FUDg5s9uKbH0To9nUHYiJ/VOZeKALoftFQfYXljN3z/bxgdrAjeuDs5O5NWfn0xGwpHNaG9ORa2HL7cVsSm/EpMJzhiYycl92rcFprTGzf/7eBP/XLkXgKtP7smfLx3W4o24Ev2+D+TNHwwEHPFJuSIi0jIFcuGb3aUADOueFPL2BLPZxK/OGcCkE7L444cbWbqzhHs+2EBRtZuZkwY2WT8qJ4WPfnUad763jiU7SoLVcQjMFz99QAazfzicr7cX89Ha/ODIxIM1BPGsJAdWs5l95XUUVQdef+Hwrlw8qhvj+qQRZ2/7L3+X18fCjYW8tWJP8Oh4kwl+Mq4Xsy4YfETXak5uSS1/+3QbH63dH5xwAfDU5zuY/cPhXH1yy+0+h2MYBmW1Hspr3cGbXmvdXnaX1LJ0Rwn/Xbs/OFryjskDufms/kc8c16iy/dzyJtWyO3BCrmvQ/ckIhLNFMiFvWV1AAzMTDzMyqM3ODuJt24Yx9Nf7ODhT7bwxKfb6JEa2+zNo70z4nnrhlPYlF/JZ5sLWZ1bztq95RRVuVi4qZCFmwrJSYvl/07tjdlkIre0lgOVTlxeP3arGZ/fX/9Y4HRNu9XMNSf35Kaz+pGZeGTtOLuKa/jH17t4f/U+KutHLJpMcM7gLGacOyA4N/1oOT0+Hlu4lZcX7wremDogM4FxfdPYU1LLV9uKefKz7Vw+ugd2a9vaYbw+P6vzylmyvYRVuWWsyS0L7r0lQ7smcd/FJ7R7NV4iw/dTVpqrkJsbrRERkWOnQC7B2d2edp6aYDKZuPms/jg9Pv7+2XZm/WcdDqu5xQN0hnRNYkjXwA2whmGw9UA1b6/I5d1Ve8krreO5L1uf3pIYY+Xqk3tyw8S+dEk8snaS7/aW8/jCbXy+pZCG256zk2K4YkwPfnRyTkg+SVi/r4Jb56xmZ1ENABMHZDBz0kBG5aRgMpmodXs56c8L2Vdex4VPfMXEAV0Y3iOJc4dkkRhja3Qtp8fH0h0lfLa5kI/X5ze6EbZBosMaHA8ZZ7fSLSWGET1SOGdIJqf2y8CsFhWp5/L6MJvA0swnJbb6XydujT4UEQkZBXIJHmW/dEcJLq8Ph7V9b9S67dyB7C938u63e/n1nDV8tDafa8blcFLvtCZBs4HJZGJQdiL3XXwCvz1/EB+vK2DuunxW55VTWhMInzaLiZ5pcYztlcZ5w7I4tX/GEb+X1bll/P2z7Xy2uTD42FmDuvDz0/owoV9GyPqq31i2h/s/2ojb5ycz0cEDlw3n3KGNT36Ns1v5+zUnMmPOGrYVVrOtsBoITIqZfkY/RvVM4UCliyU7ipm/4UDwVFEI9Naf2j+DcX3SGN0zlf6ZCboBT9qszh34c6C51iVVyEVEQk+BXDitfwbZSTEUVDq5+731/PmyYe0ays1mEw9ePpysJAfPfbmzUZ94VpKDnmlx9M9MYNLQLM4enNXk9XF2K5eP6cHlYwLzwV1eH16fQazNclRV3mqXlwUbC3jnmzyW7Qz005tNcOmJ3fnV2QMOO/rwSBiGwSPzt/DU5zsAOHdIJo9cOZKUOHuz688enMXC28/gi81FbCqo5MutRewoquGvC7Y2Wds1OYazBmcyaUgWpw3IiOiJL9K5nB4fjhZapOwHTVkREZHQUCAXbBYz9108lJve/JZ/rdrL51uKOGNgF/pkxJHgsOL1GxRXu9lXXkdJtYtYm4UzBnXhqrE5R111tVrM/Pb8wVx2YndeX7aHz7cUkldax4FKFwcqXXyzu4y3V+Rx9ck5/OmSYc2eGNjAYbVw6HAUt9fPyj2lfLOrjG2FVewvr8Pt85McayMjwUG8w0qd28eu4ho27q8MfvxuMZu47MTu3HxW/5AG8Qb/+Hp3MIzfPmkgt5x9+BsoMxNjuOqkQK+932/w7rd7+e93+eRX1JEWb2dYt2TOH5bN6J6pajuRkKjz+HDYmv89pykrIiKhp0AuAJw/rCvPTRvLPe+vp6Ay0E7Smk83F/LPlXk8N20s3VNij/rrDshK5P5LhgFQXutmd0kte0pqWLm7jDeW7+HtFXkkOKzcdeHQVq/j9xuszitn6Y5iVu4p45tdpdS42z4Fond6HJee2J2rxubQ7RjeT2t2FFXzwNxNANx5wWB+cXq/I76G2WziyrE5XHmMJ6mKtKbW7WvxJmKbWlZEREJOgVyCJg3N4oyBXfh6RzFrcsvZX15HrduH1WIiNc5O95RYuiQ6OFDp5Lkvd7J+XyXn/nURV4zpwblDsxjVI4XkuOZ7wNsiJc7OqDg7o3JSuGRUd8b1TeOWt1bzwle7yEmL49pmZpdvKajivdX7+GjtfvaV1zV6Lj3ezmkDMjihWxI5qXHE2CyU17kpqnJR6/YRY7PQPSWWET2S6ZkW166j/gzD4L4PN+D1G5w1qAs3TOzbbl9L5Fi11rLSUCFXy4qISOgokEsjdquZswZlctagzFbXXTC8KzPeWcOqPWW8vmwPry/bA0CP1FiG1k9HGZCVQO/0eHqlx7V4s2ZrLhrRja0FVTzx2Xb+8MEGdhbV8JNTeuLzw/JdJXywZj+r9pQF1yc4rJwxsAtje6dycp80hmQnhUULh89vMHvuJr7aVozdauaei4ZqzreEtTq3D7ul+XY0zSEXEQk9BXI5Kjlpcfx7+ni+3l7CB2v2sWJ3KXtKatlbVsfesjrmbzzQaH3X5BjG9UnjyrE5nNo/o81f57ZJAzGAv3+2nVeW7OaVJbsbPW81mzh7cCaXntidswdnhtUkEafHxycbCnhu0U425lcCcN8PTqBvl4RO3plI6+raUCFXy4qISOgokMtRM5lMnDYgg9MGBAJ2Ra2HDfkVbNxfyZaCKrYXVZNXWktxtZv8Cifvr9nP+2v2c/XJOfzl0uFtql6bTCZunzyI0T1TeXbRDr7bW4HVbGJotyTOGZLJpaO6k5l0ZIf9HKmCCicr95Syt6wOi8lEVnIMfTPi6ZkeR9JBlf9ql5dtB6pYm1fO0p0lLN5WHOxjT3BY+ctlw1qcuS4STlrrIbeYTJjQHHIRkVBSIJeQSY6zMaFfBhP6Na6AVzo9bNhXydx1+by1Ipe3V+Th98O9Fw9t85HzZw3O5KzBrbfRhNrK3aU8tnArX28vaXFNjM1MnN2K0+OjtpmbSLunBE4jnTa+F2nxzY82FAk3dW4fsfbmP20ymUzYLGZcHgVyEZFQUSCXdpcUY2N8v3TG90tnVE4Kd/x7Le+szOPTzYWcPbgLPdPiiHdYSYu3B3rPMxM6tcd6e2E1D87bzIL6thuTCYZ1S6Z/ZgJ+w2BfWR27imsoqXHj9Phxer4/FTMjwcEJ3ZI4qXdq4GTN7slh0ccuciTqPD5SWrlB22Y1qUIuIhJCCuTSoS4f04MuiQ5m/Wcd+8rr+OfKpuMVB2QmMOuCwc0eCtSe1u+r4OXFu/hg7X58fgOL2cRVY3tw81n96ZEa12R9jctLSbUbp9eH3WImI9FBwqED0UUiUJ3bh72Vw8FsFrN6yEVEQkjpQTrc6QO78MVvzmTxtmK+zS3jQKWTGrePokoXa/aWs62wmp+/spLzTsjioStGkhx79KMUD6eizsOHa/fzz2/yWLevIvj4uUOy+P2UQfTPTGzxtfEOK/EK4BKFaj0+YlroIQcFchGRUFOakE5hs5ib7Quvcnp48rPtvLh4F59sOEBu6TKenzaGnLSmFepjkVday7OLdvDut3tx1vfC2iwmpgzrynWn9WFkTkpIv55IJHG2clMnBH6vaOyhiEjoKJBLWEmMsTHrgiFcOKIrP3/lGzblV3L5M0v4v1P70D8zgawkBz3T4kiJO7obJOvcPh5fuJWXv96Fx2cAMCgrkSvH9uCyE7uTnuAI5dsRiUitHQwEYDOrQi4iEkoK5BKWRvRI4YNbTuMnLy5nV3END87b3Oj5XulxnD8sm5vP6t9o9GBrNuVXcstb37KjqAaA0/pncPNZ/Tmlb5oO6hGp5/cbOL3+VnvIrRbd1CkiEkoK5BK2uqfE8r9bT+NfK/eybGcJ+8rrKKhwUljlYk9JLc8t2sm2A9W89NOxhw3UX2wp5OY3v6XG7SMrycEDlw3nnCEde9OoSCRw1Ve+W6uQWy3m4DoRETl2CuQS1uLsVn46oTc/ndA7+Fil08Onmw5w2ztr+WxzIVsPVDMou+WbLz/ddIAbX1+F128woV86T14zWjPBRVpQ6/YCrQfyQA+5ArmISKgokEvESYqxkZUYOJ3TbjWTldRy3/fq3DJ++ca3eP0GF47oymNXjWr1ZjWR412dJ3CzZqs3daqHXEQkpBTIJeLUur3Mem8dAFPH5rR4g2dRlYsbXluF2+fn3CFZPD51FDaLwrhIa5z1gdxxuB5yBXIRkZBROpGI8/TnO9hTUkvX5Bh+e/6gZtf4/Qa/+fdaiqtdDMpK5PEfKYyLtEWdOxC0W6uQq4dcRCS0lFAk4ry3eh8Av58ymMQWJqw8/cV2vthShMNq5m9Xj9IJmiJt1NBD3trBQHaLWXPIRURCKGICeVlZGdOmTSM5OZnk5GSmTZtGeXl5q68xDIP77ruPbt26ERsby5lnnsmGDRsarXG5XPzqV78iIyOD+Ph4Lr74YvbubXyc+1/+8hcmTJhAXFwcKSkpIX5ncqQaPlLfXVyL3280eq7O7eOPH23gkflbAbjnoqEMzk7q8D2KRKq29JBbzWpZEREJpYgJ5Ndccw1r1qxh3rx5zJs3jzVr1jBt2rRWX/PQQw/x6KOP8uSTT/LNN9+QnZ3NpEmTqKqqCq6ZMWMG7733HnPmzGHx4sVUV1dz0UUX4fN9X/1xu91ceeWV/PKXv2y39ydt1zBx5bGFW7n4qcXMWZHL51sKefiTzUx86DP+8fVuAO6YPJAfj+vZeRsViUBt6SG3WXRTp4hIKEXE5/ibNm1i3rx5LFu2jHHjxgHwwgsvMH78eLZs2cKgQU37iA3D4PHHH+euu+7ihz/8IQCvvvoqWVlZvPXWW9x4441UVFTw0ksv8frrr3PuuecC8MYbb5CTk8PChQs577zzAPjjH/8IwCuvvNIB71YO5+az+uOwmnni022s31fJ7/+zrtHz3VNiuf+SEzRnXOQotKlCrrGHIiIhFRGBfOnSpSQnJwfDOMApp5xCcnIyS5YsaTaQ79q1i4KCAiZPnhx8zOFwcMYZZ7BkyRJuvPFGVq1ahcfjabSmW7duDBs2jCVLlgQD+dFwuVy4XK7gzysrK4/6WtKYxWzixjP6ccWYHry9IpcvtxVTWeehb5d4LhjelfNOyNYNnCJHqcblw2wKzBpviV0VchGRkIqIQF5QUEBmZmaTxzMzMykoKGjxNQBZWY2rpFlZWezZsye4xm63k5qa2mRNS9dtq9mzZwcr69I+0hMc3HL2AG45e0Bnb0UkalQ5vcQ7rK2efmu1mHHrpk4RkZDp1DLifffdh8lkavXHypUrAZr9y8EwjMMemX7o8215TVvWHM6sWbOoqKgI/sjLyzum64mIdIRKp4d4e+u1GpvFhNtntLpGRETarlMr5Lfccgs/+tGPWl3Tu3dvvvvuOw4cONDkuaKioiYV8AbZ2dlAoAretWvX4OOFhYXB12RnZ+N2uykrK2tUJS8sLGTChAlH/H4O5nA4cDhaPkFSRCQcVdZ5iLO3fEMnBFpWGm7+FBGRY9epFfKMjAwGDx7c6o+YmBjGjx9PRUUFK1asCL52+fLlVFRUtBic+/TpQ3Z2NgsWLAg+5na7WbRoUfA1Y8aMwWazNVqTn5/P+vXrjzmQi4hEokqnl9jDBHKHzYLXb6iPXEQkRCKih3zIkCGcf/753HDDDTz33HMA/OIXv+Ciiy5qdEPn4MGDmT17Npdddhkmk4kZM2bwwAMPMGDAAAYMGMADDzxAXFwc11xzDQDJyclcd9113H777aSnp5OWlsYdd9zB8OHDg1NXAHJzcyktLSU3Nxefz8eaNWsA6N+/PwkJCR33jRARaWdtqZDH2AK1nDq3r9VpLCIi0jYREcgB3nzzTW699dbgRJSLL76YJ598stGaLVu2UFFREfz5b3/7W+rq6rjpppsoKytj3LhxzJ8/n8TExOCaxx57DKvVylVXXUVdXR3nnHMOr7zyChbL938h/eEPf+DVV18N/vzEE08E4PPPP+fMM89sj7crItIpKuo8JMc2fwJug5j6GeU1bi/Jca2vFRGRwzMZhqE7czpAZWUlycnJVFRUkJSkkyNFJDyd89cvGJSVyLTxvVtcs6Wgivs+2sDCmafTPzOxxXUiItI2+qxRRESCKp1e4hytf3ja0LJS49KNnSIioaBALiIiQVVt6iH/vmVFRESOnQK5iIgA4PL6cHr9xB1mDrmj/kbOWlXIRURCQoFcRESAwCmdAPGqkIuIdCgFchERAb4P5IfrIbdbzZiAWrcq5CIioaBALiIiQGAGORy+Qm42mYixWahxqUIuIhIKCuQiIgJApTMQyA93UycEJq2oQi4iEhoK5CIiAkBlXX3LymFu6oRAH7l6yEVEQkOBXEREgMApnSYg1taWCrlFU1ZEREJEgVwiimEYlNW4qdNH5SIhV1ztIjnOhtlsOuzaGJtZFXIRkRA5/OeSImFi4cYDzP54EzuKanBYzfz8tD7cMXkQljaEBxE5vKIqFymxtjatdVhVIRcRCRUFcokIz3+5g9kfb8YwAj93ef0888UOkmNtTD+jX+duTiRKFFW5SG5zIFeFXEQkVNSyImHvjWV7eGBuIIxfM64na++dzB8uGgrA4wu3cqDS2ck7FIkOhVXONgdyjT0UEQkdBXIJa0t3lPCHD9YDcMtZ/XngsuEkx9r4v1N7M7RrEk6Pn6+2FXfyLkWiQ1GVi5Q4e5vWBgK5WlZEREJBgVzCVlGVi5vf+ha/AT88sTu3Tx4YfM5kMjG8ezIA+eV1nbVFkahhGAZF1W1vWQnMIVeFXEQkFBTIJWzd8/56SmvcDM5O5IEfDsdkanzz5oGqQKtKclzbAoSItKzG7cPp8ZPSxt9PMVYLNZp2JCISEgrkEpaWbC9m3oYCrGYTj141iphD5iJXu7ws31kKwJheqZ2xRZGoUlTlAmjzlJWGHnKj4U5rERE5agrkEpae/2onAD8e15Oh3ZKaPD9nRS51Hh99M+IZ2rXp8yJyZBoCeXIbe8iTYq24vH5qVSUXETlmCuQSdlxeH4vrb9S8dkLvJs+X17p56vPtAPzi9L5NWllE5MgdaYU8KSawrqTa3W57EhE5XiiQS9gprXHj9Qc+Bu+THt/oOcMwuPfDDZTVehiYlcDlY3p0xhZFok5+RR0Oq5k4u+XwiyF482dxjas9tyUiclxQIJewk5HgILa+Z3zZzpLg436/weyPN/PBmv1YzCZm/3A4Not+CYuEQl5pLZlJjjZ/4pQUqwq5iEio6KROCTs2i5kfju7Om8tz+c2/v+PuC4fg8Ru88vUuvs0tB+CPF5/AmF5pnbtRkSiSV1pLlwRHm9cnOqyYgJJqVchFRI6VArmEpd+cN4hFW4vYW1bHL9/8Nvh4jM3MXy4drlYVkRDLLa2jX2ZCm9ebzSaSYm0UK5CLiBwzBXIJSylxdj665TT+umALy3aWYreYmTgwg/+b0Ifs5JjO3p5IVDEMg73ltYzvl35Er0uKtVKslhURkWOmQC5hKzXezp8vHd7Z2xCJesXVbpweP10S296yAoFJKyU1CuQiIsdKd8SJiBzn8spqAcg8ikBeXKWWFRGRYxUxgbysrIxp06aRnJxMcnIy06ZNo7y8vNXXGIbBfffdR7du3YiNjeXMM89kw4YNjda4XC5+9atfkZGRQXx8PBdffDF79+4NPr97926uu+46+vTpQ2xsLP369ePee+/F7VZVSESiQ15pIJAfcYVcPeQiIiERMYH8mmuuYc2aNcybN4958+axZs0apk2b1uprHnroIR599FGefPJJvvnmG7Kzs5k0aRJVVVXBNTNmzOC9995jzpw5LF68mOrqai666CJ8vsDpc5s3b8bv9/Pcc8+xYcMGHnvsMZ599lnuvPPOdn2/IiIdZUdRDSlxNuLsR9bFmBRj1ZQVEZEQMBmGYXT2Jg5n06ZNDB06lGXLljFu3DgAli1bxvjx49m8eTODBg1q8hrDMOjWrRszZszgd7/7HRCohmdlZfHggw9y4403UlFRQZcuXXj99deZOnUqAPv37ycnJ4e5c+dy3nnnNbufhx9+mGeeeYadO3e2+T1UVlaSnJxMRUUFSUk66l1EwsdNb64it6SWuy4cekSvW7S1iGcX7WDj/ecdcZgXEZHvRUSFfOnSpSQnJwfDOMApp5xCcnIyS5YsafY1u3btoqCggMmTJwcfczgcnHHGGcHXrFq1Co/H02hNt27dGDZsWIvXBaioqCAtrfUZ2C6Xi8rKykY/RETC0daCarqlxB7x67qnBCYe7SyqCfWWRESOKxERyAsKCsjMzGzyeGZmJgUFBS2+BiArK6vR41lZWcHnCgoKsNvtpKamtrjmUDt27ODvf/8706dPb3XPs2fPDva7Jycnk5OT0+p6EZHO4PH52V1SQ4/UIw/kXZMDr9lRVB3qbYmIHFc6NZDfd999mEymVn+sXLkSoNnjnA3DOOwxz4c+35bXtLRm//79nH/++Vx55ZVcf/31rV5j1qxZVFRUBH/k5eW1ul5EpDPsLq7B6zfonhp3xK+Nd1hJjbOxo1CBXETkWHRq098tt9zCj370o1bX9O7dm++++44DBw40ea6oqKhJBbxBdnY2EKiCd+3aNfh4YWFh8DXZ2dm43W7KysoaVckLCwuZMGFCo+vt37+fs846i/Hjx/P8888f9r05HA4cjiObWCAi0tG21YfpHkfRsgLQLSWWHWpZERE5Jp1aIc/IyGDw4MGt/oiJiWH8+PFUVFSwYsWK4GuXL19ORUVFk+DcoE+fPmRnZ7NgwYLgY263m0WLFgVfM2bMGGw2W6M1+fn5rF+/vtF19+3bx5lnnsno0aP5xz/+gdkcEZ0+IiKH9d3eCtLj7STF2o7q9V2TY9lWWHX4hSIi0qKISJZDhgzh/PPP54YbbmDZsmUsW7aMG264gYsuuqjRhJXBgwfz3nvvAYFWlRkzZvDAAw/w3nvvsX79en72s58RFxfHNddcA0BycjLXXXcdt99+O59++imrV6/mJz/5CcOHD+fcc88FApXxM888k5ycHB555BGKioooKChoscdcRCSSrM4to19mwlG/Pic1lp1FNdS5fSHclYjI8SVi5lS9+eab3HrrrcGJKBdffDFPPvlkozVbtmyhoqIi+PPf/va31NXVcdNNN1FWVsa4ceOYP38+iYmJwTWPPfYYVquVq666irq6Os455xxeeeUVLBYLAPPnz2f79u1s376dHj16NPp6ETAxUkSkRV6fn+/2VvDD0d2P+hpDuibh9Rus3FPKxAFdQrg7EZHjR0TMIY8GmkMuIuFm4/5KLnjiK+69aCiDux7dn0uGYXDzW99y1Uk5zJoyJMQ7FBE5PkREy4qIiITeN7tLsZpN9OkSf9TXMJlMnNAtma+2FodwZyIixxcFchGR49SCjQcY2jUJh9VyTNc5sWcKG/Mr2a7xhyIiR0WBXETkOFTp9LBsZwmje6UefvFhnNQ7jaQYK2+vyA3BzkREjj8K5CIix6HPNhXi9RuM7nnsgdxmMXPGwC7885s8ymrcIdidiMjxRYFcROQ4YxgGLy/exbBuSXRJDM0BZhcM74rPMHh0wdaQXE9E5HiiQC4icpxZvquU7/ZVcMHwrodf3EYpcXYuH92DN5bt4fMthSG7rojI8UCBXETkOOLy+rj7/fX06xLPyJyUkF77/GHZnNgzhVvfWs36fRWHf4GIiAAK5CIixw3DMLj3gw3sKq7hhol9MZtMIb2+2WTi5rP6k5nk4OoXlvHppgMhvb6ISLRSIBcROQ44PT5+++/vmPNNHjdM7Euv9KOfPd6aOLuVWVOGMCAzgeteXcm1Ly3nkw0FOD2+dvl6IiLRQCd1dhCd1CkinWXl7lJ+8+/v2FtWyw0T+3bIEfeGYbBsZyn/XbefnUU1xFjNnNQnjVP6pnNa/wxG9EjGFOIKvYhIpFIg7yAK5CLS0SpqPfx1wRZeX7qH/pkJ/OL0vvRIjevwfewrr+PbPWVszK9gS0E1dR4f3VJiuHRUdyYNzWJY92RsFn1gKyLHLwXyDqJALiIdodbtZeXuMj7bXMi73+7F4/MzdWwOk4dmYzZ3fkXa5zfYUlDJkh0lrNhVSpXLi8Nqpn9mAgOzEumTEU+P1FgyE2NIjrURa7fgsJpJcFhJirVhCYP3ICISagrkHUSBXERCzevzU1ztZlthFSt3l/H19mLW5JXj9RukxtmY0C+Di0Z0JSXO3tlbbZbX72dnUQ3bC6vJK61lf0UdBRVOKp3eZtebTZAcayM93kF2cgw90+PonhJLSpwNq9mE2WQizm4lLd5OVpKDLokOEhxWTCYTfr+B2+fHajZhVTVeRMKMAnkHqaioICUlhby8PAVykcNITEw8ov5iwzCoqqpqt/0YhoHHZ1Dt8lJe56Ws1kN5nYfyOi8VdR7qPH4wDOxWM/F2CzE2CxazCb9h4PUZeP0GLq8fp8eH129gNpmIsX2/1mwCt8/A7fXj8xuYTYGJJS6fn4o6LwWVLvaU1pFf4aTC6cXrMzCZwH/Qn97xdguDs+IZnJ3A4Kx4uiY5IrZH2+X1U1nnpcbtw+Pz4/b5cXr8VLt9VDm9VDoD/w2Kq92U1nqocflo6S8yE2Axm/Ae9M1KirGSneSgS4KdxBgrMVYzNksg0BuAx+fH4zPw+b//b5ro+P6/q6n+v4/dYiLGZsFqMWGt/157/AZOjw+X14/L66fa5aPS6cXl9WO3mEiNs5EaZyPBYcVuMWGzmLFbzdjrv37DfzLDAG/9PyIAYm0WUmKtJMZYsZpNVLt87C6pZVNBNQeq3MTZLQzMjGd4t0RyUmOIsVla/P4e6e8vEWl/CuQdZO/eveTk5HT2NkQiwpF+ktTwCRRmKz1ufhVLXHI77i48+V21gRR3PDLV/x+TGZPVjsmsCnhziv/3GDXrP9UntSJhSIG8g/j9fvbv349hGPTs2VOV8g5WWVlJTk6Ovu+d4Gi+951dIdevl8b0/Wgs0r8fqpCLhB9rZ2/geGE2m+nRoweVlZUAJCUlReQf5JFO3/fO057fe5PJ1C7X1q+XxvT9aEzfDxEJFX2uJyIiIiLSiRTIRUREREQ6kQJ5B3M4HNx77704HI7O3spxRd/3zhOJ3/tI3HN70vejMX0/RCTUdFOniIiIiEgnUoVcRERERKQTKZCLiIiIiHQiBXIRERERkU6kQC4iIiIi0okUyEVEREREOpECuYiIiIhIJ4rKQP7000/Tp08fYmJiGDNmDF999VWr6xctWsSYMWOIiYmhb9++PPvss42ef+GFF5g4cSKpqamkpqZy7rnnsmLFiiPak2EYVFZWoimTIqGn318iIhLJoi6Qv/POO8yYMYO77rqL1atXM3HiRKZMmUJubm6z63ft2sUFF1zAxIkTWb16NXfeeSe33nor7777bnDNF198wdVXX83nn3/O0qVL6dmzJ5MnT2bfvn1t3ldVVRXJyclUVVUd83sUkcb0+0tERCJZ1B0MNG7cOEaPHs0zzzwTfGzIkCFceumlzJ49u8n63/3ud3z44Yds2rQp+Nj06dNZu3YtS5cubfZr+Hw+UlNTefLJJ7n22mvbtK/KykqSk5OpqKggKSnpCN+ViLRGv79ERCSSRVWF3O12s2rVKiZPntzo8cmTJ7NkyZJmX7N06dIm68877zxWrlyJx+Np9jW1tbV4PB7S0tJCs3GR44RhGOwsqmbhxgN8t7e8s7cjEjUMw2DR1iL+tnAbByqdnb0dETlC1s7eQCgVFxfj8/nIyspq9HhWVhYFBQXNvqagoKDZ9V6vl+LiYrp27drkNb///e/p3r075557bot7cblcuFyu4M8rKyuP5K2IRJUal5eXFu/iX6vyyCutCz7+0OUjuOqknCO+nn5/iXzvQKWTmf9cw9fbSwB4fdluvv792Tislk7emYi0VVRVyBuYTKZGPzcMo8ljh1vf3OMADz30EG+//Tb/+c9/iImJafGas2fPJjk5OfgjJ+fIQ4dIpPP6/Dz/5Q7OePhzHl2wlbzSOmwWE0kxgVrAs4t2HNV19ftLJGDbgSoufeprvt5egtUc+DuruNpNaY27k3cmIkciqgJ5RkYGFoulSTW8sLCwSRW8QXZ2drPrrVYr6enpjR5/5JFHeOCBB5g/fz4jRoxodS+zZs2ioqIi+CMvL+8o3pFI5NqUX8nlzy7lgbmbKa520zMtjsemjmTtvZN5/EejAHB5/Ud1bf3+EoFdxTX86Pll5Fc46dclnuemjQHAajaRHGvr5N2JyJGIqpYVu93OmDFjWLBgAZdddlnw8QULFnDJJZc0+5rx48fz0UcfNXps/vz5jB07Fpvt+z/QHn74Yf785z/zySefMHbs2MPuxeFw4HA4jvKdiEQuwzB4Y9ke/vTfTbh9fhIcVu65aAg/HN0Dm8WMYRg8+dl2ACYNbf4fyoej319yPKlz+3hj2R4q6jzces4A7FYzZTVurn15OSU1boZ1T+L1n4/j/v9uBOC0ARnE2aPqr3eRqBd1v2NnzpzJtGnTGDt2LOPHj+f5558nNzeX6dOnA4HK2r59+3jttdeAwESVJ598kpkzZ3LDDTewdOlSXnrpJd5+++3gNR966CHuuece3nrrLXr37h2sqCckJJCQkNDxb1IkTPn8Bn/4YD1vLg+MGT1ncCZ/uWw42cnft3ct2HiAb3PLibVZuOnMfp21VZGIsKekhv975Rt2FtUAUFLj4oHLhvObf39HXmkdPdPi+MfPTqa42sUHawKjeG+fNKgztywiRyHqAvnUqVMpKSnh/vvvJz8/n2HDhjF37lx69eoFQH5+fqOZ5H369GHu3LncdtttPPXUU3Tr1o0nnniCyy+/PLjm6aefxu12c8UVVzT6Wvfeey/33Xdfh7wvkXDn8fn59ZzVzF1XgMkEs6YM5vrT+mI2f38vhsvr48//C4wY/b9Te5OZ1PJ9GCLHu13FNVz13FKKqr6/gfmrbcXM+SaPhZsOYLeaefrHo0mJs3H9q9/gN+DcIVkM75HcibsWkaMRdXPIw5XmJEs08/sNbp2zmv9+l4/dYuZvPxrFlOFNJxS9uXwPd723nsxEB5/dcSYJjtDUBPT7S6LNgUonP3x6CfvK6xiYlUBpjZviajdTT8rh43X5VDq93H3hEK47rQ93vx/4VCrRYWXBzDMafSIlkcfp8bGjqJoTuukfVseTqLqpU0Q6x8Pzt/Df7/KxWUw8O210s2Ec4P3VgY/Uf3F635CFcZFoU+v2cuPrq9hXXkefjHhO69+F4mp3cDpRpdPLyJwUfjahN48t3Maby3MxmeDRqaMUxqPA+6v3cdnTS/D5VS89niiQi8gxWbGrlGe+CIwvfPiKkZw9uOUbNXcVB/pgT+6jQ7VEmmMYBve8v4E1eeUkxViZOWkgry3dDcBdFw5l/obAPUy/Oqs/f/rvRp74dBsA91w49KhvkpbwUlTlwu31U1ar0ZXHE5WoROSYPDA30BM+dWwOl57YvdW1WUkxFFe7Kax0tbpO5Hj15vJc3v12LyYT/L/LRzD74014/QYXDu/KsO5JlNUGTpD+8/82srukFoC7LxzCz0/r05nblhCqqAv8Ny6tcZORoGlSxwsFchE5agUVTtbklWMxm/jN+Yef7NDQplLj9rb31kQizuaCSv5UP7rw1rMH8MrXu4OTVB64bDh2q5nkWBsVdR52l9SSHGvjr1eO5FxVxqNKeX0gL652MTArsZN3Ix1FgVxEjtqBSicAGQn2NlVy9pbVAdA1ObZd9yUSjtxeP68v28P+8jpO65/BWYMzGz1/93vrcXn9jMpJYfmuElbsLiXBYeWFa8eSHBc4F+Oln45l4aZCspIc/HB0Dx0AFIUaKuQl1WpZOZ4okIvIUetafwNZYZWLkmoX6a2Ecp/fIL8iEMgzEuwdsj+RcJFbUsvP/rGCnfX3Uby0eBdP/3g0F9TfAL2vvI6Ve8oAWJNXDkCc3cKrPz+JQdnfV0nH9k5jbG/dgxHNyut7x0trFMiPJ7qpU0SOWmZSDMO6J2EYMHddfqtrzSbo2yVwkFbDwUEix4PcklqmPr+UncU1pMTZ6JsRD3w/dQggMcZKZuL3/6DtnR7Hu7+cwJheCt/Hm/Lahgq57rU5niiQi8gxOXNg4GP3zQVVra4zmUzcc9FQAF5fuoeK+r90RKJZUZWLa19eTn6Fk35d4pk/43SuGdcTAP9Bx4AkxdhYMPMM/n71ibxw7VgWzDyDIV01U/941NCyUqwK+XFFLSsickx89aHCbDIdZiWM75sOgNvnp9bjJRn1v0r0qnV7uf7Vb9hdUkuP1FjeuuEU0hMc/GvlXgDG98totD451sYPRnbrjK1KGKlsmLKiHvLjiirkInJMVu0O9L0O7nr4aQBfbi0CAj3k2Uk6wESil99v8Ku3VrN2bwWpcTZev24cWUkxvPvtXrYcqCLBYeWK0T06e5sSZpweH06vH4vJRLFaVo4rCuQictTyK+r4Zk8pAGcM7NLqWsMweO7LwAFCl53YHVMbKuoiker+/27k082FOKxmXvzpSfTJiCevtJY/fRQYa/irs/sHJ6eINGhoV8lMclCilpXjigK5iBy115buwTACJ2/2SI1rde23ueV8s7sMu9XM9RP7dtAORTreB2v28cqS3ZhM8MiVIxnTK5WKOg/Xv7qSKpeXE3umcJ0O8pFmNATyrKSY4LQVOT4okIvIUal1e3lz2R6ANoWLt+onq1w8shtZaleRKOX0+PhjfRX8F6f35Qcju1FS7WLaS8vZcqCKzEQHT10zGqtFf/1KUw0TVlLj7Li8/k7ejXQk/YkgIkfl7RV5VDq99EqP49whhz8p8PMthQBcOUZ9sxI9th6o4rf/XssX9b++3/12L6U1brqnxPKbyYNYv6+Cy55ewnd7K0iLt/Pqz0+mW4oOxpLmNVTIU+JsuBXIjyuasiIiR8zp8fF8fT/49DP6YTEfvh+8YXKAwohEi883F/J/r3wDwKb8Ks4clMnH6woAmHpSDk9/sYMnP9uO2+cnJy2Wf/zsJPpn6ih0aVmt2wsE5tJ7/QZ+v4G5DX++SuRTIBeRI/bS4l0cqHTRNTmGH47u3qbX9OuSwJYDVWwpqCInrfV+c5Fwt6WgilvnrA7+vOEIe6slEJ4eXbA1+Ny5Q7J45MoRpMTphFppXUObSpw9EM/cPj8xZktnbkk6iAK5iByRPSU1/P2zbQD85rxBOKxt+8sipX6iRE19BUgkUrm8Pmb+cw1Vzu9/Ld9ydn8App3Si6+3F+PxGXRPieW35w/i4pHdNFVI2sTl8WE1m7DX32Pg9vmJsSmQHw8UyEWkzXx+g1vfXo3T4+eUvmlcdmLbquNur5+N+ZUA9EqPb88tirS7F77cyYb9lcGfj+2Vyrg+gSPuzxmSxfI7z6W0xkWv9HhsunlTjoDL68dmMWOr/6RFfeTHD/1JISJt9sayPazdWwGA3w+/f3cdX20rOuzrPtlQQJXTS2aig+Hdk9t7myLtxuX18cqSPcGfx9jMPHTFiEYV8LR4O/0zExXG5Yi5vH7sVnNwCo8mrRw/9KeFiLTZwTdvrthdyjsr85j20orghInmHHwg0I9O7tmmG0BFwtX8DQcanaD4wGXD6dsloRN3JNHE6fFht5qxq0J+3FHLioi02dUn98QAiqpcJMVYmfNNHtsLq/l8cyFnDsps9jULNh5g/b5K4uwWfjahd4fuVyTUrAf9g/LuC4fww9Ea4ymhE2hZMQUr5Arkxw8FchFpM4vZxLRTegV/7vb5eWjeFmrcvmbX+/1GcNrEzyb0Ji1eUyYksk0Z3pUPbzmVnmlxmpoiIefy+Op7yBXIjzcK5CJy1NLqA8m2wupmn1++q5TNBVUkOKz84vS+Hbk1kXYzokdKZ29BopTL68duMQc/iXH7mi92SPRRD7mIHLVT+2cA8N3ecgzDaPL8wk0HALhgeLaqiSIih+H0+LBaTMEKuW7qPH4okIvIUSupcQNgM5tpJo+zYX9gIsvJfdI7clsiIhGpoULeMPZQgfz4oUAuIkfFMAye+DRwQNB5w7KbPd55Z1ENAH27aPa4iMjhqIf8+KVALiJH5d+r9vLZ5kJsFhMzzh3Q5PmdRdUUVrmwmE0Mzk7shB2KiEQWZ/3BQFaNPTzuKJCLyBHblF/JHz7YAMCvzxlAv2bmML+2NHB4yukDMoiz6/5xEZHDcXp82A7qIVcgP34okIvIESmrcXPDayup8/iYOCCDX57Zv8ma7YVVvLk8EMivn6jpKiIibRE8qTM4ZUWB/HihQC4ibeb3G/zq7dXsLaujZ1ocT149usnJm4ZhcOd76/H4DM4a1CU4iUVERFrn8gRaVkwmEzaLSRXy44gCuYi02ZvL97B4ezExNjMv/nQsyXG2JmveX7OPFbtKcVjN/Pmy4Z2wSxGRyOTy+oLtKjaLGZdXc8iPFwrkItImhmHw/Fc7AfjNeYMZmNX8jZofrNkPgNdvYGtm8opIuDMMgw37K1SdlA7XcFMnBAK5fg0ePxTIRaTN/PV/N7yxbA/PfLGDijpPkzUNp3f6/AbnPf4lZfWzykUixR8/2siFTyzmwie+otLZ9Ne4SHtxeXzY6yesqGXl+KJALiJtYjKZuOeioZhMsKu4hgfnbebiJxc3CSwPXTGCv145EoCyWg9r95Z3wm5Fjs689fm8smQ3ANsKq6ls5h+dIu3FXX9TJ9S3rOimzuOGArmItNn5w7JZcNvp/OWyYaTF29lTUsvc7/IbrbFazPRKjwv+vFtKbEdvU+So/W9dQfB/TxyQQY/UuFZWi4SOYRi4DmpZsapCflxRIBeRI9I/M5Ef///27js8qmpr4PBvenpCOiEJCTWETuggRRGwoGJviF0u18q162fv16tcFUURsSsqYBeBK72XhBpKSCCk955MPd8fk4yEFBJIMmSy3ufJAzmzz5k9k3OSNfusvfaIrtwyqisAG5Lyaj2+L72Yuz7fAcCVg7s0mGsuxLnIrXp0MszXjTer7/QI0RZMVhsK/J1DrpYc8o5EVusQQpyRvmG+gD19BcBstfH11lRe++MglWYrAyP8eOGKfs7sohDN9tQlfRgW7c+U2NB6qwgJ0VqM1cH3ySPkRgnIOwwJyIUQZ6SmHNfx/AqeWLqXNYdyyCyuAuy3+t++biA6jVRZEe2Ln4eea4dGOLsbogMymu3B98k55DJC3nFIQC6EOCOjuwcS4mMgu8TIN9tSAQjw0nNxv84cyS5l1Kt/YbYqTOoTzLybhmDQapzcYyGEOHfVDHLUDGRIDnnHIgG5EOKM+HvqWTp7DPNWJ+Gm1dAzxJMlO9L5YsvxWu1WJebwx94srhjcxUk9FQKO5ZWzKjGbSX1CiAr0dHZ3hKijqmaEvFYOuSwM1FHIpE4hxBnr4ufOK9P7c1H/UF5ffogdqYUYtGpuHxPNmocnEObrBoBKMleEEymKwi2fbOOl3xK59N0NsvqhOCc5Rsi1J+WQS9nDDkNGyIUQZ2X1wRzu+XInJouN/l18ef+mIUT4e7DpaB4ZxVXotWpGdw90djdFB5ZTaiS1oAKwfzjUqmUsSpx7aiZwnjxCXiUfHjsMCciFEGdsY1Ied3+xw5Er/u4NQ3DXa1AUhdeXHwLguqERBHkbnNxT0ZH5uv9dLeW20VFo1HLLRpx7aiZ1ah055GqqZGGqDkMCciHEGUnKKWPWFzsxWxUu6hfKOzcMdpTrWpWYw+4TRbjrNNx/QU8n91R0dG46Dd/PGsVPCencNa6bs7sjRL1qUlYcI+QyqbNDkYBcCNFs5UYLd3+xg1KjhWFRnZh7/SBHMA7wy+4MwL6yp4yOi9ZgtSkYLVY89E37MzYsyp9hUf6t3CshzlxN8K3VnFT2UHLIOwxJpBNCNIuiKDy6ZA/JueWE+rjxwc1xdUoaWhUFgLWHc8mqrk0uREtJySvn4v+uZ8TL/+NQVqmzuyNEi6gJvk8ue2iRgLzDcMmA/P333yc6Oho3Nzfi4uJYv359o+3Xrl1LXFwcbm5udOvWjfnz59d6fP/+/Vx11VVERUWhUqmYO3duK/ZeiHPbgvXJ/LYnE61axbybBhPoVXcE/LlpfYkK8KCg3MTjS/c4oZfCVWUWV3LN/E0cyi6l1Gjhr4M5zu6SEC2iJoe85m6jRq3CbFWc2SXRhlwuIF+8eDEPPvggTz31FPHx8Zx33nlcdNFFpKam1ts+JSWFiy++mPPOO4/4+HiefPJJ7r//fpYsWeJoU1FRQbdu3XjttdcIDQ1tq5cixDlnWXwar/5xELAvMR7Xtf4UgCBvA09fEgvAluT8NuufcG2VJiu3LdpOXpnJsS3UV1KihGuoGSHXVk861qolZaUjcbmA/K233uKOO+7gzjvvpE+fPsydO5eIiAg++OCDetvPnz+fyMhI5s6dS58+fbjzzju5/fbbefPNNx1thg0bxr///W+uv/56DAb55S86HkVR+Hh9MnO+242iwC2junLr6KhG99mQlAcgebvijBRVmCitql1h4oVf93PwpBSVLn7uXNSvc1t3TYhWYbLY0KpVqFQ1AbmkrHQkLhWQm0wmdu7cyeTJk2ttnzx5Mps2bap3n82bN9dpP2XKFHbs2IHZfOblhoxGIyUlJbW+hGiPKkwWHvg2gZd+S3QE489N6+v4o1Gf+NRCx4qds8Z3b/E+yfXl2o7nlTPxzTVMfHONIyBZeziXb7adqNXu1Sv746bT1HcIIdodo8WKXvt3WKbVSMpKR+JSAXleXh5Wq5WQkJBa20NCQsjKyqp3n6ysrHrbWywW8vLyzrgvr776Kr6+vo6viIiIMz6WEM6SklfOtHc38PPuDLRqFc9Oi+X5y/qibqSOc2G5ifu/jcdqU7hsYBhjerT8okByfbmukiozl763gcIKM3llJsqMFsqMFp7+cW+tdk9cFMO4XkFsSc7nocUJ/POrXcSnFjqp10KcPZPFVqtalT2HXEbIOwqXCshrnDpypyhKo6N59bWvb3tzPPHEExQXFzu+Tpw4cfqdhDiHbEsp4LL3NnA0t5wQHwNf3TmC28ZEN3pdWKw2HlicwImCSiL83Xlper9W6ZtcX67rv6uOUFplAWBsjwD0GjX3fb2LEwWVjjYPTerFned148VfD3D9R1tYFp/Ob3szmf7+JuZ8l1DnNr/NplBUYXL8bhfiXGQPyP/+/apVq7HYFDlvOwiXqkMeGBiIRqOpMxqek5NTZxS8RmhoaL3ttVotAQEBZ9wXg8Eg+eai3Vp7OJe7P9+B0WJjcKQfH80Y2qR64nNXHWHd4VwMWjULbhmKj5vutPucCbm+XNO+9GIWbkhxfH/t0Eiu/GBTrbzx/7s0lquGdGHmJ9sc8xQuHxSGxarw295Mlu5KZ3JsKJP6BHMwq5Tvdpzgl90ZFFaYCfTSM2t8d24bEy2rdYpzjtFae4S8ZnKnxabUCtSFa3KpgFyv1xMXF8fKlSuZPn26Y/vKlSu5/PLL691n1KhR/PLLL7W2rVixgqFDh6LTtU4wIcS5bP2Rv4Pxib2D+ODmuCbl6eaUVvHhuqMAGC02fk7IwGOYlsgAj9busnABVpvCv77b7fi+W6Anjy/dQ4XJ6tg2rlcQKmDy2+vIKTXirtPwn2sHcnF/+8TOtHkb2X2iiFlf7rRPiLPVHlnMKzPx0m+JeLtpuW5YZJu8LiGaymi2oT15hLz6/+ZTAnXhmlzuJzxnzhw+/vhjPvnkExITE3nooYdITU1l1qxZgP1W9y233OJoP2vWLI4fP86cOXNITEzkk08+YeHChTz88MOONiaTiYSEBBISEjCZTKSnp5OQkEBSUlKbvz4hWtOOYwXc/flOjBYbk/qE8OGMoU2eNOep1xLm5+74/v01R7nk3fWUGS2t1V3hQj5Yk8ShbPtIuFatIjmvnAqTldHd/75Tue5wLi/8eoCcUiNRAR4snT3aEYwDXDYwjJqBb4tNwUOvYXJsCF/cMZz9z0/B31MPQGHFmU/YF6K1mKw2dOqTR8jt/zdbJGWlI3CpEXKA6667jvz8fF544QUyMzPp168fv//+O127dgUgMzOzVk3y6Ohofv/9dx566CHmzZtHWFgY77zzDldddZWjTUZGBoMHD3Z8/+abb/Lmm28yfvx41qxZ02avTYjWlJRTyu2fbqfSbGVcryDev2lIrRn/p+Np0LJqzni2pRSQklfO0z/uo7TKQnphJb1DvVux56I9UxSFhRtSeHPFYce2mpHtW0dH8fQlfbh10XZHesrgSD+mD+7CdcMi6qwQe8fYaCbHhpCUW0bPYC/CfN0dE5B/SkinoNyEWgUTege10asTounqm9QJSC3yDsLlAnKA2bNnM3v27Hof+/TTT+tsGz9+PLt27WrweFFRUTKpQri0ogoTt326nZIqC0Mi/fjw5rhmBeM1dBo1Y3oEUnO5GLRqQn3cWri3wlWUGS08//N+vt+ZVuex2RO688iU3qhUKr64Yzj55Sa0ahV+HvpGjxnh70GEf+00qeTcMp5caq/Scu/5PYkJ9Wm5FyFECzFZTklZUf+dsiJcn0sG5EKIplMUhYeqK6NE+nvw8cxhuOvPvLZzldnKMz/tA+D6YRH4eshcDFHXrtRCHvg2vlb1lBpT+oY4gnGwV7wK9DqzSbyVJiuzv9pFucnKyG7+3H9+j7PqtxCtxWix1ptDbpFa5B2CBORCdHBfb0tl9SF7ZZQPbh7iyLM9U6/9cZDkvHKCvQ3Mmdy7hXopXMlnm47x4q8HsNgUgr0N5JQaHY/pNCpeuqL/WZWdraEoCk//uI+DWaUEehl45/rBaGVynDhHmSz155BLykrHIL+ZhOjA0osqeeW3RAAemdKbvmG+Z3W8TUfz+GzzMQBev3oAvu4yOi5qe3vlYZ79eT8Wm8Il/Tvzjwm1V3L9v0tjm1Risym+3JrKkl1pqFXwzvWDCJb0KXEOMzaQQy4pKx2DBORCdFAWq42Hvk2g3GRlaNdO3D4m+qyOZ7baePrHfSiKPVVlYu/gFuqpcBVfb03lv/87Atg/AL5342CO5JQ5Hr9sYBgzRnZtkedadziX537eD8CjU2MY3QorxgrRkoyn5pBrJCDvSCRlRYgOat7qo2w7VoCXQcub1wx0VKM4UxuT8kjOLcfboOWpS/q0UC+Fq9iXXsyzP9vnFsy5sBf/nGjP5b7//J6UVlno7OtWK2/8bGxNzueeL3ZitSlcObgL94zrdtbHFKK1GS22WncV/57UKTnkHYEE5EJ0QJuP5jP3f/Yyc89f1peoQM+zPmZ+mQmACrOVCpMV71ZapVO0P0aLlYcWJ2C2KlwYG8J9J02sDPV1490bBjeyd/Oe54vNx3lj+SFMVhvjegXx6lUtk48uRGszWaynrNRZXYdcRsg7BElZEaKDySyuZPZXO1EUuCYunKviwlvkuOfHBBPh747VpvD8L/tb5JjCNfxnxWGO5JQR6KXn9asGtEqAvHRXGuPeWM1LvyVistqY2jeUj2bE1alVLsS5yl6HXFJWOioJyIXoQIwWK3d9voPCCjN9w3x44fJ+LXbsTp56XrqiPwDrj+S12HFF+/a/xGwWrE8G4NUrB5x1FZ/6fLoxhTnf7Sa7xEiIj4GXp/fj/ZuGNHmVWSHOBUaLzTEqDjKps6ORlBUhOpC3Vh5mX3oJnTx0zL857qzqjddn1/FCAHqFyMqcAralFHDfN/EoCtw0IpILY0Na/Dl2Hi/kxepKQXeMjebRqb1lVFy0S3VGyGtW6rRIDnlHIAG5EB1EaZWZRRuPAfDaVQPqrGZ4tlLyyvlw3VHAvuS56LjMVhtfbjnOa38cxGixcV7PQJ67rG+LP0+V2coD38ZjtSlcPiiM/7s0tsWfQ4i2YrLa6s0ht9hkhLwjkIBciA7CYlUwWey/2AdH+rXosY0WK/d/E0+V2caYHgFcOqBzix5ftA9VZitfb01l0aYUxwqck/oE896NQ2oFGi1l4YYU0gor6ezrxsvT+7f48YVoS5JD3rFJQC5EB9HJU8/AcF92pxXz574sZoyKarFjP/fzfvamF+PnoeM/1wySqhYdxPJ9mTz38wFmju5Kl04evLH8IGmF9kA80MvAg5N6cuPwyLMuqVmfgnIT769OAuDxi2LwMsifM9F+KYpSHZDXk0MuKSsdgvwGE6IDuTA2hN1pxew4XthiAfl3O07wzbYTqFTwzvWDCfWV1RA7gv+uOsLbqw4T4e/O0l3pjgV+Ovu6MXtiD64a0gUPfev9iflw3VHKTVb6dfHhsoFhrfY8QrQFi01BAbQnBeRqlQq1yp7KIlyfBORCdCB9u/gCEJ9a1CLHO5ZX7lgN8aFJvRjXK6hFjivObZ9tOsbbq+x17GtSUzRqFfed34O7x3Vr1UDc/pwVjvkQD03qJXdkRLtXk054csqK/Xs1FgnIOwQJyIXoQLpWT+RML6rEZlPOOpXg3ysOUWGyMiLan3sn9jj9DsIl/LY3s9b3fu5aPpwxlBHdAtrk+V/89QAmi43R3QM4Pya4TZ5TiNZkrAnI1bXnWmjVKlmps4OQOuRCdCA/JmQAMCjC76yDcbPVxp/7sgB4Zlpsq+QJi3PTPyd0R199az3YW8+S2WPaLBhfdSCbFQey0ahVPDutr4yOC5fgGCHX1j6ftRq1pKx0EDJCLkQbKakyU1huQqdRE+Lj5piw01aKKkx8siEFsNdrPlv5ZSYsNgW1CmI7+5z18UT7oCgKP+xKx2S14eeh45u7R9E9yKtNnrvCZOHZ6hSpO8+Lpneo1LsXrqEmINeeMkKuUaukykoHIQG5EK0oJa+czzYdY+WBbNKLKh3bO/u68ey0WKb2a7vygN9uP0GZ0UJMqDdT+4ae9fFqFhWyKfbbrbIqYsfw8foUftmdgVat4sOb49osGAeYv+Yo6UWVdPFz54ELerbZ8wrR2kxWK0Cd8qBaCcg7DAnIRYeVW2pk7eFcVMDkviF4u+la7NhGi5W5q46wYF0yFtvf+X8eeg1VZiuZxVXM/moXu5+dfMbP29wc8KW70gC4bUxUi6SXHMwsAcDHTYtBK9lvHcGaQzm8+od9Vcz/uzS2zdJUwF7jfGH1HZ6nLunT6hNHhWhLVebqEXLNqSkrKiySQ94hyG800eEUlpt4b3USX2457phIc01yOP++ZqCjTZXZyv6MYnafKOZ4fjlVZhujugdwyYDOp13gJK/MyN2f72BXdSWT8b2CuGVUV4ZF++PjpqPSZKXPM8sdI8vNueleVGHih51pLN5+gqziKt65YTATmzCpzWZTOJpbDkDPFljWXlEU3v3LXgN6ct9QyePtANYfyeUfX+7CpsDVceHcMqprmz7/3vRiyk1WAr0MXNTv7O/wCHEuqflbpK8zQi455B2FBOSiQ/lfYjaPLdlDXpmp1vbvd6bRNcCDQ9llJGaWkJJXjtVWe1Ri8Y4TbE3J59UrBzR4/NxSI9d9uJnkvHJ83XW8cfUAppySHuKmU6NSgaJAudFCoJfhtP1OK6zgm22pfL7pOKVGi2P7PV/sZMPjEwn2brz2t1qtom+YD3vSirnqg02MjA7g/y6NJTbszHK/v9xynA1JeRi0aqmu4sKKKkz8vjeLLcn5/LonA5ti/4D5yvT+bf4hzNfdfiepuNLEkZwyerXAB0shzhVGiz1lRa+VlJWOSgJy0SFYbQqv/p7Ix9W3vHsGe/HUJX0I83Pn0nc3YLLYeHPF4Vr7BHrpGRTRiZ4hXqQXVvLz7gyW7EqnXxdfPPQabDbwdtPSr4svYX7ulBktzFi4leS8csJ83fj8jhH0CK6bX6tSqRjatRPbjxXy+vKDvHXtINx0GrKKq1iyK42/DuaQV2Yk1MeNMD93ThRUsDO1EKX680GvEC8OZ9sXYfFx19ZZoTCvzMiR7DKyS6pQq1WM7xWEr7uO164cwIOL4zmcXcbm5HxuXbSN9Y9NxKBtXu73zuMFvPDrAQAenRpDVKBns/YX5z6rTeHDdUd5768kKkxWx/ar48J56Yp+dYKGttAjyMux0uyNC7ay/tGJjnkMQrR3f9chr2dSp6zU2SFIQC5cnsVq44HFCfy2x147+c6x0Tw8pbdjEuIXtw9nwfpk3PVaYkK9ie3sQ5/OPoT4GByjgEaLlX0ZxSTnlvPUsn11nuPi/qHklZo4mFVKoJeBr+8a2Wig+vhFMVz74RZ+35vFruNr6NLJnfjUQk4elD+eX1FrnzE9Apgxsiu7Uos4nF2GRq3i7esGcSirlC3JBSScKGRvWjEZxVW19vMyaPl+1ihiw3xY/sA47vx8B38dzMGmKGiaOcp5PL+cuz/fidmqcFG/UG4fE9Ws/cW5r6DcxAPfxrP+SB4AvUO8mRATxMX9OjMwws9p/VKrVbxweT8un7eR4krT6XcQoh0xNrAwkFajwmyTEfKOQAJy4dJsNoWHv9/Nb3sy0WvUvHntwDrLbI/oFnDayWkGrYbFd49i3uokkvPKUaqHqwvKTezPKOH3vfZ63N4GLYtuHXbaUeO4rv58fMtQHvlhD1klVWSV2IPoYVGduHJION0CPUkrrCS/3EiAp4Hh0f5E+Hvw+95MPlqXDNhHMR/+fjfZJcZax1apIKKTB+Gd3Nl0NJ8yo4X41CI89Bqe/+UAfx3MAeyj29rT5MOfLK/MyMxPtpFfbqJfFx/+c+1AyR13AYqi8PPuDP7Ym4XFprA1OZ9SowV3nYbnL+/LNXHh58zPed3hXACGdvWX0XHhUowNjJBr1WpZGKiDkIBcuLR/rzjEjwn2Em3v3zSESbEhZ3ysIG8Dz13Wt872pbvS+Nf3uwnzdee9GwfTP9y3ScebGBPM2kcmsO5wLuUmK3FdOxF9UiA/op59Mk4qnQiQXWLE203LmO6BDI70Y0C4H/3DfR1pLHd9voOVB7J5ctledBr7im9atYpXruzPtUMjmvzaiyvMzFi4jWP5FXTxc+eTmcOkyoULqDJbeeDbeP7cn11re68QL965YTAxoedOffmiCpPjw+jVceFO7o0QLctorr/soT1lRUbIOwL5iypc1g870/hgzVEAXrtqwFkF4425ckg4w6L8CfDSNztI9TRouah/02uR3zYmGne9hh3HCokK8CSuayeGRXdqMA+8q7+H4/9mq8J5PQN5+pLYZi2oUlxpZsYnW0nMLCHQS88Xdwwn2KfxSaTi3Gey2Lj7i52sO5yLXqvm1tFRRPh74OOmZUrf0HOurvxLvyVSWl1Hf/rgLs7ujhAtymixoVGr6iwYJwsDdRwSkAuXdCCjhKeW7QXgvvN7tPqIWsRJgW9r0qhV3DSiKzeNaFrJuTmTezEo0o/CchODIjo1efS+RnGFPRjfk1aMv6eeL+8cQbc2XAhGtA5FUXhsyR7WHc7FQ6/hk1uHMbINa4o3118Hs/lhZxoqFbx0Rb8WqaMvxLnEaLHVyR8He5UVKXvYMUhALlyOzabw5LK9GC02zo8J5qFJvZzdJafx0Gu5dEDY6RvWo6TKzC0nBeNf3TninEphEGfujT8PsSw+HY1axQc3x53TwXhOSRUPf78HgDvGRDM0yt/JPRKi5Rkt1jo1yKGm7KHkkHcEsryecDlHc8tIOFEEwJMX95HRtDNQYbJw26Lt7E4rppOHjq/vGkGfzhKMu4IP1hx1pHK9emV/xvcKcnKPGmazKTz0XQIF5SZiO/vw8JTezu6SEK3CaLbVu+icVqPGZLHWs4dwNRKQC5fTLcjLMTny1z0ZTu5N+2O0WLn7853sPF6Ij5uWL2Vk3GUsWJfM68sPAvDY1JhmTex1hsU7TrAxKR93nYZ3bhh8zuW1C9FS7Ckr9Y+Qm2SEvEOQgFy4HI1aRXgndwBWnFI9QjTOZLHxz692sSEpDw+9hk9vH07fsOblnYtz02ebjvHy74kAPHBBT/4xobuTe9Q4s9XGf6oX63p4Su96F9kSwlWYLDZ02npyyGWEvMOQgFy4nL8OZrM1pQCwL9jTXIqiUFxhdtQa7yiqzFZmfbmTVYk5GLRqPp45lCGRnZzdLdECfoxP59mf9wNw78QePHThuT+vYufxQvLKjAR46rllVNMmMQvRXjWUQ67TqByreArXJpM6hUv5ZXcG//puNyarjSl9Q5g9oUeT9lMUhb8O5vD11lS2JOdTbrIS6GXg2WmxTBt4ZpMi25P8MiN3f2FPUzFo1Sy4ZSijuwc6u1uiBWw6msfD3+8G4LYxUfxr8rkfjAMk55YDMCDct95b+UK4ksZTViQg7wgkIBcuQVEUFqxP5tU/DqIo9pHxd64f3KQJnVuT83nh1wPszyiptT2vzMic7xLo18W31oI9riY+tZB7v44nvagSbzctH98y9LQrl4r24Xh+Ofd8sROLTeGygWH83yWxrbLqZkmVmT/3ZZFbZmRCr2Biw85+zsH6I/ZVOWNkMrHoABoMyDWyUmdHIQG5aPdMFhvP/LSPb7efAODW0VE8c2nsaYPx0iozb/55iM+3HEdRwF2nYcaorlw+KIyuAZ7ctGALu9OKefX3RO4YG02Qt4EwP/d2M7HMYrWhbWRk0WpT+GBNEm+vOoLVphAd6MmCW4ZKrq6LMFqszP5qF6VVFgZH+vHG1QNatOJQcaWZdYdzWZWYzaoD2ZSb7Hmu/1lxmH9fPYArh5x57f/EzBL+2JcFwCXNWDhLiPbKaLairacOuU4tKSsdhQTkol0rqTJz12c72JpSgEoF/3dJLLeNiTrtKOC+9GIe+Daeo9W3xa8dGs4TF/Whk6fe0WbGqCh2f7+bFQeyWXHAPjlUpYIhkZ148uI+xHU9N/Ord6UW8vbKw2xMyiPS34NPbh1WZzGfAxklPLFsL7ury0NeOqAzr1zZHx83nRN6LFrDf1cdYX9GCf6eeubdOKRFPkjabArrk/L4eutx/jqYU2vkrnuQJz7uOuJTi3h8yV56hXjTr0vzJwSbrTYeX2pf1OuS/p3P6BhCtDdGiw2duqGyhxKQdwQSkIt2q6TKzA0fbWF/RgneBi3v3DCYiTHBje5jtFj5bNMx/rPiMEaLjRAfA29dO4gxPermS18dF04nDx2fbT7O8fxy8kqNlJus7DxeyA0LtvDPCT3oHeqN1aZQZjSjKBAVaF/O3hk5r8UVZl79I9FxpwDgWH4F3+1I4/GLYgB7CsO81Un8sDMNmwLeblqem9aXK4d0aZVUBuEcR7JLWbA+GYBXpvcnzM/9rI6XklfO11uP88e+LNIKKx3bewR7cUFMMJP7hjIk0g9FgXu+3MnKA9k8tWwvX901Ei9D8/7MvLXyMLtPFOFt0PL0pX3Oqt9CtBdVZmv9K3VqVJglh7xDkIBctEs2m8KD3yawP6OEAE89n9/ReHk+RVFYcyiX15cf5GBWKQDnxwTz5jUD8T9pVPxUF/QJ4YI+IY5jZBZX8cxP+1iVmMPbqw7Xu0/vEG++uHM4wd5uZ/EKm+eX3Rk89/N+8stNAFwTF46vu46PN6Tw1ZbjKIrC3vRiNifnU1M85tIBnXn6klhCfduun6JtfLQuGbNVYVKfYKb0DTnj45QbLby18jCLNqZgqz5vvA1arooL57phEXUWi1Kp4LnL+rI1OZ/dacXc+/UuPr1teJOf79c9GY5Fi16/egCdfc/ug4QQ7YXRYsPdve4dSp1ajcWmYLMpssidi5OAXLRL32xP5a+D9vJ8i24b1mAwbrMprD2Sy/urk9h+rBAAf089j0+N4eq48Gb9glOpVIT5uTP/5jh+TMhgxf4s8sqMaDVqPPX2dIAdxwo5lF3KrC928v5Nca0e7OaXGXnm5/38ticTsI9YvjK9P8Oj/TFarKxKzOZYfgUfrkt27DO+VxAPTOopJQ1d1L70YpbGpwMwa3z3M77zcSCjhPu+2eVI65rYO4ir4yI4PyYYd33D6S9d/Nz5/I4RXDFvI2sO5VJcYcbX4/SpULtPFPHI93sAuHNsNBdL7rjoQIwWKzqtoc72mrxyk9WGm7p9zF8SZ0YCctHuHMoq5aVf7QucPDo1hgHhfnXaWG0K647k8vbKw+xJKwbAQ6/hphGR3D2uO0HedX/xNZVWo+bquHCujqs7aS05t4zL39vIrtQiRr32PwaE+zE5NoS7zuuGXttyaSyKorAsPp0Xfz1AYYUZjVrFPyf24N6JPRzPY9Bq+OqukSzblUZOqZGuAZ5Mjg0hwt+jxfohzj3zVidhtSlc0r8zQ6P8m72/zabw6aZjvPbHQUxWG6E+brx6VX8m9m48HexkgyL80GvUmKw2So2nD8izS6q454udVJqtjO8VxBMXS6qK6FhMDZY9tG8zWW3tpqCAODNtHpCfOHGCZ599lk8++aStn1q4gINZJdz88VYqzVbG9gjk1tFRtR43WWysPpTD2ysPO1JTvA1arh4azl3ndas3l7bSZGVDUh5/HczhcHYpOo2KC2JCuHlk10ZHAuvTLciLb+4eyQu/HGDbsQJ2nyhi94ki9qYVM39G3Bm/7pMl5ZTywq+JrDtcXRYu1Jt/Xz2Q/uF17xJ08XPn3vN7tsjzinNfbqmRP/fbq5Pcd0HTavCfrKDcxL++S2D1Ifu5NalPCK9f1Z8Ar9ofYHNLjaQWlGO02BgY7ofnKXniJovNUTvZ29B4MG61Kdz/TTxZJVX0CPZi3k1D0MitedHBGC029PVVWaneZpaJnS6vzQPygoICPvvsMwnIRbMoisIPO9N45qf9VJqtxHb24b/XD8JqUziaW0Zybjmbjubx255MRx61t5uWq4aEM3ti9zr53IqicDi7jC+3HGfJrjQqTLWXJt6SXMC321N569pBDIzwa1Zf+3Xx5btZo8gsruS77Wm8veowy/dnkVNadVZ55QXlJuavPcqijSmYrQo6jYoHJ/Xi7nHdZOEUAdhrd9sU+2I6MaHNq9+94UgeD32XQG6pEYNWzVOX9GHGyK6OlJec0iq+236CpfHpjkV7wH6dvXHVAC46KcXk5Elop7sztGB9MltTCvDUa1hwy9BmTwIVwhU0VocckMWBOoAW/833888/N/p4cnJyo48LcarcUiMPfBvPpqP5AIyI7sSE3sHM+nInCSeK6iyaEOhl4Kq4Llw/LIL9GSWsPJDN2B6BdA3wpLjCzJ8HsliwLpkjOWWOfcJ83bgwNoShUf4UlJuYtzqJo7nlXD5vI+fHBHPlkC5M6hPSrFuGfu56tqbY+9w3zIcgrzNLkzmeX86320/wxebjlBktgH1C6jOXxhLlwgsWiearKY/W3PKVn2xI4aXfDmBT7PMQ3r1hsGPCZlZxFXNXHeaHnWlYqmd2qlT2uy+VJiv55SYeW7KHiTHBjuuj0vz3B9z6KkfUSMop5a2V9snRz07r69ILcAnRGKPZ2uBKnYCUPuwAWjwgv+KKK1CpVChKwytLSXk10RSKovD1tlRe/+MgJVUW9FoVEZ082HG8iK0phY523gYt0UGe9A3zYXJsKJ193fh4QwpT5q6v9Uss2NtATqnR8X3NWagAWSVVJJwoIjLAk2uHhnPZwDBe/PUAyxLS+etgDn8dzKGzrxuvXzWAcb2CTtv3fenFPPz9bg5mleKh1/DC5X2bfN5Xma3sSStm5/FC1hzKYWtKgeOx2M4+PDylFxN7B8t1JOoYFOkHwLaUAqrM1iZ9gJy/9iiv/XEQsFfneeHyfrjrNdhsCp9sTOHNFYeoMtuvo75hPnT2dSOzuAqrTeHOsdHMW51EbpmJbSkFjmvjcHW6WBc/9wYXp6oyW3lwcQImi40JvYO4ZuiZLyQkRHvXUA55zTYpfej6Wjwg79y5M/PmzeOKK66o9/GEhATi4loml1a4rpySKu77Jt4RjHoaNJQbrY6KD71CvLh+WCQX9Akm0t8DlUpFSZWZt1ce5vPNx7FWj+TFhHrjrtcQn1pUKxgHeyBew6bA7rRidqcV8+WW4yy+eyRvXTeI+y7oybfbU1m2K53M4ipmfbmTbU9NavC2ek5JFe/8dYRvtp3AalMI8NTz4Yw44ro2PLlOURQSM0vZmJTHhqQ8tqbkOwIgsI9GntcziBuHRzI5NkRKX4kG9Q7xRqNWYbLaKKowE+rbeED+v8RsRzD+8ORe/HNiD1QqFWVGCw9+m8CqRPuCWIPCfQn1dWNVYg77M0oc+z/3ywFiO3uTW2bieEGFY/u6I3kADIuqv5KPzabw2JI97EsvoZOHjlev7C8fMEWHpSiKPWVFW38dcrCntAjX1uKJp3FxcezatavBx083et4S3n//faKjo3FzcyMuLo7169c32n7t2rXExcXh5uZGt27dmD9/fp02S5YsITY2FoPBQGxsLMuWLWut7ndoiqKwaGMKU+auY2tKAWoVaNQqyo32W+Bd/NwZ3T2AqX1DuXFEJF0DPFGpVGw6msfkt9axaOMxrDaFSX1CWDp7NM9f1hcfNy2N/a2/pH8oGx+byIuX9yXQy0BKXjkv/HoAgOhAT564qA93ndcNsN8+rO8WfE5JFa/8nsi4f6/myy2pjioXKx4aV2+lC6tNYWtyPs//sp8xr/3Fxe+s5+XfE1l7OJcqs40gbwNT+obwzKWxrHtkIp/fPpyp/UIlGBeNKqm0OD6Mers1Pt5SZbby5DL7ipi3jo7i3vN7olKpqDJbufWTbaxKzEavVXPn2GgyS6pYvj/bkbIC4F49+p5dYv+ga6kewTNZbPyUYC+7OCm2bg10q03h8aV7+CkhA61axbs3DJF646JDM1sVFKh/pU5JWekwWnyE/JFHHqG8vLzBx3v06MHq1atb+mkdFi9ezIMPPsj777/PmDFj+PDDD7nooos4cOAAkZGRddqnpKRw8cUXc9ddd/Hll1+yceNGZs+eTVBQEFdddRUAmzdv5rrrruPFF19k+vTpLFu2jGuvvZYNGzYwYsSIVnstHU1OSRWPLtnDmuoKDzqNyp4friiO/6cXVZJeVMmmo/nsSS9m0a3DePevJN5edRhFsQfQz06LJafUyIu/HCC+emn4+gR46ikoN/Hb3iwuH9SFGaOiOJpbzqebjlFQPTHUYrXx/pqjjkWAbhsTjUH796hjZnElH61L5qutqY5fmIMj/XhsagwjuwXUec7M4kq+2XaCxdtTHYEM2IObkd38GdMjkPN6BtErxEtGDEWznfz3vKTKXKf6ycl+3p1BdomRMF83x0quAE8u3cuO44X4uGn55/k9+M+fh+udUFaTJ17zr3d13vpPCfa7SYFeBib1qR2QV5mtPPBtPH/uz0atgreuG8TYnnVXyRWiIzFa7NdQYykrEpC7vhYPyM8777xGH/f09GT8+PEt/bQOb731FnfccQd33nknAHPnzuXPP//kgw8+4NVXX63Tfv78+URGRjJ37lwA+vTpw44dO3jzzTcdAfncuXO58MILeeKJJwB44oknWLt2LXPnzuWbb75ptdfSUSiKwvc70nh9+UHyy02oVfYUErNVqfX/8E7uTBsYxuaj+SScKCIpp4x7v4l3LIozbUBnOvu589SyvaQXVTX4fDXBfX65iX5hPuzLKOFITik5pUa+2HIcgMmxIew+UcRzv+wnPrUIgJmjuvLgJHsJweP55cxfm8wPO084JpXGde3EvRN7MKF3UJ1g+kBGCfNWJ/HHvkzHioc+blomxYYwpW8o43sFSY1Zcda83XT06exDYmYJ//fjPj6eOazBtmurP/heOyzCce6tPpTD0vh01Cp4eEpvXvot8bTVHWpGzSM6uWOy2D/AAtwxNrrWOV1YbuL2z7YTn1qEXqPmv9cPqlWZRYiOqiYdpb6UFUfZQ2vrZhYI53Op+lImk4mdO3fy+OOP19o+efJkNm3aVO8+mzdvZvLkybW2TZkyhYULF2I2m9HpdGzevJmHHnqoTpuaIF6cudT8Cl75PZHl1bWTDVp1rVy5k+6Q29NUhkfyw840wD4C+NueTDQqGBjhx/L9WU36pWW2Ko5FS/ZV58P+dTCXncftE0Un9QlmW0oBz/1iT1vxMmh58Yq+XD4wjC3JBSxYn8zqQzmOJehHRPtz7/k9GNsjsE4gviu1kP+sOMTGpHzHtuHR/tw8sitT+4a26GJBQgD8Y0J37v8m3vFBsiG70+yPD4+2p1QpisK/lx8C4KYRkXyw5miTRuVMFhsqFcR09uHb7amk5JUT4KlnxqiujjbZJVXcsGALybnl+Lrr+HBGXL13kIToiKqq7zLpGy17aK3zmHAtLhWQ5+XlYbVaCQmpfZs0JCSErKysevfJysqqt73FYiEvL4/OnTs32KahYwIYjUaMxr9TEkpKShps2xFlFVexaFMKizYcw2S1oVaBChVGi80xKn6qnxIy+DEhnbwyEyrs+bI1Afyu0wQfpzp51E+rVrHzeCEatYoufvaJa2CfTDl9UBfuGdedvw7lMPE/azme//fEtQm9g/jnxB4MqydHfG9aMa8vP8iGJPvkNo1axdR+odx3fo9m14cWdcn11bCMokoAYsMaPs9MFhvp1e16BnsDkHCiiAOZJbjrNFSZbWQWN3yX6VQDw/2w2hRHCcMHJvV0THwuLDdxY3UwHubrxme3D6dniPcZvTYhXFHNJP56A3LJIe8wXCogr3HqKKWiKI3m49bX/tTtzT3mq6++yvPPP9/kPncUe9OK+XzzMX5MSHeMZkd0cudEYSWgoFGrHJPSTpVfbnQE6jUtWmLmucWmoNeoMFkVUgsq0ahVXNy/M1NiQ/hjXxaXv7/B8QvTQ69h+uAu3DE2mm5BXnWOlV1Sxau/J/JjQgZg/2U6fXAXHpjUk/BOsmR9S5Hrq2GrD9o/UE6uZ0JljYJyE4pi/6AY6KUHYMUBe0WV4dH+fF99F6qpxvcK4r+rDlNUYSYm1Jsbhtvn65itNv7x1U6O5pbT2deNxfeMIsJfrgMhTlYzQq6r545pTQ65VFlxfS4VkAcGBqLRaOqMXOfk5NQZ4a4RGhpab3utVktAQECjbRo6JtjzzOfMmeP4vqSkhIiIiGa9HleyLaWAuasOOxb3AYiL7IQNxXFrvSYYD/TSk1dmcrTTqlVYbEq9o+aN0WlUDAz3Y8fxwtO2NVkV/Dx03DAsggh/D37Zncm938Q7Ho8J9eb2sdFc0r9zvRPlLFYbn20+ztsrDzsW77liUBgPT+ktgXgrkOurYUdz7QteNTZCXmGyn6PuOo2j8tXyffbfcSdOKl94OirsH467BXny0OIjADxzaawjiHjvryS2JBfgZdDy6W3DJRgXoh41kzrrT1mRHPKOwqUCcr1eT1xcHCtXrmT69OmO7StXruTyyy+vd59Ro0bxyy+/1Nq2YsUKhg4dik6nc7RZuXJlrTzyFStWMHr06Ab7YjAYMBjObGVGV7I/o5gXfz3AlmR7PXFt9ejztIFhzF11mP0ZJejUKrQaNZVmK5P6BDPnwl7cumg7uWVGFIVapdZOpVbZv04dPAjxMTChVzDf7Thx2j52D/LktjHRlFaaWRqf7ljBU6WCyweGcfvYaPp38W3wjkh8aiFPLdvHgUx72sSgCD9evLwf/cN9m/IWiTMg11fDogM9ySszcTi7rMH69zVXVE0VzYQTRaTklaPTqEjOa7hKVn3HOa9nIPPXJmNT4LKBYYzuYa+asi+9mPdWJwHwypX96R0qaSpC1KfmDqyhnhFyjUpSVjoKlwrIAebMmcOMGTMYOnQoo0aN4qOPPiI1NZVZs2YB9pG19PR0Pv/8cwBmzZrFe++9x5w5c7jrrrvYvHkzCxcurFU95YEHHmDcuHG8/vrrXH755fz000+sWrWKDRs2OOU1tgc5pVW88tvfqRt6jZqr4sK59/weGM1WZi7axomCSgI89UQFerLzeCF9w3y4Oi6CD9clk18djDfEnt8dxoak/DoL/gCUG60sPk0w7u+h487zoskrM/HmikMUVZgB+yTOW0dHccOISLr4NVwfOaOokjdXHGLpLnvNZV93HY9NjeH6YRFSL1w4zajugWw/Vsj2lAJH6sipKk32EbmaKihfb00F7NepuZmTxzr7urH+SB7+nnr+79JYwF5r/Okf9znq8U8bINVUhGiIY1JnPQG5SmVf+8JkkUmdrs7lAvLrrruO/Px8XnjhBTIzM+nXrx+///47XbvaZ/xnZmaSmprqaB8dHc3vv//OQw89xLx58wgLC+Odd95xlDwEGD16NN9++y1PP/00//d//0f37t1ZvHix1CCvh9lqY+GGFP676giVZisqFVw6IIzHptpTNxIzS5ixcBt5ZUa6Bnjwxe3DmfiftQDszyhh1pc7HcfydtNSWmWp8xyxnX349zUD+G77iTrBeE3aS03aSEOGRPrR2deNN1ccdqTCdKseKb98UBg+1TWV63Msr5xPNqbw7fYTjlGLq4aE88TFMQR6yaitcK7iCnu6V2MLA6VWp6V09nMns7iSZfH2D5Xlpub90R/TPYAf4+0fup+/rC9B3vbz/4edJ0g4UYS3Qcsz02Klpr4QjXBM6myg6pZOo5aUlQ7A5QJygNmzZzN79ux6H/v000/rbBs/fnyjq4sCXH311Vx99dUt0T2XtTU5n8eX7iWl+pb3qakbe9KKmLFwG8WVZvp09uGLO4YT6GXg7nHdWLghBZPFRqCXnkl9QtiaXEBKfv23zgdG+OLrruO7HX9PPPMyaCgzWhucEFpr/3Bf9qQVsav6c9mkPsFcNyySib2DHCWmTlVpsvLn/iy+33midgnDKH+evKQPgyL8mvIWCdGqqsxWftptD5DH9QpqsN2etGIAYjt7883WVCw2BR83LSX1fABuiJ+HjqySKkxWGxfGhnBp9Sh4SZWZ/6z4u9pKiI/bmb4cITqExsoegj3V83TrAYj2zyUDctG2skuqeOHXA44FegI89Tx+UQxXx4U7Rsb2pBVx04KtlBotDI7049PbhuPrbh+FfmxqDLMndKfMaMFdp+HGBVtrBeNXDQln+b5Mx+jdN9tOsDetmEqz1VEdpczYtJG9qAAPdlcHIxN6BzHnwl4MCPert63FamP7sUKWxafx+96sWqPuE3oHcfd53RjVPUBG/8Q548/9WRRVmOni586E3sH1tlEUhf8l2iuqDI7oxBt/2muPNycYB+gf5sv6pDwCvQy8Mr2/4zqYu/IIOaVGogM9uXlk19McRQhRabaiVtnv8NZHp1FLlZUOQAJyccaMFisfr09h/tqjlFZZUKng2rgInr60j2MZbYCknDJu/tgejA+P8ueT24Y5ahTX8HbT4anXMnPRNg5klqBRgVWBywfZ010u6hfKgcwS0gsrWbzjBIeyS6tHDRS6VN92b2xwXK9REerrxrH8CsdCP1cM6lIrmDZarOw8XkjCiSJ2nyhia0qBI68cIMLfnauGhHPVkHCpFiHOSTWVUq4c0qXBP+6704o5klOGQasmwEtPXpkRT72mWekqF8QE87+DOahU8N/rBzlSVeJTC/l0UwoAz13WV1afFaIJqsxW9Fp1g4M7Oo1aJnV2ABKQi2ZTFIU/9mXx5opDJOfaR7L7d/HljasH0Kdz7VJrVWYrd362nZIq+8h4fcF4jYUbUlh/JA+DVoWiqLBabfyUkMFP1RND+3fx5dPbhvHnAfsoYKiPgawSo2OBk4b4uGnxcdeRWlBJoJeeT24dVmtUvKZk4Tv/O0JxpbnWvr7uOqb2DeWquHCGRXWS0XBxTqtJRRlbXemkPjVB+4WxIY70sq4BnhzILEGnUWG2Krhp1VQ1EABM7B3EpqP2Ba8emtSLMdXPVW608K/vdmNT7CU/xzeSMiOE+JvRYmswXQXsI+dmSVlxeRKQi2Y5nF3Ki78eYP0R+x/kAE89T1/ah8sG1j8i9+WW4xzLr6CTh46PZgwls6iS/RkldAvyrJMq8tnmYwA8MKkXKlS88edBFMVeUUVRYG96Mf/4chfTBoTx7fZUskrqVlc5VXSgBxabwomCSkJ93PjijtqrBGaXVPGPL3c6VvoM8jYwPNqfAV18GRrViYHhfg3mlQtxLiksNzk+nDZUYtD+YdqeWnZhbAhHq0t8+rjb/xR08tCTU2psNBg/nl9OpdnG6O4B/HNiD8dxn/5xH8l55YT4GHjusr4t+tqEcGU1I+QNsVdZkYDc1UlALpqkwmRh3uokPlybjMWmoNOo+Mf47tw1rlut9JRTZRTZl98urDAz7o3VVJr/vi0+58Je3H9BT8f3NaXY3lh+iFAfN4ZEdOLhKb0ZFtWJ1YdyufuLHWw7VsC2Y/aa5oFeelQqFYXlJqw2hVMzVi7p35mEtELSC6sI83Xjq7tGEh3o6Xj8cHYpMxZuJbvEiLeblicv7sN1Q6VkoWiffq8OtHuHeOPnoa+3zb70Eo7nV+Ch13BhbAjZJfbrs2Z0LqfUiKdBQ3k9czKmD+5CXpmR5LwKQn3ceOeGwY4P4Qs3pLAsPh2NWsU71w9u8PmFEHWdPiCXlJWOQIb+xGkdyirlqg82M2/1USw2hUl9gln50HjmTO7daDAOcPPISMdiB5VmK+4n5ZTWTCyr8dntwwnztVdkyCqpYmdqIbO+3MmLvx5gzaEcJvQKYnCkH33DfNCqVeSVmcgtNWI5JRj3cdPy2NTebDqaR3phFV0DPFh8z6hawfixvHJuXGAPxnsEe/HrfWO5YXikBOOiXbJYbXy4NhmAa4aGN9huS7K9QtDo7gF46LWOu0WHs8u4t3q0u9xoRQW1rtV/TuiORgXrj+ThplPz0S1xjhKfy/dl8vLviQA8eXEfRnQLaPHXJ4QrqzI3nrKi1UjKSkcgI+SiQYqi8MWW47z46wHMVvuS9vdN7IGCPWCOOinAbUi3IC82PX4+xwsq8HXXEehlYOzrf1FaZeHucd1rte3XxZc1j0wkrbCC/HITL/2WyO4TRXy2+Xid4w4M90WtUnGisIK8MpNj+/TBXRjatRPP/3IAk9VG/y6+LLx1KMHef5deKzdauOvzHeSVGYnt7MPXd42QET3Rri3dlU5qQQUBnnpuHFH/YkAAiVl/ryYLMKpbAD5uWrJKqlhzOIcL+gRzIKOEzOIqKs1W/D31vDK9HxuT8vlh198j4DXpZluT87n/2wQUBW4aEcntY6Ja+ZUK4XpON0KuUaswSkDu8iQgF/UyWWw8sXQvS3bZa30Pj/LHYrPx7C8HuKBPMOuO5DGyiSNhAV4GAqpH05bFp1FaZSEqwIOL+oXWaavXqukW5EW3IFh890h+SkjnWH4FOo0aD72GPWlF/Lk/21G6EOw55hN7B/Pw5F78dTCHp37cB8CUviG8fd0gPPS1T/O5qw5zJKeMEB8Dn942TIJx0a4pisJH6+2j4/eM71bnfD9ZTYpKWPUKtG46Da9eOYB/fZ/AvvQS9qXbA3a9Vs0tI7sye0J3Xv3jIN/vTEOlgjeuGsDkvvbrNimnjLs+34HJYmNybAjPX9ZXJj0LcQaqTjOpU6dWYzRLQO7qJCAXdVSarNzz5U7WHc5Fo1Zxw7AIvtz69+qmaw7msuyfo8/o2DU55cfyK7jlk22YLDY8DBqGRflz+5ho3PV/3yZ302m4bljd0b60wgo2HMmjuNJMZz93hkV1Itjbjed/2c/n1aPpd4/rxuNTY+qkoJQZLXy2yd7mtSsHECyLloh2LimnjKTqMobXD294dBzsuagAlpNW/btkQGcGhPuy4kA2FquNbkFejOzmj0ql4r6vd7H6UC5qFfz76oFcFWdPhymtMnP35zsoqbIwJNKPd24YLJOfhThDlSYrukZGyPVaNUZL81bRFe2PBOSilgqThds/3c6W5ALcdRrev2kIr/1xsFabZ6bFNriYzulMGxDGoo3HyCszsiEpz7F9zaFcvt6aylVx4QR66TFZbKhVKnqFeDO2Z+0SbuGdPGoFHoqi8OSyfXyzzf6h4blpsdw6Jrre509ILcJktRHh787EmPoXThGiPckts1cb6uLnjs9p5nQEV9cLrxkprxHh78EdY/++ZlLzK7jr8x0cyi7FTafmnesHO0bGAZ75aT/JeeV09nXjo1uGSr1xIc5Cldna6Ai5Xqt2FD0QrksCcuFgtFi554udbEkuwMug5dPbhjE0yp/skioeX7qXvmE+PH5RDOf1PPP6wpEBHqx9ZALbUgoorjSj16rJKali/tpk0osqeed/R+rsM31wF964eoBjdO9U81Yn8c22VFQqmHvdIC4f1KXB5z+SUwpAiLeMjAvX0NnXnn6SUdx4PX6Ayurb3g3lqyqKwq97Mnlq2V5KqiwEeRv4+JahDKzOOQf4KSGdZfHpqFXw3o2DHZM7hRBnpuqUggen0mvUFJhNDT4uXIME5AKw/yF+5sf9rD+Sh4dew2e3DyeuaycArh8eyXXDIlosP9TToK0zOn3dsEiW7Eoj4UQRFSYLeo2aCpOV/x3MYVl8Oj2CvRw1j0+29nAu/1l5GICXrujXaDCeWVzJ/LVHAZgUG9Iir0UIZ7NWL1GrVTeeMmKy2NhcvaBPbJhPnccTThTx9srDrD2cC9gnfn5w8xBHwA/2iktPLt0LwL3n9ySuq3+LvAYhOrIqsxVf94bvbhlkhLxDkIBcAPD73iwW7ziBWgXzbhriCMZrtPZkLXe9hptHduXmkV1rbf9+xwke+WEPH649ym1jompNWDuSXcoD38ajKHDD8AhuGtH11MM65JcZuW3RdrJLjHQL9GTGyIbbCtGe7M+wT3DuHtR41aOVB7LJKzMR4mNwTMgurTLzx74sFm8/wc7jhYB9EZLZE3rwz4k9ao2kH8oq5eaFWyk3WRnZzZ/7z6/7AVkI0XxVZttpcsg1VEkOucuTgFxgtSm8/NsBAGZP6MHE3qfPrTZbbVSarafNWT1bVw0J592/kkgtqOCvgzlcOiAMgH3pxdz+6XaKKswMivDj2WkNrwyYX2bk5oXbOJhVSqCXgc9uH46nQU594Rq2ptgXyhpyyofoUx2sLnnYO9SHPWnFfLf9BD/vznAs1qXTqJg2MIz7z+9Zq6Spoij8sDONZ3/eT4XJSkyoN/NvjpNJnEK0kCpL4znkBq2aKhkhd3kSlQiO55eTUWyf5FVfWsjJjuWVM3/tUZbFp2O02LhpRCQvT+/fan1Tq1WM6RFI6rZUDmeXoSgK3+9M47nq4KB3iDeLbh3W4KSygnITN3281RGML75nJBH+Hq3WXyHaksVqcyywdd4pk59P1at6EaB1h3NZV52WAtAtyJOrhoRzTVx4napDSTllPPPTPjYd/XtBoXk3DpFSoUK0oNPVIddr1Y75H8J1SUAu8PPQo9eoMVltPLF0D49MjaGLn3utNhlFlcxbncS32084clYBvt+RxtOXxNYqV9jSalb6/GRDCpuS8thRfWt9bI9A5t00pMHcu6IKEzcu2MLBrFKCvQ18c/dIugd5tVo/hWhrv+/LIrvEiL+nnjE9Gg/ILx3Qmf8lZvNjQgZuOjUX9evMDcMjGRbVqU5KmtWm8O5fR3jvryQsNgWDVs2Dk3px13nRMjIuRAs73UqdNWUPFUWRWv8uTAJygb+nnicvjuG5Xw7wY0IGPyZkMLF3EDeO6IrVZmPlgRx+3p2Oubp28YTeQcwa353rP9qCyWqjqNKEu94ewCuKQlphJSl55WjUKvqH+551WktI9ahdmdHCjuOFGLRqHrqwF3ed1w1NA0vdF1eaHSPjQRKMCxdktFiZu8o+ofnW0VEYtI1/KFapVLx93SBevKIfHnptg9dOTkkV930T70iFmdQnmGcu7UtkgNxZEqI1nG6E3KBVY1PAZLWd9joX7ZcE5AKAW8dEE9PZh7dXHmbbsQJWH8pl9aHcWm1GRPvz0IW9GNktoLpOONgU2HAkD7VKxdrDuWw6mldrKXtvNy3PX9aXK4eEn3Hf7h7XDbUKdqUW0jfMl2uHRhDq23DZwqIKEzMWbmN/RgmBXnq+unOEBOPC5cxfk0xybjmBXnpubeKS9SqVCu9GPiDvSy/mjs/sk5899Rpemt6P6YPP/NoVQjTOalOw2JTGR8irH6sySUDuyiQgFw4juwWw+J5RpOSVs2B9MpuS8vA0aBkc6cdVQ8IZHPn3pDG9Vk3/cD92nyjikR/21DqOTqMiKsCT0ioLWSVVPLF0L8Oi/OvkbheWm1h7OJe/DuZwKKuUTp46HpzUy1EBooZGreKe8d0Bew77F1uOcSirjABPPY9O7U3ASXWQk3LK+MeXOzmSU4a/p57Pbx/hyJ0VwlXsTStm3pokAJ6Z1rdFJlfvSi1k5ifbKK2y0CPYiwW3DCU6sPHKLUKIs1Mzqfp0OeQ1bX1p3UIKwnkkIBd1RAd68koTJmrOvW4Qr/9xkKTcMjp56Ijr6s/E3kEMjPDDTafBalO46eMtbEkuYOaibdwwLJJKs5VjeeXszyjhcE4pilL7mLd/up2Nj51PJ8+/J42VGy0s3ZXG73uz2JKSX2ufA5klfDgjjkqzlW+2pvLV1lQqzVaCvA18ccdwYkLr1lsWoj2z2hSeXLYXk8XGBTHBTBvQ+ayPuSetiJkLt1FqtDA8yp+Pbx3a6hWUhBD21bGBRle7rZlHVWWWSiuuTAJyccaiAz2ZPyOuwcc1ahX/vnogV32wieTccl7+PbFOm14hXlzQJ4ShXTvx8m+JJOeVM3PRNs6PCaaw3ERSbhk7jxdSVT3DXKWCib2DGN09kPfXJLE3vZjRr/1V65jDojox76YhBMtqnMIFbUzKY2+6vfb4q1f2P+tJXnvTirn5462OYPzT24fVqvcvhGg9NQv+GE5Thxz+Hk0Xrkl+64pWFeHvwe8PnMfH61PILK7ETashvJM7vUO9GRTpVyto9vPQceOCrexJK2ZPWnGt40QHenLTiEim9A11pL6c1yuQx37Yw+60YvQaNf3DfSmqMLH9WCE/xWdw53nRMiNduJziSjMAPYO96pQpbK6VB7J5aHECZUYLcV078cltEowL0ZYqqgNyN13TUlaE65LfvKLVBXoZePyimNO2i+vqz2/3j+Xn3Znkllbh664nKsCDQZF+9A7xrhNcx4T68NO9YykzWjCZrYx/cw2lVfbbfy//nsigSD+GRcnS3sK19OlsT8M6klNGaZW50UmaDUnJK+fNFYf4bU8mAKO6BfDhLXF4yYJZQrSpCscIuaSsdHTy21ecU3oEezPnwuZNwvQyaPl4W6ojGAcYEulH71CZzClcz18H7QsB9Qz2qhVAK4pCQbkJnVZdK//bYrWxN72YzOIqLDaFzUfz+WHnCcxWBZUK7hgTzcNTejeawyqEaB1NS1mRgLwjkIBcuITh0f70DPbieEEF95/fg39M6NFgnWUh2qsKk4WP16cAcNd53Rx3jY7llXP/t/HsSStGpYLeId5E+nvgadCyMSmPnFJjnWNN6B3Eo1NiiA2Tic9COEt59aROQxMmdVaaZLVOVyYBuXAJA8L9WDlnvLO7IUSr+mhdMjmlRrr4uXP54DAAThRUcPX8zeSV2YNuRYGDWaUczCp17OfrrqNHsBcalYroQE+mD+lSp7yoEKLtNWmEXCM55B2BBORCCNEOFFeYWbAuGYDHL4rBoNVQXGlm5qJt5JUZiQn1ZtFtw1CrVOzPKCatsJIKk5VugZ5M6B3caJ1jIYRzVJisqGi8DrlGrUKtkpQVVycBuRBCtAN/7Muk3GSlV4gXl/TvjMli459f7SI5t5zOvm58ettwxwq2IWdZfUUI0TYqTBYMOjXqRiqCqVQqDFqNBOQuTgJyIYRoBwoqTACUG60k5Zbx7l9JbEjKw12n4eOZQx3BuBCi/ag0WXFrpMJKDYNO7UhvEa5J7mEKIUQ7cEFMCDqNivSiSia/vY5fdmegVav44OYh9A3zdXb3hBBnoMJsxdBIDfIaeo2aKosE5K5MAnIhhGgHeod68+3do5jUJxi1yr6QyPyb45jQO9jZXRNCnKFKk7XRGuQ1DFq1VFlxcZKyIoQQ7URc1058PHMYOSVVAGe9UqcQwrkqTJZGK6zU0GvVVJotp20n2i8JyIUQop2RQFwI11BhsjYpIHfTaSgzSsqKK5OUFSGEEEIIJ6gwWRtdFKiGu05DaaW5DXoknEUCciGEEEIIJyg3Ni1lxdOgpbhKAnJXJgG5EEIIIYQTVDRxUqe7XkNppeSQuzIJyIUQQgghnKDS1LSyhx56DaVGGSF3ZRKQCyGEEEI4QYXZgltTUlb0WkpkhNylSUAuhBBCCOEETa1D7q7XUGm2YrFKLXJXJQG5EEIIIYQTVJisuDUxZQWgzCij5K5KAnIhhBBCiDZmstgwWmy460+/JIxndRtJW3FdEpALIYQQQrSxmtFuj6bUIa8eIS+R0ocuS1bqFO3OL7sz+GRjCiaLjYUzhxHqK6sWCiGEaF9Kq4PrmmC7MTUpK6VVMkLuqiQgF+3Kf1cd4e1Vhx3frz2cw3XDIp3YIyEaV2a0cDy/HK1aTa8QL1QqlbO7JIQ4B9QE1x5NCMgdKSsyQu6yJCAX7canG1NqBeMAo7sHOqk3QjSupMrMf/48xNfbUjFbFQDO6xnIwpnD0DehzJkQwrXVBOQyQi5AcshFO5FeVMnLvycCMLVvqGN7uUl+OYlzi8Vq45fdGUx9ex2fbT6O2arg56EDYP2RPDYezXNyD4UQ54KalBWPJkzq1GrU6DVqxz7C9bhUQF5YWMiMGTPw9fXF19eXGTNmUFRU1Og+iqLw3HPPERYWhru7OxMmTGD//v212nz00UdMmDABHx8fVCrVaY8pWt78NUcxWxVGdvPn3RsHM7p7AAC3frKdvDKjk3snBBgtVj5Yc5SRr/7Ffd/Ek1FcRdcAD766cwTTB3cBwNtNy6BwP+d2VAhxTnBM6mzCCDmAh0EjVVZcmEsF5DfeeCMJCQksX76c5cuXk5CQwIwZMxrd54033uCtt97ivffeY/v27YSGhnLhhRdSWlrqaFNRUcHUqVN58sknW/sliHqkFVaweMcJAB64oBc6jZp3bhhMhL87WSVVfL8jzck9FB3dwawSLn1nA68vP0hemRF/Tz0PTerFL/eN5dc9GSzaeAyA5y/rSydPvXM7K4Q4J5RWWdBqVOg0TQvFvAxaiipNrdwr4Swuk0OemJjI8uXL2bJlCyNGjABgwYIFjBo1ikOHDtG7d+86+yiKwty5c3nqqae48sorAfjss88ICQnh66+/5p577gHgwQcfBGDNmjVt8lrE3yxWG3MW78ZksTE82p+R3fwBCPQyML5XEF9uSZURcuFUv+3J5JEfdlNhshLopefxi/pw+aAwKs1W7vs6nrWHc1Gp4MXL+3HlkHBnd1cIcY4orTI7Jms2hY+bjvwyCchdlcsE5Js3b8bX19cRjAOMHDkSX19fNm3aVG9AnpKSQlZWFpMnT3ZsMxgMjB8/nk2bNjkC8jNhNBoxGv8OFEtKSs74WB3Zv1ccYtuxArwMWl69sr+jQkVxpZnl+7IB6N/F15ldFE7g7OtLURS2Hyvkiy3H+WV3BgBjegTw3g1D6OSpJzW/grs+38Gh7FLcdGr+e/1gppw090EIIUqNlianqwD4uGvJLZUBKFflMgF5VlYWwcHBdbYHBweTlZXV4D4AISEhtbaHhIRw/Pjxs+rPq6++yvPPP39Wx+joft+byYdrkwF49cr+dA/yAuyj5v/6bjd5ZUYi/T24uH9nZ3ZTOIEzr69Kk5XHluzh5+pAHODucd14bGoMGrWKLcn5zP5qFwXlJoK8DXwycxj9w+VDoxCittIqC+5NWBSoho+bjpS88lbskXCmcz6H/LnnnkOlUjX6tWPHDoB66/sqinLaur+nPt6UfU7niSeeoLi42PF14sSJszpeR3M0t4yHv98NwD3jujFtYBhgnzj34OIEViVmo6/OJZcSch2Ps64vm03hn1/v4ufdGWjUKq4aEs7v95/Hkxf3QaNW8e22VG7+eCsF5Sb6d/Hl1/vGSjAuhKhXaZWlSSUPa/i668iXFE2Xdc6PkN97771cf/31jbaJiopiz549ZGdn13ksNze3zgh4jdBQ+y3krKwsOnf+e5Q1JyenwX2aymAwYDAYzuoYHZXZauOBb+OpMFkZ2c2fR6bY040Kyk3M/monW5IL0KpVvH/TEAZF+Dm3s8IpnHV9LVifzF8HczBo1Xx623BGVVf7MVlsvPJ7Ip9uOgbAtIFh/PvqAbg1Y/RLCNGxlFWZmzVC7uuho7DCjMVqQ9vEiaCi/TjnA/LAwEACA0+/+MuoUaMoLi5m27ZtDB8+HICtW7dSXFzM6NGj690nOjqa0NBQVq5cyeDBgwEwmUysXbuW119/veVehGiWTzaksC+9BD8PHXOvG4xWo2b1wRweX7qH7BIjnnoNH9wcx7heQc7uquhglsWnA3Df+T0cwfi+9GIe+WEPiZn2PPY5F/bivvN7yIqcQohGlVQ1L4fc112HAhRUmAj2dmu9jgmnOOcD8qbq06cPU6dO5a677uLDDz8E4O677+bSSy+tNaEzJiaGV199lenTp6NSqXjwwQd55ZVX6NmzJz179uSVV17Bw8ODG2+80bFPVlYWWVlZJCUlAbB37168vb2JjIzE39+/bV+oi7NYbXyyMQWAJy/qQ05pFY8v3cOaQ7kAdAv05IOb4+gd6u3MbooOqsJkBeDtVUew2BRSCyr4MT4dmwKdPHS8cfVALow9u7trQoiOoaTSTKBX0+/0+brZFxjLK5WA3BW5TEAO8NVXX3H//fc7qqZcdtllvPfee7XaHDp0iOLiYsf3jz76KJWVlcyePZvCwkJGjBjBihUr8Pb+O+CbP39+rQlk48aNA2DRokXceuutrfiKOp6CchPZJfYcuZd+O0BJ9TLBWrWKmaOjeGRKb0kDEE7z3+sH8eDiBI7nVzB31RHH9mkDw3jm0liCvCVNTQjRNM2tsuLrbg/I88slj9wVqRRFUZzdiY6gpKQEX19fiouL8fHxcXZ3zlmKojDnu92O1AC9Rs3F/UN5YFIvogM9ndw7ca5qy+vLaLHy/uqjrDyQTUyoNzNHRzFQ5jIIIZpBURRi/m851w2L4KJ+TasUZrRYuXXRdt6+biDTB8uaBq7GpUbIRfunUql4+7pB/GNCd/LKjPTr4otP9W06Ic4FBq2Ghy7sxUMX9nJ2V4QQ7VSl2YrRYmvW3zeDVoO7TiO1yF2UBOTinNQrxJteIZInLoQQwvXUrLjp7da8MCzAS09GUVVrdEk4mdTNEUIIIYRoQwXlNQF58+4AB3jpSS+qbI0uCSeTgFwIIYQQog0VVNgDcp9mjpAHehpIL5SA3BVJQC6EEEII0YYKys5shDzQyyAj5C5KAnIhhBBCiDZUUG7CXadBr21eGBbobaC40ky50dJKPRPOIgG5EEIIIUQbKqgw4ePe/LoagV56ABkld0ESkAshhBBCtKGCMlOzK6wABFWv7CkBueuRgFwIIYQQog3ll5vwNjR/jY1OHnq0ahUnCipaoVfCmSQgF0IIIYRoQ/nlRrzOYIRcrVYR6utGcm55K/RKOJME5EIIIYQQbSiruAp/T/0Z7dvZ142juWUt3CPhbBKQCyGEEEK0EYvVRk6JkcDqfPDm6uzrTlKOBOSuRgJyIYQQQog2klVShVVRzjggD/NzI7O4ikqTtYV7JpxJAnIhhBBCiDaSUVQF/F3CsLnCfN0BSM6TUXJXIgG5EEIIIUQbSS+yV0g58xFye0B+OLu0xfoknE8CciGEEEKINpJeWImPmxY3neaM9vc0aAn1cWNvWkkL90w4kwTkQgghhBBtJL2o8oxHx2tEB3qyJ62oZTokzgkSkAshhBBCtJHUggoCzjB/vEa3IE/2ZRRjtSkt1CvhbBKQCyGEEEK0kcTMUiI6eZzVMboFelJltkn5QxciAbkQQgghRBvIKa2ioNxE1wDPszpOtyAvdBoVm47mtVDPhLNJQC6EEEII0QYOZNgnYnYNOLsRcjedhphQH9Ycym2JbolzgATkQgghhBBtIDGzFA+9hiDvs5vUCTAg3JctyflUmWWBIFcgAbkQQgghRBvYfaKQrgEeqFWqsz5WXGQnjBYbf+7PaoGeCWeTgFwIIYQQopUZLVbWH8mjfxe/FjleZz93+ob58MXm4y1yPOFcEpALIYQQQrSyrckFlJusDIn0a7FjTo4NZcfxQtYfkVzy9k4CciGEEEKIVvbrngyCvA1E+p/dhM6TDYvqRN8wH55YupeiClOLHVe0PQnIhRBCCCFaUUZRJUt3pXNhnxBULZA/XkOlUnHXed0orjRz1+c7qDBZWuzYom1JQC6EEEII0YpeX34Qd52GSX1CWvzYIT5uPDy5N/vSS7ht0XbKjBKUt0cSkAshhBBCtJJf92TwU0IGM0Z1xV2vaZXn6BXizWNTY9iTVsxNH2+hoFzSV9obCciFEEIIIVrB/oxiHvl+D6O6BTC2R2CrPlfvUG+evqQPx/IquPy9DexJK2rV5xMtSwJyIYQQQogWtjetmBkLt9HZz427x3Vr0dzxhnQL8uKFy/qi06q5Yt5GHv1hN4eySlv9ecXZUymKoji7Ex1BSUkJvr6+FBcX4+Pj4+zuCOFS5PoSQpwryowWPlx7lA/XJhPh785jU2PwdtO1aR8sNhsr9mfz654MCivM9A7xZlyvQAZFdGJAuC/hndzb5AOCaDoJyNuIBAxCtB65voQQ54Jfdmfw3M/7Kakyc0n/zkwfHI5e67xkBIvVRvyJIranFJCYVUJemT23PMzPjUl9QpgYE0xc1074tPEHBlGXBORtRAIGIVqPXF9CCGcqrjDz7M/7+DEhg+HR/twysisBXgZnd6uOogoTSbll7E0rJj61iNwyIwCdfd3oFeJN71BvIvw9cNdpMFqsmC029FoNnTx0BHkbCPI2EOhlwEOvkRH2FiYBeRuRgEGI1iPXlxCirZVUmTmSXcaaQzl8seU4ZouNmaOjOK9nkLO71iSKopBZXMXR3DLSCitJK6wgvaiS3FIjNgVUgFajwmJVODVQ1KpVuOs0qFRgtiooKAR4Gugf7svIaH8GRvjRNcATP3cdarUE7k2hdXYHhBBCCCHOVnGFmX0ZxaQXVmJVFHzddfi663DTqVGrVGjVavRaNVqNPUC0WBXMVhtmqw2LTcFksVFhslJhslBpsmK02B8zWW2UGy0UlJvILKoivaiSzOIqR71vT72G0T0CuWJQF/w99c58C5pFpVIR5udOmJ97re02RcFmU9CoVahUKmyKQpnRQnGFmeJKMyVVZsqMFoxmGwr24BygsMLE0dwyVh3IxmKzh/AqwEOvwctNi4+bDj8PHT5uOvRa+89ErVbhrlPj56HH112HWqWi0myl3GjBaLGiVqlw02lw12nw0Nu/PA1a3HQaNGoVZquN0ir7z6aowkSl2QqAVm1PEyo3WiissPdZBfh76gnxcSPAU4+HQYteo0IBSqssnCio4EhOGbmlRvzcdYzqEcC0AWH0DfNpk7sBMkLeRoqLi/Hz8+PEiRMygifEaXh7ezfrF6BcX0I0XXOvL0VRKC09faWODUcLmL14/9l0rV3Ra1SE+Bjo4uvmCPIFmK02MoqN5JebqDDZnN2dFjXv2r6c18P/tO2ae42BBORtJi0tjYiICGd3Q4h2obmpJ3J9CdF0zb2+alLCTsdrwGQCLrr/bLp21qxVZViKssBmQ+3midrgiUqrA5UalVpr//9JFKsZxWoFxYpiMWMzV6KYjShmE+BawaRrUKHS6FBp9aBWo1itKOZKUFrhZ6XWYgjtUWtT/h/vULZnxWl3PZP0SQnI24jNZiMjIwNFUYiMjJSRvDZWUlJCRESEvO9OcCbvfXNHF2qurzMZlaiPnC+1yftRW3t/P1prhFy0rPZ+nrmKtvgbBpJD3mbUajXh4eGUlJQA4OPjIxeYE8j77jyt+d7XXF8tTc6X2uT9qK2jvB8qlapDvM5zVUc5z851rf1zkJU6hRBCCCGEcCIJyIUQQgghhHAiCcjbmMFg4Nlnn8VgOPcWDHBl8r47T3t879tjn1uTvB+1yfsh2oKcZ+eGtvo5yKROIYQQQgghnEhGyIUQQgghhHAiCciFEEIIIYRwIgnIhRBCCCGEcCIJyJ3o5ZdfZvTo0Xh4eODn5+fs7ri0999/n+joaNzc3IiLi2P9+vXO7pLLW7duHdOmTSMsLAyVSsWPP/7otL4UFhYyY8YMfH198fX1ZcaMGRQVFTW6j6IoPPfcc4SFheHu7s6ECRPYv7/2suBGo5H77ruPwMBAPD09ueyyy0hLS3M8fuzYMe644w6io6Nxd3ene/fuPPvss5hMptZ4mQ1q7vm/du1a4uLicHNzo1u3bsyfP79OmyVLlhAbG4vBYCA2NpZly5ad9fO2FWe8H6+++irDhg3D29ub4OBgrrjiCg4dOtSir0uc25x1HYraWvrnsGDBAs477zw6depEp06dmDRpEtu2bWt+xxThNM8884zy1ltvKXPmzFF8fX2d3R2X9e233yo6nU5ZsGCBcuDAAeWBBx5QPD09lePHjzu7ay7t999/V5566illyZIlCqAsW7bMaX2ZOnWq0q9fP2XTpk3Kpk2blH79+imXXnppo/u89tprire3t7JkyRJl7969ynXXXad07txZKSkpcbSZNWuW0qVLF2XlypXKrl27lIkTJyoDBw5ULBaLoiiK8scffyi33nqr8ueffypHjx5VfvrpJyU4OFj517/+1aqv92TNPf+Tk5MVDw8P5YEHHlAOHDigLFiwQNHpdMoPP/zgaLNp0yZFo9Eor7zyipKYmKi88sorilarVbZs2XLGz9tWnPV+TJkyRVm0aJGyb98+JSEhQbnkkkuUyMhIpaysrNVfs3A+Z513orbW+DnceOONyrx585T4+HglMTFRue222xRfX18lLS2tWX2TgPwcsGjRIgnIW9Hw4cOVWbNm1doWExOjPP74407qUcfjzID8wIEDClDrj9TmzZsVQDl48GC9+9hsNiU0NFR57bXXHNuqqqoUX19fZf78+YqiKEpRUZGi0+mUb7/91tEmPT1dUavVyvLlyxvszxtvvKFER0ef7ctqsuae/48++qgSExNTa9s999yjjBw50vH9tddeq0ydOrVWmylTpijXX3/9GT9vW3HW+3GqnJwcBVDWrl3b3Jcg2qFz5bzr6Frj53Aqi8WieHt7K5999lmz+iYpK8KlmUwmdu7cyeTJk2ttnzx5Mps2bXJSr0Rb2rx5M76+vowYMcKxbeTIkfj6+jZ4DqSkpJCVlVXrvDEYDIwfP96xz86dOzGbzbXahIWF0a9fv0bPreLiYvz9/c/2ZTXJmZz/mzdvrtN+ypQp7NixA7PZ3GibmmOeq9eds96P+hQXFwO02bkgnOdcOu86stb6OZyqoqICs9nc7GtbAnLh0vLy8rBarYSEhNTaHhISQlZWlpN6JdpSVlYWwcHBdbYHBwc3eA7UbG/svMnKykKv19OpU6cG25zq6NGjvPvuu8yaNavZr+NMnMn5n5WVVW97i8VCXl5eo21qjnmuXnfOej9OpSgKc+bMYezYsfTr1+9MX45oJ86V866ja62fw6kef/xxunTpwqRJk5rVPwnIW9hzzz2HSqVq9GvHjh3O7maHo1Kpan2vKEqdbaJ9ac61Vt/PuinnwJmcNw21ycjIYOrUqVxzzTXceeedp3t5Laq5r6O+9qdub8oxz9XrzlnvR417772XPXv28M033zSr36J9c/Z5J+xa4+dQ44033uCbb75h6dKluLm5Natf2ma1Fqd17733cv311zfaJioqqm06IwgMDESj0dT59JuTk1PnU69oX5p6re3Zs4fs7Ow6j+Xm5jZ4DoSGhgL20ZHOnTs7tp983oSGhmIymSgsLKw1Sp6Tk8Po0aNrHS8jI4OJEycyatQoPvroo6a9wBZwJud/aGhove21Wi0BAQGNtqk55rl63Tnr/TjZfffdx88//8y6desIDw8/m5cj2olz4bwTrfdzqPHmm2/yyiuvsGrVKgYMGNDs/skIeQsLDAwkJiam0a/mfmoSZ06v1xMXF8fKlStrbV+5cmWdoEm0L0291kaNGkVxcXGtMlRbt26luLi4wXMgOjqa0NDQWueNyWRi7dq1jn3i4uLQ6XS12mRmZrJv375ax01PT2fChAkMGTKERYsWoVa33a/dMzn/R40aVaf9ihUrGDp0KDqdrtE2Ncc8V687Z70fYB9Vu/fee1m6dCl//fUX0dHRLfGSRDvgzPNO/K21fg4A//73v3nxxRdZvnw5Q4cOPbMONmsKqGhRx48fV+Lj45Xnn39e8fLyUuLj45X4+HiltLTU2V1zKTVljhYuXKgcOHBAefDBBxVPT0/l2LFjzu6aSystLXWc04Dy1ltvKfHx8U4pezd16lRlwIAByubNm5XNmzcr/fv3r1P2sHfv3srSpUsd37/22muKr6+vsnTpUmXv3r3KDTfcUG/Zw/DwcGXVqlXKrl27lPPPP79W2cP09HSlR48eyvnnn6+kpaUpmZmZjq+2crrz//HHH1dmzJjhaF9T5uuhhx5SDhw4oCxcuLBOma+NGzcqGo1Gee2115TExETltddea7Ds4bl23Tnr/fjHP/6h+Pr6KmvWrKl1HlRUVLTdixdO46zzTtTWGj+H119/XdHr9coPP/xQ69pubiwnAbkTzZw5UwHqfK1evdrZXXM58+bNU7p27aro9XplyJAhUmqsDaxevbre83vmzJlt3pf8/HzlpptuUry9vRVvb2/lpptuUgoLC2u1AZRFixY5vrfZbMqzzz6rhIaGKgaDQRk3bpyyd+/eWvtUVlYq9957r+Lv76+4u7srl156qZKamup4fNGiRfW+B209FtLY+T9z5kxl/PjxtdqvWbNGGTx4sKLX65WoqCjlgw8+qHPM77//Xundu7ei0+mUmJgYZcmSJc16XmdyxvvR0Hlw8jknXJuzrkNRW0v/HLp27Vrvtf3ss882q18qRanOThdCCCGEEEK0OckhF0IIIYQQwokkIBdCCCGEEMKJJCAXQgghhBDCiSQgF0IIIYQQwokkIBdCCCGEEMKJJCAXQgghhBDCiSQgF0IIIYQQwokkIBdCCCGEEMKJJCAXThcVFcXcuXOb3P7YsWOoVCoSEhJarU8n+/TTT/Hz82uT5zrVrbfeyhVXXOGU5xZCCCFE25CAXDjd9u3bufvuu1v0mM4Mos9EQx8y/vvf//Lpp586pU9CnI3333+f6Oho3NzciIuLY/369c7ukhAuYd26dUybNo2wsDBUKhU//vijs7skWoAE5MLpgoKC8PDwcHY3WoXZbD6r/X19fdvVBwshABYvXsyDDz7IU089RXx8POeddx4XXXQRqampzu6aEO1eeXk5AwcO5L333nN2V0QLkoBcNNsvv/yCn58fNpsNgISEBFQqFY888oijzT333MMNN9wAwKZNmxg3bhzu7u5ERERw//33U15e7mh7asrKwYMHGTt2LG5ubsTGxrJq1ap6RwGSk5OZOHEiHh4eDBw4kM2bNwOwZs0abrvtNoqLi1GpVKhUKp577jkATCYTjz76KF26dMHT05MRI0awZs2aWsf99NNPiYyMxMPDg+nTp5Ofn9/k9+a5555j0KBBfPLJJ3Tr1g2DwYCiKCxfvpyxY8fi5+dHQEAAl156KUePHnXsFx0dDcDgwYNRqVRMmDABqJuyYjQauf/++wkODsbNzY2xY8eyffv2JvdPiLbw1ltvcccdd3DnnXfSp08f5s6dS0REBB988IGzuyZEu3fRRRfx0ksvceWVVzq7K6IFSUAumm3cuHGUlpYSHx8PwNq1awkMDGTt2rWONmvWrGH8+PHs3buXKVOmcOWVV7Jnzx4WL17Mhg0buPfee+s9ts1m44orrsDDw4OtW7fy0Ucf8dRTT9Xb9qmnnuLhhx8mISGBXr16ccMNN2CxWBg9ejRz587Fx8eHzMxMMjMzefjhhwG47bbb2LhxI99++y179uzhmmuuYerUqRw5cgSArVu3cvvttzN79mwSEhKYOHEiL730UrPen6SkJL777juWLFniSEEpLy9nzpw5bN++nf/973+o1WqmT5/u+FCzbds2AFatWkVmZiZLly6t99iPPvooS5Ys4bPPPmPXrl306NGDKVOmUFBQ0Kw+CtFaTCYTO3fuZPLkybW2T548mU2bNjmpV0IIcY5ThDgDQ4YMUd58801FURTliiuuUF5++WVFr9crJSUlSmZmpgIoiYmJyowZM5S777671r7r169X1Gq1UllZqSiKonTt2lV5++23FUVRlD/++EPRarVKZmamo/3KlSsVQFm2bJmiKIqSkpKiAMrHH3/saLN//37HcyqKoixatEjx9fWt9bxJSUmKSqVS0tPTa22/4IILlCeeeEJRFEW54YYblKlTp9Z6/LrrrqtzrIY8++yzik6nU3Jychptl5OTowDK3r17a72m+Pj4Wu1mzpypXH755YqiKEpZWZmi0+mUr776yvG4yWRSwsLClDfeeKNJ/ROitaWnpyuAsnHjxlrbX375ZaVXr15O6pUQrunkv42ifZMRcnFGJkyYwJo1a1AUhfXr13P55ZfTr18/NmzYwOrVqwkJCSEmJoadO3fy6aef4uXl5fiaMmUKNpuNlJSUOsc9dOgQERERhIaGOrYNHz683j4MGDDA8f/OnTsDkJOT02Cfd+3ahaIo9OrVq1Z/1q5d60gfSUxMZNSoUbX2O/X70+natStBQUG1th09epQbb7yRbt264ePj40hRaU5O7dGjRzGbzYwZM8axTafTMXz4cBITE5vVRyFam0qlqvW9oih1tgkhhLDTOrsDon2aMGECCxcuZPfu3ajVamJjYxk/fjxr166lsLCQ8ePHA/YUlHvuuYf777+/zjEiIyPrbGvOH22dTuf4f80+NSkg9bHZbGg0Gnbu3IlGo6n1mJeXl+P5z5anp2edbdOmTSMiIoIFCxYQFhaGzWajX79+mEymJh+3pm8S6IhzWWBgIBqNhqysrFrbc3JyCAkJcVKvhBDi3CYj5OKM1OSRz507l/Hjx6NSqRg/fjxr1qxx5I8DDBkyhP3799OjR486X3q9vs5xY2JiSE1NJTs727HtTCYt6vV6rFZrrW2DBw/GarWSk5NTpy81I/KxsbFs2bKl1n6nft9c+fn5JCYm8vTTT3PBBRfQp08fCgsL6/QXqNPnk9W8Zxs2bHBsM5vN7Nixgz59+pxVH4VoKXq9nri4OFauXFlr+8qVKxk9erSTeiWEEOc2GSEXZ8TX15dBgwbx5Zdf8t///hewB+nXXHMNZrPZUSXkscceY+TIkfzzn//krrvuwtPTk8TERFauXMm7775b57gXXngh3bt3Z+bMmbzxxhuUlpY6JnU2ZxQ4KiqKsrIy/ve//zFw4EA8PDzo1asXN910E7fccgv/+c9/GDx4MHl5efz111/079+fiy++mPvvv5/Ro0fzxhtvcMUVV7BixQqWL19+Vu9Vp06dCAgI4KOPPqJz586kpqby+OOP12oTHByMu7s7y5cvJzw8HDc3N3x9fWu18fT05B//+AePPPII/v7+REZG8sYbb1BRUcEdd9xxVn0UoiXNmTOHGTNmMHToUEaNGsVHH31Eamoqs2bNcnbXhGj3ysrKSEpKcnyfkpJCQkKC4++CaKecmL8u2rl//etfCqDs27fPsW3gwIFKUFCQYrPZHNu2bdumXHjhhYqXl5fi6empDBgwQHn55Zcdj588qVNRFCUxMVEZM2aMotfrlZiYGOWXX35RAGX58uWKotQ/AbKwsFABlNWrVzu2zZo1SwkICFAA5dlnn1UUxT4J8plnnlGioqIUnU6nhIaGKtOnT1f27Nnj2G/hwoVKeHi44u7urkybNk158803mzWpc+DAgXW2r1y5UunTp49iMBiUAQMGKGvWrKkzGWfBggVKRESEolarlfHjxyuKUntSp6IoSmVlpXLfffcpgYGBisFgUMaMGaNs27atSX0Toi3NmzdP6dq1q6LX65UhQ4Yoa9eudXaXhHAJq1evVoA6XzNnznR218RZUClKCyTNCtGKNm7cyNixY0lKSqJ79+7O7o4QQgghRIuSgFycc5YtW4aXlxc9e/YkKSmJBx54gE6dOtXKnRZCCCGEcBUyqVOcc0pLS5k9ezYxMTHceuutDBs2jJ9++snZ3QKgb9++tUomnvz11VdfObt7QgghhGiHZIRciGY4fvw4ZrO53sdCQkLw9vZu4x4JIYQQor2TgFwIIYQQQggnkpQVIYQQQgghnEgCciGEEEIIIZxIAnIhhBBCCCGcSAJyIYQQQgghnEgCciGEEEIIIZxIAnIhhBBCCCGcSAJyIYQQQgghnEgCciGEEEIIIZzo/wFpfkkCqPRxogAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 750x750 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_tree_features = {}\n",
    "\n",
    "for iteration in range(len(decision_tree_importance_dict.keys())):\n",
    "    if iteration == 0:\n",
    "        df = pd.DataFrame(decision_tree_importance_dict[iteration], columns=['forest_{}'.format(iteration)])\n",
    "        df2 = pd.DataFrame(ridge_importances_dict[iteration], columns=['ridge_{}'.format(iteration)])\n",
    "        df3 = pd.DataFrame(logReg_importances_dict[iteration], columns=['logReg_{}'.format(iteration)])\n",
    "        selected = decision_tree_importance_dict[iteration][decision_tree_importance_dict[iteration] > 0]\n",
    "        selected_tree_features[iteration] = selected\n",
    "    else:\n",
    "        df['forest_{}'.format(iteration)] = decision_tree_importance_dict[iteration]\n",
    "        df2['ridge_{}'.format(iteration)] = ridge_importances_dict[iteration]\n",
    "        df3['logReg_{}'.format(iteration)] = logReg_importances_dict[iteration]\n",
    "        selected = decision_tree_importance_dict[iteration][decision_tree_importance_dict[iteration] > 0]\n",
    "        selected_tree_features[iteration] = selected\n",
    "\n",
    "\n",
    "tree_feature_counter_df = {}\n",
    "#print (selected_tree_features)\n",
    "for iteration in selected_tree_features.keys():\n",
    "    if len(selected_tree_features[iteration].index) > 1:\n",
    "        for feature in selected_tree_features[iteration].index:\n",
    "            if feature not in tree_feature_counter_df.keys():\n",
    "                tree_feature_counter_df[feature] = 1\n",
    "            else:\n",
    "                tree_feature_counter_df[feature] += 1\n",
    "    else:\n",
    "        if selected_tree_features[iteration].index[0] not in tree_feature_counter_df.keys():\n",
    "            tree_feature_counter_df[selected_tree_features[iteration].index[0]] = 1\n",
    "        else:\n",
    "            tree_feature_counter_df[selected_tree_features[iteration].index[0]] += 1\n",
    "\n",
    "tree_feature_counter_df = pd.DataFrame.from_dict(tree_feature_counter_df, orient='index', columns=['count'])\n",
    "#print (tree_feature_counter_df.sort_values(by='count', ascending=False)[:100])\n",
    "\n",
    "#merge df2 and df3\n",
    "ml_summary_df = pd.concat([df2, df3],axis=1)\n",
    "#print (ml_summary_df)\n",
    "\n",
    "average_importance_ridge = df2.mean(axis=1)\n",
    "average_rank_ridge = average_importance_ridge.rank(ascending=False)\n",
    "#print (average_importance_ridge.sort_values(ascending=False)[:int(len(average_importance_ridge)*0.05)])\n",
    "print (average_importance_ridge['GC_00001531'])\n",
    "print (average_rank_ridge['GC_00001531'])\n",
    "\n",
    "average_importance_logReg = df3.mean(axis=1)\n",
    "average_rank_logReg = average_importance_logReg.rank(ascending=False)\n",
    "#print (average_importance_logReg.sort_values(ascending=False)[:int(len(average_importance_logReg)*0.05)])\n",
    "print (average_importance_logReg['GC_00001531'])\n",
    "print (average_rank_logReg['GC_00001531'])\n",
    "\n",
    "plotting_data = pd.concat([weighted_purity_df.loc[:, 'weighted_ratio'], average_importance_ridge, average_importance_logReg], axis=1)\n",
    "\n",
    "sns.pairplot(plotting_data, kind='kde', corner=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2286\n",
      "1418\n",
      "2133\n",
      "153\n",
      "GH102\n",
      "GT51\n",
      "GH13\n",
      "GH43\n",
      "GT39\n",
      "GT28\n",
      "GT20\n",
      "CE10\n",
      "GH3\n",
      "GT51\n",
      "GT35\n",
      "GT28\n",
      "CE10\n",
      "GT5\n",
      "GH3\n",
      "GT51\n",
      "GH3\n",
      "GT26\n",
      "GH31\n",
      "GT2\n",
      "GT4\n",
      "GT51\n",
      "GH23\n",
      "CE1\n",
      "GT51\n",
      "CBM48,GH13\n",
      "CE10\n",
      "GH5,GH9\n",
      "GH51\n",
      "GT2\n",
      "GT28\n",
      "GT2\n",
      "GH32,GH68\n",
      "GT4\n",
      "GH43,GH51\n",
      "          AA10,CBM73,GH5,GH9  GH23  CBM42,GH54  GH47  GT2  GH37  GH8  GH88   \n",
      "layer                                                                        \n",
      "CALOFZ02                   0     1           0     0    7     0    1     0  \\\n",
      "CALOGA02                   0     1           0     0    3     1    0     0   \n",
      "CALOGB02                   0     1           0     0    6     1    3     0   \n",
      "CALOGC02                   0     1           0     0   15     0    1     0   \n",
      "CALOGD02                   0     1           0     0   15     0    1     0   \n",
      "...                      ...   ...         ...   ...  ...   ...  ...   ...   \n",
      "S65                        0     0           1     0    2     0    0     0   \n",
      "S7                         1     1           0     0    3     0    0     0   \n",
      "S71                        1     1           0     0    3     0    0     0   \n",
      "S72                        0     1           0     0    4     0    0     0   \n",
      "Si1                        0     0           0     0    2     0    0     1   \n",
      "\n",
      "          GH102  PL4  ...  GH130  GT85  GH39  GT81  GH94,GT36  GH38  GH57   \n",
      "layer                 ...                                                   \n",
      "CALOFZ02      1    0  ...      0     0     0     0          0     0     0  \\\n",
      "CALOGA02      1    0  ...      0     0     0     0          0     0     0   \n",
      "CALOGB02      1    0  ...      0     0     0     0          0     0     0   \n",
      "CALOGC02      1    1  ...      0     0     1     0          0     0     0   \n",
      "CALOGD02      1    1  ...      0     0     1     0          0     0     0   \n",
      "...         ...  ...  ...    ...   ...   ...   ...        ...   ...   ...   \n",
      "S65           0    0  ...      0     0     0     0          0     0     0   \n",
      "S7            0    0  ...      0     0     0     0          0     0     0   \n",
      "S71           0    0  ...      0     0     0     0          0     0     0   \n",
      "S72           1    0  ...      0     0     0     0          0     0     0   \n",
      "Si1           0    0  ...      0     0     0     0          0     0     0   \n",
      "\n",
      "          GH4,GT4  GT35  GT21  \n",
      "layer                          \n",
      "CALOFZ02        0     1     0  \n",
      "CALOGA02        0     1     0  \n",
      "CALOGB02        0     1     0  \n",
      "CALOGC02        0     1     0  \n",
      "CALOGD02        0     1     0  \n",
      "...           ...   ...   ...  \n",
      "S65             0     1     0  \n",
      "S7              0     0     0  \n",
      "S71             0     0     0  \n",
      "S72             0     0     0  \n",
      "Si1             0     0     0  \n",
      "\n",
      "[1260 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "#if not stored, save to csv the dataframes of tree_feature_counter_df, average_importance_ridge, average_importance_logReg\n",
    "#Get features that are high in both the ridge and logistic regression\n",
    "#Pairplot their weighted ratio with both the ridge and logistic regression importance. Ideally, we should see both high weighted ratio and low weighted ratio features with high importance in both ridge and logistic regression.\n",
    "#Based on their weighted ratio, we can decide whether they are enriched or depleted in sphingo genomes.\n",
    "#Get the annotation for both groups\n",
    "#Plot per KO, KEGG, PFAM, COG, CAZy, description their weighted ratio and their importance\n",
    "\n",
    "if not os.path.isfile('{}tree_feature_counter_df.tsv'.format(output_dir)):\n",
    "    tree_feature_counter_df.to_csv('{}tree_feature_counter_df.tsv'.format(output_dir), sep='\\t')\n",
    "\n",
    "if not os.path.isfile('{}average_importance_ridge.tsv'.format(output_dir)):\n",
    "    average_importance_ridge.to_csv('{}average_importance_ridge.tsv'.format(output_dir), sep='\\t')\n",
    "\n",
    "if not os.path.isfile('{}average_importance_logReg.tsv'.format(output_dir)):\n",
    "    average_importance_logReg.to_csv('{}average_importance_logReg.tsv'.format(output_dir), sep='\\t')\n",
    "\n",
    "average_rank_ridge = average_importance_ridge.rank(ascending=False)\n",
    "average_rank_logReg = average_importance_logReg.rank(ascending=False)\n",
    "\n",
    "percentile_ridge = average_rank_ridge[average_rank_ridge < int(len(average_rank_ridge)*0.05)]\n",
    "percentile_logReg = average_rank_logReg[average_rank_logReg < int(len(average_rank_logReg)*0.05)]\n",
    "\n",
    "#print (average_importance_ridge.loc[percentile_ridge.index])\n",
    "#print (average_importance_logReg.loc[percentile_logReg.index])\n",
    "\n",
    "shared_important_features = list(set(percentile_ridge.index).intersection(set(percentile_logReg.index)))\n",
    "combined_important_features = list(set(percentile_ridge.index).union(set(percentile_logReg.index)))\n",
    "print (len(combined_important_features))\n",
    "print (len(shared_important_features))\n",
    "\n",
    "combined_sphingo_enriched = []\n",
    "combined_sphingo_depleted = []\n",
    "\n",
    "for gc in combined_important_features:\n",
    "    if weighted_purity_df.loc[gc, 'weighted_ratio'] > 0:\n",
    "        combined_sphingo_enriched.append(gc)\n",
    "    else:\n",
    "        combined_sphingo_depleted.append(gc)\n",
    "\n",
    "print (len(combined_sphingo_enriched))\n",
    "print (len(combined_sphingo_depleted))\n",
    "\n",
    "for gc in combined_sphingo_enriched:\n",
    "    #print (gc)\n",
    "    #if gc in annotation_dict_COG_reformat.keys():\n",
    "    #    print (annotation_dict_COG_reformat[gc])\n",
    "    #if gc in annotation_dict_PFAM_reformat.keys():\n",
    "    #    print (annotation_dict_PFAM_reformat[gc])\n",
    "    #if gc in annotation_dict_KEGG_reformat.keys():\n",
    "    #    print (annotation_dict_KEGG_reformat[gc])\n",
    "    if gc in annotation_dict_CAZy_reformat.keys():\n",
    "        print (annotation_dict_CAZy_reformat[gc])\n",
    "    #if gc in annotation_dict_description_reformat.keys():\n",
    "    #    print (annotation_dict_description_reformat[gc])\n",
    "    \n",
    "\n",
    "print (cazyme_per_genome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A   B     C    D     E    F     G     H     I    J  ...  R     S   \n",
      "enriched  0   3   107   29   175   43   128    95   101  108  ...  0   474  \\\n",
      "depleted  0   0    11    0    20    1     8     5    13    1  ...  0    39   \n",
      "neutral   5  10  1504  348  2690  569  2270  1069  1282  952  ...  0  8078   \n",
      "\n",
      "             T    U    V  W  X  Y   Z     -  \n",
      "enriched   101   69   29  0  0  0   0   140  \n",
      "depleted     4    2    1  0  0  0   0     2  \n",
      "neutral   1696  835  425  4  0  1  19  3393  \n",
      "\n",
      "[3 rows x 27 columns]\n",
      "                 A         B         C         D         E         F   \n",
      "enriched  0.000000  0.001316  0.046930  0.012719  0.076754  0.018860  \\\n",
      "depleted  0.000000  0.000000  0.064706  0.000000  0.117647  0.005882   \n",
      "neutral   0.000138  0.000277  0.041617  0.009629  0.074435  0.015745   \n",
      "\n",
      "                 G         H         I         J  ...  R         S         T   \n",
      "enriched  0.056140  0.041667  0.044298  0.047368  ...  0  0.207895  0.044298  \\\n",
      "depleted  0.047059  0.029412  0.076471  0.005882  ...  0  0.229412  0.023529   \n",
      "neutral   0.062813  0.029580  0.035474  0.026343  ...  0  0.223526  0.046930   \n",
      "\n",
      "                 U         V         W  X         Y         Z         -  \n",
      "enriched  0.030263  0.012719  0.000000  0  0.000000  0.000000  0.061404  \n",
      "depleted  0.011765  0.005882  0.000000  0  0.000000  0.000000  0.011765  \n",
      "neutral   0.023105  0.011760  0.000111  0  0.000028  0.000526  0.093887  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make table where you count the cog counts for gc in combined_sphingo_enriched, combined_sphingo_depleted, and all GCs minus the combined_sphingo_enriched and combined_sphingo_depleted\n",
    "\n",
    "cog_table = pd.DataFrame(0, index=['enriched', 'depleted', 'neutral'], columns=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '-'])\n",
    "\n",
    "annotation_dict_COG_reformat_keys = annotation_dict_COG_reformat.keys()\n",
    "\n",
    "for gc in gene_cluster_presence_absence.columns:\n",
    "    if gc in annotation_dict_COG_reformat_keys:\n",
    "        if gc in combined_sphingo_enriched:\n",
    "            if len(annotation_dict_COG_reformat[gc]) == 1:\n",
    "                cog_table.loc['enriched', annotation_dict_COG_reformat[gc]] += 1\n",
    "            else:\n",
    "                for annot in annotation_dict_COG_reformat[gc]:\n",
    "                    cog_table.loc['enriched', annot] += 1\n",
    "        elif gc in combined_sphingo_depleted:\n",
    "            if len(annotation_dict_COG_reformat[gc]) == 1:\n",
    "                cog_table.loc['depleted', annotation_dict_COG_reformat[gc]] += 1\n",
    "            else:\n",
    "                for annot in annotation_dict_COG_reformat[gc]:\n",
    "                    cog_table.loc['depleted', annot] += 1\n",
    "        else:\n",
    "            if len(annotation_dict_COG_reformat[gc]) == 1:\n",
    "                cog_table.loc['neutral', annotation_dict_COG_reformat[gc]] += 1\n",
    "            else:\n",
    "                for annot in annotation_dict_COG_reformat[gc]:\n",
    "                    cog_table.loc['neutral', annot] += 1\n",
    "\n",
    "print (cog_table)\n",
    "\n",
    "#make 3 stacked barplots for each COG category, one for enriched, one for depleted, one for neutral with the relative abundance of the COG category.\n",
    "\n",
    "\n",
    "cog_table.loc['enriched'] = cog_table.loc['enriched']/cog_table.loc['enriched'].sum()\n",
    "cog_table.loc['depleted'] = cog_table.loc['depleted']/cog_table.loc['depleted'].sum()\n",
    "cog_table.loc['neutral'] = cog_table.loc['neutral']/cog_table.loc['neutral'].sum()\n",
    "\n",
    "print (cog_table)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cog_table.plot.bar(stacked=True, ax=ax)\n",
    "ax.set_title(\"COG categories\")\n",
    "ax.set_ylabel(\"Relative abundance\")\n",
    "fig.tight_layout()\n",
    "#remove the legend\n",
    "ax.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['GC_00026744', 'GC_00023617', 'GC_00009660', 'GC_00009817', 'GC_00010540', 'GC_00028975', 'GC_00031343', 'GC_00018509', 'GC_00026617', 'GC_00010020', 'GC_00007002', 'GC_00008764', 'GC_00010132', 'GC_00015897', 'GC_00024503', 'GC_00013317', 'GC_00018218', 'GC_00001349', 'GC_00020664', 'GC_00035275', 'GC_00002052', 'GC_00009546', 'GC_00007911', 'GC_00007467', 'GC_00035119', 'GC_00002690', 'GC_00015731', 'GC_00017133', 'GC_00003674', 'GC_00024315', 'GC_00009225', 'GC_00020615', 'GC_00002432', 'GC_00002496', 'GC_00022256', 'GC_00001471', 'GC_00027717', 'GC_00009066', 'GC_00001728', 'GC_00005858', 'GC_00002211', 'GC_00003912', 'GC_00003526', 'GC_00005149', 'GC_00007496', 'GC_00000396', 'GC_00023492', 'GC_00009478', 'GC_00029383', 'GC_00008479', 'GC_00034769', 'GC_00027891', 'GC_00032525', 'GC_00022586', 'GC_00031949', 'GC_00018587', 'GC_00020782', 'GC_00005952', 'GC_00013883', 'GC_00021610', 'GC_00022824', 'GC_00025937', 'GC_00035307', 'GC_00019761', 'GC_00005235', 'GC_00018022', 'GC_00000127', 'GC_00003992', 'GC_00016602', 'GC_00024930', 'GC_00020816', 'GC_00016142', 'GC_00037978', 'GC_00000013', 'GC_00028202', 'GC_00003565', 'GC_00012531', 'GC_00020172', 'GC_00007298', 'GC_00011292', 'GC_00004437', 'GC_00024223', 'GC_00030186', 'GC_00031088', 'GC_00013415', 'GC_00036533', 'GC_00014261', 'GC_00033665', 'GC_00014419', 'GC_00023328', 'GC_00032193', 'GC_00010524', 'GC_00031860', 'GC_00001926', 'GC_00005354', 'GC_00002778', 'GC_00028756', 'GC_00017565', 'GC_00006272', 'GC_00012679', 'GC_00019616', 'GC_00023375', 'GC_00037360', 'GC_00004269', 'GC_00024926', 'GC_00036949', 'GC_00013062', 'GC_00012982', 'GC_00000827', 'GC_00008087', 'GC_00011640', 'GC_00031639', 'GC_00002689', 'GC_00021333', 'GC_00012712', 'GC_00003367', 'GC_00002483', 'GC_00000081', 'GC_00008681', 'GC_00004705', 'GC_00002340', 'GC_00012034', 'GC_00018835', 'GC_00027237', 'GC_00010577', 'GC_00033717', 'GC_00002113', 'GC_00031827', 'GC_00002775', 'GC_00033220', 'GC_00008461', 'GC_00015547', 'GC_00006104', 'GC_00013744', 'GC_00020994', 'GC_00009084', 'GC_00021958', 'GC_00002777', 'GC_00015007', 'GC_00016523', 'GC_00023255', 'GC_00002430', 'GC_00005888', 'GC_00005595', 'GC_00022709', 'GC_00011921', 'GC_00031865', 'GC_00026651', 'GC_00034637', 'GC_00032464', 'GC_00013125', 'GC_00013164', 'GC_00014982', 'GC_00011712', 'GC_00011098', 'GC_00008226', 'GC_00005836', 'GC_00016143', 'GC_00012116', 'GC_00004231', 'GC_00005944', 'GC_00020897', 'GC_00002188', 'GC_00020278', 'GC_00028809', 'GC_00030861', 'GC_00009791', 'GC_00015889', 'GC_00010232', 'GC_00017558', 'GC_00037825', 'GC_00027628', 'GC_00026476', 'GC_00009966', 'GC_00021925', 'GC_00024691', 'GC_00007655', 'GC_00016825', 'GC_00001772', 'GC_00025930', 'GC_00004573', 'GC_00032632', 'GC_00011883', 'GC_00004518', 'GC_00012656', 'GC_00032667', 'GC_00006115', 'GC_00011205', 'GC_00001771', 'GC_00035121', 'GC_00002484', 'GC_00005076', 'GC_00004019', 'GC_00003134', 'GC_00014812', 'GC_00021916', 'GC_00012280', 'GC_00024900', 'GC_00006170', 'GC_00009897', 'GC_00029948', 'GC_00016664', 'GC_00019842', 'GC_00016900', 'GC_00018592', 'GC_00025550', 'GC_00011464', 'GC_00006460', 'GC_00006439', 'GC_00006405', 'GC_00020408', 'GC_00034246', 'GC_00009063', 'GC_00024659', 'GC_00004365', 'GC_00031682', 'GC_00020681', 'GC_00004005', 'GC_00011682', 'GC_00003160', 'GC_00006768', 'GC_00004847', 'GC_00016906', 'GC_00029974', 'GC_00009571', 'GC_00033390', 'GC_00029318', 'GC_00016072', 'GC_00012079', 'GC_00003760', 'GC_00009699', 'GC_00015532', 'GC_00003079', 'GC_00021861', 'GC_00032054', 'GC_00022888', 'GC_00005462', 'GC_00024707', 'GC_00007951', 'GC_00030112', 'GC_00000777', 'GC_00013015', 'GC_00021359', 'GC_00004700', 'GC_00015003', 'GC_00034063', 'GC_00004044', 'GC_00036779', 'GC_00018340', 'GC_00033818', 'GC_00025332', 'GC_00032479', 'GC_00028505', 'GC_00009813', 'GC_00011893', 'GC_00027839', 'GC_00022407', 'GC_00021164', 'GC_00011177', 'GC_00006090', 'GC_00028914', 'GC_00005173', 'GC_00035616', 'GC_00000617', 'GC_00015451', 'GC_00011689', 'GC_00023867', 'GC_00023235', 'GC_00002217', 'GC_00008768', 'GC_00036665', 'GC_00033420', 'GC_00023823', 'GC_00033918', 'GC_00008514', 'GC_00002750', 'GC_00029240', 'GC_00007473', 'GC_00019512', 'GC_00003211', 'GC_00016638', 'GC_00018302', 'GC_00005103', 'GC_00003799', 'GC_00018490', 'GC_00035793', 'GC_00010757', 'GC_00016788', 'GC_00022556', 'GC_00017778', 'GC_00021660', 'GC_00034218', 'GC_00000309', 'GC_00014102', 'GC_00015893', 'GC_00005184', 'GC_00000143', 'GC_00023396', 'GC_00036833', 'GC_00036306', 'GC_00010669', 'GC_00000432', 'GC_00015741', 'GC_00023331', 'GC_00035380', 'GC_00000605', 'GC_00023780', 'GC_00016562', 'GC_00029214', 'GC_00030450', 'GC_00025950', 'GC_00021278', 'GC_00012711', 'GC_00006145', 'GC_00019628', 'GC_00010106', 'GC_00012578', 'GC_00010723', 'GC_00019177', 'GC_00002621', 'GC_00027198', 'GC_00022293', 'GC_00011409', 'GC_00005133', 'GC_00025915', 'GC_00035456', 'GC_00001343', 'GC_00017060', 'GC_00035565', 'GC_00014936', 'GC_00024463', 'GC_00012559', 'GC_00003942', 'GC_00025894', 'GC_00010340', 'GC_00009583', 'GC_00032485', 'GC_00034277', 'GC_00004960', 'GC_00022710', 'GC_00014771', 'GC_00010408', 'GC_00037458', 'GC_00025662', 'GC_00004533', 'GC_00024650', 'GC_00033276', 'GC_00003089', 'GC_00013152', 'GC_00021849', 'GC_00033840', 'GC_00028049', 'GC_00007372', 'GC_00027892', 'GC_00018352', 'GC_00031415', 'GC_00008753', 'GC_00011311', 'GC_00028686', 'GC_00004182', 'GC_00014776', 'GC_00019167', 'GC_00012584', 'GC_00016832', 'GC_00022003', 'GC_00005375', 'GC_00001253', 'GC_00022438', 'GC_00012613', 'GC_00003054', 'GC_00022112', 'GC_00014219', 'GC_00010695', 'GC_00017931', 'GC_00001192', 'GC_00030924', 'GC_00011963', 'GC_00028022', 'GC_00005117', 'GC_00003004', 'GC_00035462', 'GC_00010582', 'GC_00025957', 'GC_00000001', 'GC_00015646', 'GC_00008388', 'GC_00015790', 'GC_00009020', 'GC_00022923', 'GC_00012734', 'GC_00018533', 'GC_00011698', 'GC_00004378', 'GC_00016640', 'GC_00014193', 'GC_00024708', 'GC_00027440', 'GC_00008325', 'GC_00016317', 'GC_00026340', 'GC_00021489', 'GC_00016217', 'GC_00005570', 'GC_00027754', 'GC_00022392', 'GC_00004037', 'GC_00003480', 'GC_00015021', 'GC_00028404', 'GC_00003008', 'GC_00001826', 'GC_00012406', 'GC_00007723', 'GC_00011674', 'GC_00021467', 'GC_00021976', 'GC_00029338', 'GC_00033611', 'GC_00000484', 'GC_00006660', 'GC_00015820', 'GC_00002299', 'GC_00001938', 'GC_00000773', 'GC_00005725', 'GC_00019210', 'GC_00028877', 'GC_00020827', 'GC_00001612', 'GC_00007059', 'GC_00000323', 'GC_00002716', 'GC_00035115', 'GC_00021335', 'GC_00005336', 'GC_00021040', 'GC_00030895', 'GC_00025408', 'GC_00021653', 'GC_00007896', 'GC_00000480', 'GC_00015434', 'GC_00024334', 'GC_00017373', 'GC_00022028', 'GC_00011663', 'GC_00007419', 'GC_00032290', 'GC_00013649', 'GC_00036777', 'GC_00015333', 'GC_00026556', 'GC_00018430', 'GC_00024733', 'GC_00007163', 'GC_00004888', 'GC_00019341', 'GC_00014690', 'GC_00006077', 'GC_00010386', 'GC_00025500', 'GC_00001894', 'GC_00009627', 'GC_00031863', 'GC_00005979', 'GC_00033676', 'GC_00003331', 'GC_00005038', 'GC_00028725', 'GC_00027850', 'GC_00000285', 'GC_00012195', 'GC_00018946', 'GC_00010205', 'GC_00017173', 'GC_00003938', 'GC_00015025', 'GC_00013756', 'GC_00002915', 'GC_00036904', 'GC_00024454', 'GC_00002264', 'GC_00017359', 'GC_00014616', 'GC_00023080', 'GC_00003511', 'GC_00023890', 'GC_00002688', 'GC_00007460', 'GC_00002067', 'GC_00019696', 'GC_00002096', 'GC_00000239', 'GC_00018962', 'GC_00024608', 'GC_00035140', 'GC_00031687', 'GC_00014844', 'GC_00009061', 'GC_00007043', 'GC_00000022', 'GC_00035747', 'GC_00013526', 'GC_00029685', 'GC_00028917', 'GC_00033900', 'GC_00021974', 'GC_00024224', 'GC_00028688', 'GC_00029998', 'GC_00012057', 'GC_00033399', 'GC_00010847', 'GC_00025320', 'GC_00028423', 'GC_00025990', 'GC_00004438', 'GC_00026620', 'GC_00011390', 'GC_00011725', 'GC_00000504', 'GC_00009255', 'GC_00013844', 'GC_00017793', 'GC_00020665', 'GC_00021568', 'GC_00024753', 'GC_00017736', 'GC_00011284', 'GC_00003790', 'GC_00017709', 'GC_00005191', 'GC_00026793', 'GC_00032548', 'GC_00024356', 'GC_00031656', 'GC_00021198', 'GC_00019223', 'GC_00018863', 'GC_00006330', 'GC_00008667', 'GC_00004281', 'GC_00026224', 'GC_00026542', 'GC_00017148', 'GC_00026239', 'GC_00021468', 'GC_00016486', 'GC_00010850', 'GC_00025299', 'GC_00016696', 'GC_00020360', 'GC_00030715', 'GC_00014216', 'GC_00019011', 'GC_00013858', 'GC_00011030', 'GC_00004527', 'GC_00031648', 'GC_00004523', 'GC_00034184', 'GC_00003365', 'GC_00031091', 'GC_00007654', 'GC_00000693', 'GC_00000672', 'GC_00010174', 'GC_00005249', 'GC_00019556', 'GC_00015228', 'GC_00018596', 'GC_00036885', 'GC_00032241', 'GC_00030142', 'GC_00018539', 'GC_00015330', 'GC_00002620', 'GC_00005896', 'GC_00021236'])\n",
      "dict_values(['GH31', 'GT4', 'GT28', 'GT4', 'GH3', 'CE10', 'GT87', 'GT28', 'GT89', 'GT4', 'GH3', 'GT2,GT4', 'GT26', 'GH31', 'GT26', 'GH5,GH9', 'GT2', 'GT4', 'GT4', 'GT51', 'GT51', 'GH26', 'GT4', 'GH23', 'GT51', 'GH77', 'GT2', 'GH5,GH9', 'GT51', 'GH23', 'GH29', 'GT30', 'GH3', 'GH15', 'GT51', 'GT2', 'GH18', 'GH101', 'GT28', 'PL4', 'GH102', 'PL11', 'GH43', 'GH8', 'GH95', 'GH3', 'GH31', 'GH13', 'GH47', 'GH3', 'GT28', 'GT4', 'GH130', 'GT2,GT4', 'AA10,CBM73', 'GH43,GH51', 'GT25', 'GT4', 'GT1', 'PL8', 'GT56', 'GT39', 'GT4', 'GT4', 'CE1,GH5,GH9', 'GT2', 'CBM48,GH13', 'GT4', 'GT4', 'GT2,GT4', 'GH31', 'GT21', 'GT2,GT4', 'GT28', 'GH20', 'GT2', 'GH31', 'GH51', 'GT28', 'GT4', 'CE10', 'GH18', 'GT2,GT4', 'GT2', 'GH5,GH9', 'GT26', 'GT2', 'GT4', 'GT70', 'GT9', 'GH18', 'GH5', 'GT2', 'GT51', 'GH31', 'GH29', 'CBM42,GH54', 'GH77', 'GT2', 'GT2', 'AA10,CBM73', 'GT26', 'GT4', 'GH5,GH9', 'GT4', 'GH13', 'GH101', 'GH94,GT36', 'GH43', 'GT19', 'GT4', 'GH32', 'GT4', 'GT2,GT4', 'GT35', 'GT1', 'CE1', 'GT4', 'GH13', 'GH105', 'GT51', 'GH31', 'GT2,GT4', 'GH65', 'GT51', 'GT2', 'GH23', 'CE1', 'GH5,GH9', 'GH3', 'GH103', 'GT2,GT4', 'GH102', 'GH88', 'GH32', 'GT4', 'GT2', 'GH31', 'GH23', 'GT4', 'GT1', 'GH3', 'GT4', 'GH18,GH5,GH9', 'GH23', 'GH5,GH9', 'GH5', 'GH23', 'GT28', 'GH103', 'CE10', 'GT28', 'GT51', 'GT21', 'CBM20,GH13', 'GH5,GH9', 'GT2', 'GT51', 'GT2', 'GH23', 'GT51', 'GH65', 'GH31', 'GH103', 'CE10', 'GT2,GT4', 'GH3', 'GH32', 'GT4', 'GT2', 'GT87', 'GH5,GH9', 'GH13', 'GT2', 'GH31', 'GT19', 'GT30', 'GH16', 'GT51', 'GT85', 'GH51', 'GT4', 'GH43,GH51', 'GT2', 'GT2', 'GT26', 'GT51', 'GH3', 'GH18', 'GH32', 'GH3', 'GH103', 'GT2', 'GT5', 'GT19', 'GT2', 'GH13', 'GH5,GH8,GH9', 'GH13,GH77', 'GH13', 'GT2,GT4', 'GH5,GH9', 'GT5', 'CE10', 'GT2,GT4', 'GH13,GH77', 'GT4', 'GH23', 'GH18,GH5,GH9', 'GT28', 'GH43', 'GH13', 'GT2,GT4', 'GT21', 'GH20', 'GH130', 'GH105', 'GH29', 'GT4', 'GH3', 'GH18', 'GT30', 'CBM48,GH13', 'GH5,GH9', 'GH23', 'GT28', 'GH51', 'GT4', 'GT2', 'GH19', 'GH68', 'GT2,GT4', 'GT4', 'GH95', 'GH31', 'AA10,CBM73,GH5,GH9', 'GT5', 'CBM48,GH13', 'GT2', 'GT70', 'GH3', 'GH13', 'AA10,CBM73', 'GH5,GH9', 'GH13', 'GH3', 'GT2,GT4', 'GT2', 'GT2,GT4', 'GH32', 'GH8', 'GH13', 'GH13', 'GH43,GH51', 'GT4', 'GT4', 'GT51', 'GH32', 'GT2', 'CE1', 'GH57', 'GH51', 'GH43', 'CBM48,GH13', 'GH32', 'GT2', 'GH29', 'GT4', 'GH29', 'GT51', 'GT4', 'GT28', 'GT51', 'GT51', 'GT51', 'GH13', 'GH105', 'GH30', 'GT30', 'GT4', 'GT2', 'GH95', 'GT4', 'GH5,GH9', 'GH30', 'GH29', 'GT2', 'GT4', 'GT2', 'GT1', 'GH3', 'GT2', 'GH13', 'CBM48,GH13', 'GH30,GH5,GH9', 'GT39', 'CBM48,GH13', 'GH103', 'GH5,GH9', 'GH32', 'GT51', 'GT35', 'GH32', 'GH102', 'GT51', 'GH3', 'GH20', 'GT26', 'GT2', 'GT2', 'CBM48,GH13', 'GH23', 'GT19', 'GT51', 'GH13', 'CBM50', 'GT1', 'GH19', 'GH8', 'GH13', 'GT87', 'GT73', 'AA10,CBM73,GH5,GH9', 'GH3', 'GT2', 'GH105', 'GH95', 'GT20', 'GH31', 'GH102', 'GH51', 'GH5,GH8,GH9', 'CBM48,GH13', 'GT2', 'GT4', 'CBM48,GH13', 'GT2', 'GT2', 'GT9', 'GH43', 'GH103', 'GH77', 'GT51', 'GT28', 'GH26', 'GH5,GH8,GH9', 'GT2', 'GH43', 'GH23', 'GT2', 'GT4', 'GT2,GT4', 'GT4', 'GT9', 'GH29', 'GH32', 'GT2,GT4', 'GH18', 'GT2', 'GT4', 'GT4', 'GH101', 'GT2', 'GT2', 'GT51', 'GH20', 'GT1', 'GT30', 'GT51', 'CBM20,GH13', 'GH105', 'GH38', 'GT2,GT4', 'GT4', 'CE10', 'GH105', 'GT2', 'GT4', 'GH43', 'GH43,GH51', 'GT4', 'GT28', 'GT2', 'GT1', 'GT2', 'GT2,GT4', 'GT51', 'GT51', 'GH19', 'GH28', 'GH77', 'GH65', 'GT2', 'GT2', 'GT4', 'GH103', 'GH31', 'GH3', 'GT51', 'GH37', 'GH32', 'CBM48,GH13', 'GH3', 'GT4', 'GH3', 'GH20', 'CE10', 'GT2', 'GT26', 'GH8', 'GT2', 'GH32,GH68', 'GH43', 'GH43', 'GH5,GH6,GH9', 'GH103', 'GT2', 'GT2', 'GH31', 'GT1', 'GH94,GT84', 'GT28', 'GH20', 'GT5', 'GH13', 'GT2', 'GH130', 'CE10', 'GT51', 'GT20', 'GH3', 'GH43', 'GT51', 'GT25', 'GH43', 'GH37', 'GH3', 'GH29', 'GH5,GH9', 'GT51', 'GH51', 'GT4', 'GT26', 'GH4,GT4', 'GH5,GH9', 'GH39', 'GT2', 'GT4', 'GH19', 'CE10', 'GH5,GH9', 'GH57', 'CE10', 'GT51', 'GH43', 'GT9', 'GT4', 'GT2,GT4', 'GH13', 'GT2', 'GT30', 'GT2', 'GT4', 'GT2', 'GH19', 'GH130', 'GH18', 'GT19', 'GH13', 'GT4', 'CE1', 'GH103', 'GH20', 'GT70', 'GT39', 'GT2', 'GH121', 'GH3', 'GH5,GH9', 'GT8', 'CBM48,GH13', 'GH37', 'GH13', 'GT30', 'GT14', 'GH3', 'GT4', 'CE10', 'GT51', 'CE10', 'GT4', 'GT51', 'GT51', 'GT4', 'GT2', 'GT28', 'GT4', 'GH103', 'GH95', 'GT2', 'GH31', 'CE1', 'GT2', 'GH5,GH9', 'GT2', 'GT26', 'GT2', 'GH5,GH8,GH9', 'GH20', 'GT51', 'GH102', 'GT51', 'CE10', 'GH20', 'GT4', 'GT4', 'GH31', 'GT2', 'GH5,GH9', 'CE10', 'GT20', 'GH3', 'GT4', 'CBM50', 'GH3', 'GH3', 'GH29', 'GT81', 'CE10', 'GH31', 'GH5,GH9', 'GT4', 'GT2', 'GH13', 'GT2', 'GT4', 'GT2', 'CE10', 'GH3', 'GH103', 'GT9', 'GH31', 'GH102', 'GT4', 'GT2', 'GH103', 'GT4', 'GT19', 'GT73', 'GT4', 'GT4', 'CBM48,GH13', 'GH13', 'GH13', 'GT5', 'GH33', 'GT25', 'GH37', 'GT2,GT4', 'CE10', 'GH5', 'GT51', 'GT2,GT4', 'GT28', 'GH29', 'GH3', 'GH3', 'GH103', 'GH3', 'CBM48,GH13', 'GT4,GT9', 'GH18', 'GH3', 'GT2', 'GT51', 'GH13', 'GT4', 'GT2', 'GH88'])\n",
      "['GT2', 'GT1', 'GH65', 'GH38', 'GT28', 'GH23', 'GH51', 'GT39', 'GT73', 'GT9', 'GH18', 'GH5', 'GH9', 'GH47', 'GT19', 'CE1', 'GH121', 'GH101', 'GH77', 'GH43', 'GH32', 'GH68', 'CE10', 'GH88', 'PL8', 'PL11', 'GT35', 'GT20', 'GH13', 'GH30', 'GT89', 'GT4', 'GH102', 'GT85', 'GH103', 'CBM20', 'GT30', 'GT56', 'GH94', 'GT36', 'GT25', 'GH37', 'CBM42', 'GH54', 'GT70', 'GT21', 'GT87', 'GH57', 'GH26', 'GT14', 'GT8', 'GH130', 'AA10', 'CBM73', 'GH29', 'GH33', 'GH20', 'CBM50', 'GH39', 'GH95', 'GH31', 'GT5', 'GH15', 'GT26', 'GH8', 'GH4', 'GT81', 'GH28', 'GH3', 'GT84', 'PL4', 'CBM48', 'GH16', 'GH19', 'GT51', 'GH6', 'GH105']\n",
      "          GT2  GT1  GH65  GH38  GT28  GH23  GH51  GT39  GT73  GT9  ...  GH28   \n",
      "enriched    3    0     0     0     3     1     2     1     0    0  ...     0  \\\n",
      "neutral    86    8     3     1    13    10     8     2     2    6  ...     1   \n",
      "\n",
      "          GH3  GT84  PL4  CBM48  GH16  GH19  GT51  GH6  GH105  \n",
      "enriched    3     0    0      1     0     0     5    0      0  \n",
      "neutral    27     1    1     12     1     5    33    1      6  \n",
      "\n",
      "[2 rows x 77 columns]\n",
      "GT2 3 86\n",
      "GT28 3 13\n",
      "GH23 1 10\n",
      "GH51 2 8\n",
      "GT39 1 2\n",
      "GH5 1 33\n",
      "GH9 1 30\n",
      "CE1 1 5\n",
      "GH43 2 14\n",
      "GH32 1 11\n",
      "GH68 1 1\n",
      "CE10 3 13\n",
      "GT35 1 1\n",
      "GT20 1 2\n",
      "GH13 2 38\n",
      "GT4 2 86\n",
      "GH102 1 5\n",
      "GH31 1 17\n",
      "GT5 1 4\n",
      "GT26 1 8\n",
      "GH3 3 27\n",
      "CBM48 1 12\n",
      "GT51 5 33\n",
      "enriched     39\n",
      "neutral     634\n",
      "dtype: int64\n",
      "2133 153 37060 0.05755531570426336 0.004128440366972477\n",
      "               GT2       GT1      GH65      GH38      GT28      GH23   \n",
      "enriched  0.076923  0.000000  0.000000  0.000000  0.076923  0.025641  \\\n",
      "neutral   0.135647  0.012618  0.004732  0.001577  0.020505  0.015773   \n",
      "\n",
      "              GH51      GT39      GT73       GT9  ...      GH28       GH3   \n",
      "enriched  0.051282  0.025641  0.000000  0.000000  ...  0.000000  0.076923  \\\n",
      "neutral   0.012618  0.003155  0.003155  0.009464  ...  0.001577  0.042587   \n",
      "\n",
      "              GT84       PL4     CBM48      GH16      GH19      GT51   \n",
      "enriched  0.000000  0.000000  0.025641  0.000000  0.000000  0.128205  \\\n",
      "neutral   0.001577  0.001577  0.018927  0.001577  0.007886  0.052050   \n",
      "\n",
      "               GH6     GH105  \n",
      "enriched  0.000000  0.000000  \n",
      "neutral   0.001577  0.009464  \n",
      "\n",
      "[2 rows x 77 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2769852/3294934617.py:61: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make table where you count the cazyme for gc in combined_sphingo_enriched, combined_sphingo_depleted, and all GCs minus the combined_sphingo_enriched and combined_sphingo_depleted\n",
    "\n",
    "annotation_dict_CAZy_reformat_keys = annotation_dict_CAZy_reformat.keys()\n",
    "print (annotation_dict_CAZy_reformat_keys)\n",
    "print (annotation_dict_CAZy_reformat.values())\n",
    "cazymes_in_db = list(set(annotation_dict_CAZy_reformat.values()))\n",
    "cazyme_list = []\n",
    "for cazyme in cazymes_in_db:\n",
    "    if len(cazyme.split(','))>1:\n",
    "        for caz in cazyme.split(','):\n",
    "            if caz not in cazyme_list:\n",
    "                cazyme_list.append(caz)\n",
    "    elif cazyme not in cazyme_list:\n",
    "        cazyme_list.append(cazyme)\n",
    "\n",
    "print (cazyme_list)\n",
    "\n",
    "cazyme_table = pd.DataFrame(0, index=['enriched', 'neutral'], columns=cazyme_list)\n",
    "\n",
    "for gc in gene_cluster_presence_absence.columns:\n",
    "    if gc in annotation_dict_CAZy_reformat_keys:\n",
    "        cazyme = annotation_dict_CAZy_reformat[gc]\n",
    "        if gc in combined_sphingo_enriched:\n",
    "            if len(cazyme.split(',')) == 1:\n",
    "                cazyme_table.loc['enriched', cazyme] += 1\n",
    "            else:\n",
    "                for caz in cazyme.split(','):\n",
    "                    cazyme_table.loc['enriched', caz] += 1\n",
    "        #elif gc in combined_sphingo_depleted:\n",
    "        #    if len(cazyme.split(',')) == 1:\n",
    "        #        cazyme_table.loc['depleted', cazyme] += 1\n",
    "        #    else:\n",
    "        #        for caz in cazyme.split(','):\n",
    "        #            cazyme_table.loc['depleted', caz] += 1\n",
    "        elif gc not in combined_sphingo_depleted:\n",
    "            if len(cazyme.split(',')) == 1:\n",
    "                cazyme_table.loc['neutral', cazyme] += 1\n",
    "            else:\n",
    "                for caz in cazyme.split(','):\n",
    "                    cazyme_table.loc['neutral', caz] += 1\n",
    "\n",
    "print (cazyme_table)\n",
    "for cazyme in cazyme_table.columns:\n",
    "    if cazyme_table.loc['enriched', cazyme] != 0:\n",
    "        print (cazyme, cazyme_table.loc['enriched', cazyme], cazyme_table.loc['neutral', cazyme])\n",
    "print (cazyme_table.sum(axis=1))\n",
    "print (len(combined_sphingo_enriched), len(combined_sphingo_depleted), len(gene_cluster_presence_absence.columns), len(combined_sphingo_enriched)/len(gene_cluster_presence_absence.columns), len(combined_sphingo_depleted)/len(gene_cluster_presence_absence.columns))\n",
    "\n",
    "#make 3 stacked barplots for each CAZy category, one for enriched, one for depleted, one for neutral with the relative abundance of the CAZy category.\n",
    "\n",
    "cazyme_table.loc['enriched'] = cazyme_table.loc['enriched']/cazyme_table.loc['enriched'].sum()\n",
    "#cazyme_table.loc['depleted'] = cazyme_table.loc['depleted']/cazyme_table.loc['depleted'].sum()\n",
    "cazyme_table.loc['neutral'] = cazyme_table.loc['neutral']/cazyme_table.loc['neutral'].sum()\n",
    "\n",
    "print (cazyme_table)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cazyme_table.plot.bar(stacked=True, ax=ax)\n",
    "ax.set_title(\"CAZy categories\")\n",
    "ax.set_ylabel(\"Relative abundance\")\n",
    "fig.tight_layout()\n",
    "#remove the legend\n",
    "ax.legend().remove()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT2 0.0769 0.1356 0.5671\n",
      "GT1 0.0 0.0126 0.0\n",
      "GH65 0.0 0.0047 0.0\n",
      "GH38 0.0 0.0016 0.0\n",
      "GT28 0.0769 0.0205 3.7515\n",
      "GH23 0.0256 0.0158 1.6256\n",
      "GH51 0.0513 0.0126 4.0641\n",
      "GT39 0.0256 0.0032 8.1282\n",
      "GT73 0.0 0.0032 0.0\n",
      "GT9 0.0 0.0095 0.0\n",
      "GH18 0.0 0.0158 0.0\n",
      "GH5 0.0256 0.0521 0.4926\n",
      "GH9 0.0256 0.0473 0.5419\n",
      "GH47 0.0 0.0016 0.0\n",
      "GT19 0.0 0.0095 0.0\n",
      "CE1 0.0256 0.0079 3.2513\n",
      "GH121 0.0 0.0016 0.0\n",
      "GH101 0.0 0.0047 0.0\n",
      "GH77 0.0 0.0095 0.0\n",
      "GH43 0.0513 0.0221 2.3223\n",
      "GH32 0.0256 0.0174 1.4779\n",
      "GH68 0.0256 0.0016 16.2564\n",
      "CE10 0.0769 0.0205 3.7515\n",
      "GH88 0.0 0.0032 0.0\n",
      "PL8 0.0 0.0016 0.0\n",
      "PL11 0.0 0.0016 0.0\n",
      "GT35 0.0256 0.0016 16.2564\n",
      "GT20 0.0256 0.0032 8.1282\n",
      "GH13 0.0513 0.0599 0.8556\n",
      "GH30 0.0 0.0047 0.0\n",
      "GT89 0.0 0.0016 0.0\n",
      "GT4 0.0513 0.1356 0.3781\n",
      "GH102 0.0256 0.0079 3.2513\n",
      "GT85 0.0 0.0016 0.0\n",
      "GH103 0.0 0.0205 0.0\n",
      "CBM20 0.0 0.0032 0.0\n",
      "GT30 0.0 0.011 0.0\n",
      "GT56 0.0 0.0016 0.0\n",
      "GH94 0.0 0.0032 0.0\n",
      "GT36 0.0 0.0016 0.0\n",
      "GT25 0.0 0.0047 0.0\n",
      "GH37 0.0 0.0063 0.0\n",
      "CBM42 0.0 0.0016 0.0\n",
      "GH54 0.0 0.0016 0.0\n",
      "GT70 0.0 0.0047 0.0\n",
      "GT21 0.0 0.0047 0.0\n",
      "GT87 0.0 0.0047 0.0\n",
      "GH57 0.0 0.0032 0.0\n",
      "GH26 0.0 0.0032 0.0\n",
      "GT14 0.0 0.0016 0.0\n",
      "GT8 0.0 0.0016 0.0\n",
      "GH130 0.0 0.0063 0.0\n",
      "AA10 0.0 0.0079 0.0\n",
      "CBM73 0.0 0.0079 0.0\n",
      "GH29 0.0 0.0158 0.0\n",
      "GH33 0.0 0.0016 0.0\n",
      "GH20 0.0 0.0142 0.0\n",
      "CBM50 0.0 0.0032 0.0\n",
      "GH39 0.0 0.0016 0.0\n",
      "GH95 0.0 0.0079 0.0\n",
      "GH31 0.0256 0.0268 0.9563\n",
      "GT5 0.0256 0.0063 4.0641\n",
      "GH15 0.0 0.0016 0.0\n",
      "GT26 0.0256 0.0126 2.0321\n",
      "GH8 0.0 0.0126 0.0\n",
      "GH4 0.0 0.0016 0.0\n",
      "GT81 0.0 0.0016 0.0\n",
      "GH28 0.0 0.0016 0.0\n",
      "GH3 0.0769 0.0426 1.8063\n",
      "GT84 0.0 0.0016 0.0\n",
      "PL4 0.0 0.0016 0.0\n",
      "CBM48 0.0256 0.0189 1.3547\n",
      "GH16 0.0 0.0016 0.0\n",
      "GH19 0.0 0.0079 0.0\n",
      "GT51 0.1282 0.0521 2.4631\n",
      "GH6 0.0 0.0016 0.0\n",
      "GH105 0.0 0.0095 0.0\n"
     ]
    }
   ],
   "source": [
    "for cazyme in cazyme_table.columns:\n",
    "    print (cazyme, round(cazyme_table.loc['enriched', cazyme], 4), round(cazyme_table.loc['neutral', cazyme], 4), round(cazyme_table.loc['enriched', cazyme]/cazyme_table.loc['neutral', cazyme], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "0.0 0.0 0.0001 0.0\n",
      "B\n",
      "0.0013 0.0 0.0003 4.7551\n",
      "C\n",
      "0.0469 0.0647 0.0416 1.1277\n",
      "D\n",
      "0.0127 0.0 0.0096 1.3209\n",
      "E\n",
      "0.0768 0.1176 0.0744 1.0312\n",
      "F\n",
      "0.0189 0.0059 0.0157 1.1978\n",
      "G\n",
      "0.0561 0.0471 0.0628 0.8938\n",
      "H\n",
      "0.0417 0.0294 0.0296 1.4086\n",
      "I\n",
      "0.0443 0.0765 0.0355 1.2487\n",
      "J\n",
      "0.0474 0.0059 0.0263 1.7982\n",
      "K\n",
      "0.0557 0.0941 0.0807 0.6906\n",
      "L\n",
      "0.0417 0.0059 0.0358 1.1637\n",
      "M\n",
      "0.0601 0.0412 0.0596 1.0081\n",
      "N\n",
      "0.0224 0.0059 0.0168 1.3296\n",
      "O\n",
      "0.0368 0.0588 0.0239 1.5428\n",
      "P\n",
      "0.0566 0.0824 0.0603 0.9384\n",
      "Q\n",
      "0.0241 0.0824 0.027 0.8932\n",
      "R\n",
      "0 0 0 nan\n",
      "S\n",
      "0.2079 0.2294 0.2235 0.9301\n",
      "T\n",
      "0.0443 0.0235 0.0469 0.9439\n",
      "U\n",
      "0.0303 0.0118 0.0231 1.3098\n",
      "V\n",
      "0.0127 0.0059 0.0118 1.0816\n",
      "W\n",
      "0.0 0.0 0.0001 0.0\n",
      "X\n",
      "0 0 0 nan\n",
      "Y\n",
      "0.0 0.0 0.0 0.0\n",
      "Z\n",
      "0.0 0.0 0.0005 0.0\n",
      "-\n",
      "0.0614 0.0118 0.0939 0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2769852/102094520.py:3: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print (round(cog_table.loc['enriched', cog], 4), round(cog_table.loc['depleted', cog], 4), round(cog_table.loc['neutral', cog], 4), round(cog_table.loc['enriched', cog]/cog_table.loc['neutral', cog], 4))\n"
     ]
    }
   ],
   "source": [
    "for cog in cog_table.columns:\n",
    "    print (cog)\n",
    "    print (round(cog_table.loc['enriched', cog], 4), round(cog_table.loc['depleted', cog], 4), round(cog_table.loc['neutral', cog], 4), round(cog_table.loc['enriched', cog]/cog_table.loc['neutral', cog], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphingo_incidence_histogram = []\n",
    "non_sphingo_incidence_histogram = []\n",
    "\n",
    "for gc in purity_df.index:\n",
    "    ps = purity_df.loc[gc, 'purity_sphingo']\n",
    "    pns = purity_df.loc[gc, 'purity_non_sphingo']\n",
    "    if ps > pns:\n",
    "        if pns > 0:\n",
    "            sphingo_incidence_histogram.append((ps/pns)*((ps+pns)/2))\n",
    "        else:\n",
    "            sphingo_incidence_histogram.append((ps/(1/len(non_sphingo_list)))*((ps+(1/len(non_sphingo_list)))/2))\n",
    "    else:\n",
    "        if ps > 0:\n",
    "            non_sphingo_incidence_histogram.append((pns/ps)*((ps+pns)/2))\n",
    "        else:\n",
    "            non_sphingo_incidence_histogram.append((pns/(1/len(sphingo_list)))*((pns+(1/len(sphingo_list)))/2))\n",
    "\n",
    "#sns.histplot(sphingo_incidence_histogram)\n",
    "#plt.show()\n",
    "\n",
    "#sns.histplot(non_sphingo_incidence_histogram)\n",
    "#plt.show()\n",
    "\n",
    "#print (sorted(sphingo_incidence_histogram, reverse=True))\n",
    "#print (sorted(non_sphingo_incidence_histogram, reverse=True))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
